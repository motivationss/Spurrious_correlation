wandb: Currently logged in as: gaotang (use `wandb login --relogin` to force relogin)
wandb: wandb version 0.12.21 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.10.8
wandb: Syncing run glamorous-sea-34
wandb: ‚≠êÔ∏è View project at https://wandb.ai/gaotang/spurious_CUB
wandb: üöÄ View run at https://wandb.ai/gaotang/spurious_CUB/runs/e3nkrqsx
wandb: Run data is saved locally in wandb/run-20220710_204033-e3nkrqsx
wandb: Run `wandb off` to turn off syncing.
Dataset: CUB
Shift type: confounder
Wandb: True
Project name: spurious
Target name: waterbird_complete95
Confounder names: ['forest2water2']
Up weight: 0
Resume: False
Minority fraction: None
Imbalance ratio: None
Fraction: 1.0
Root dir: ./cub
Reweight groups: False
Augment data: False
Val fraction: 0.1
Loss type: erm
Alpha: 0.2
Generalization adjustment: 0.0
Automatic adjustment: False
Robust step size: 0.01
Joint dro alpha: 1
Use normalized loss: False
Btl: False
Hinge: False
Model: resnet50
Train from scratch: False
N epochs: 306
Batch size: 64
Lr: 1e-05
Scheduler: False
Weight decay: 0.0
Gamma: 0.1
Minimum variational weight: 0
Seed: 0
Show progress: False
Log dir: results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs
Log every: 50
Save step: 10
Save best: False
Save last: False
Use bert params: 0
Num folds per sweep: 5
Num sweeps: 4
Q: 0.7
Metadata csv name: metadata.csv
Fold: None
Metadata path: results/CUB/CUB_sample_exp/metadata_aug.csv
Aug col: None

Reading './cub/data/waterbird_complete95_forest2water2/metadata.csv'
length of train_data:  4795
length of test_data:  5794
length of val_data:  1199
args fold:  None


WARNING: aug_col is not being used.


Training Data...
    waterbird_complete95 = 0, forest2water2 = 0: n = 3498
    waterbird_complete95 = 0, forest2water2 = 1: n = 184
    waterbird_complete95 = 1, forest2water2 = 0: n = 56
    waterbird_complete95 = 1, forest2water2 = 1: n = 1057
Validation Data...
    waterbird_complete95 = 0, forest2water2 = 0: n = 467
    waterbird_complete95 = 0, forest2water2 = 1: n = 466
    waterbird_complete95 = 1, forest2water2 = 0: n = 133
    waterbird_complete95 = 1, forest2water2 = 1: n = 133
Test Data...
    waterbird_complete95 = 0, forest2water2 = 0: n = 2255
    waterbird_complete95 = 0, forest2water2 = 1: n = 2255
    waterbird_complete95 = 1, forest2water2 = 0: n = 642
    waterbird_complete95 = 1, forest2water2 = 1: n = 642

Epoch [0]:
Training:
/home/gaotang/jtt/venv/lib/python3.6/site-packages/torch/nn/modules/module.py:795: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
Average incurred loss: 0.606  
Average sample loss: 0.606  
Average acc: 0.738  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2322]:	loss = 0.476  exp loss = 0.417  adjusted loss = 0.417  adv prob = 0.250000   acc = 0.957
  waterbird_complete95 = 0, forest2water2 = 1  [n = 129]:	loss = 0.419  exp loss = 0.373  adjusted loss = 0.373  adv prob = 0.250000   acc = 0.984
  waterbird_complete95 = 1, forest2water2 = 0  [n = 35]:	loss = 0.957  exp loss = 0.970  adjusted loss = 0.970  adv prob = 0.250000   acc = 0.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 714]:	loss = 1.046  exp loss = 1.135  adjusted loss = 1.135  adv prob = 0.250000   acc = 0.017
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_train_epoch_0.csv
logged to wandb
Average incurred loss: 0.551  
Average sample loss: 0.551  
Average acc: 0.772  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 1176]:	loss = 0.360  exp loss = 0.355  adjusted loss = 0.355  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 55]:	loss = 0.321  exp loss = 0.323  adjusted loss = 0.323  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 0  [n = 21]:	loss = 1.183  exp loss = 1.164  adjusted loss = 1.164  adv prob = 0.250000   acc = 0.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 343]:	loss = 1.207  exp loss = 1.217  adjusted loss = 1.217  adv prob = 0.250000   acc = 0.003

Validation:
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_val_epoch_0.csv
logged to wandb
Average incurred loss: 0.520  
Average sample loss: 0.517  
Average acc: 0.779  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.340  exp loss = 0.331  adjusted loss = 0.331  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.310  exp loss = 0.308  adjusted loss = 0.308  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.184  exp loss = 1.225  adjusted loss = 1.225  adv prob = 0.250000   acc = 0.008
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 1.228  exp loss = 1.237  adjusted loss = 1.237  adv prob = 0.250000   acc = 0.000
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_test_epoch_0.csv
logged to wandb
Current lr: 0.000010


Epoch [1]:
Training:
Average incurred loss: 0.527  
Average sample loss: 0.527  
Average acc: 0.769  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2334]:	loss = 0.309  exp loss = 0.296  adjusted loss = 0.296  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 126]:	loss = 0.301  exp loss = 0.320  adjusted loss = 0.320  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 0  [n = 35]:	loss = 1.246  exp loss = 1.242  adjusted loss = 1.242  adv prob = 0.250000   acc = 0.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 705]:	loss = 1.253  exp loss = 1.262  adjusted loss = 1.262  adv prob = 0.250000   acc = 0.001
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_train_epoch_1.csv
logged to wandb
Average incurred loss: 0.509  
Average sample loss: 0.509  
Average acc: 0.766  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 1164]:	loss = 0.281  exp loss = 0.279  adjusted loss = 0.279  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 58]:	loss = 0.287  exp loss = 0.279  adjusted loss = 0.279  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 0  [n = 21]:	loss = 1.299  exp loss = 1.274  adjusted loss = 1.274  adv prob = 0.250000   acc = 0.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 352]:	loss = 1.253  exp loss = 1.253  adjusted loss = 1.253  adv prob = 0.250000   acc = 0.000

Validation:
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_val_epoch_1.csv
logged to wandb
Average incurred loss: 0.503  
Average sample loss: 0.500  
Average acc: 0.778  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.281  exp loss = 0.273  adjusted loss = 0.273  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.288  exp loss = 0.285  adjusted loss = 0.285  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.293  exp loss = 1.339  adjusted loss = 1.339  adv prob = 0.250000   acc = 0.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 1.245  exp loss = 1.259  adjusted loss = 1.259  adv prob = 0.250000   acc = 0.000
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_test_epoch_1.csv
logged to wandb
Current lr: 0.000010


Epoch [2]:
Training:
Average incurred loss: 0.490  
Average sample loss: 0.490  
Average acc: 0.765  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2312]:	loss = 0.272  exp loss = 0.266  adjusted loss = 0.266  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 136]:	loss = 0.299  exp loss = 0.300  adjusted loss = 0.300  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 0  [n = 34]:	loss = 1.260  exp loss = 1.285  adjusted loss = 1.285  adv prob = 0.250000   acc = 0.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 718]:	loss = 1.194  exp loss = 1.167  adjusted loss = 1.167  adv prob = 0.250000   acc = 0.001
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_train_epoch_2.csv
logged to wandb
Average incurred loss: 0.467  
Average sample loss: 0.467  
Average acc: 0.774  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 1186]:	loss = 0.260  exp loss = 0.259  adjusted loss = 0.259  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 48]:	loss = 0.293  exp loss = 0.287  adjusted loss = 0.287  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 0  [n = 22]:	loss = 1.314  exp loss = 1.304  adjusted loss = 1.304  adv prob = 0.250000   acc = 0.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 339]:	loss = 1.161  exp loss = 1.160  adjusted loss = 1.160  adv prob = 0.250000   acc = 0.000

Validation:
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_val_epoch_2.csv
logged to wandb
Average incurred loss: 0.494  
Average sample loss: 0.490  
Average acc: 0.778  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.261  exp loss = 0.253  adjusted loss = 0.253  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.300  exp loss = 0.296  adjusted loss = 0.296  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.308  exp loss = 1.355  adjusted loss = 1.355  adv prob = 0.250000   acc = 0.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 1.176  exp loss = 1.192  adjusted loss = 1.192  adv prob = 0.250000   acc = 0.000
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_test_epoch_2.csv
logged to wandb
Current lr: 0.000010


Epoch [3]:
Training:
Average incurred loss: 0.450  
Average sample loss: 0.450  
Average acc: 0.773  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2344]:	loss = 0.243  exp loss = 0.235  adjusted loss = 0.235  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 127]:	loss = 0.297  exp loss = 0.291  adjusted loss = 0.291  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 0  [n = 40]:	loss = 1.333  exp loss = 1.344  adjusted loss = 1.344  adv prob = 0.250000   acc = 0.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 689]:	loss = 1.133  exp loss = 1.129  adjusted loss = 1.129  adv prob = 0.250000   acc = 0.001
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_train_epoch_3.csv
logged to wandb
Average incurred loss: 0.448  
Average sample loss: 0.448  
Average acc: 0.761  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 1154]:	loss = 0.236  exp loss = 0.236  adjusted loss = 0.236  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 57]:	loss = 0.300  exp loss = 0.314  adjusted loss = 0.314  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 0  [n = 16]:	loss = 1.257  exp loss = 1.274  adjusted loss = 1.274  adv prob = 0.250000   acc = 0.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 368]:	loss = 1.102  exp loss = 1.096  adjusted loss = 1.096  adv prob = 0.250000   acc = 0.008

Validation:
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_val_epoch_3.csv
logged to wandb
Average incurred loss: 0.487  
Average sample loss: 0.484  
Average acc: 0.778  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.247  exp loss = 0.239  adjusted loss = 0.239  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.319  exp loss = 0.314  adjusted loss = 0.314  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.309  exp loss = 1.359  adjusted loss = 1.359  adv prob = 0.250000   acc = 0.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 1.096  exp loss = 1.113  adjusted loss = 1.113  adv prob = 0.250000   acc = 0.000
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_test_epoch_3.csv
logged to wandb
Current lr: 0.000010


Epoch [4]:
Training:
Average incurred loss: 0.424  
Average sample loss: 0.424  
Average acc: 0.773  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2334]:	loss = 0.236  exp loss = 0.235  adjusted loss = 0.235  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 116]:	loss = 0.311  exp loss = 0.314  adjusted loss = 0.314  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 0  [n = 39]:	loss = 1.265  exp loss = 1.273  adjusted loss = 1.273  adv prob = 0.250000   acc = 0.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 711]:	loss = 1.014  exp loss = 0.989  adjusted loss = 0.989  adv prob = 0.250000   acc = 0.035
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_train_epoch_4.csv
logged to wandb
Average incurred loss: 0.412  
Average sample loss: 0.412  
Average acc: 0.783  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 1164]:	loss = 0.227  exp loss = 0.226  adjusted loss = 0.226  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 68]:	loss = 0.349  exp loss = 0.364  adjusted loss = 0.364  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 0  [n = 17]:	loss = 1.281  exp loss = 1.303  adjusted loss = 1.303  adv prob = 0.250000   acc = 0.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 346]:	loss = 1.003  exp loss = 0.996  adjusted loss = 0.996  adv prob = 0.250000   acc = 0.049

Validation:
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_val_epoch_4.csv
logged to wandb
Average incurred loss: 0.481  
Average sample loss: 0.478  
Average acc: 0.776  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.235  exp loss = 0.226  adjusted loss = 0.226  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.340  exp loss = 0.334  adjusted loss = 0.334  adv prob = 0.250000   acc = 0.994
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.305  exp loss = 1.355  adjusted loss = 1.355  adv prob = 0.250000   acc = 0.008
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 1.017  exp loss = 1.035  adjusted loss = 1.035  adv prob = 0.250000   acc = 0.000
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_test_epoch_4.csv
logged to wandb
Current lr: 0.000010


Epoch [5]:
Training:
Average incurred loss: 0.391  
Average sample loss: 0.391  
Average acc: 0.792  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2359]:	loss = 0.217  exp loss = 0.210  adjusted loss = 0.210  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 120]:	loss = 0.330  exp loss = 0.319  adjusted loss = 0.319  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 0  [n = 38]:	loss = 1.260  exp loss = 1.293  adjusted loss = 1.293  adv prob = 0.250000   acc = 0.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 683]:	loss = 0.956  exp loss = 0.944  adjusted loss = 0.944  adv prob = 0.250000   acc = 0.079
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_train_epoch_5.csv
logged to wandb
Average incurred loss: 0.400  
Average sample loss: 0.400  
Average acc: 0.787  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 1139]:	loss = 0.208  exp loss = 0.208  adjusted loss = 0.208  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 64]:	loss = 0.329  exp loss = 0.340  adjusted loss = 0.340  adv prob = 0.250000   acc = 0.984
  waterbird_complete95 = 1, forest2water2 = 0  [n = 18]:	loss = 1.299  exp loss = 1.314  adjusted loss = 1.314  adv prob = 0.250000   acc = 0.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 374]:	loss = 0.953  exp loss = 0.946  adjusted loss = 0.946  adv prob = 0.250000   acc = 0.142

Validation:
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_val_epoch_5.csv
logged to wandb
Average incurred loss: 0.476  
Average sample loss: 0.472  
Average acc: 0.784  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.220  exp loss = 0.211  adjusted loss = 0.211  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.350  exp loss = 0.344  adjusted loss = 0.344  adv prob = 0.250000   acc = 0.991
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.322  exp loss = 1.377  adjusted loss = 1.377  adv prob = 0.250000   acc = 0.015
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.969  exp loss = 0.988  adjusted loss = 0.988  adv prob = 0.250000   acc = 0.068
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_test_epoch_5.csv
logged to wandb
Current lr: 0.000010


Epoch [6]:
Training:
Average incurred loss: 0.374  
Average sample loss: 0.374  
Average acc: 0.813  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2348]:	loss = 0.209  exp loss = 0.205  adjusted loss = 0.205  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 115]:	loss = 0.352  exp loss = 0.352  adjusted loss = 0.352  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 0  [n = 38]:	loss = 1.210  exp loss = 1.184  adjusted loss = 1.184  adv prob = 0.250000   acc = 0.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 699]:	loss = 0.887  exp loss = 0.850  adjusted loss = 0.850  adv prob = 0.250000   acc = 0.197
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_train_epoch_6.csv
logged to wandb
Average incurred loss: 0.370  
Average sample loss: 0.370  
Average acc: 0.828  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 1150]:	loss = 0.201  exp loss = 0.197  adjusted loss = 0.197  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 69]:	loss = 0.363  exp loss = 0.348  adjusted loss = 0.348  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 0  [n = 18]:	loss = 1.304  exp loss = 1.329  adjusted loss = 1.329  adv prob = 0.250000   acc = 0.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 358]:	loss = 0.867  exp loss = 0.855  adjusted loss = 0.855  adv prob = 0.250000   acc = 0.285

Validation:
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_val_epoch_6.csv
logged to wandb
Average incurred loss: 0.471  
Average sample loss: 0.468  
Average acc: 0.792  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.204  exp loss = 0.196  adjusted loss = 0.196  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.357  exp loss = 0.350  adjusted loss = 0.350  adv prob = 0.250000   acc = 0.987
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.347  exp loss = 1.404  adjusted loss = 1.404  adv prob = 0.250000   acc = 0.015
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.932  exp loss = 0.954  adjusted loss = 0.954  adv prob = 0.250000   acc = 0.158
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_test_epoch_6.csv
logged to wandb
Current lr: 0.000010


Epoch [7]:
Training:
Average incurred loss: 0.349  
Average sample loss: 0.349  
Average acc: 0.845  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2346]:	loss = 0.195  exp loss = 0.197  adjusted loss = 0.197  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 123]:	loss = 0.370  exp loss = 0.372  adjusted loss = 0.372  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 0  [n = 29]:	loss = 1.204  exp loss = 1.222  adjusted loss = 1.222  adv prob = 0.250000   acc = 0.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 702]:	loss = 0.824  exp loss = 0.806  adjusted loss = 0.806  adv prob = 0.250000   acc = 0.333
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_train_epoch_7.csv
logged to wandb
Average incurred loss: 0.355  
Average sample loss: 0.355  
Average acc: 0.833  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 1152]:	loss = 0.190  exp loss = 0.188  adjusted loss = 0.188  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 61]:	loss = 0.357  exp loss = 0.339  adjusted loss = 0.339  adv prob = 0.250000   acc = 0.967
  waterbird_complete95 = 1, forest2water2 = 0  [n = 27]:	loss = 1.263  exp loss = 1.256  adjusted loss = 1.256  adv prob = 0.250000   acc = 0.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 355]:	loss = 0.822  exp loss = 0.814  adjusted loss = 0.814  adv prob = 0.250000   acc = 0.330

Validation:
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_val_epoch_7.csv
logged to wandb
Average incurred loss: 0.470  
Average sample loss: 0.466  
Average acc: 0.800  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.198  exp loss = 0.190  adjusted loss = 0.190  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.381  exp loss = 0.373  adjusted loss = 0.373  adv prob = 0.250000   acc = 0.979
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.337  exp loss = 1.394  adjusted loss = 1.394  adv prob = 0.250000   acc = 0.023
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.868  exp loss = 0.891  adjusted loss = 0.891  adv prob = 0.250000   acc = 0.248
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_test_epoch_7.csv
logged to wandb
Current lr: 0.000010


Epoch [8]:
Training:
Average incurred loss: 0.327  
Average sample loss: 0.327  
Average acc: 0.874  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2371]:	loss = 0.186  exp loss = 0.178  adjusted loss = 0.178  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 117]:	loss = 0.382  exp loss = 0.388  adjusted loss = 0.388  adv prob = 0.250000   acc = 0.983
  waterbird_complete95 = 1, forest2water2 = 0  [n = 35]:	loss = 1.234  exp loss = 1.224  adjusted loss = 1.224  adv prob = 0.250000   acc = 0.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 677]:	loss = 0.764  exp loss = 0.743  adjusted loss = 0.743  adv prob = 0.250000   acc = 0.459
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_train_epoch_8.csv
logged to wandb
Average incurred loss: 0.343  
Average sample loss: 0.343  
Average acc: 0.842  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 1127]:	loss = 0.175  exp loss = 0.177  adjusted loss = 0.177  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 67]:	loss = 0.355  exp loss = 0.346  adjusted loss = 0.346  adv prob = 0.250000   acc = 0.970
  waterbird_complete95 = 1, forest2water2 = 0  [n = 21]:	loss = 1.283  exp loss = 1.258  adjusted loss = 1.258  adv prob = 0.250000   acc = 0.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 380]:	loss = 0.788  exp loss = 0.779  adjusted loss = 0.779  adv prob = 0.250000   acc = 0.397

Validation:
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_val_epoch_8.csv
logged to wandb
Average incurred loss: 0.467  
Average sample loss: 0.464  
Average acc: 0.807  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.187  exp loss = 0.179  adjusted loss = 0.179  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.392  exp loss = 0.383  adjusted loss = 0.383  adv prob = 0.250000   acc = 0.966
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.353  exp loss = 1.412  adjusted loss = 1.412  adv prob = 0.250000   acc = 0.030
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.830  exp loss = 0.854  adjusted loss = 0.854  adv prob = 0.250000   acc = 0.346
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_test_epoch_8.csv
logged to wandb
Current lr: 0.000010


Epoch [9]:
Training:
Average incurred loss: 0.314  
Average sample loss: 0.314  
Average acc: 0.887  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2348]:	loss = 0.176  exp loss = 0.169  adjusted loss = 0.169  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 124]:	loss = 0.391  exp loss = 0.320  adjusted loss = 0.320  adv prob = 0.250000   acc = 0.968
  waterbird_complete95 = 1, forest2water2 = 0  [n = 39]:	loss = 1.168  exp loss = 1.199  adjusted loss = 1.199  adv prob = 0.250000   acc = 0.026
  waterbird_complete95 = 1, forest2water2 = 1  [n = 689]:	loss = 0.723  exp loss = 0.732  adjusted loss = 0.732  adv prob = 0.250000   acc = 0.537
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_train_epoch_9.csv
logged to wandb
Average incurred loss: 0.313  
Average sample loss: 0.313  
Average acc: 0.883  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 1150]:	loss = 0.169  exp loss = 0.169  adjusted loss = 0.169  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 60]:	loss = 0.369  exp loss = 0.360  adjusted loss = 0.360  adv prob = 0.250000   acc = 0.950
  waterbird_complete95 = 1, forest2water2 = 0  [n = 17]:	loss = 1.315  exp loss = 1.338  adjusted loss = 1.338  adv prob = 0.250000   acc = 0.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 368]:	loss = 0.709  exp loss = 0.700  adjusted loss = 0.700  adv prob = 0.250000   acc = 0.549

Validation:
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_val_epoch_9.csv
logged to wandb
Average incurred loss: 0.468  
Average sample loss: 0.465  
Average acc: 0.806  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.182  exp loss = 0.174  adjusted loss = 0.174  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.415  exp loss = 0.405  adjusted loss = 0.405  adv prob = 0.250000   acc = 0.946
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.345  exp loss = 1.404  adjusted loss = 1.404  adv prob = 0.250000   acc = 0.030
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.781  exp loss = 0.804  adjusted loss = 0.804  adv prob = 0.250000   acc = 0.406
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_test_epoch_9.csv
logged to wandb
Current lr: 0.000010


Epoch [10]:
Training:
Average incurred loss: 0.304  
Average sample loss: 0.304  
Average acc: 0.898  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2314]:	loss = 0.168  exp loss = 0.167  adjusted loss = 0.167  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 132]:	loss = 0.396  exp loss = 0.427  adjusted loss = 0.427  adv prob = 0.250000   acc = 0.955
  waterbird_complete95 = 1, forest2water2 = 0  [n = 40]:	loss = 1.197  exp loss = 1.140  adjusted loss = 1.140  adv prob = 0.250000   acc = 0.050
  waterbird_complete95 = 1, forest2water2 = 1  [n = 714]:	loss = 0.679  exp loss = 0.640  adjusted loss = 0.640  adv prob = 0.250000   acc = 0.605
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_train_epoch_10.csv
logged to wandb
Average incurred loss: 0.289  
Average sample loss: 0.289  
Average acc: 0.911  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 1184]:	loss = 0.167  exp loss = 0.165  adjusted loss = 0.165  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 52]:	loss = 0.406  exp loss = 0.421  adjusted loss = 0.421  adv prob = 0.250000   acc = 0.942
  waterbird_complete95 = 1, forest2water2 = 0  [n = 16]:	loss = 1.191  exp loss = 1.171  adjusted loss = 1.171  adv prob = 0.250000   acc = 0.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 343]:	loss = 0.648  exp loss = 0.643  adjusted loss = 0.643  adv prob = 0.250000   acc = 0.641

Validation:
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_val_epoch_10.csv
logged to wandb
Average incurred loss: 0.471  
Average sample loss: 0.468  
Average acc: 0.799  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.178  exp loss = 0.170  adjusted loss = 0.170  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.443  exp loss = 0.432  adjusted loss = 0.432  adv prob = 0.250000   acc = 0.901
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.336  exp loss = 1.393  adjusted loss = 1.393  adv prob = 0.250000   acc = 0.038
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.729  exp loss = 0.752  adjusted loss = 0.752  adv prob = 0.250000   acc = 0.496
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_test_epoch_10.csv
logged to wandb
Current lr: 0.000010


Epoch [11]:
Training:
Average incurred loss: 0.284  
Average sample loss: 0.284  
Average acc: 0.916  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2363]:	loss = 0.160  exp loss = 0.156  adjusted loss = 0.156  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 117]:	loss = 0.426  exp loss = 0.466  adjusted loss = 0.466  adv prob = 0.250000   acc = 0.923
  waterbird_complete95 = 1, forest2water2 = 0  [n = 37]:	loss = 1.195  exp loss = 1.227  adjusted loss = 1.227  adv prob = 0.250000   acc = 0.027
  waterbird_complete95 = 1, forest2water2 = 1  [n = 683]:	loss = 0.642  exp loss = 0.626  adjusted loss = 0.626  adv prob = 0.250000   acc = 0.673
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_train_epoch_11.csv
logged to wandb
Average incurred loss: 0.288  
Average sample loss: 0.288  
Average acc: 0.900  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 1135]:	loss = 0.148  exp loss = 0.147  adjusted loss = 0.147  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 67]:	loss = 0.369  exp loss = 0.372  adjusted loss = 0.372  adv prob = 0.250000   acc = 0.985
  waterbird_complete95 = 1, forest2water2 = 0  [n = 19]:	loss = 1.240  exp loss = 1.208  adjusted loss = 1.208  adv prob = 0.250000   acc = 0.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 374]:	loss = 0.651  exp loss = 0.636  adjusted loss = 0.636  adv prob = 0.250000   acc = 0.626

Validation:
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_val_epoch_11.csv
logged to wandb
Average incurred loss: 0.465  
Average sample loss: 0.462  
Average acc: 0.802  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.158  exp loss = 0.151  adjusted loss = 0.151  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.423  exp loss = 0.412  adjusted loss = 0.412  adv prob = 0.250000   acc = 0.914
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.411  exp loss = 1.479  adjusted loss = 1.479  adv prob = 0.250000   acc = 0.038
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.744  exp loss = 0.770  adjusted loss = 0.770  adv prob = 0.250000   acc = 0.481
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_test_epoch_11.csv
logged to wandb
Current lr: 0.000010


Epoch [12]:
Training:
Average incurred loss: 0.278  
Average sample loss: 0.278  
Average acc: 0.916  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2318]:	loss = 0.151  exp loss = 0.150  adjusted loss = 0.150  adv prob = 0.250000   acc = 0.999
  waterbird_complete95 = 0, forest2water2 = 1  [n = 130]:	loss = 0.408  exp loss = 0.408  adjusted loss = 0.408  adv prob = 0.250000   acc = 0.946
  waterbird_complete95 = 1, forest2water2 = 0  [n = 40]:	loss = 1.141  exp loss = 1.190  adjusted loss = 1.190  adv prob = 0.250000   acc = 0.025
  waterbird_complete95 = 1, forest2water2 = 1  [n = 712]:	loss = 0.619  exp loss = 0.580  adjusted loss = 0.580  adv prob = 0.250000   acc = 0.691
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_train_epoch_12.csv
logged to wandb
Average incurred loss: 0.269  
Average sample loss: 0.269  
Average acc: 0.928  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 1180]:	loss = 0.151  exp loss = 0.150  adjusted loss = 0.150  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 54]:	loss = 0.464  exp loss = 0.397  adjusted loss = 0.397  adv prob = 0.250000   acc = 0.833
  waterbird_complete95 = 1, forest2water2 = 0  [n = 16]:	loss = 1.429  exp loss = 1.402  adjusted loss = 1.402  adv prob = 0.250000   acc = 0.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 345]:	loss = 0.590  exp loss = 0.570  adjusted loss = 0.570  adv prob = 0.250000   acc = 0.739

Validation:
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_val_epoch_12.csv
logged to wandb
Average incurred loss: 0.469  
Average sample loss: 0.466  
Average acc: 0.795  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.161  exp loss = 0.154  adjusted loss = 0.154  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.462  exp loss = 0.449  adjusted loss = 0.449  adv prob = 0.250000   acc = 0.858
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.362  exp loss = 1.424  adjusted loss = 1.424  adv prob = 0.250000   acc = 0.045
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.677  exp loss = 0.702  adjusted loss = 0.702  adv prob = 0.250000   acc = 0.602
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_test_epoch_12.csv
logged to wandb
Current lr: 0.000010


Epoch [13]:
Training:
Average incurred loss: 0.264  
Average sample loss: 0.264  
Average acc: 0.926  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2324]:	loss = 0.143  exp loss = 0.142  adjusted loss = 0.142  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 130]:	loss = 0.432  exp loss = 0.416  adjusted loss = 0.416  adv prob = 0.250000   acc = 0.923
  waterbird_complete95 = 1, forest2water2 = 0  [n = 37]:	loss = 1.163  exp loss = 1.201  adjusted loss = 1.201  adv prob = 0.250000   acc = 0.054
  waterbird_complete95 = 1, forest2water2 = 1  [n = 709]:	loss = 0.585  exp loss = 0.553  adjusted loss = 0.553  adv prob = 0.250000   acc = 0.729
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_train_epoch_13.csv
logged to wandb
Average incurred loss: 0.253  
Average sample loss: 0.253  
Average acc: 0.936  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 1174]:	loss = 0.142  exp loss = 0.141  adjusted loss = 0.141  adv prob = 0.250000   acc = 0.998
  waterbird_complete95 = 0, forest2water2 = 1  [n = 54]:	loss = 0.399  exp loss = 0.416  adjusted loss = 0.416  adv prob = 0.250000   acc = 0.944
  waterbird_complete95 = 1, forest2water2 = 0  [n = 19]:	loss = 1.197  exp loss = 1.196  adjusted loss = 1.196  adv prob = 0.250000   acc = 0.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 348]:	loss = 0.551  exp loss = 0.542  adjusted loss = 0.542  adv prob = 0.250000   acc = 0.776

Validation:
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_val_epoch_13.csv
logged to wandb
Average incurred loss: 0.470  
Average sample loss: 0.467  
Average acc: 0.788  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.154  exp loss = 0.146  adjusted loss = 0.146  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.472  exp loss = 0.459  adjusted loss = 0.459  adv prob = 0.250000   acc = 0.830
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.385  exp loss = 1.450  adjusted loss = 1.450  adv prob = 0.250000   acc = 0.045
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.658  exp loss = 0.684  adjusted loss = 0.684  adv prob = 0.250000   acc = 0.639
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_test_epoch_13.csv
logged to wandb
Current lr: 0.000010


Epoch [14]:
Training:
Average incurred loss: 0.254  
Average sample loss: 0.254  
Average acc: 0.933  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2318]:	loss = 0.137  exp loss = 0.140  adjusted loss = 0.140  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 124]:	loss = 0.422  exp loss = 0.438  adjusted loss = 0.438  adv prob = 0.250000   acc = 0.903
  waterbird_complete95 = 1, forest2water2 = 0  [n = 29]:	loss = 1.206  exp loss = 1.159  adjusted loss = 1.159  adv prob = 0.250000   acc = 0.069
  waterbird_complete95 = 1, forest2water2 = 1  [n = 729]:	loss = 0.560  exp loss = 0.520  adjusted loss = 0.520  adv prob = 0.250000   acc = 0.757
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_train_epoch_14.csv
logged to wandb
Average incurred loss: 0.247  
Average sample loss: 0.247  
Average acc: 0.937  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 1180]:	loss = 0.136  exp loss = 0.130  adjusted loss = 0.130  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 60]:	loss = 0.460  exp loss = 0.467  adjusted loss = 0.467  adv prob = 0.250000   acc = 0.867
  waterbird_complete95 = 1, forest2water2 = 0  [n = 27]:	loss = 1.231  exp loss = 1.226  adjusted loss = 1.226  adv prob = 0.250000   acc = 0.074
  waterbird_complete95 = 1, forest2water2 = 1  [n = 328]:	loss = 0.528  exp loss = 0.534  adjusted loss = 0.534  adv prob = 0.250000   acc = 0.796

Validation:
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_val_epoch_14.csv
logged to wandb
Average incurred loss: 0.468  
Average sample loss: 0.465  
Average acc: 0.788  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.142  exp loss = 0.134  adjusted loss = 0.134  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.470  exp loss = 0.456  adjusted loss = 0.456  adv prob = 0.250000   acc = 0.824
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.426  exp loss = 1.494  adjusted loss = 1.494  adv prob = 0.250000   acc = 0.045
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.649  exp loss = 0.676  adjusted loss = 0.676  adv prob = 0.250000   acc = 0.662
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_test_epoch_14.csv
logged to wandb
Current lr: 0.000010


Epoch [15]:
Training:
Average incurred loss: 0.241  
Average sample loss: 0.241  
Average acc: 0.940  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2358]:	loss = 0.132  exp loss = 0.130  adjusted loss = 0.130  adv prob = 0.250000   acc = 0.999
  waterbird_complete95 = 0, forest2water2 = 1  [n = 115]:	loss = 0.430  exp loss = 0.454  adjusted loss = 0.454  adv prob = 0.250000   acc = 0.878
  waterbird_complete95 = 1, forest2water2 = 0  [n = 38]:	loss = 1.189  exp loss = 1.130  adjusted loss = 1.130  adv prob = 0.250000   acc = 0.053
  waterbird_complete95 = 1, forest2water2 = 1  [n = 689]:	loss = 0.529  exp loss = 0.509  adjusted loss = 0.509  adv prob = 0.250000   acc = 0.798
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_train_epoch_15.csv
logged to wandb
Average incurred loss: 0.242  
Average sample loss: 0.242  
Average acc: 0.932  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 1140]:	loss = 0.123  exp loss = 0.123  adjusted loss = 0.123  adv prob = 0.250000   acc = 0.999
  waterbird_complete95 = 0, forest2water2 = 1  [n = 69]:	loss = 0.439  exp loss = 0.449  adjusted loss = 0.449  adv prob = 0.250000   acc = 0.855
  waterbird_complete95 = 1, forest2water2 = 0  [n = 18]:	loss = 1.163  exp loss = 1.126  adjusted loss = 1.126  adv prob = 0.250000   acc = 0.167
  waterbird_complete95 = 1, forest2water2 = 1  [n = 368]:	loss = 0.528  exp loss = 0.497  adjusted loss = 0.497  adv prob = 0.250000   acc = 0.777

Validation:
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_val_epoch_15.csv
logged to wandb
Average incurred loss: 0.465  
Average sample loss: 0.462  
Average acc: 0.791  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.137  exp loss = 0.130  adjusted loss = 0.130  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.472  exp loss = 0.458  adjusted loss = 0.458  adv prob = 0.250000   acc = 0.822
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.426  exp loss = 1.494  adjusted loss = 1.494  adv prob = 0.250000   acc = 0.053
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.633  exp loss = 0.660  adjusted loss = 0.660  adv prob = 0.250000   acc = 0.684
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_test_epoch_15.csv
logged to wandb
Current lr: 0.000010


Epoch [16]:
Training:
Average incurred loss: 0.237  
Average sample loss: 0.237  
Average acc: 0.940  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2330]:	loss = 0.126  exp loss = 0.124  adjusted loss = 0.124  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 119]:	loss = 0.437  exp loss = 0.436  adjusted loss = 0.436  adv prob = 0.250000   acc = 0.840
  waterbird_complete95 = 1, forest2water2 = 0  [n = 45]:	loss = 1.172  exp loss = 1.183  adjusted loss = 1.183  adv prob = 0.250000   acc = 0.089
  waterbird_complete95 = 1, forest2water2 = 1  [n = 706]:	loss = 0.508  exp loss = 0.502  adjusted loss = 0.502  adv prob = 0.250000   acc = 0.814
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_train_epoch_16.csv
logged to wandb
Average incurred loss: 0.228  
Average sample loss: 0.227  
Average acc: 0.942  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 1168]:	loss = 0.125  exp loss = 0.126  adjusted loss = 0.126  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 65]:	loss = 0.480  exp loss = 0.529  adjusted loss = 0.529  adv prob = 0.250000   acc = 0.723
  waterbird_complete95 = 1, forest2water2 = 0  [n = 11]:	loss = 1.194  exp loss = 1.143  adjusted loss = 1.143  adv prob = 0.250000   acc = 0.091
  waterbird_complete95 = 1, forest2water2 = 1  [n = 351]:	loss = 0.493  exp loss = 0.486  adjusted loss = 0.486  adv prob = 0.250000   acc = 0.815

Validation:
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_val_epoch_16.csv
logged to wandb
Average incurred loss: 0.474  
Average sample loss: 0.471  
Average acc: 0.772  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.141  exp loss = 0.133  adjusted loss = 0.133  adv prob = 0.250000   acc = 0.996
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.516  exp loss = 0.500  adjusted loss = 0.500  adv prob = 0.250000   acc = 0.758
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.389  exp loss = 1.457  adjusted loss = 1.457  adv prob = 0.250000   acc = 0.075
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.579  exp loss = 0.604  adjusted loss = 0.604  adv prob = 0.250000   acc = 0.737
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_test_epoch_16.csv
logged to wandb
Current lr: 0.000010


Epoch [17]:
Training:
Average incurred loss: 0.224  
Average sample loss: 0.224  
Average acc: 0.947  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2341]:	loss = 0.120  exp loss = 0.114  adjusted loss = 0.114  adv prob = 0.250000   acc = 0.999
  waterbird_complete95 = 0, forest2water2 = 1  [n = 129]:	loss = 0.418  exp loss = 0.412  adjusted loss = 0.412  adv prob = 0.250000   acc = 0.884
  waterbird_complete95 = 1, forest2water2 = 0  [n = 37]:	loss = 1.165  exp loss = 1.204  adjusted loss = 1.204  adv prob = 0.250000   acc = 0.108
  waterbird_complete95 = 1, forest2water2 = 1  [n = 693]:	loss = 0.488  exp loss = 0.505  adjusted loss = 0.505  adv prob = 0.250000   acc = 0.830
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_train_epoch_17.csv
logged to wandb
Average incurred loss: 0.226  
Average sample loss: 0.226  
Average acc: 0.944  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 1157]:	loss = 0.115  exp loss = 0.114  adjusted loss = 0.114  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 55]:	loss = 0.498  exp loss = 0.442  adjusted loss = 0.442  adv prob = 0.250000   acc = 0.800
  waterbird_complete95 = 1, forest2water2 = 0  [n = 19]:	loss = 1.183  exp loss = 1.137  adjusted loss = 1.137  adv prob = 0.250000   acc = 0.105
  waterbird_complete95 = 1, forest2water2 = 1  [n = 364]:	loss = 0.489  exp loss = 0.488  adjusted loss = 0.488  adv prob = 0.250000   acc = 0.832

Validation:
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_val_epoch_17.csv
logged to wandb
Average incurred loss: 0.468  
Average sample loss: 0.465  
Average acc: 0.785  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.126  exp loss = 0.119  adjusted loss = 0.119  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.491  exp loss = 0.475  adjusted loss = 0.475  adv prob = 0.250000   acc = 0.792
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.459  exp loss = 1.533  adjusted loss = 1.533  adv prob = 0.250000   acc = 0.060
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.597  exp loss = 0.622  adjusted loss = 0.622  adv prob = 0.250000   acc = 0.729
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_test_epoch_17.csv
logged to wandb
Current lr: 0.000010


Epoch [18]:
Training:
Average incurred loss: 0.218  
Average sample loss: 0.218  
Average acc: 0.947  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2333]:	loss = 0.117  exp loss = 0.119  adjusted loss = 0.119  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 123]:	loss = 0.495  exp loss = 0.567  adjusted loss = 0.567  adv prob = 0.250000   acc = 0.756
  waterbird_complete95 = 1, forest2water2 = 0  [n = 34]:	loss = 1.117  exp loss = 0.949  adjusted loss = 0.949  adv prob = 0.250000   acc = 0.147
  waterbird_complete95 = 1, forest2water2 = 1  [n = 710]:	loss = 0.461  exp loss = 0.462  adjusted loss = 0.462  adv prob = 0.250000   acc = 0.842
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_train_epoch_18.csv
logged to wandb
Average incurred loss: 0.215  
Average sample loss: 0.215  
Average acc: 0.952  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 1165]:	loss = 0.113  exp loss = 0.111  adjusted loss = 0.111  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 61]:	loss = 0.431  exp loss = 0.422  adjusted loss = 0.422  adv prob = 0.250000   acc = 0.836
  waterbird_complete95 = 1, forest2water2 = 0  [n = 22]:	loss = 1.204  exp loss = 1.102  adjusted loss = 1.102  adv prob = 0.250000   acc = 0.136
  waterbird_complete95 = 1, forest2water2 = 1  [n = 347]:	loss = 0.456  exp loss = 0.457  adjusted loss = 0.457  adv prob = 0.250000   acc = 0.862

Validation:
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_val_epoch_18.csv
logged to wandb
Average incurred loss: 0.473  
Average sample loss: 0.470  
Average acc: 0.770  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.123  exp loss = 0.116  adjusted loss = 0.116  adv prob = 0.250000   acc = 0.998
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.511  exp loss = 0.494  adjusted loss = 0.494  adv prob = 0.250000   acc = 0.753
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.465  exp loss = 1.539  adjusted loss = 1.539  adv prob = 0.250000   acc = 0.060
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.575  exp loss = 0.601  adjusted loss = 0.601  adv prob = 0.250000   acc = 0.737
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_test_epoch_18.csv
logged to wandb
Current lr: 0.000010


Epoch [19]:
Training:
Average incurred loss: 0.212  
Average sample loss: 0.212  
Average acc: 0.949  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2326]:	loss = 0.111  exp loss = 0.112  adjusted loss = 0.112  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 122]:	loss = 0.457  exp loss = 0.487  adjusted loss = 0.487  adv prob = 0.250000   acc = 0.828
  waterbird_complete95 = 1, forest2water2 = 0  [n = 36]:	loss = 1.143  exp loss = 1.090  adjusted loss = 1.090  adv prob = 0.250000   acc = 0.111
  waterbird_complete95 = 1, forest2water2 = 1  [n = 716]:	loss = 0.451  exp loss = 0.404  adjusted loss = 0.404  adv prob = 0.250000   acc = 0.848
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_train_epoch_19.csv
logged to wandb
Average incurred loss: 0.204  
Average sample loss: 0.204  
Average acc: 0.954  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 1172]:	loss = 0.111  exp loss = 0.111  adjusted loss = 0.111  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 62]:	loss = 0.442  exp loss = 0.515  adjusted loss = 0.515  adv prob = 0.250000   acc = 0.855
  waterbird_complete95 = 1, forest2water2 = 0  [n = 20]:	loss = 1.162  exp loss = 1.171  adjusted loss = 1.171  adv prob = 0.250000   acc = 0.100
  waterbird_complete95 = 1, forest2water2 = 1  [n = 341]:	loss = 0.422  exp loss = 0.405  adjusted loss = 0.405  adv prob = 0.250000   acc = 0.862

Validation:
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_val_epoch_19.csv
logged to wandb
Average incurred loss: 0.477  
Average sample loss: 0.474  
Average acc: 0.763  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.124  exp loss = 0.117  adjusted loss = 0.117  adv prob = 0.250000   acc = 0.996
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.541  exp loss = 0.522  adjusted loss = 0.522  adv prob = 0.250000   acc = 0.719
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.437  exp loss = 1.508  adjusted loss = 1.508  adv prob = 0.250000   acc = 0.083
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.537  exp loss = 0.562  adjusted loss = 0.562  adv prob = 0.250000   acc = 0.782
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_test_epoch_19.csv
logged to wandb
Current lr: 0.000010


Epoch [20]:
Training:
Average incurred loss: 0.205  
Average sample loss: 0.205  
Average acc: 0.952  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2340]:	loss = 0.107  exp loss = 0.104  adjusted loss = 0.104  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 124]:	loss = 0.460  exp loss = 0.465  adjusted loss = 0.465  adv prob = 0.250000   acc = 0.831
  waterbird_complete95 = 1, forest2water2 = 0  [n = 43]:	loss = 1.130  exp loss = 1.008  adjusted loss = 1.008  adv prob = 0.250000   acc = 0.140
  waterbird_complete95 = 1, forest2water2 = 1  [n = 693]:	loss = 0.434  exp loss = 0.434  adjusted loss = 0.434  adv prob = 0.250000   acc = 0.861
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_train_epoch_20.csv
logged to wandb
Average incurred loss: 0.201  
Average sample loss: 0.202  
Average acc: 0.960  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 1158]:	loss = 0.104  exp loss = 0.101  adjusted loss = 0.101  adv prob = 0.250000   acc = 0.998
  waterbird_complete95 = 0, forest2water2 = 1  [n = 60]:	loss = 0.432  exp loss = 0.467  adjusted loss = 0.467  adv prob = 0.250000   acc = 0.900
  waterbird_complete95 = 1, forest2water2 = 0  [n = 13]:	loss = 1.238  exp loss = 1.194  adjusted loss = 1.194  adv prob = 0.250000   acc = 0.077
  waterbird_complete95 = 1, forest2water2 = 1  [n = 364]:	loss = 0.436  exp loss = 0.433  adjusted loss = 0.433  adv prob = 0.250000   acc = 0.879

Validation:
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_val_epoch_20.csv
logged to wandb
Average incurred loss: 0.473  
Average sample loss: 0.470  
Average acc: 0.766  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.114  exp loss = 0.107  adjusted loss = 0.107  adv prob = 0.250000   acc = 0.998
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.525  exp loss = 0.507  adjusted loss = 0.507  adv prob = 0.250000   acc = 0.727
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.485  exp loss = 1.563  adjusted loss = 1.563  adv prob = 0.250000   acc = 0.083
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.542  exp loss = 0.569  adjusted loss = 0.569  adv prob = 0.250000   acc = 0.767
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_test_epoch_20.csv
logged to wandb
Current lr: 0.000010


Epoch [21]:
Training:
Average incurred loss: 0.195  
Average sample loss: 0.195  
Average acc: 0.959  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2347]:	loss = 0.104  exp loss = 0.109  adjusted loss = 0.109  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 119]:	loss = 0.462  exp loss = 0.523  adjusted loss = 0.523  adv prob = 0.250000   acc = 0.840
  waterbird_complete95 = 1, forest2water2 = 0  [n = 37]:	loss = 1.152  exp loss = 1.125  adjusted loss = 1.125  adv prob = 0.250000   acc = 0.216
  waterbird_complete95 = 1, forest2water2 = 1  [n = 697]:	loss = 0.403  exp loss = 0.375  adjusted loss = 0.375  adv prob = 0.250000   acc = 0.881
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_train_epoch_21.csv
logged to wandb
Average incurred loss: 0.198  
Average sample loss: 0.198  
Average acc: 0.956  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 1151]:	loss = 0.099  exp loss = 0.098  adjusted loss = 0.098  adv prob = 0.250000   acc = 0.999
  waterbird_complete95 = 0, forest2water2 = 1  [n = 65]:	loss = 0.469  exp loss = 0.444  adjusted loss = 0.444  adv prob = 0.250000   acc = 0.800
  waterbird_complete95 = 1, forest2water2 = 0  [n = 19]:	loss = 1.114  exp loss = 1.074  adjusted loss = 1.074  adv prob = 0.250000   acc = 0.158
  waterbird_complete95 = 1, forest2water2 = 1  [n = 360]:	loss = 0.418  exp loss = 0.419  adjusted loss = 0.419  adv prob = 0.250000   acc = 0.889

Validation:
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_val_epoch_21.csv
logged to wandb
Average incurred loss: 0.473  
Average sample loss: 0.470  
Average acc: 0.766  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.111  exp loss = 0.104  adjusted loss = 0.104  adv prob = 0.250000   acc = 0.998
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.527  exp loss = 0.509  adjusted loss = 0.509  adv prob = 0.250000   acc = 0.727
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.492  exp loss = 1.569  adjusted loss = 1.569  adv prob = 0.250000   acc = 0.075
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.535  exp loss = 0.561  adjusted loss = 0.561  adv prob = 0.250000   acc = 0.782
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_test_epoch_21.csv
logged to wandb
Current lr: 0.000010


Epoch [22]:
Training:
Average incurred loss: 0.191  
Average sample loss: 0.191  
Average acc: 0.958  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2335]:	loss = 0.100  exp loss = 0.100  adjusted loss = 0.100  adv prob = 0.250000   acc = 0.999
  waterbird_complete95 = 0, forest2water2 = 1  [n = 123]:	loss = 0.443  exp loss = 0.462  adjusted loss = 0.462  adv prob = 0.250000   acc = 0.829
  waterbird_complete95 = 1, forest2water2 = 0  [n = 37]:	loss = 1.101  exp loss = 1.056  adjusted loss = 1.056  adv prob = 0.250000   acc = 0.189
  waterbird_complete95 = 1, forest2water2 = 1  [n = 705]:	loss = 0.400  exp loss = 0.354  adjusted loss = 0.354  adv prob = 0.250000   acc = 0.884
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_train_epoch_22.csv
logged to wandb
Average incurred loss: 0.192  
Average sample loss: 0.192  
Average acc: 0.954  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 1163]:	loss = 0.097  exp loss = 0.097  adjusted loss = 0.097  adv prob = 0.250000   acc = 0.999
  waterbird_complete95 = 0, forest2water2 = 1  [n = 61]:	loss = 0.526  exp loss = 0.501  adjusted loss = 0.501  adv prob = 0.250000   acc = 0.754
  waterbird_complete95 = 1, forest2water2 = 0  [n = 19]:	loss = 1.083  exp loss = 1.080  adjusted loss = 1.080  adv prob = 0.250000   acc = 0.211
  waterbird_complete95 = 1, forest2water2 = 1  [n = 352]:	loss = 0.399  exp loss = 0.382  adjusted loss = 0.382  adv prob = 0.250000   acc = 0.881

Validation:
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_val_epoch_22.csv
logged to wandb
Average incurred loss: 0.481  
Average sample loss: 0.478  
Average acc: 0.751  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.114  exp loss = 0.107  adjusted loss = 0.107  adv prob = 0.250000   acc = 0.994
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.569  exp loss = 0.549  adjusted loss = 0.549  adv prob = 0.250000   acc = 0.678
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.451  exp loss = 1.526  adjusted loss = 1.526  adv prob = 0.250000   acc = 0.090
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.493  exp loss = 0.517  adjusted loss = 0.517  adv prob = 0.250000   acc = 0.812
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_test_epoch_22.csv
logged to wandb
Current lr: 0.000010


Epoch [23]:
Training:
Average incurred loss: 0.186  
Average sample loss: 0.186  
Average acc: 0.959  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2335]:	loss = 0.095  exp loss = 0.093  adjusted loss = 0.093  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 116]:	loss = 0.485  exp loss = 0.486  adjusted loss = 0.486  adv prob = 0.250000   acc = 0.819
  waterbird_complete95 = 1, forest2water2 = 0  [n = 42]:	loss = 1.108  exp loss = 1.004  adjusted loss = 1.004  adv prob = 0.250000   acc = 0.143
  waterbird_complete95 = 1, forest2water2 = 1  [n = 707]:	loss = 0.384  exp loss = 0.364  adjusted loss = 0.364  adv prob = 0.250000   acc = 0.898
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_train_epoch_23.csv
logged to wandb
Average incurred loss: 0.180  
Average sample loss: 0.180  
Average acc: 0.963  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 1163]:	loss = 0.096  exp loss = 0.096  adjusted loss = 0.096  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 68]:	loss = 0.436  exp loss = 0.406  adjusted loss = 0.406  adv prob = 0.250000   acc = 0.824
  waterbird_complete95 = 1, forest2water2 = 0  [n = 14]:	loss = 1.091  exp loss = 1.121  adjusted loss = 1.121  adv prob = 0.250000   acc = 0.214
  waterbird_complete95 = 1, forest2water2 = 1  [n = 350]:	loss = 0.371  exp loss = 0.362  adjusted loss = 0.362  adv prob = 0.250000   acc = 0.897

Validation:
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_val_epoch_23.csv
logged to wandb
Average incurred loss: 0.475  
Average sample loss: 0.472  
Average acc: 0.757  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.108  exp loss = 0.102  adjusted loss = 0.102  adv prob = 0.250000   acc = 0.994
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.552  exp loss = 0.533  adjusted loss = 0.533  adv prob = 0.250000   acc = 0.697
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.470  exp loss = 1.545  adjusted loss = 1.545  adv prob = 0.250000   acc = 0.090
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.496  exp loss = 0.521  adjusted loss = 0.521  adv prob = 0.250000   acc = 0.805
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_test_epoch_23.csv
logged to wandb
Current lr: 0.000010


Epoch [24]:
Training:
Average incurred loss: 0.180  
Average sample loss: 0.180  
Average acc: 0.961  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2318]:	loss = 0.091  exp loss = 0.093  adjusted loss = 0.093  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 125]:	loss = 0.449  exp loss = 0.467  adjusted loss = 0.467  adv prob = 0.250000   acc = 0.824
  waterbird_complete95 = 1, forest2water2 = 0  [n = 43]:	loss = 1.065  exp loss = 1.027  adjusted loss = 1.027  adv prob = 0.250000   acc = 0.209
  waterbird_complete95 = 1, forest2water2 = 1  [n = 714]:	loss = 0.368  exp loss = 0.329  adjusted loss = 0.329  adv prob = 0.250000   acc = 0.906
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_train_epoch_24.csv
logged to wandb
Average incurred loss: 0.178  
Average sample loss: 0.178  
Average acc: 0.957  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 1180]:	loss = 0.093  exp loss = 0.093  adjusted loss = 0.093  adv prob = 0.250000   acc = 0.999
  waterbird_complete95 = 0, forest2water2 = 1  [n = 59]:	loss = 0.523  exp loss = 0.594  adjusted loss = 0.594  adv prob = 0.250000   acc = 0.695
  waterbird_complete95 = 1, forest2water2 = 0  [n = 13]:	loss = 1.222  exp loss = 1.153  adjusted loss = 1.153  adv prob = 0.250000   acc = 0.077
  waterbird_complete95 = 1, forest2water2 = 1  [n = 343]:	loss = 0.370  exp loss = 0.364  adjusted loss = 0.364  adv prob = 0.250000   acc = 0.889

Validation:
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_val_epoch_24.csv
logged to wandb
Average incurred loss: 0.482  
Average sample loss: 0.479  
Average acc: 0.750  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.105  exp loss = 0.098  adjusted loss = 0.098  adv prob = 0.250000   acc = 0.994
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.571  exp loss = 0.551  adjusted loss = 0.551  adv prob = 0.250000   acc = 0.678
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.495  exp loss = 1.574  adjusted loss = 1.574  adv prob = 0.250000   acc = 0.090
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.482  exp loss = 0.506  adjusted loss = 0.506  adv prob = 0.250000   acc = 0.805
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_test_epoch_24.csv
logged to wandb
Current lr: 0.000010


Epoch [25]:
Training:
Average incurred loss: 0.173  
Average sample loss: 0.173  
Average acc: 0.965  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2372]:	loss = 0.091  exp loss = 0.094  adjusted loss = 0.094  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 118]:	loss = 0.491  exp loss = 0.509  adjusted loss = 0.509  adv prob = 0.250000   acc = 0.788
  waterbird_complete95 = 1, forest2water2 = 0  [n = 30]:	loss = 1.106  exp loss = 1.116  adjusted loss = 1.116  adv prob = 0.250000   acc = 0.233
  waterbird_complete95 = 1, forest2water2 = 1  [n = 680]:	loss = 0.363  exp loss = 0.355  adjusted loss = 0.355  adv prob = 0.250000   acc = 0.906
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_train_epoch_25.csv
logged to wandb
Average incurred loss: 0.179  
Average sample loss: 0.179  
Average acc: 0.957  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 1126]:	loss = 0.081  exp loss = 0.081  adjusted loss = 0.081  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 66]:	loss = 0.400  exp loss = 0.427  adjusted loss = 0.427  adv prob = 0.250000   acc = 0.894
  waterbird_complete95 = 1, forest2water2 = 0  [n = 26]:	loss = 1.170  exp loss = 1.137  adjusted loss = 1.137  adv prob = 0.250000   acc = 0.077
  waterbird_complete95 = 1, forest2water2 = 1  [n = 377]:	loss = 0.367  exp loss = 0.357  adjusted loss = 0.357  adv prob = 0.250000   acc = 0.899

Validation:
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_val_epoch_25.csv
logged to wandb
Average incurred loss: 0.472  
Average sample loss: 0.469  
Average acc: 0.763  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.095  exp loss = 0.089  adjusted loss = 0.089  adv prob = 0.250000   acc = 0.998
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.532  exp loss = 0.513  adjusted loss = 0.513  adv prob = 0.250000   acc = 0.710
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.553  exp loss = 1.633  adjusted loss = 1.633  adv prob = 0.250000   acc = 0.090
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.505  exp loss = 0.531  adjusted loss = 0.531  adv prob = 0.250000   acc = 0.797
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_test_epoch_25.csv
logged to wandb
Current lr: 0.000010


Epoch [26]:
Training:
Average incurred loss: 0.173  
Average sample loss: 0.173  
Average acc: 0.959  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2330]:	loss = 0.087  exp loss = 0.086  adjusted loss = 0.086  adv prob = 0.250000   acc = 0.999
  waterbird_complete95 = 0, forest2water2 = 1  [n = 122]:	loss = 0.478  exp loss = 0.491  adjusted loss = 0.491  adv prob = 0.250000   acc = 0.738
  waterbird_complete95 = 1, forest2water2 = 0  [n = 37]:	loss = 1.062  exp loss = 1.117  adjusted loss = 1.117  adv prob = 0.250000   acc = 0.189
  waterbird_complete95 = 1, forest2water2 = 1  [n = 711]:	loss = 0.356  exp loss = 0.356  adjusted loss = 0.356  adv prob = 0.250000   acc = 0.907
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_train_epoch_26.csv
logged to wandb
Average incurred loss: 0.165  
Average sample loss: 0.165  
Average acc: 0.967  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 1168]:	loss = 0.086  exp loss = 0.084  adjusted loss = 0.084  adv prob = 0.250000   acc = 0.999
  waterbird_complete95 = 0, forest2water2 = 1  [n = 62]:	loss = 0.446  exp loss = 0.471  adjusted loss = 0.471  adv prob = 0.250000   acc = 0.839
  waterbird_complete95 = 1, forest2water2 = 0  [n = 19]:	loss = 1.118  exp loss = 1.136  adjusted loss = 1.136  adv prob = 0.250000   acc = 0.316
  waterbird_complete95 = 1, forest2water2 = 1  [n = 346]:	loss = 0.329  exp loss = 0.331  adjusted loss = 0.331  adv prob = 0.250000   acc = 0.916

Validation:
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_val_epoch_26.csv
logged to wandb
Average incurred loss: 0.481  
Average sample loss: 0.477  
Average acc: 0.753  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.098  exp loss = 0.091  adjusted loss = 0.091  adv prob = 0.250000   acc = 0.994
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.571  exp loss = 0.550  adjusted loss = 0.550  adv prob = 0.250000   acc = 0.680
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.521  exp loss = 1.601  adjusted loss = 1.601  adv prob = 0.250000   acc = 0.098
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.467  exp loss = 0.493  adjusted loss = 0.493  adv prob = 0.250000   acc = 0.820
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_test_epoch_26.csv
logged to wandb
Current lr: 0.000010


Epoch [27]:
Training:
Average incurred loss: 0.165  
Average sample loss: 0.165  
Average acc: 0.965  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2345]:	loss = 0.084  exp loss = 0.083  adjusted loss = 0.083  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 123]:	loss = 0.461  exp loss = 0.471  adjusted loss = 0.471  adv prob = 0.250000   acc = 0.821
  waterbird_complete95 = 1, forest2water2 = 0  [n = 38]:	loss = 1.095  exp loss = 1.096  adjusted loss = 1.096  adv prob = 0.250000   acc = 0.263
  waterbird_complete95 = 1, forest2water2 = 1  [n = 694]:	loss = 0.335  exp loss = 0.331  adjusted loss = 0.331  adv prob = 0.250000   acc = 0.911
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_train_epoch_27.csv
logged to wandb
Average incurred loss: 0.167  
Average sample loss: 0.167  
Average acc: 0.961  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 1153]:	loss = 0.081  exp loss = 0.079  adjusted loss = 0.079  adv prob = 0.250000   acc = 0.999
  waterbird_complete95 = 0, forest2water2 = 1  [n = 61]:	loss = 0.444  exp loss = 0.473  adjusted loss = 0.473  adv prob = 0.250000   acc = 0.787
  waterbird_complete95 = 1, forest2water2 = 0  [n = 18]:	loss = 1.156  exp loss = 1.180  adjusted loss = 1.180  adv prob = 0.250000   acc = 0.111
  waterbird_complete95 = 1, forest2water2 = 1  [n = 363]:	loss = 0.346  exp loss = 0.344  adjusted loss = 0.344  adv prob = 0.250000   acc = 0.912

Validation:
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_val_epoch_27.csv
logged to wandb
Average incurred loss: 0.479  
Average sample loss: 0.476  
Average acc: 0.754  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.094  exp loss = 0.088  adjusted loss = 0.088  adv prob = 0.250000   acc = 0.994
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.569  exp loss = 0.548  adjusted loss = 0.548  adv prob = 0.250000   acc = 0.682
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.529  exp loss = 1.610  adjusted loss = 1.610  adv prob = 0.250000   acc = 0.098
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.462  exp loss = 0.487  adjusted loss = 0.487  adv prob = 0.250000   acc = 0.820
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_test_epoch_27.csv
logged to wandb
Current lr: 0.000010


Epoch [28]:
Training:
Average incurred loss: 0.163  
Average sample loss: 0.163  
Average acc: 0.965  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2324]:	loss = 0.081  exp loss = 0.085  adjusted loss = 0.085  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 122]:	loss = 0.461  exp loss = 0.484  adjusted loss = 0.484  adv prob = 0.250000   acc = 0.811
  waterbird_complete95 = 1, forest2water2 = 0  [n = 35]:	loss = 1.134  exp loss = 1.060  adjusted loss = 1.060  adv prob = 0.250000   acc = 0.114
  waterbird_complete95 = 1, forest2water2 = 1  [n = 719]:	loss = 0.330  exp loss = 0.301  adjusted loss = 0.301  adv prob = 0.250000   acc = 0.922
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_train_epoch_28.csv
logged to wandb
Average incurred loss: 0.159  
Average sample loss: 0.159  
Average acc: 0.968  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 1174]:	loss = 0.082  exp loss = 0.079  adjusted loss = 0.079  adv prob = 0.250000   acc = 0.999
  waterbird_complete95 = 0, forest2water2 = 1  [n = 62]:	loss = 0.504  exp loss = 0.456  adjusted loss = 0.456  adv prob = 0.250000   acc = 0.742
  waterbird_complete95 = 1, forest2water2 = 0  [n = 21]:	loss = 1.026  exp loss = 1.067  adjusted loss = 1.067  adv prob = 0.250000   acc = 0.286
  waterbird_complete95 = 1, forest2water2 = 1  [n = 338]:	loss = 0.311  exp loss = 0.320  adjusted loss = 0.320  adv prob = 0.250000   acc = 0.944

Validation:
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_val_epoch_28.csv
logged to wandb
Average incurred loss: 0.487  
Average sample loss: 0.484  
Average acc: 0.744  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.096  exp loss = 0.089  adjusted loss = 0.089  adv prob = 0.250000   acc = 0.994
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.603  exp loss = 0.580  adjusted loss = 0.580  adv prob = 0.250000   acc = 0.644
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.506  exp loss = 1.588  adjusted loss = 1.588  adv prob = 0.250000   acc = 0.113
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.434  exp loss = 0.457  adjusted loss = 0.457  adv prob = 0.250000   acc = 0.850
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_test_epoch_28.csv
logged to wandb
Current lr: 0.000010


Epoch [29]:
Training:
Average incurred loss: 0.158  
Average sample loss: 0.158  
Average acc: 0.969  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2330]:	loss = 0.079  exp loss = 0.078  adjusted loss = 0.078  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 127]:	loss = 0.442  exp loss = 0.458  adjusted loss = 0.458  adv prob = 0.250000   acc = 0.850
  waterbird_complete95 = 1, forest2water2 = 0  [n = 37]:	loss = 1.009  exp loss = 1.047  adjusted loss = 1.047  adv prob = 0.250000   acc = 0.243
  waterbird_complete95 = 1, forest2water2 = 1  [n = 706]:	loss = 0.320  exp loss = 0.306  adjusted loss = 0.306  adv prob = 0.250000   acc = 0.926
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_train_epoch_29.csv
logged to wandb
Average incurred loss: 0.159  
Average sample loss: 0.159  
Average acc: 0.966  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 1168]:	loss = 0.078  exp loss = 0.079  adjusted loss = 0.079  adv prob = 0.250000   acc = 0.998
  waterbird_complete95 = 0, forest2water2 = 1  [n = 57]:	loss = 0.505  exp loss = 0.693  adjusted loss = 0.693  adv prob = 0.250000   acc = 0.789
  waterbird_complete95 = 1, forest2water2 = 0  [n = 19]:	loss = 1.177  exp loss = 1.165  adjusted loss = 1.165  adv prob = 0.250000   acc = 0.211
  waterbird_complete95 = 1, forest2water2 = 1  [n = 351]:	loss = 0.319  exp loss = 0.305  adjusted loss = 0.305  adv prob = 0.250000   acc = 0.926

Validation:
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_val_epoch_29.csv
logged to wandb
Average incurred loss: 0.486  
Average sample loss: 0.483  
Average acc: 0.747  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.093  exp loss = 0.087  adjusted loss = 0.087  adv prob = 0.250000   acc = 0.994
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.600  exp loss = 0.577  adjusted loss = 0.577  adv prob = 0.250000   acc = 0.650
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.518  exp loss = 1.601  adjusted loss = 1.601  adv prob = 0.250000   acc = 0.120
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.432  exp loss = 0.455  adjusted loss = 0.455  adv prob = 0.250000   acc = 0.850
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_test_epoch_29.csv
logged to wandb
Current lr: 0.000010


Epoch [30]:
Training:
Average incurred loss: 0.157  
Average sample loss: 0.157  
Average acc: 0.967  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2314]:	loss = 0.075  exp loss = 0.072  adjusted loss = 0.072  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 125]:	loss = 0.453  exp loss = 0.439  adjusted loss = 0.439  adv prob = 0.250000   acc = 0.832
  waterbird_complete95 = 1, forest2water2 = 0  [n = 39]:	loss = 1.104  exp loss = 1.284  adjusted loss = 1.284  adv prob = 0.250000   acc = 0.256
  waterbird_complete95 = 1, forest2water2 = 1  [n = 722]:	loss = 0.315  exp loss = 0.327  adjusted loss = 0.327  adv prob = 0.250000   acc = 0.922
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_train_epoch_30.csv
logged to wandb
Average incurred loss: 0.151  
Average sample loss: 0.151  
Average acc: 0.964  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 1184]:	loss = 0.079  exp loss = 0.079  adjusted loss = 0.079  adv prob = 0.250000   acc = 0.997
  waterbird_complete95 = 0, forest2water2 = 1  [n = 59]:	loss = 0.482  exp loss = 0.481  adjusted loss = 0.481  adv prob = 0.250000   acc = 0.746
  waterbird_complete95 = 1, forest2water2 = 0  [n = 17]:	loss = 0.994  exp loss = 1.064  adjusted loss = 1.064  adv prob = 0.250000   acc = 0.294
  waterbird_complete95 = 1, forest2water2 = 1  [n = 335]:	loss = 0.304  exp loss = 0.296  adjusted loss = 0.296  adv prob = 0.250000   acc = 0.922

Validation:
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_val_epoch_30.csv
logged to wandb
Average incurred loss: 0.486  
Average sample loss: 0.483  
Average acc: 0.746  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.091  exp loss = 0.085  adjusted loss = 0.085  adv prob = 0.250000   acc = 0.994
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.604  exp loss = 0.581  adjusted loss = 0.581  adv prob = 0.250000   acc = 0.646
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.525  exp loss = 1.607  adjusted loss = 1.607  adv prob = 0.250000   acc = 0.113
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.423  exp loss = 0.447  adjusted loss = 0.447  adv prob = 0.250000   acc = 0.865
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_test_epoch_30.csv
logged to wandb
Current lr: 0.000010


Epoch [31]:
Training:
Average incurred loss: 0.153  
Average sample loss: 0.153  
Average acc: 0.966  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2320]:	loss = 0.073  exp loss = 0.071  adjusted loss = 0.071  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 126]:	loss = 0.489  exp loss = 0.491  adjusted loss = 0.491  adv prob = 0.250000   acc = 0.762
  waterbird_complete95 = 1, forest2water2 = 0  [n = 41]:	loss = 1.058  exp loss = 1.122  adjusted loss = 1.122  adv prob = 0.250000   acc = 0.244
  waterbird_complete95 = 1, forest2water2 = 1  [n = 713]:	loss = 0.302  exp loss = 0.279  adjusted loss = 0.279  adv prob = 0.250000   acc = 0.931
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_train_epoch_31.csv
logged to wandb
Average incurred loss: 0.149  
Average sample loss: 0.149  
Average acc: 0.969  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 1178]:	loss = 0.078  exp loss = 0.076  adjusted loss = 0.076  adv prob = 0.250000   acc = 0.999
  waterbird_complete95 = 0, forest2water2 = 1  [n = 58]:	loss = 0.444  exp loss = 0.511  adjusted loss = 0.511  adv prob = 0.250000   acc = 0.793
  waterbird_complete95 = 1, forest2water2 = 0  [n = 15]:	loss = 1.057  exp loss = 1.051  adjusted loss = 1.051  adv prob = 0.250000   acc = 0.400
  waterbird_complete95 = 1, forest2water2 = 1  [n = 344]:	loss = 0.304  exp loss = 0.288  adjusted loss = 0.288  adv prob = 0.250000   acc = 0.922

Validation:
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_val_epoch_31.csv
logged to wandb
Average incurred loss: 0.496  
Average sample loss: 0.493  
Average acc: 0.736  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.092  exp loss = 0.086  adjusted loss = 0.086  adv prob = 0.250000   acc = 0.994
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.638  exp loss = 0.613  adjusted loss = 0.613  adv prob = 0.250000   acc = 0.614
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.507  exp loss = 1.588  adjusted loss = 1.588  adv prob = 0.250000   acc = 0.120
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.401  exp loss = 0.424  adjusted loss = 0.424  adv prob = 0.250000   acc = 0.880
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_test_epoch_31.csv
logged to wandb
Current lr: 0.000010


Epoch [32]:
Training:
Average incurred loss: 0.147  
Average sample loss: 0.147  
Average acc: 0.970  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2323]:	loss = 0.071  exp loss = 0.069  adjusted loss = 0.069  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 116]:	loss = 0.460  exp loss = 0.509  adjusted loss = 0.509  adv prob = 0.250000   acc = 0.819
  waterbird_complete95 = 1, forest2water2 = 0  [n = 37]:	loss = 1.083  exp loss = 1.078  adjusted loss = 1.078  adv prob = 0.250000   acc = 0.243
  waterbird_complete95 = 1, forest2water2 = 1  [n = 724]:	loss = 0.295  exp loss = 0.288  adjusted loss = 0.288  adv prob = 0.250000   acc = 0.934
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_train_epoch_32.csv
logged to wandb
Average incurred loss: 0.151  
Average sample loss: 0.151  
Average acc: 0.964  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 1175]:	loss = 0.076  exp loss = 0.076  adjusted loss = 0.076  adv prob = 0.250000   acc = 0.998
  waterbird_complete95 = 0, forest2water2 = 1  [n = 68]:	loss = 0.511  exp loss = 0.504  adjusted loss = 0.504  adv prob = 0.250000   acc = 0.735
  waterbird_complete95 = 1, forest2water2 = 0  [n = 19]:	loss = 0.962  exp loss = 1.021  adjusted loss = 1.021  adv prob = 0.250000   acc = 0.211
  waterbird_complete95 = 1, forest2water2 = 1  [n = 333]:	loss = 0.295  exp loss = 0.284  adjusted loss = 0.284  adv prob = 0.250000   acc = 0.931

Validation:
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_val_epoch_32.csv
logged to wandb
Average incurred loss: 0.493  
Average sample loss: 0.490  
Average acc: 0.741  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.089  exp loss = 0.082  adjusted loss = 0.082  adv prob = 0.250000   acc = 0.994
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.629  exp loss = 0.603  adjusted loss = 0.603  adv prob = 0.250000   acc = 0.627
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.530  exp loss = 1.615  adjusted loss = 1.615  adv prob = 0.250000   acc = 0.120
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.403  exp loss = 0.425  adjusted loss = 0.425  adv prob = 0.250000   acc = 0.880
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_test_epoch_32.csv
logged to wandb
Current lr: 0.000010


Epoch [33]:
Training:
Average incurred loss: 0.149  
Average sample loss: 0.149  
Average acc: 0.967  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2314]:	loss = 0.070  exp loss = 0.069  adjusted loss = 0.069  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 130]:	loss = 0.445  exp loss = 0.460  adjusted loss = 0.460  adv prob = 0.250000   acc = 0.838
  waterbird_complete95 = 1, forest2water2 = 0  [n = 39]:	loss = 1.099  exp loss = 1.104  adjusted loss = 1.104  adv prob = 0.250000   acc = 0.256
  waterbird_complete95 = 1, forest2water2 = 1  [n = 717]:	loss = 0.299  exp loss = 0.286  adjusted loss = 0.286  adv prob = 0.250000   acc = 0.926
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_train_epoch_33.csv
logged to wandb
Average incurred loss: 0.139  
Average sample loss: 0.138  
Average acc: 0.972  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 1184]:	loss = 0.072  exp loss = 0.070  adjusted loss = 0.070  adv prob = 0.250000   acc = 0.999
  waterbird_complete95 = 0, forest2water2 = 1  [n = 54]:	loss = 0.505  exp loss = 0.488  adjusted loss = 0.488  adv prob = 0.250000   acc = 0.759
  waterbird_complete95 = 1, forest2water2 = 0  [n = 17]:	loss = 0.892  exp loss = 0.917  adjusted loss = 0.917  adv prob = 0.250000   acc = 0.353
  waterbird_complete95 = 1, forest2water2 = 1  [n = 340]:	loss = 0.274  exp loss = 0.251  adjusted loss = 0.251  adv prob = 0.250000   acc = 0.944

Validation:
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_val_epoch_33.csv
logged to wandb
Average incurred loss: 0.490  
Average sample loss: 0.487  
Average acc: 0.745  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.085  exp loss = 0.079  adjusted loss = 0.079  adv prob = 0.250000   acc = 0.994
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.622  exp loss = 0.599  adjusted loss = 0.599  adv prob = 0.250000   acc = 0.633
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.543  exp loss = 1.628  adjusted loss = 1.628  adv prob = 0.250000   acc = 0.120
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.401  exp loss = 0.422  adjusted loss = 0.422  adv prob = 0.250000   acc = 0.887
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_test_epoch_33.csv
logged to wandb
Current lr: 0.000010


Epoch [34]:
Training:
Average incurred loss: 0.142  
Average sample loss: 0.142  
Average acc: 0.969  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2350]:	loss = 0.070  exp loss = 0.073  adjusted loss = 0.073  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 123]:	loss = 0.471  exp loss = 0.460  adjusted loss = 0.460  adv prob = 0.250000   acc = 0.780
  waterbird_complete95 = 1, forest2water2 = 0  [n = 34]:	loss = 1.066  exp loss = 1.103  adjusted loss = 1.103  adv prob = 0.250000   acc = 0.324
  waterbird_complete95 = 1, forest2water2 = 1  [n = 693]:	loss = 0.282  exp loss = 0.256  adjusted loss = 0.256  adv prob = 0.250000   acc = 0.929
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_train_epoch_34.csv
logged to wandb
Average incurred loss: 0.141  
Average sample loss: 0.141  
Average acc: 0.970  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 1148]:	loss = 0.064  exp loss = 0.066  adjusted loss = 0.066  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 61]:	loss = 0.424  exp loss = 0.469  adjusted loss = 0.469  adv prob = 0.250000   acc = 0.820
  waterbird_complete95 = 1, forest2water2 = 0  [n = 22]:	loss = 1.030  exp loss = 0.996  adjusted loss = 0.996  adv prob = 0.250000   acc = 0.227
  waterbird_complete95 = 1, forest2water2 = 1  [n = 364]:	loss = 0.280  exp loss = 0.259  adjusted loss = 0.259  adv prob = 0.250000   acc = 0.945

Validation:
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_val_epoch_34.csv
logged to wandb
Average incurred loss: 0.490  
Average sample loss: 0.487  
Average acc: 0.743  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.083  exp loss = 0.077  adjusted loss = 0.077  adv prob = 0.250000   acc = 0.994
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.622  exp loss = 0.598  adjusted loss = 0.598  adv prob = 0.250000   acc = 0.633
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.553  exp loss = 1.638  adjusted loss = 1.638  adv prob = 0.250000   acc = 0.120
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.397  exp loss = 0.419  adjusted loss = 0.419  adv prob = 0.250000   acc = 0.872
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_test_epoch_34.csv
logged to wandb
Current lr: 0.000010


Epoch [35]:
Training:
Average incurred loss: 0.141  
Average sample loss: 0.141  
Average acc: 0.968  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2300]:	loss = 0.065  exp loss = 0.066  adjusted loss = 0.066  adv prob = 0.250000   acc = 0.999
  waterbird_complete95 = 0, forest2water2 = 1  [n = 129]:	loss = 0.440  exp loss = 0.482  adjusted loss = 0.482  adv prob = 0.250000   acc = 0.806
  waterbird_complete95 = 1, forest2water2 = 0  [n = 43]:	loss = 0.956  exp loss = 1.034  adjusted loss = 1.034  adv prob = 0.250000   acc = 0.372
  waterbird_complete95 = 1, forest2water2 = 1  [n = 728]:	loss = 0.282  exp loss = 0.266  adjusted loss = 0.266  adv prob = 0.250000   acc = 0.935
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_train_epoch_35.csv
logged to wandb
Average incurred loss: 0.131  
Average sample loss: 0.131  
Average acc: 0.976  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 1198]:	loss = 0.072  exp loss = 0.069  adjusted loss = 0.069  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 55]:	loss = 0.508  exp loss = 0.541  adjusted loss = 0.541  adv prob = 0.250000   acc = 0.764
  waterbird_complete95 = 1, forest2water2 = 0  [n = 13]:	loss = 1.161  exp loss = 1.109  adjusted loss = 1.109  adv prob = 0.250000   acc = 0.077
  waterbird_complete95 = 1, forest2water2 = 1  [n = 329]:	loss = 0.244  exp loss = 0.245  adjusted loss = 0.245  adv prob = 0.250000   acc = 0.957

Validation:
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_val_epoch_35.csv
logged to wandb
Average incurred loss: 0.494  
Average sample loss: 0.491  
Average acc: 0.740  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.085  exp loss = 0.079  adjusted loss = 0.079  adv prob = 0.250000   acc = 0.994
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.648  exp loss = 0.623  adjusted loss = 0.623  adv prob = 0.250000   acc = 0.614
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.518  exp loss = 1.602  adjusted loss = 1.602  adv prob = 0.250000   acc = 0.135
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.372  exp loss = 0.393  adjusted loss = 0.393  adv prob = 0.250000   acc = 0.895
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_test_epoch_35.csv
logged to wandb
Current lr: 0.000010


Epoch [36]:
Training:
Average incurred loss: 0.140  
Average sample loss: 0.140  
Average acc: 0.969  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2329]:	loss = 0.066  exp loss = 0.064  adjusted loss = 0.064  adv prob = 0.250000   acc = 0.999
  waterbird_complete95 = 0, forest2water2 = 1  [n = 123]:	loss = 0.469  exp loss = 0.422  adjusted loss = 0.422  adv prob = 0.250000   acc = 0.789
  waterbird_complete95 = 1, forest2water2 = 0  [n = 40]:	loss = 0.943  exp loss = 0.966  adjusted loss = 0.966  adv prob = 0.250000   acc = 0.400
  waterbird_complete95 = 1, forest2water2 = 1  [n = 708]:	loss = 0.279  exp loss = 0.270  adjusted loss = 0.270  adv prob = 0.250000   acc = 0.935
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_train_epoch_36.csv
logged to wandb
Average incurred loss: 0.131  
Average sample loss: 0.131  
Average acc: 0.975  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 1169]:	loss = 0.064  exp loss = 0.060  adjusted loss = 0.060  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 61]:	loss = 0.423  exp loss = 0.389  adjusted loss = 0.389  adv prob = 0.250000   acc = 0.820
  waterbird_complete95 = 1, forest2water2 = 0  [n = 16]:	loss = 1.015  exp loss = 0.896  adjusted loss = 0.896  adv prob = 0.250000   acc = 0.438
  waterbird_complete95 = 1, forest2water2 = 1  [n = 349]:	loss = 0.261  exp loss = 0.253  adjusted loss = 0.253  adv prob = 0.250000   acc = 0.943

Validation:
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_val_epoch_36.csv
logged to wandb
Average incurred loss: 0.486  
Average sample loss: 0.483  
Average acc: 0.752  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.075  exp loss = 0.070  adjusted loss = 0.070  adv prob = 0.250000   acc = 0.994
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.599  exp loss = 0.576  adjusted loss = 0.576  adv prob = 0.250000   acc = 0.655
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.616  exp loss = 1.709  adjusted loss = 1.709  adv prob = 0.250000   acc = 0.120
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.405  exp loss = 0.428  adjusted loss = 0.428  adv prob = 0.250000   acc = 0.880
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_test_epoch_36.csv
logged to wandb
Current lr: 0.000010


Epoch [37]:
Training:
Average incurred loss: 0.135  
Average sample loss: 0.135  
Average acc: 0.972  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2345]:	loss = 0.065  exp loss = 0.065  adjusted loss = 0.065  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 126]:	loss = 0.446  exp loss = 0.543  adjusted loss = 0.543  adv prob = 0.250000   acc = 0.825
  waterbird_complete95 = 1, forest2water2 = 0  [n = 37]:	loss = 1.085  exp loss = 1.054  adjusted loss = 1.054  adv prob = 0.250000   acc = 0.216
  waterbird_complete95 = 1, forest2water2 = 1  [n = 692]:	loss = 0.265  exp loss = 0.230  adjusted loss = 0.230  adv prob = 0.250000   acc = 0.942
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_train_epoch_37.csv
logged to wandb
Average incurred loss: 0.134  
Average sample loss: 0.134  
Average acc: 0.969  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 1153]:	loss = 0.061  exp loss = 0.062  adjusted loss = 0.062  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 58]:	loss = 0.457  exp loss = 0.456  adjusted loss = 0.456  adv prob = 0.250000   acc = 0.810
  waterbird_complete95 = 1, forest2water2 = 0  [n = 19]:	loss = 0.793  exp loss = 0.814  adjusted loss = 0.814  adv prob = 0.250000   acc = 0.421
  waterbird_complete95 = 1, forest2water2 = 1  [n = 365]:	loss = 0.277  exp loss = 0.251  adjusted loss = 0.251  adv prob = 0.250000   acc = 0.923

Validation:
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_val_epoch_37.csv
logged to wandb
Average incurred loss: 0.497  
Average sample loss: 0.494  
Average acc: 0.737  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.082  exp loss = 0.076  adjusted loss = 0.076  adv prob = 0.250000   acc = 0.994
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.656  exp loss = 0.630  adjusted loss = 0.630  adv prob = 0.250000   acc = 0.607
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.536  exp loss = 1.622  adjusted loss = 1.622  adv prob = 0.250000   acc = 0.135
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.363  exp loss = 0.383  adjusted loss = 0.383  adv prob = 0.250000   acc = 0.895
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_test_epoch_37.csv
logged to wandb
Current lr: 0.000010


Epoch [38]:
Training:
Average incurred loss: 0.130  
Average sample loss: 0.130  
Average acc: 0.972  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2339]:	loss = 0.062  exp loss = 0.058  adjusted loss = 0.058  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 103]:	loss = 0.450  exp loss = 0.432  adjusted loss = 0.432  adv prob = 0.250000   acc = 0.816
  waterbird_complete95 = 1, forest2water2 = 0  [n = 36]:	loss = 1.037  exp loss = 1.027  adjusted loss = 1.027  adv prob = 0.250000   acc = 0.222
  waterbird_complete95 = 1, forest2water2 = 1  [n = 722]:	loss = 0.260  exp loss = 0.291  adjusted loss = 0.291  adv prob = 0.250000   acc = 0.942
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_train_epoch_38.csv
logged to wandb
Average incurred loss: 0.131  
Average sample loss: 0.131  
Average acc: 0.974  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 1159]:	loss = 0.063  exp loss = 0.063  adjusted loss = 0.063  adv prob = 0.250000   acc = 0.999
  waterbird_complete95 = 0, forest2water2 = 1  [n = 81]:	loss = 0.440  exp loss = 0.434  adjusted loss = 0.434  adv prob = 0.250000   acc = 0.815
  waterbird_complete95 = 1, forest2water2 = 0  [n = 20]:	loss = 0.886  exp loss = 0.964  adjusted loss = 0.964  adv prob = 0.250000   acc = 0.500
  waterbird_complete95 = 1, forest2water2 = 1  [n = 335]:	loss = 0.244  exp loss = 0.246  adjusted loss = 0.246  adv prob = 0.250000   acc = 0.955

Validation:
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_val_epoch_38.csv
logged to wandb
Average incurred loss: 0.481  
Average sample loss: 0.478  
Average acc: 0.755  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.073  exp loss = 0.068  adjusted loss = 0.068  adv prob = 0.250000   acc = 0.996
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.598  exp loss = 0.575  adjusted loss = 0.575  adv prob = 0.250000   acc = 0.659
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.595  exp loss = 1.685  adjusted loss = 1.685  adv prob = 0.250000   acc = 0.120
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.388  exp loss = 0.410  adjusted loss = 0.410  adv prob = 0.250000   acc = 0.880
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_test_epoch_38.csv
logged to wandb
Current lr: 0.000010


Epoch [39]:
Training:
Average incurred loss: 0.131  
Average sample loss: 0.131  
Average acc: 0.973  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2340]:	loss = 0.061  exp loss = 0.062  adjusted loss = 0.062  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 126]:	loss = 0.462  exp loss = 0.468  adjusted loss = 0.468  adv prob = 0.250000   acc = 0.810
  waterbird_complete95 = 1, forest2water2 = 0  [n = 40]:	loss = 1.099  exp loss = 1.152  adjusted loss = 1.152  adv prob = 0.250000   acc = 0.275
  waterbird_complete95 = 1, forest2water2 = 1  [n = 694]:	loss = 0.248  exp loss = 0.236  adjusted loss = 0.236  adv prob = 0.250000   acc = 0.954
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_train_epoch_39.csv
logged to wandb
Average incurred loss: 0.126  
Average sample loss: 0.126  
Average acc: 0.973  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 1158]:	loss = 0.059  exp loss = 0.061  adjusted loss = 0.061  adv prob = 0.250000   acc = 0.999
  waterbird_complete95 = 0, forest2water2 = 1  [n = 58]:	loss = 0.429  exp loss = 0.388  adjusted loss = 0.388  adv prob = 0.250000   acc = 0.776
  waterbird_complete95 = 1, forest2water2 = 0  [n = 16]:	loss = 0.934  exp loss = 0.942  adjusted loss = 0.942  adv prob = 0.250000   acc = 0.250
  waterbird_complete95 = 1, forest2water2 = 1  [n = 363]:	loss = 0.254  exp loss = 0.240  adjusted loss = 0.240  adv prob = 0.250000   acc = 0.953

Validation:
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_val_epoch_39.csv
logged to wandb
Average incurred loss: 0.493  
Average sample loss: 0.490  
Average acc: 0.742  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.076  exp loss = 0.070  adjusted loss = 0.070  adv prob = 0.250000   acc = 0.994
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.642  exp loss = 0.617  adjusted loss = 0.617  adv prob = 0.250000   acc = 0.620
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.564  exp loss = 1.652  adjusted loss = 1.652  adv prob = 0.250000   acc = 0.135
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.364  exp loss = 0.385  adjusted loss = 0.385  adv prob = 0.250000   acc = 0.895
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_test_epoch_39.csv
logged to wandb
Current lr: 0.000010


Epoch [40]:
Training:
Average incurred loss: 0.130  
Average sample loss: 0.130  
Average acc: 0.973  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2325]:	loss = 0.060  exp loss = 0.057  adjusted loss = 0.057  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 135]:	loss = 0.425  exp loss = 0.433  adjusted loss = 0.433  adv prob = 0.250000   acc = 0.837
  waterbird_complete95 = 1, forest2water2 = 0  [n = 35]:	loss = 1.012  exp loss = 0.897  adjusted loss = 0.897  adv prob = 0.250000   acc = 0.314
  waterbird_complete95 = 1, forest2water2 = 1  [n = 705]:	loss = 0.259  exp loss = 0.256  adjusted loss = 0.256  adv prob = 0.250000   acc = 0.943
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_train_epoch_40.csv
logged to wandb
Average incurred loss: 0.122  
Average sample loss: 0.122  
Average acc: 0.973  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 1173]:	loss = 0.059  exp loss = 0.058  adjusted loss = 0.058  adv prob = 0.250000   acc = 0.999
  waterbird_complete95 = 0, forest2water2 = 1  [n = 49]:	loss = 0.485  exp loss = 0.588  adjusted loss = 0.588  adv prob = 0.250000   acc = 0.735
  waterbird_complete95 = 1, forest2water2 = 0  [n = 21]:	loss = 0.845  exp loss = 0.866  adjusted loss = 0.866  adv prob = 0.250000   acc = 0.476
  waterbird_complete95 = 1, forest2water2 = 1  [n = 352]:	loss = 0.238  exp loss = 0.238  adjusted loss = 0.238  adv prob = 0.250000   acc = 0.949

Validation:
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_val_epoch_40.csv
logged to wandb
Average incurred loss: 0.501  
Average sample loss: 0.497  
Average acc: 0.734  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.078  exp loss = 0.072  adjusted loss = 0.072  adv prob = 0.250000   acc = 0.994
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.671  exp loss = 0.643  adjusted loss = 0.643  adv prob = 0.250000   acc = 0.599
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.539  exp loss = 1.627  adjusted loss = 1.627  adv prob = 0.250000   acc = 0.135
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.348  exp loss = 0.368  adjusted loss = 0.368  adv prob = 0.250000   acc = 0.895
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_test_epoch_40.csv
logged to wandb
Current lr: 0.000010


Epoch [41]:
Training:
Average incurred loss: 0.123  
Average sample loss: 0.123  
Average acc: 0.976  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2343]:	loss = 0.059  exp loss = 0.059  adjusted loss = 0.059  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 115]:	loss = 0.444  exp loss = 0.449  adjusted loss = 0.449  adv prob = 0.250000   acc = 0.843
  waterbird_complete95 = 1, forest2water2 = 0  [n = 31]:	loss = 0.883  exp loss = 0.852  adjusted loss = 0.852  adv prob = 0.250000   acc = 0.387
  waterbird_complete95 = 1, forest2water2 = 1  [n = 711]:	loss = 0.248  exp loss = 0.207  adjusted loss = 0.207  adv prob = 0.250000   acc = 0.947
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_train_epoch_41.csv
logged to wandb
Average incurred loss: 0.129  
Average sample loss: 0.129  
Average acc: 0.972  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 1155]:	loss = 0.058  exp loss = 0.054  adjusted loss = 0.054  adv prob = 0.250000   acc = 0.999
  waterbird_complete95 = 0, forest2water2 = 1  [n = 69]:	loss = 0.467  exp loss = 0.445  adjusted loss = 0.445  adv prob = 0.250000   acc = 0.797
  waterbird_complete95 = 1, forest2water2 = 0  [n = 25]:	loss = 1.070  exp loss = 0.848  adjusted loss = 0.848  adv prob = 0.250000   acc = 0.320
  waterbird_complete95 = 1, forest2water2 = 1  [n = 346]:	loss = 0.229  exp loss = 0.237  adjusted loss = 0.237  adv prob = 0.250000   acc = 0.962

Validation:
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_val_epoch_41.csv
logged to wandb
Average incurred loss: 0.481  
Average sample loss: 0.478  
Average acc: 0.753  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.070  exp loss = 0.065  adjusted loss = 0.065  adv prob = 0.250000   acc = 0.996
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.604  exp loss = 0.580  adjusted loss = 0.580  adv prob = 0.250000   acc = 0.655
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.599  exp loss = 1.691  adjusted loss = 1.691  adv prob = 0.250000   acc = 0.120
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.377  exp loss = 0.400  adjusted loss = 0.400  adv prob = 0.250000   acc = 0.880
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_test_epoch_41.csv
logged to wandb
Current lr: 0.000010


Epoch [42]:
Training:
Average incurred loss: 0.120  
Average sample loss: 0.120  
Average acc: 0.974  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2349]:	loss = 0.058  exp loss = 0.059  adjusted loss = 0.059  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 130]:	loss = 0.456  exp loss = 0.452  adjusted loss = 0.452  adv prob = 0.250000   acc = 0.792
  waterbird_complete95 = 1, forest2water2 = 0  [n = 34]:	loss = 0.901  exp loss = 0.929  adjusted loss = 0.929  adv prob = 0.250000   acc = 0.441
  waterbird_complete95 = 1, forest2water2 = 1  [n = 687]:	loss = 0.232  exp loss = 0.230  adjusted loss = 0.230  adv prob = 0.250000   acc = 0.946
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_train_epoch_42.csv
logged to wandb
Average incurred loss: 0.122  
Average sample loss: 0.122  
Average acc: 0.975  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 1149]:	loss = 0.054  exp loss = 0.055  adjusted loss = 0.055  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 54]:	loss = 0.426  exp loss = 0.411  adjusted loss = 0.411  adv prob = 0.250000   acc = 0.889
  waterbird_complete95 = 1, forest2water2 = 0  [n = 22]:	loss = 0.961  exp loss = 0.937  adjusted loss = 0.937  adv prob = 0.250000   acc = 0.318
  waterbird_complete95 = 1, forest2water2 = 1  [n = 370]:	loss = 0.239  exp loss = 0.214  adjusted loss = 0.214  adv prob = 0.250000   acc = 0.949

Validation:
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_val_epoch_42.csv
logged to wandb
Average incurred loss: 0.492  
Average sample loss: 0.489  
Average acc: 0.744  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.073  exp loss = 0.067  adjusted loss = 0.067  adv prob = 0.250000   acc = 0.994
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.644  exp loss = 0.619  adjusted loss = 0.619  adv prob = 0.250000   acc = 0.622
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.572  exp loss = 1.661  adjusted loss = 1.661  adv prob = 0.250000   acc = 0.143
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.352  exp loss = 0.372  adjusted loss = 0.372  adv prob = 0.250000   acc = 0.895
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_test_epoch_42.csv
logged to wandb
Current lr: 0.000010


Epoch [43]:
Training:
Average incurred loss: 0.120  
Average sample loss: 0.120  
Average acc: 0.975  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2333]:	loss = 0.056  exp loss = 0.054  adjusted loss = 0.054  adv prob = 0.250000   acc = 0.999
  waterbird_complete95 = 0, forest2water2 = 1  [n = 128]:	loss = 0.418  exp loss = 0.485  adjusted loss = 0.485  adv prob = 0.250000   acc = 0.828
  waterbird_complete95 = 1, forest2water2 = 0  [n = 35]:	loss = 1.054  exp loss = 1.067  adjusted loss = 1.067  adv prob = 0.250000   acc = 0.343
  waterbird_complete95 = 1, forest2water2 = 1  [n = 704]:	loss = 0.228  exp loss = 0.230  adjusted loss = 0.230  adv prob = 0.250000   acc = 0.955
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_train_epoch_43.csv
logged to wandb
Average incurred loss: 0.114  
Average sample loss: 0.114  
Average acc: 0.979  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 1165]:	loss = 0.054  exp loss = 0.055  adjusted loss = 0.055  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 56]:	loss = 0.416  exp loss = 0.414  adjusted loss = 0.414  adv prob = 0.250000   acc = 0.893
  waterbird_complete95 = 1, forest2water2 = 0  [n = 21]:	loss = 0.677  exp loss = 0.781  adjusted loss = 0.781  adv prob = 0.250000   acc = 0.429
  waterbird_complete95 = 1, forest2water2 = 1  [n = 353]:	loss = 0.230  exp loss = 0.238  adjusted loss = 0.238  adv prob = 0.250000   acc = 0.955

Validation:
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_val_epoch_43.csv
logged to wandb
Average incurred loss: 0.489  
Average sample loss: 0.486  
Average acc: 0.747  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.069  exp loss = 0.063  adjusted loss = 0.063  adv prob = 0.250000   acc = 0.994
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.629  exp loss = 0.605  adjusted loss = 0.605  adv prob = 0.250000   acc = 0.631
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.610  exp loss = 1.703  adjusted loss = 1.703  adv prob = 0.250000   acc = 0.135
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.356  exp loss = 0.377  adjusted loss = 0.377  adv prob = 0.250000   acc = 0.902
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_test_epoch_43.csv
logged to wandb
Current lr: 0.000010


Epoch [44]:
Training:
Average incurred loss: 0.120  
Average sample loss: 0.120  
Average acc: 0.972  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2310]:	loss = 0.054  exp loss = 0.052  adjusted loss = 0.052  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 133]:	loss = 0.431  exp loss = 0.362  adjusted loss = 0.362  adv prob = 0.250000   acc = 0.820
  waterbird_complete95 = 1, forest2water2 = 0  [n = 39]:	loss = 0.961  exp loss = 0.940  adjusted loss = 0.940  adv prob = 0.250000   acc = 0.308
  waterbird_complete95 = 1, forest2water2 = 1  [n = 718]:	loss = 0.232  exp loss = 0.225  adjusted loss = 0.225  adv prob = 0.250000   acc = 0.946
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_train_epoch_44.csv
logged to wandb
Average incurred loss: 0.110  
Average sample loss: 0.111  
Average acc: 0.981  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 1188]:	loss = 0.057  exp loss = 0.055  adjusted loss = 0.055  adv prob = 0.250000   acc = 0.999
  waterbird_complete95 = 0, forest2water2 = 1  [n = 51]:	loss = 0.427  exp loss = 0.451  adjusted loss = 0.451  adv prob = 0.250000   acc = 0.824
  waterbird_complete95 = 1, forest2water2 = 0  [n = 17]:	loss = 0.785  exp loss = 0.830  adjusted loss = 0.830  adv prob = 0.250000   acc = 0.529
  waterbird_complete95 = 1, forest2water2 = 1  [n = 339]:	loss = 0.216  exp loss = 0.213  adjusted loss = 0.213  adv prob = 0.250000   acc = 0.962

Validation:
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_val_epoch_44.csv
logged to wandb
Average incurred loss: 0.496  
Average sample loss: 0.492  
Average acc: 0.744  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.070  exp loss = 0.065  adjusted loss = 0.065  adv prob = 0.250000   acc = 0.994
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.656  exp loss = 0.631  adjusted loss = 0.631  adv prob = 0.250000   acc = 0.618
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.584  exp loss = 1.676  adjusted loss = 1.676  adv prob = 0.250000   acc = 0.150
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.337  exp loss = 0.356  adjusted loss = 0.356  adv prob = 0.250000   acc = 0.902
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_test_epoch_44.csv
logged to wandb
Current lr: 0.000010


Epoch [45]:
Training:
Average incurred loss: 0.119  
Average sample loss: 0.119  
Average acc: 0.972  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2336]:	loss = 0.054  exp loss = 0.050  adjusted loss = 0.050  adv prob = 0.250000   acc = 0.999
  waterbird_complete95 = 0, forest2water2 = 1  [n = 133]:	loss = 0.438  exp loss = 0.405  adjusted loss = 0.405  adv prob = 0.250000   acc = 0.805
  waterbird_complete95 = 1, forest2water2 = 0  [n = 37]:	loss = 0.875  exp loss = 0.780  adjusted loss = 0.780  adv prob = 0.250000   acc = 0.351
  waterbird_complete95 = 1, forest2water2 = 1  [n = 694]:	loss = 0.234  exp loss = 0.240  adjusted loss = 0.240  adv prob = 0.250000   acc = 0.944
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_train_epoch_45.csv
logged to wandb
Average incurred loss: 0.115  
Average sample loss: 0.115  
Average acc: 0.977  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 1162]:	loss = 0.052  exp loss = 0.051  adjusted loss = 0.051  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 51]:	loss = 0.461  exp loss = 0.436  adjusted loss = 0.436  adv prob = 0.250000   acc = 0.804
  waterbird_complete95 = 1, forest2water2 = 0  [n = 19]:	loss = 0.921  exp loss = 0.896  adjusted loss = 0.896  adv prob = 0.250000   acc = 0.526
  waterbird_complete95 = 1, forest2water2 = 1  [n = 363]:	loss = 0.227  exp loss = 0.212  adjusted loss = 0.212  adv prob = 0.250000   acc = 0.953

Validation:
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_val_epoch_45.csv
logged to wandb
Average incurred loss: 0.497  
Average sample loss: 0.494  
Average acc: 0.741  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.072  exp loss = 0.066  adjusted loss = 0.066  adv prob = 0.250000   acc = 0.994
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.667  exp loss = 0.641  adjusted loss = 0.641  adv prob = 0.250000   acc = 0.607
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.563  exp loss = 1.654  adjusted loss = 1.654  adv prob = 0.250000   acc = 0.165
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.329  exp loss = 0.349  adjusted loss = 0.349  adv prob = 0.250000   acc = 0.902
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_test_epoch_45.csv
logged to wandb
Current lr: 0.000010


Epoch [46]:
Training:
Average incurred loss: 0.114  
Average sample loss: 0.114  
Average acc: 0.976  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2339]:	loss = 0.054  exp loss = 0.055  adjusted loss = 0.055  adv prob = 0.250000   acc = 0.999
  waterbird_complete95 = 0, forest2water2 = 1  [n = 129]:	loss = 0.424  exp loss = 0.462  adjusted loss = 0.462  adv prob = 0.250000   acc = 0.814
  waterbird_complete95 = 1, forest2water2 = 0  [n = 39]:	loss = 0.903  exp loss = 1.020  adjusted loss = 1.020  adv prob = 0.250000   acc = 0.385
  waterbird_complete95 = 1, forest2water2 = 1  [n = 693]:	loss = 0.212  exp loss = 0.184  adjusted loss = 0.184  adv prob = 0.250000   acc = 0.961
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_train_epoch_46.csv
logged to wandb
Average incurred loss: 0.113  
Average sample loss: 0.113  
Average acc: 0.977  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 1159]:	loss = 0.052  exp loss = 0.051  adjusted loss = 0.051  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 55]:	loss = 0.412  exp loss = 0.447  adjusted loss = 0.447  adv prob = 0.250000   acc = 0.873
  waterbird_complete95 = 1, forest2water2 = 0  [n = 17]:	loss = 0.834  exp loss = 0.921  adjusted loss = 0.921  adv prob = 0.250000   acc = 0.529
  waterbird_complete95 = 1, forest2water2 = 1  [n = 364]:	loss = 0.228  exp loss = 0.217  adjusted loss = 0.217  adv prob = 0.250000   acc = 0.940

Validation:
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_val_epoch_46.csv
logged to wandb
Average incurred loss: 0.489  
Average sample loss: 0.485  
Average acc: 0.748  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.067  exp loss = 0.062  adjusted loss = 0.062  adv prob = 0.250000   acc = 0.994
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.639  exp loss = 0.614  adjusted loss = 0.614  adv prob = 0.250000   acc = 0.627
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.594  exp loss = 1.686  adjusted loss = 1.686  adv prob = 0.250000   acc = 0.158
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.336  exp loss = 0.356  adjusted loss = 0.356  adv prob = 0.250000   acc = 0.902
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_test_epoch_46.csv
logged to wandb
Current lr: 0.000010


Epoch [47]:
Training:
Average incurred loss: 0.111  
Average sample loss: 0.111  
Average acc: 0.975  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2337]:	loss = 0.052  exp loss = 0.048  adjusted loss = 0.048  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 122]:	loss = 0.429  exp loss = 0.369  adjusted loss = 0.369  adv prob = 0.250000   acc = 0.828
  waterbird_complete95 = 1, forest2water2 = 0  [n = 35]:	loss = 0.827  exp loss = 0.800  adjusted loss = 0.800  adv prob = 0.250000   acc = 0.429
  waterbird_complete95 = 1, forest2water2 = 1  [n = 706]:	loss = 0.218  exp loss = 0.210  adjusted loss = 0.210  adv prob = 0.250000   acc = 0.946
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_train_epoch_47.csv
logged to wandb
Average incurred loss: 0.113  
Average sample loss: 0.113  
Average acc: 0.976  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 1161]:	loss = 0.052  exp loss = 0.056  adjusted loss = 0.056  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 62]:	loss = 0.419  exp loss = 0.406  adjusted loss = 0.406  adv prob = 0.250000   acc = 0.823
  waterbird_complete95 = 1, forest2water2 = 0  [n = 21]:	loss = 1.001  exp loss = 0.948  adjusted loss = 0.948  adv prob = 0.250000   acc = 0.333
  waterbird_complete95 = 1, forest2water2 = 1  [n = 351]:	loss = 0.206  exp loss = 0.191  adjusted loss = 0.191  adv prob = 0.250000   acc = 0.963

Validation:
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_val_epoch_47.csv
logged to wandb
Average incurred loss: 0.495  
Average sample loss: 0.492  
Average acc: 0.742  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.069  exp loss = 0.064  adjusted loss = 0.064  adv prob = 0.250000   acc = 0.994
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.661  exp loss = 0.635  adjusted loss = 0.635  adv prob = 0.250000   acc = 0.612
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.572  exp loss = 1.664  adjusted loss = 1.664  adv prob = 0.250000   acc = 0.158
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.330  exp loss = 0.350  adjusted loss = 0.350  adv prob = 0.250000   acc = 0.902
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_test_epoch_47.csv
logged to wandb
Current lr: 0.000010


Epoch [48]:
Training:
Average incurred loss: 0.110  
Average sample loss: 0.110  
Average acc: 0.976  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2343]:	loss = 0.051  exp loss = 0.051  adjusted loss = 0.051  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 116]:	loss = 0.460  exp loss = 0.521  adjusted loss = 0.521  adv prob = 0.250000   acc = 0.784
  waterbird_complete95 = 1, forest2water2 = 0  [n = 37]:	loss = 0.860  exp loss = 1.012  adjusted loss = 1.012  adv prob = 0.250000   acc = 0.432
  waterbird_complete95 = 1, forest2water2 = 1  [n = 704]:	loss = 0.209  exp loss = 0.188  adjusted loss = 0.188  adv prob = 0.250000   acc = 0.957
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_train_epoch_48.csv
logged to wandb
Average incurred loss: 0.111  
Average sample loss: 0.111  
Average acc: 0.979  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 1155]:	loss = 0.050  exp loss = 0.049  adjusted loss = 0.049  adv prob = 0.250000   acc = 0.999
  waterbird_complete95 = 0, forest2water2 = 1  [n = 68]:	loss = 0.373  exp loss = 0.438  adjusted loss = 0.438  adv prob = 0.250000   acc = 0.853
  waterbird_complete95 = 1, forest2water2 = 0  [n = 19]:	loss = 0.898  exp loss = 0.876  adjusted loss = 0.876  adv prob = 0.250000   acc = 0.632
  waterbird_complete95 = 1, forest2water2 = 1  [n = 353]:	loss = 0.216  exp loss = 0.189  adjusted loss = 0.189  adv prob = 0.250000   acc = 0.958

Validation:
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_val_epoch_48.csv
logged to wandb
Average incurred loss: 0.491  
Average sample loss: 0.488  
Average acc: 0.749  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.067  exp loss = 0.061  adjusted loss = 0.061  adv prob = 0.250000   acc = 0.994
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.649  exp loss = 0.623  adjusted loss = 0.623  adv prob = 0.250000   acc = 0.624
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.587  exp loss = 1.679  adjusted loss = 1.679  adv prob = 0.250000   acc = 0.173
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.330  exp loss = 0.350  adjusted loss = 0.350  adv prob = 0.250000   acc = 0.902
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_test_epoch_48.csv
logged to wandb
Current lr: 0.000010


Epoch [49]:
Training:
Average incurred loss: 0.105  
Average sample loss: 0.105  
Average acc: 0.979  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2346]:	loss = 0.049  exp loss = 0.046  adjusted loss = 0.046  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 123]:	loss = 0.421  exp loss = 0.452  adjusted loss = 0.452  adv prob = 0.250000   acc = 0.829
  waterbird_complete95 = 1, forest2water2 = 0  [n = 33]:	loss = 0.912  exp loss = 0.824  adjusted loss = 0.824  adv prob = 0.250000   acc = 0.424
  waterbird_complete95 = 1, forest2water2 = 1  [n = 698]:	loss = 0.200  exp loss = 0.207  adjusted loss = 0.207  adv prob = 0.250000   acc = 0.961
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_train_epoch_49.csv
logged to wandb
Average incurred loss: 0.110  
Average sample loss: 0.110  
Average acc: 0.979  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 1152]:	loss = 0.050  exp loss = 0.047  adjusted loss = 0.047  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 61]:	loss = 0.356  exp loss = 0.352  adjusted loss = 0.352  adv prob = 0.250000   acc = 0.918
  waterbird_complete95 = 1, forest2water2 = 0  [n = 23]:	loss = 0.815  exp loss = 0.847  adjusted loss = 0.847  adv prob = 0.250000   acc = 0.435
  waterbird_complete95 = 1, forest2water2 = 1  [n = 359]:	loss = 0.218  exp loss = 0.197  adjusted loss = 0.197  adv prob = 0.250000   acc = 0.955

Validation:
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_val_epoch_49.csv
logged to wandb
Average incurred loss: 0.486  
Average sample loss: 0.483  
Average acc: 0.751  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.060  exp loss = 0.055  adjusted loss = 0.055  adv prob = 0.250000   acc = 0.994
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.621  exp loss = 0.596  adjusted loss = 0.596  adv prob = 0.250000   acc = 0.639
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.653  exp loss = 1.752  adjusted loss = 1.752  adv prob = 0.250000   acc = 0.150
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.342  exp loss = 0.362  adjusted loss = 0.362  adv prob = 0.250000   acc = 0.895
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_test_epoch_49.csv
logged to wandb
Current lr: 0.000010


Epoch [50]:
Training:
Average incurred loss: 0.108  
Average sample loss: 0.108  
Average acc: 0.977  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2340]:	loss = 0.050  exp loss = 0.044  adjusted loss = 0.044  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 114]:	loss = 0.404  exp loss = 0.400  adjusted loss = 0.400  adv prob = 0.250000   acc = 0.868
  waterbird_complete95 = 1, forest2water2 = 0  [n = 42]:	loss = 0.895  exp loss = 1.027  adjusted loss = 1.027  adv prob = 0.250000   acc = 0.429
  waterbird_complete95 = 1, forest2water2 = 1  [n = 704]:	loss = 0.206  exp loss = 0.198  adjusted loss = 0.198  adv prob = 0.250000   acc = 0.953
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_train_epoch_50.csv
logged to wandb
Average incurred loss: 0.102  
Average sample loss: 0.102  
Average acc: 0.979  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 1158]:	loss = 0.047  exp loss = 0.045  adjusted loss = 0.045  adv prob = 0.250000   acc = 0.999
  waterbird_complete95 = 0, forest2water2 = 1  [n = 70]:	loss = 0.407  exp loss = 0.403  adjusted loss = 0.403  adv prob = 0.250000   acc = 0.814
  waterbird_complete95 = 1, forest2water2 = 0  [n = 14]:	loss = 0.760  exp loss = 0.895  adjusted loss = 0.895  adv prob = 0.250000   acc = 0.500
  waterbird_complete95 = 1, forest2water2 = 1  [n = 353]:	loss = 0.196  exp loss = 0.192  adjusted loss = 0.192  adv prob = 0.250000   acc = 0.966

Validation:
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_val_epoch_50.csv
logged to wandb
Average incurred loss: 0.484  
Average sample loss: 0.481  
Average acc: 0.754  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.062  exp loss = 0.057  adjusted loss = 0.057  adv prob = 0.250000   acc = 0.994
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.621  exp loss = 0.597  adjusted loss = 0.597  adv prob = 0.250000   acc = 0.642
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.636  exp loss = 1.734  adjusted loss = 1.734  adv prob = 0.250000   acc = 0.158
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.338  exp loss = 0.359  adjusted loss = 0.359  adv prob = 0.250000   acc = 0.902
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_test_epoch_50.csv
logged to wandb
Current lr: 0.000010


Epoch [51]:
Training:
Average incurred loss: 0.107  
Average sample loss: 0.107  
Average acc: 0.976  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2319]:	loss = 0.048  exp loss = 0.048  adjusted loss = 0.048  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 117]:	loss = 0.402  exp loss = 0.448  adjusted loss = 0.448  adv prob = 0.250000   acc = 0.855
  waterbird_complete95 = 1, forest2water2 = 0  [n = 40]:	loss = 0.820  exp loss = 0.849  adjusted loss = 0.849  adv prob = 0.250000   acc = 0.450
  waterbird_complete95 = 1, forest2water2 = 1  [n = 724]:	loss = 0.210  exp loss = 0.171  adjusted loss = 0.171  adv prob = 0.250000   acc = 0.949
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_train_epoch_51.csv
logged to wandb
Average incurred loss: 0.102  
Average sample loss: 0.102  
Average acc: 0.979  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 1179]:	loss = 0.050  exp loss = 0.049  adjusted loss = 0.049  adv prob = 0.250000   acc = 0.999
  waterbird_complete95 = 0, forest2water2 = 1  [n = 67]:	loss = 0.431  exp loss = 0.420  adjusted loss = 0.420  adv prob = 0.250000   acc = 0.791
  waterbird_complete95 = 1, forest2water2 = 0  [n = 16]:	loss = 0.768  exp loss = 0.773  adjusted loss = 0.773  adv prob = 0.250000   acc = 0.625
  waterbird_complete95 = 1, forest2water2 = 1  [n = 333]:	loss = 0.187  exp loss = 0.178  adjusted loss = 0.178  adv prob = 0.250000   acc = 0.961

Validation:
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_val_epoch_51.csv
logged to wandb
Average incurred loss: 0.494  
Average sample loss: 0.491  
Average acc: 0.744  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.064  exp loss = 0.059  adjusted loss = 0.059  adv prob = 0.250000   acc = 0.994
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.667  exp loss = 0.641  adjusted loss = 0.641  adv prob = 0.250000   acc = 0.605
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.585  exp loss = 1.680  adjusted loss = 1.680  adv prob = 0.250000   acc = 0.195
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.308  exp loss = 0.327  adjusted loss = 0.327  adv prob = 0.250000   acc = 0.902
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_test_epoch_51.csv
logged to wandb
Current lr: 0.000010


Epoch [52]:
Training:
Average incurred loss: 0.102  
Average sample loss: 0.102  
Average acc: 0.981  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2343]:	loss = 0.048  exp loss = 0.049  adjusted loss = 0.049  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 120]:	loss = 0.392  exp loss = 0.355  adjusted loss = 0.355  adv prob = 0.250000   acc = 0.850
  waterbird_complete95 = 1, forest2water2 = 0  [n = 40]:	loss = 0.741  exp loss = 0.710  adjusted loss = 0.710  adv prob = 0.250000   acc = 0.525
  waterbird_complete95 = 1, forest2water2 = 1  [n = 697]:	loss = 0.196  exp loss = 0.191  adjusted loss = 0.191  adv prob = 0.250000   acc = 0.966
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_train_epoch_52.csv
logged to wandb
Average incurred loss: 0.105  
Average sample loss: 0.105  
Average acc: 0.979  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 1155]:	loss = 0.044  exp loss = 0.041  adjusted loss = 0.041  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 64]:	loss = 0.408  exp loss = 0.397  adjusted loss = 0.397  adv prob = 0.250000   acc = 0.875
  waterbird_complete95 = 1, forest2water2 = 0  [n = 16]:	loss = 1.135  exp loss = 0.973  adjusted loss = 0.973  adv prob = 0.250000   acc = 0.313
  waterbird_complete95 = 1, forest2water2 = 1  [n = 360]:	loss = 0.202  exp loss = 0.196  adjusted loss = 0.196  adv prob = 0.250000   acc = 0.961

Validation:
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_val_epoch_52.csv
logged to wandb
Average incurred loss: 0.470  
Average sample loss: 0.467  
Average acc: 0.767  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.055  exp loss = 0.051  adjusted loss = 0.051  adv prob = 0.250000   acc = 0.996
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.573  exp loss = 0.551  adjusted loss = 0.551  adv prob = 0.250000   acc = 0.682
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.686  exp loss = 1.786  adjusted loss = 1.786  adv prob = 0.250000   acc = 0.143
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.353  exp loss = 0.374  adjusted loss = 0.374  adv prob = 0.250000   acc = 0.887
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_test_epoch_52.csv
logged to wandb
Current lr: 0.000010


Epoch [53]:
Training:
Average incurred loss: 0.099  
Average sample loss: 0.099  
Average acc: 0.981  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2352]:	loss = 0.047  exp loss = 0.045  adjusted loss = 0.045  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 117]:	loss = 0.415  exp loss = 0.486  adjusted loss = 0.486  adv prob = 0.250000   acc = 0.812
  waterbird_complete95 = 1, forest2water2 = 0  [n = 38]:	loss = 0.728  exp loss = 0.694  adjusted loss = 0.694  adv prob = 0.250000   acc = 0.632
  waterbird_complete95 = 1, forest2water2 = 1  [n = 693]:	loss = 0.188  exp loss = 0.165  adjusted loss = 0.165  adv prob = 0.250000   acc = 0.967
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_train_epoch_53.csv
logged to wandb
Average incurred loss: 0.106  
Average sample loss: 0.106  
Average acc: 0.976  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 1146]:	loss = 0.044  exp loss = 0.041  adjusted loss = 0.041  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 67]:	loss = 0.365  exp loss = 0.355  adjusted loss = 0.355  adv prob = 0.250000   acc = 0.866
  waterbird_complete95 = 1, forest2water2 = 0  [n = 18]:	loss = 1.139  exp loss = 0.881  adjusted loss = 0.881  adv prob = 0.250000   acc = 0.222
  waterbird_complete95 = 1, forest2water2 = 1  [n = 364]:	loss = 0.200  exp loss = 0.210  adjusted loss = 0.210  adv prob = 0.250000   acc = 0.959

Validation:
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_val_epoch_53.csv
logged to wandb
Average incurred loss: 0.474  
Average sample loss: 0.471  
Average acc: 0.765  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.054  exp loss = 0.049  adjusted loss = 0.049  adv prob = 0.250000   acc = 0.996
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.576  exp loss = 0.554  adjusted loss = 0.554  adv prob = 0.250000   acc = 0.676
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.712  exp loss = 1.814  adjusted loss = 1.814  adv prob = 0.250000   acc = 0.135
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.355  exp loss = 0.376  adjusted loss = 0.376  adv prob = 0.250000   acc = 0.895
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_test_epoch_53.csv
logged to wandb
Current lr: 0.000010


Epoch [54]:
Training:
Average incurred loss: 0.099  
Average sample loss: 0.099  
Average acc: 0.981  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2332]:	loss = 0.044  exp loss = 0.044  adjusted loss = 0.044  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 127]:	loss = 0.398  exp loss = 0.434  adjusted loss = 0.434  adv prob = 0.250000   acc = 0.850
  waterbird_complete95 = 1, forest2water2 = 0  [n = 40]:	loss = 0.807  exp loss = 0.775  adjusted loss = 0.775  adv prob = 0.250000   acc = 0.575
  waterbird_complete95 = 1, forest2water2 = 1  [n = 701]:	loss = 0.186  exp loss = 0.163  adjusted loss = 0.163  adv prob = 0.250000   acc = 0.964
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_train_epoch_54.csv
logged to wandb
Average incurred loss: 0.099  
Average sample loss: 0.099  
Average acc: 0.984  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 1166]:	loss = 0.046  exp loss = 0.041  adjusted loss = 0.041  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 57]:	loss = 0.347  exp loss = 0.343  adjusted loss = 0.343  adv prob = 0.250000   acc = 0.912
  waterbird_complete95 = 1, forest2water2 = 0  [n = 16]:	loss = 0.868  exp loss = 0.791  adjusted loss = 0.791  adv prob = 0.250000   acc = 0.562
  waterbird_complete95 = 1, forest2water2 = 1  [n = 356]:	loss = 0.198  exp loss = 0.195  adjusted loss = 0.195  adv prob = 0.250000   acc = 0.963

Validation:
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_val_epoch_54.csv
logged to wandb
Average incurred loss: 0.481  
Average sample loss: 0.477  
Average acc: 0.759  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.054  exp loss = 0.050  adjusted loss = 0.050  adv prob = 0.250000   acc = 0.996
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.597  exp loss = 0.573  adjusted loss = 0.573  adv prob = 0.250000   acc = 0.659
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.705  exp loss = 1.809  adjusted loss = 1.809  adv prob = 0.250000   acc = 0.143
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.343  exp loss = 0.365  adjusted loss = 0.365  adv prob = 0.250000   acc = 0.895
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_test_epoch_54.csv
logged to wandb
Current lr: 0.000010


Epoch [55]:
Training:
Average incurred loss: 0.096  
Average sample loss: 0.096  
Average acc: 0.982  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2333]:	loss = 0.044  exp loss = 0.050  adjusted loss = 0.050  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 126]:	loss = 0.377  exp loss = 0.487  adjusted loss = 0.487  adv prob = 0.250000   acc = 0.865
  waterbird_complete95 = 1, forest2water2 = 0  [n = 32]:	loss = 0.729  exp loss = 0.752  adjusted loss = 0.752  adv prob = 0.250000   acc = 0.656
  waterbird_complete95 = 1, forest2water2 = 1  [n = 709]:	loss = 0.186  exp loss = 0.170  adjusted loss = 0.170  adv prob = 0.250000   acc = 0.959
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_train_epoch_55.csv
logged to wandb
Average incurred loss: 0.100  
Average sample loss: 0.100  
Average acc: 0.977  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 1165]:	loss = 0.045  exp loss = 0.046  adjusted loss = 0.046  adv prob = 0.250000   acc = 0.999
  waterbird_complete95 = 0, forest2water2 = 1  [n = 58]:	loss = 0.416  exp loss = 0.401  adjusted loss = 0.401  adv prob = 0.250000   acc = 0.793
  waterbird_complete95 = 1, forest2water2 = 0  [n = 24]:	loss = 0.841  exp loss = 0.952  adjusted loss = 0.952  adv prob = 0.250000   acc = 0.500
  waterbird_complete95 = 1, forest2water2 = 1  [n = 348]:	loss = 0.181  exp loss = 0.175  adjusted loss = 0.175  adv prob = 0.250000   acc = 0.966

Validation:
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_val_epoch_55.csv
logged to wandb
Average incurred loss: 0.493  
Average sample loss: 0.490  
Average acc: 0.749  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.061  exp loss = 0.055  adjusted loss = 0.055  adv prob = 0.250000   acc = 0.994
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.663  exp loss = 0.637  adjusted loss = 0.637  adv prob = 0.250000   acc = 0.618
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.608  exp loss = 1.704  adjusted loss = 1.704  adv prob = 0.250000   acc = 0.188
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.304  exp loss = 0.321  adjusted loss = 0.321  adv prob = 0.250000   acc = 0.910
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_test_epoch_55.csv
logged to wandb
Current lr: 0.000010


Epoch [56]:
Training:
Average incurred loss: 0.095  
Average sample loss: 0.095  
Average acc: 0.982  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2342]:	loss = 0.043  exp loss = 0.042  adjusted loss = 0.042  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 120]:	loss = 0.384  exp loss = 0.399  adjusted loss = 0.399  adv prob = 0.250000   acc = 0.858
  waterbird_complete95 = 1, forest2water2 = 0  [n = 33]:	loss = 0.840  exp loss = 0.937  adjusted loss = 0.937  adv prob = 0.250000   acc = 0.545
  waterbird_complete95 = 1, forest2water2 = 1  [n = 705]:	loss = 0.185  exp loss = 0.179  adjusted loss = 0.179  adv prob = 0.250000   acc = 0.963
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_train_epoch_56.csv
logged to wandb
Average incurred loss: 0.099  
Average sample loss: 0.099  
Average acc: 0.982  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 1156]:	loss = 0.044  exp loss = 0.042  adjusted loss = 0.042  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 64]:	loss = 0.382  exp loss = 0.449  adjusted loss = 0.449  adv prob = 0.250000   acc = 0.844
  waterbird_complete95 = 1, forest2water2 = 0  [n = 23]:	loss = 0.697  exp loss = 0.697  adjusted loss = 0.697  adv prob = 0.250000   acc = 0.652
  waterbird_complete95 = 1, forest2water2 = 1  [n = 352]:	loss = 0.191  exp loss = 0.169  adjusted loss = 0.169  adv prob = 0.250000   acc = 0.969

Validation:
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_val_epoch_56.csv
logged to wandb
Average incurred loss: 0.485  
Average sample loss: 0.482  
Average acc: 0.756  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.055  exp loss = 0.050  adjusted loss = 0.050  adv prob = 0.250000   acc = 0.996
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.623  exp loss = 0.599  adjusted loss = 0.599  adv prob = 0.250000   acc = 0.637
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.678  exp loss = 1.783  adjusted loss = 1.783  adv prob = 0.250000   acc = 0.173
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.319  exp loss = 0.339  adjusted loss = 0.339  adv prob = 0.250000   acc = 0.910
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_test_epoch_56.csv
logged to wandb
Current lr: 0.000010


Epoch [57]:
Training:
Average incurred loss: 0.096  
Average sample loss: 0.096  
Average acc: 0.982  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2318]:	loss = 0.042  exp loss = 0.043  adjusted loss = 0.043  adv prob = 0.250000   acc = 0.999
  waterbird_complete95 = 0, forest2water2 = 1  [n = 126]:	loss = 0.399  exp loss = 0.372  adjusted loss = 0.372  adv prob = 0.250000   acc = 0.873
  waterbird_complete95 = 1, forest2water2 = 0  [n = 35]:	loss = 0.770  exp loss = 0.637  adjusted loss = 0.637  adv prob = 0.250000   acc = 0.600
  waterbird_complete95 = 1, forest2water2 = 1  [n = 721]:	loss = 0.185  exp loss = 0.165  adjusted loss = 0.165  adv prob = 0.250000   acc = 0.965
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_train_epoch_57.csv
logged to wandb
Average incurred loss: 0.093  
Average sample loss: 0.093  
Average acc: 0.981  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 1180]:	loss = 0.046  exp loss = 0.044  adjusted loss = 0.044  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 58]:	loss = 0.392  exp loss = 0.422  adjusted loss = 0.422  adv prob = 0.250000   acc = 0.793
  waterbird_complete95 = 1, forest2water2 = 0  [n = 21]:	loss = 0.744  exp loss = 0.695  adjusted loss = 0.695  adv prob = 0.250000   acc = 0.571
  waterbird_complete95 = 1, forest2water2 = 1  [n = 336]:	loss = 0.166  exp loss = 0.166  adjusted loss = 0.166  adv prob = 0.250000   acc = 0.970

Validation:
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_val_epoch_57.csv
logged to wandb
Average incurred loss: 0.493  
Average sample loss: 0.490  
Average acc: 0.748  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.060  exp loss = 0.055  adjusted loss = 0.055  adv prob = 0.250000   acc = 0.994
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.669  exp loss = 0.643  adjusted loss = 0.643  adv prob = 0.250000   acc = 0.612
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.594  exp loss = 1.692  adjusted loss = 1.692  adv prob = 0.250000   acc = 0.195
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.293  exp loss = 0.310  adjusted loss = 0.310  adv prob = 0.250000   acc = 0.917
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_test_epoch_57.csv
logged to wandb
Current lr: 0.000010


Epoch [58]:
Training:
Average incurred loss: 0.092  
Average sample loss: 0.092  
Average acc: 0.984  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2328]:	loss = 0.042  exp loss = 0.042  adjusted loss = 0.042  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 121]:	loss = 0.353  exp loss = 0.363  adjusted loss = 0.363  adv prob = 0.250000   acc = 0.926
  waterbird_complete95 = 1, forest2water2 = 0  [n = 34]:	loss = 0.744  exp loss = 0.683  adjusted loss = 0.683  adv prob = 0.250000   acc = 0.529
  waterbird_complete95 = 1, forest2water2 = 1  [n = 717]:	loss = 0.180  exp loss = 0.155  adjusted loss = 0.155  adv prob = 0.250000   acc = 0.964
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_train_epoch_58.csv
logged to wandb
Average incurred loss: 0.095  
Average sample loss: 0.095  
Average acc: 0.983  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 1170]:	loss = 0.044  exp loss = 0.044  adjusted loss = 0.044  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 63]:	loss = 0.379  exp loss = 0.370  adjusted loss = 0.370  adv prob = 0.250000   acc = 0.873
  waterbird_complete95 = 1, forest2water2 = 0  [n = 22]:	loss = 0.814  exp loss = 0.666  adjusted loss = 0.666  adv prob = 0.250000   acc = 0.636
  waterbird_complete95 = 1, forest2water2 = 1  [n = 340]:	loss = 0.172  exp loss = 0.157  adjusted loss = 0.157  adv prob = 0.250000   acc = 0.968

Validation:
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_val_epoch_58.csv
logged to wandb
Average incurred loss: 0.496  
Average sample loss: 0.492  
Average acc: 0.749  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.060  exp loss = 0.055  adjusted loss = 0.055  adv prob = 0.250000   acc = 0.994
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.675  exp loss = 0.649  adjusted loss = 0.649  adv prob = 0.250000   acc = 0.607
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.602  exp loss = 1.696  adjusted loss = 1.696  adv prob = 0.250000   acc = 0.211
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.292  exp loss = 0.308  adjusted loss = 0.308  adv prob = 0.250000   acc = 0.925
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_test_epoch_58.csv
logged to wandb
Current lr: 0.000010


Epoch [59]:
Training:
Average incurred loss: 0.091  
Average sample loss: 0.091  
Average acc: 0.984  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2332]:	loss = 0.042  exp loss = 0.044  adjusted loss = 0.044  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 126]:	loss = 0.344  exp loss = 0.323  adjusted loss = 0.323  adv prob = 0.250000   acc = 0.905
  waterbird_complete95 = 1, forest2water2 = 0  [n = 40]:	loss = 0.799  exp loss = 0.782  adjusted loss = 0.782  adv prob = 0.250000   acc = 0.500
  waterbird_complete95 = 1, forest2water2 = 1  [n = 702]:	loss = 0.168  exp loss = 0.160  adjusted loss = 0.160  adv prob = 0.250000   acc = 0.974
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_train_epoch_59.csv
logged to wandb
Average incurred loss: 0.093  
Average sample loss: 0.093  
Average acc: 0.982  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 1166]:	loss = 0.040  exp loss = 0.041  adjusted loss = 0.041  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 58]:	loss = 0.390  exp loss = 0.427  adjusted loss = 0.427  adv prob = 0.250000   acc = 0.879
  waterbird_complete95 = 1, forest2water2 = 0  [n = 16]:	loss = 0.752  exp loss = 0.785  adjusted loss = 0.785  adv prob = 0.250000   acc = 0.625
  waterbird_complete95 = 1, forest2water2 = 1  [n = 355]:	loss = 0.187  exp loss = 0.172  adjusted loss = 0.172  adv prob = 0.250000   acc = 0.958

Validation:
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_val_epoch_59.csv
logged to wandb
Average incurred loss: 0.494  
Average sample loss: 0.491  
Average acc: 0.752  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.058  exp loss = 0.053  adjusted loss = 0.053  adv prob = 0.250000   acc = 0.994
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.669  exp loss = 0.644  adjusted loss = 0.644  adv prob = 0.250000   acc = 0.616
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.616  exp loss = 1.713  adjusted loss = 1.713  adv prob = 0.250000   acc = 0.211
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.291  exp loss = 0.307  adjusted loss = 0.307  adv prob = 0.250000   acc = 0.925
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_test_epoch_59.csv
logged to wandb
Current lr: 0.000010


Epoch [60]:
Training:
Average incurred loss: 0.089  
Average sample loss: 0.089  
Average acc: 0.983  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2344]:	loss = 0.041  exp loss = 0.043  adjusted loss = 0.043  adv prob = 0.250000   acc = 0.999
  waterbird_complete95 = 0, forest2water2 = 1  [n = 123]:	loss = 0.358  exp loss = 0.373  adjusted loss = 0.373  adv prob = 0.250000   acc = 0.878
  waterbird_complete95 = 1, forest2water2 = 0  [n = 35]:	loss = 0.677  exp loss = 0.700  adjusted loss = 0.700  adv prob = 0.250000   acc = 0.600
  waterbird_complete95 = 1, forest2water2 = 1  [n = 698]:	loss = 0.171  exp loss = 0.161  adjusted loss = 0.161  adv prob = 0.250000   acc = 0.966
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_train_epoch_60.csv
logged to wandb
Average incurred loss: 0.093  
Average sample loss: 0.093  
Average acc: 0.979  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 1154]:	loss = 0.041  exp loss = 0.041  adjusted loss = 0.041  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 61]:	loss = 0.369  exp loss = 0.372  adjusted loss = 0.372  adv prob = 0.250000   acc = 0.803
  waterbird_complete95 = 1, forest2water2 = 0  [n = 21]:	loss = 0.873  exp loss = 0.813  adjusted loss = 0.813  adv prob = 0.250000   acc = 0.476
  waterbird_complete95 = 1, forest2water2 = 1  [n = 359]:	loss = 0.168  exp loss = 0.151  adjusted loss = 0.151  adv prob = 0.250000   acc = 0.972

Validation:
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_val_epoch_60.csv
logged to wandb
Average incurred loss: 0.499  
Average sample loss: 0.496  
Average acc: 0.748  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.060  exp loss = 0.055  adjusted loss = 0.055  adv prob = 0.250000   acc = 0.994
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.693  exp loss = 0.667  adjusted loss = 0.667  adv prob = 0.250000   acc = 0.597
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.582  exp loss = 1.676  adjusted loss = 1.676  adv prob = 0.250000   acc = 0.226
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.276  exp loss = 0.292  adjusted loss = 0.292  adv prob = 0.250000   acc = 0.940
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_test_epoch_60.csv
logged to wandb
Current lr: 0.000010


Epoch [61]:
Training:
Average incurred loss: 0.092  
Average sample loss: 0.092  
Average acc: 0.981  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2330]:	loss = 0.040  exp loss = 0.041  adjusted loss = 0.041  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 124]:	loss = 0.398  exp loss = 0.452  adjusted loss = 0.452  adv prob = 0.250000   acc = 0.847
  waterbird_complete95 = 1, forest2water2 = 0  [n = 36]:	loss = 0.805  exp loss = 0.832  adjusted loss = 0.832  adv prob = 0.250000   acc = 0.528
  waterbird_complete95 = 1, forest2water2 = 1  [n = 710]:	loss = 0.172  exp loss = 0.160  adjusted loss = 0.160  adv prob = 0.250000   acc = 0.966
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_train_epoch_61.csv
logged to wandb
Average incurred loss: 0.091  
Average sample loss: 0.091  
Average acc: 0.982  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 1168]:	loss = 0.040  exp loss = 0.039  adjusted loss = 0.039  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 60]:	loss = 0.417  exp loss = 0.398  adjusted loss = 0.398  adv prob = 0.250000   acc = 0.783
  waterbird_complete95 = 1, forest2water2 = 0  [n = 20]:	loss = 0.617  exp loss = 0.751  adjusted loss = 0.751  adv prob = 0.250000   acc = 0.750
  waterbird_complete95 = 1, forest2water2 = 1  [n = 347]:	loss = 0.175  exp loss = 0.168  adjusted loss = 0.168  adv prob = 0.250000   acc = 0.968

Validation:
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_val_epoch_61.csv
logged to wandb
Average incurred loss: 0.482  
Average sample loss: 0.479  
Average acc: 0.757  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.053  exp loss = 0.049  adjusted loss = 0.049  adv prob = 0.250000   acc = 0.996
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.629  exp loss = 0.605  adjusted loss = 0.605  adv prob = 0.250000   acc = 0.633
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.653  exp loss = 1.755  adjusted loss = 1.755  adv prob = 0.250000   acc = 0.195
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.301  exp loss = 0.319  adjusted loss = 0.319  adv prob = 0.250000   acc = 0.917
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_test_epoch_61.csv
logged to wandb
Current lr: 0.000010


Epoch [62]:
Training:
Average incurred loss: 0.089  
Average sample loss: 0.089  
Average acc: 0.983  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2336]:	loss = 0.041  exp loss = 0.040  adjusted loss = 0.040  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 127]:	loss = 0.336  exp loss = 0.339  adjusted loss = 0.339  adv prob = 0.250000   acc = 0.913
  waterbird_complete95 = 1, forest2water2 = 0  [n = 36]:	loss = 0.767  exp loss = 0.833  adjusted loss = 0.833  adv prob = 0.250000   acc = 0.556
  waterbird_complete95 = 1, forest2water2 = 1  [n = 701]:	loss = 0.172  exp loss = 0.165  adjusted loss = 0.165  adv prob = 0.250000   acc = 0.961
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_train_epoch_62.csv
logged to wandb
Average incurred loss: 0.092  
Average sample loss: 0.092  
Average acc: 0.979  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 1162]:	loss = 0.041  exp loss = 0.038  adjusted loss = 0.038  adv prob = 0.250000   acc = 0.999
  waterbird_complete95 = 0, forest2water2 = 1  [n = 57]:	loss = 0.378  exp loss = 0.384  adjusted loss = 0.384  adv prob = 0.250000   acc = 0.807
  waterbird_complete95 = 1, forest2water2 = 0  [n = 20]:	loss = 0.768  exp loss = 0.747  adjusted loss = 0.747  adv prob = 0.250000   acc = 0.500
  waterbird_complete95 = 1, forest2water2 = 1  [n = 356]:	loss = 0.174  exp loss = 0.172  adjusted loss = 0.172  adv prob = 0.250000   acc = 0.966

Validation:
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_val_epoch_62.csv
logged to wandb
Average incurred loss: 0.478  
Average sample loss: 0.475  
Average acc: 0.762  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.051  exp loss = 0.047  adjusted loss = 0.047  adv prob = 0.250000   acc = 0.996
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.617  exp loss = 0.594  adjusted loss = 0.594  adv prob = 0.250000   acc = 0.646
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.665  exp loss = 1.766  adjusted loss = 1.766  adv prob = 0.250000   acc = 0.195
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.305  exp loss = 0.322  adjusted loss = 0.322  adv prob = 0.250000   acc = 0.917
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_test_epoch_62.csv
logged to wandb
Current lr: 0.000010


Epoch [63]:
Training:
Average incurred loss: 0.087  
Average sample loss: 0.087  
Average acc: 0.984  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2323]:	loss = 0.039  exp loss = 0.039  adjusted loss = 0.039  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 129]:	loss = 0.339  exp loss = 0.341  adjusted loss = 0.341  adv prob = 0.250000   acc = 0.899
  waterbird_complete95 = 1, forest2water2 = 0  [n = 38]:	loss = 0.766  exp loss = 0.713  adjusted loss = 0.713  adv prob = 0.250000   acc = 0.579
  waterbird_complete95 = 1, forest2water2 = 1  [n = 710]:	loss = 0.162  exp loss = 0.158  adjusted loss = 0.158  adv prob = 0.250000   acc = 0.969
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_train_epoch_63.csv
logged to wandb
Average incurred loss: 0.082  
Average sample loss: 0.082  
Average acc: 0.987  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 1175]:	loss = 0.040  exp loss = 0.037  adjusted loss = 0.037  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 55]:	loss = 0.365  exp loss = 0.373  adjusted loss = 0.373  adv prob = 0.250000   acc = 0.855
  waterbird_complete95 = 1, forest2water2 = 0  [n = 18]:	loss = 0.599  exp loss = 0.581  adjusted loss = 0.581  adv prob = 0.250000   acc = 0.611
  waterbird_complete95 = 1, forest2water2 = 1  [n = 347]:	loss = 0.155  exp loss = 0.151  adjusted loss = 0.151  adv prob = 0.250000   acc = 0.986

Validation:
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_val_epoch_63.csv
logged to wandb
Average incurred loss: 0.485  
Average sample loss: 0.481  
Average acc: 0.758  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.053  exp loss = 0.049  adjusted loss = 0.049  adv prob = 0.250000   acc = 0.996
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.645  exp loss = 0.620  adjusted loss = 0.620  adv prob = 0.250000   acc = 0.627
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.634  exp loss = 1.736  adjusted loss = 1.736  adv prob = 0.250000   acc = 0.218
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.288  exp loss = 0.304  adjusted loss = 0.304  adv prob = 0.250000   acc = 0.925
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_test_epoch_63.csv
logged to wandb
Current lr: 0.000010


Epoch [64]:
Training:
Average incurred loss: 0.087  
Average sample loss: 0.087  
Average acc: 0.987  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2378]:	loss = 0.043  exp loss = 0.042  adjusted loss = 0.042  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 123]:	loss = 0.362  exp loss = 0.379  adjusted loss = 0.379  adv prob = 0.250000   acc = 0.886
  waterbird_complete95 = 1, forest2water2 = 0  [n = 34]:	loss = 0.601  exp loss = 0.515  adjusted loss = 0.515  adv prob = 0.250000   acc = 0.735
  waterbird_complete95 = 1, forest2water2 = 1  [n = 665]:	loss = 0.167  exp loss = 0.156  adjusted loss = 0.156  adv prob = 0.250000   acc = 0.971
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_train_epoch_64.csv
logged to wandb
Average incurred loss: 0.091  
Average sample loss: 0.091  
Average acc: 0.979  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 1120]:	loss = 0.031  exp loss = 0.031  adjusted loss = 0.031  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 61]:	loss = 0.365  exp loss = 0.328  adjusted loss = 0.328  adv prob = 0.250000   acc = 0.836
  waterbird_complete95 = 1, forest2water2 = 0  [n = 22]:	loss = 0.816  exp loss = 0.727  adjusted loss = 0.727  adv prob = 0.250000   acc = 0.591
  waterbird_complete95 = 1, forest2water2 = 1  [n = 392]:	loss = 0.179  exp loss = 0.167  adjusted loss = 0.167  adv prob = 0.250000   acc = 0.962

Validation:
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_val_epoch_64.csv
logged to wandb
Average incurred loss: 0.469  
Average sample loss: 0.465  
Average acc: 0.773  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.047  exp loss = 0.043  adjusted loss = 0.043  adv prob = 0.250000   acc = 0.996
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.568  exp loss = 0.546  adjusted loss = 0.546  adv prob = 0.250000   acc = 0.693
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.738  exp loss = 1.843  adjusted loss = 1.843  adv prob = 0.250000   acc = 0.158
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.332  exp loss = 0.351  adjusted loss = 0.351  adv prob = 0.250000   acc = 0.887
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_test_epoch_64.csv
logged to wandb
Current lr: 0.000010


Epoch [65]:
Training:
Average incurred loss: 0.086  
Average sample loss: 0.086  
Average acc: 0.985  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2321]:	loss = 0.037  exp loss = 0.035  adjusted loss = 0.035  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 123]:	loss = 0.366  exp loss = 0.335  adjusted loss = 0.335  adv prob = 0.250000   acc = 0.862
  waterbird_complete95 = 1, forest2water2 = 0  [n = 46]:	loss = 0.700  exp loss = 0.745  adjusted loss = 0.745  adv prob = 0.250000   acc = 0.609
  waterbird_complete95 = 1, forest2water2 = 1  [n = 710]:	loss = 0.157  exp loss = 0.144  adjusted loss = 0.144  adv prob = 0.250000   acc = 0.980
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_train_epoch_65.csv
logged to wandb
Average incurred loss: 0.080  
Average sample loss: 0.080  
Average acc: 0.984  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 1177]:	loss = 0.039  exp loss = 0.037  adjusted loss = 0.037  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 61]:	loss = 0.320  exp loss = 0.340  adjusted loss = 0.340  adv prob = 0.250000   acc = 0.885
  waterbird_complete95 = 1, forest2water2 = 0  [n = 10]:	loss = 0.813  exp loss = 0.774  adjusted loss = 0.774  adv prob = 0.250000   acc = 0.600
  waterbird_complete95 = 1, forest2water2 = 1  [n = 347]:	loss = 0.156  exp loss = 0.134  adjusted loss = 0.134  adv prob = 0.250000   acc = 0.960

Validation:
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_val_epoch_65.csv
logged to wandb
Average incurred loss: 0.494  
Average sample loss: 0.491  
Average acc: 0.752  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.056  exp loss = 0.051  adjusted loss = 0.051  adv prob = 0.250000   acc = 0.994
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.682  exp loss = 0.656  adjusted loss = 0.656  adv prob = 0.250000   acc = 0.607
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.601  exp loss = 1.696  adjusted loss = 1.696  adv prob = 0.250000   acc = 0.226
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.271  exp loss = 0.286  adjusted loss = 0.286  adv prob = 0.250000   acc = 0.940
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_test_epoch_65.csv
logged to wandb
Current lr: 0.000010


Epoch [66]:
Training:
Average incurred loss: 0.081  
Average sample loss: 0.081  
Average acc: 0.986  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2349]:	loss = 0.038  exp loss = 0.036  adjusted loss = 0.036  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 121]:	loss = 0.343  exp loss = 0.365  adjusted loss = 0.365  adv prob = 0.250000   acc = 0.901
  waterbird_complete95 = 1, forest2water2 = 0  [n = 41]:	loss = 0.699  exp loss = 0.597  adjusted loss = 0.597  adv prob = 0.250000   acc = 0.634
  waterbird_complete95 = 1, forest2water2 = 1  [n = 689]:	loss = 0.149  exp loss = 0.131  adjusted loss = 0.131  adv prob = 0.250000   acc = 0.972
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_train_epoch_66.csv
logged to wandb
Average incurred loss: 0.084  
Average sample loss: 0.083  
Average acc: 0.986  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 1149]:	loss = 0.036  exp loss = 0.035  adjusted loss = 0.035  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 63]:	loss = 0.358  exp loss = 0.390  adjusted loss = 0.390  adv prob = 0.250000   acc = 0.889
  waterbird_complete95 = 1, forest2water2 = 0  [n = 15]:	loss = 0.709  exp loss = 0.739  adjusted loss = 0.739  adv prob = 0.250000   acc = 0.667
  waterbird_complete95 = 1, forest2water2 = 1  [n = 368]:	loss = 0.160  exp loss = 0.154  adjusted loss = 0.154  adv prob = 0.250000   acc = 0.973

Validation:
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_val_epoch_66.csv
logged to wandb
Average incurred loss: 0.481  
Average sample loss: 0.478  
Average acc: 0.761  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.051  exp loss = 0.046  adjusted loss = 0.046  adv prob = 0.250000   acc = 0.996
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.631  exp loss = 0.608  adjusted loss = 0.608  adv prob = 0.250000   acc = 0.639
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.654  exp loss = 1.754  adjusted loss = 1.754  adv prob = 0.250000   acc = 0.203
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.290  exp loss = 0.306  adjusted loss = 0.306  adv prob = 0.250000   acc = 0.917
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_test_epoch_66.csv
logged to wandb
Current lr: 0.000010


Epoch [67]:
Training:
Average incurred loss: 0.084  
Average sample loss: 0.084  
Average acc: 0.983  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2344]:	loss = 0.038  exp loss = 0.033  adjusted loss = 0.033  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 126]:	loss = 0.342  exp loss = 0.344  adjusted loss = 0.344  adv prob = 0.250000   acc = 0.857
  waterbird_complete95 = 1, forest2water2 = 0  [n = 33]:	loss = 0.693  exp loss = 0.698  adjusted loss = 0.698  adv prob = 0.250000   acc = 0.515
  waterbird_complete95 = 1, forest2water2 = 1  [n = 697]:	loss = 0.162  exp loss = 0.160  adjusted loss = 0.160  adv prob = 0.250000   acc = 0.968
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_train_epoch_67.csv
logged to wandb
Average incurred loss: 0.082  
Average sample loss: 0.082  
Average acc: 0.987  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 1154]:	loss = 0.035  exp loss = 0.035  adjusted loss = 0.035  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 58]:	loss = 0.330  exp loss = 0.353  adjusted loss = 0.353  adv prob = 0.250000   acc = 0.914
  waterbird_complete95 = 1, forest2water2 = 0  [n = 23]:	loss = 0.775  exp loss = 0.693  adjusted loss = 0.693  adv prob = 0.250000   acc = 0.609
  waterbird_complete95 = 1, forest2water2 = 1  [n = 360]:	loss = 0.148  exp loss = 0.131  adjusted loss = 0.131  adv prob = 0.250000   acc = 0.983

Validation:
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_val_epoch_67.csv
logged to wandb
Average incurred loss: 0.485  
Average sample loss: 0.482  
Average acc: 0.760  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.050  exp loss = 0.046  adjusted loss = 0.046  adv prob = 0.250000   acc = 0.996
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.641  exp loss = 0.616  adjusted loss = 0.616  adv prob = 0.250000   acc = 0.633
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.670  exp loss = 1.770  adjusted loss = 1.770  adv prob = 0.250000   acc = 0.211
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.285  exp loss = 0.300  adjusted loss = 0.300  adv prob = 0.250000   acc = 0.925
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_test_epoch_67.csv
logged to wandb
Current lr: 0.000010


Epoch [68]:
Training:
Average incurred loss: 0.083  
Average sample loss: 0.083  
Average acc: 0.987  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2316]:	loss = 0.036  exp loss = 0.037  adjusted loss = 0.037  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 119]:	loss = 0.343  exp loss = 0.408  adjusted loss = 0.408  adv prob = 0.250000   acc = 0.908
  waterbird_complete95 = 1, forest2water2 = 0  [n = 41]:	loss = 0.776  exp loss = 0.725  adjusted loss = 0.725  adv prob = 0.250000   acc = 0.610
  waterbird_complete95 = 1, forest2water2 = 1  [n = 724]:	loss = 0.155  exp loss = 0.136  adjusted loss = 0.136  adv prob = 0.250000   acc = 0.978
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_train_epoch_68.csv
logged to wandb
Average incurred loss: 0.081  
Average sample loss: 0.082  
Average acc: 0.986  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 1182]:	loss = 0.040  exp loss = 0.039  adjusted loss = 0.039  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 65]:	loss = 0.344  exp loss = 0.391  adjusted loss = 0.391  adv prob = 0.250000   acc = 0.877
  waterbird_complete95 = 1, forest2water2 = 0  [n = 15]:	loss = 0.634  exp loss = 0.695  adjusted loss = 0.695  adv prob = 0.250000   acc = 0.667
  waterbird_complete95 = 1, forest2water2 = 1  [n = 333]:	loss = 0.154  exp loss = 0.152  adjusted loss = 0.152  adv prob = 0.250000   acc = 0.970

Validation:
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_val_epoch_68.csv
logged to wandb
Average incurred loss: 0.488  
Average sample loss: 0.485  
Average acc: 0.758  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.053  exp loss = 0.048  adjusted loss = 0.048  adv prob = 0.250000   acc = 0.996
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.664  exp loss = 0.638  adjusted loss = 0.638  adv prob = 0.250000   acc = 0.620
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.618  exp loss = 1.718  adjusted loss = 1.718  adv prob = 0.250000   acc = 0.233
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.268  exp loss = 0.282  adjusted loss = 0.282  adv prob = 0.250000   acc = 0.932
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_test_epoch_68.csv
logged to wandb
Current lr: 0.000010


Epoch [69]:
Training:
Average incurred loss: 0.082  
Average sample loss: 0.082  
Average acc: 0.986  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2301]:	loss = 0.035  exp loss = 0.034  adjusted loss = 0.034  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 130]:	loss = 0.315  exp loss = 0.341  adjusted loss = 0.341  adv prob = 0.250000   acc = 0.931
  waterbird_complete95 = 1, forest2water2 = 0  [n = 36]:	loss = 0.637  exp loss = 0.590  adjusted loss = 0.590  adv prob = 0.250000   acc = 0.639
  waterbird_complete95 = 1, forest2water2 = 1  [n = 733]:	loss = 0.164  exp loss = 0.154  adjusted loss = 0.154  adv prob = 0.250000   acc = 0.969
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_train_epoch_69.csv
logged to wandb
Average incurred loss: 0.077  
Average sample loss: 0.077  
Average acc: 0.985  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 1197]:	loss = 0.039  exp loss = 0.039  adjusted loss = 0.039  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 54]:	loss = 0.381  exp loss = 0.348  adjusted loss = 0.348  adv prob = 0.250000   acc = 0.870
  waterbird_complete95 = 1, forest2water2 = 0  [n = 20]:	loss = 0.705  exp loss = 0.654  adjusted loss = 0.654  adv prob = 0.250000   acc = 0.550
  waterbird_complete95 = 1, forest2water2 = 1  [n = 324]:	loss = 0.129  exp loss = 0.114  adjusted loss = 0.114  adv prob = 0.250000   acc = 0.975

Validation:
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_val_epoch_69.csv
logged to wandb
Average incurred loss: 0.506  
Average sample loss: 0.503  
Average acc: 0.742  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.058  exp loss = 0.053  adjusted loss = 0.053  adv prob = 0.250000   acc = 0.994
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.726  exp loss = 0.699  adjusted loss = 0.699  adv prob = 0.250000   acc = 0.577
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.565  exp loss = 1.661  adjusted loss = 1.661  adv prob = 0.250000   acc = 0.233
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.249  exp loss = 0.262  adjusted loss = 0.262  adv prob = 0.250000   acc = 0.947
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_test_epoch_69.csv
logged to wandb
Current lr: 0.000010


Epoch [70]:
Training:
Average incurred loss: 0.082  
Average sample loss: 0.082  
Average acc: 0.985  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2331]:	loss = 0.036  exp loss = 0.030  adjusted loss = 0.030  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 133]:	loss = 0.331  exp loss = 0.302  adjusted loss = 0.302  adv prob = 0.250000   acc = 0.895
  waterbird_complete95 = 1, forest2water2 = 0  [n = 42]:	loss = 0.683  exp loss = 0.801  adjusted loss = 0.801  adv prob = 0.250000   acc = 0.643
  waterbird_complete95 = 1, forest2water2 = 1  [n = 694]:	loss = 0.156  exp loss = 0.148  adjusted loss = 0.148  adv prob = 0.250000   acc = 0.976
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_train_epoch_70.csv
logged to wandb
Average incurred loss: 0.077  
Average sample loss: 0.077  
Average acc: 0.989  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 1167]:	loss = 0.036  exp loss = 0.035  adjusted loss = 0.035  adv prob = 0.250000   acc = 0.999
  waterbird_complete95 = 0, forest2water2 = 1  [n = 51]:	loss = 0.327  exp loss = 0.360  adjusted loss = 0.360  adv prob = 0.250000   acc = 0.902
  waterbird_complete95 = 1, forest2water2 = 0  [n = 14]:	loss = 0.740  exp loss = 0.687  adjusted loss = 0.687  adv prob = 0.250000   acc = 0.571
  waterbird_complete95 = 1, forest2water2 = 1  [n = 363]:	loss = 0.149  exp loss = 0.160  adjusted loss = 0.160  adv prob = 0.250000   acc = 0.983

Validation:
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_val_epoch_70.csv
logged to wandb
Average incurred loss: 0.481  
Average sample loss: 0.478  
Average acc: 0.762  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.048  exp loss = 0.044  adjusted loss = 0.044  adv prob = 0.250000   acc = 0.996
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.629  exp loss = 0.606  adjusted loss = 0.606  adv prob = 0.250000   acc = 0.642
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.680  exp loss = 1.788  adjusted loss = 1.788  adv prob = 0.250000   acc = 0.203
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.284  exp loss = 0.299  adjusted loss = 0.299  adv prob = 0.250000   acc = 0.925
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_test_epoch_70.csv
logged to wandb
Current lr: 0.000010


Epoch [71]:
Training:
Average incurred loss: 0.080  
Average sample loss: 0.080  
Average acc: 0.987  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2324]:	loss = 0.036  exp loss = 0.035  adjusted loss = 0.035  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 125]:	loss = 0.315  exp loss = 0.388  adjusted loss = 0.388  adv prob = 0.250000   acc = 0.904
  waterbird_complete95 = 1, forest2water2 = 0  [n = 40]:	loss = 0.713  exp loss = 0.651  adjusted loss = 0.651  adv prob = 0.250000   acc = 0.625
  waterbird_complete95 = 1, forest2water2 = 1  [n = 711]:	loss = 0.149  exp loss = 0.135  adjusted loss = 0.135  adv prob = 0.250000   acc = 0.979
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_train_epoch_71.csv
logged to wandb
Average incurred loss: 0.076  
Average sample loss: 0.076  
Average acc: 0.989  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 1174]:	loss = 0.036  exp loss = 0.036  adjusted loss = 0.036  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 59]:	loss = 0.312  exp loss = 0.310  adjusted loss = 0.310  adv prob = 0.250000   acc = 0.915
  waterbird_complete95 = 1, forest2water2 = 0  [n = 16]:	loss = 0.579  exp loss = 0.595  adjusted loss = 0.595  adv prob = 0.250000   acc = 0.688
  waterbird_complete95 = 1, forest2water2 = 1  [n = 346]:	loss = 0.146  exp loss = 0.139  adjusted loss = 0.139  adv prob = 0.250000   acc = 0.980

Validation:
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_val_epoch_71.csv
logged to wandb
Average incurred loss: 0.489  
Average sample loss: 0.485  
Average acc: 0.757  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.051  exp loss = 0.046  adjusted loss = 0.046  adv prob = 0.250000   acc = 0.996
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.663  exp loss = 0.639  adjusted loss = 0.639  adv prob = 0.250000   acc = 0.618
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.638  exp loss = 1.738  adjusted loss = 1.738  adv prob = 0.250000   acc = 0.226
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.266  exp loss = 0.281  adjusted loss = 0.281  adv prob = 0.250000   acc = 0.940
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_test_epoch_71.csv
logged to wandb
Current lr: 0.000010


Epoch [72]:
Training:
Average incurred loss: 0.075  
Average sample loss: 0.075  
Average acc: 0.987  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2353]:	loss = 0.036  exp loss = 0.033  adjusted loss = 0.033  adv prob = 0.250000   acc = 0.999
  waterbird_complete95 = 0, forest2water2 = 1  [n = 128]:	loss = 0.324  exp loss = 0.332  adjusted loss = 0.332  adv prob = 0.250000   acc = 0.898
  waterbird_complete95 = 1, forest2water2 = 0  [n = 39]:	loss = 0.691  exp loss = 0.638  adjusted loss = 0.638  adv prob = 0.250000   acc = 0.641
  waterbird_complete95 = 1, forest2water2 = 1  [n = 680]:	loss = 0.131  exp loss = 0.127  adjusted loss = 0.127  adv prob = 0.250000   acc = 0.984
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_train_epoch_72.csv
logged to wandb
Average incurred loss: 0.078  
Average sample loss: 0.078  
Average acc: 0.987  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 1145]:	loss = 0.030  exp loss = 0.028  adjusted loss = 0.028  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 56]:	loss = 0.305  exp loss = 0.276  adjusted loss = 0.276  adv prob = 0.250000   acc = 0.964
  waterbird_complete95 = 1, forest2water2 = 0  [n = 17]:	loss = 0.587  exp loss = 0.598  adjusted loss = 0.598  adv prob = 0.250000   acc = 0.706
  waterbird_complete95 = 1, forest2water2 = 1  [n = 377]:	loss = 0.166  exp loss = 0.168  adjusted loss = 0.168  adv prob = 0.250000   acc = 0.966

Validation:
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_val_epoch_72.csv
logged to wandb
Average incurred loss: 0.466  
Average sample loss: 0.462  
Average acc: 0.780  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.042  exp loss = 0.038  adjusted loss = 0.038  adv prob = 0.250000   acc = 0.996
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.558  exp loss = 0.536  adjusted loss = 0.536  adv prob = 0.250000   acc = 0.706
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.781  exp loss = 1.891  adjusted loss = 1.891  adv prob = 0.250000   acc = 0.165
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.320  exp loss = 0.338  adjusted loss = 0.338  adv prob = 0.250000   acc = 0.895
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_test_epoch_72.csv
logged to wandb
Current lr: 0.000010


Epoch [73]:
Training:
Average incurred loss: 0.076  
Average sample loss: 0.076  
Average acc: 0.987  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2324]:	loss = 0.034  exp loss = 0.036  adjusted loss = 0.036  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 131]:	loss = 0.287  exp loss = 0.349  adjusted loss = 0.349  adv prob = 0.250000   acc = 0.924
  waterbird_complete95 = 1, forest2water2 = 0  [n = 36]:	loss = 0.668  exp loss = 0.634  adjusted loss = 0.634  adv prob = 0.250000   acc = 0.694
  waterbird_complete95 = 1, forest2water2 = 1  [n = 709]:	loss = 0.144  exp loss = 0.129  adjusted loss = 0.129  adv prob = 0.250000   acc = 0.973
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_train_epoch_73.csv
logged to wandb
Average incurred loss: 0.076  
Average sample loss: 0.076  
Average acc: 0.985  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 1174]:	loss = 0.033  exp loss = 0.034  adjusted loss = 0.034  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 53]:	loss = 0.397  exp loss = 0.417  adjusted loss = 0.417  adv prob = 0.250000   acc = 0.830
  waterbird_complete95 = 1, forest2water2 = 0  [n = 20]:	loss = 0.682  exp loss = 0.585  adjusted loss = 0.585  adv prob = 0.250000   acc = 0.650
  waterbird_complete95 = 1, forest2water2 = 1  [n = 348]:	loss = 0.136  exp loss = 0.116  adjusted loss = 0.116  adv prob = 0.250000   acc = 0.977

Validation:
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_val_epoch_73.csv
logged to wandb
Average incurred loss: 0.497  
Average sample loss: 0.493  
Average acc: 0.749  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.053  exp loss = 0.049  adjusted loss = 0.049  adv prob = 0.250000   acc = 0.994
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.698  exp loss = 0.670  adjusted loss = 0.670  adv prob = 0.250000   acc = 0.594
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.592  exp loss = 1.688  adjusted loss = 1.688  adv prob = 0.250000   acc = 0.241
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.251  exp loss = 0.264  adjusted loss = 0.264  adv prob = 0.250000   acc = 0.940
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_test_epoch_73.csv
logged to wandb
Current lr: 0.000010


Epoch [74]:
Training:
Average incurred loss: 0.073  
Average sample loss: 0.073  
Average acc: 0.991  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2344]:	loss = 0.035  exp loss = 0.034  adjusted loss = 0.034  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 129]:	loss = 0.299  exp loss = 0.356  adjusted loss = 0.356  adv prob = 0.250000   acc = 0.922
  waterbird_complete95 = 1, forest2water2 = 0  [n = 34]:	loss = 0.521  exp loss = 0.575  adjusted loss = 0.575  adv prob = 0.250000   acc = 0.794
  waterbird_complete95 = 1, forest2water2 = 1  [n = 693]:	loss = 0.140  exp loss = 0.106  adjusted loss = 0.106  adv prob = 0.250000   acc = 0.981
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_train_epoch_74.csv
logged to wandb
Average incurred loss: 0.079  
Average sample loss: 0.079  
Average acc: 0.986  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 1154]:	loss = 0.032  exp loss = 0.034  adjusted loss = 0.034  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 55]:	loss = 0.356  exp loss = 0.330  adjusted loss = 0.330  adv prob = 0.250000   acc = 0.873
  waterbird_complete95 = 1, forest2water2 = 0  [n = 22]:	loss = 0.783  exp loss = 0.802  adjusted loss = 0.802  adv prob = 0.250000   acc = 0.636
  waterbird_complete95 = 1, forest2water2 = 1  [n = 364]:	loss = 0.142  exp loss = 0.131  adjusted loss = 0.131  adv prob = 0.250000   acc = 0.978

Validation:
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_val_epoch_74.csv
logged to wandb
Average incurred loss: 0.480  
Average sample loss: 0.477  
Average acc: 0.763  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.049  exp loss = 0.045  adjusted loss = 0.045  adv prob = 0.250000   acc = 0.996
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.647  exp loss = 0.623  adjusted loss = 0.623  adv prob = 0.250000   acc = 0.631
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.627  exp loss = 1.724  adjusted loss = 1.724  adv prob = 0.250000   acc = 0.241
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.264  exp loss = 0.277  adjusted loss = 0.277  adv prob = 0.250000   acc = 0.932
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_test_epoch_74.csv
logged to wandb
Current lr: 0.000010


Epoch [75]:
Training:
Average incurred loss: 0.073  
Average sample loss: 0.073  
Average acc: 0.988  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2359]:	loss = 0.034  exp loss = 0.032  adjusted loss = 0.032  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 121]:	loss = 0.336  exp loss = 0.337  adjusted loss = 0.337  adv prob = 0.250000   acc = 0.893
  waterbird_complete95 = 1, forest2water2 = 0  [n = 37]:	loss = 0.578  exp loss = 0.598  adjusted loss = 0.598  adv prob = 0.250000   acc = 0.757
  waterbird_complete95 = 1, forest2water2 = 1  [n = 683]:	loss = 0.135  exp loss = 0.126  adjusted loss = 0.126  adv prob = 0.250000   acc = 0.978
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_train_epoch_75.csv
logged to wandb
Average incurred loss: 0.072  
Average sample loss: 0.072  
Average acc: 0.987  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 1139]:	loss = 0.029  exp loss = 0.029  adjusted loss = 0.029  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 63]:	loss = 0.247  exp loss = 0.278  adjusted loss = 0.278  adv prob = 0.250000   acc = 0.952
  waterbird_complete95 = 1, forest2water2 = 0  [n = 19]:	loss = 0.753  exp loss = 0.810  adjusted loss = 0.810  adv prob = 0.250000   acc = 0.526
  waterbird_complete95 = 1, forest2water2 = 1  [n = 374]:	loss = 0.139  exp loss = 0.131  adjusted loss = 0.131  adv prob = 0.250000   acc = 0.979

Validation:
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_val_epoch_75.csv
logged to wandb
Average incurred loss: 0.472  
Average sample loss: 0.469  
Average acc: 0.773  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.045  exp loss = 0.041  adjusted loss = 0.041  adv prob = 0.250000   acc = 0.996
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.611  exp loss = 0.589  adjusted loss = 0.589  adv prob = 0.250000   acc = 0.661
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.681  exp loss = 1.788  adjusted loss = 1.788  adv prob = 0.250000   acc = 0.226
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.278  exp loss = 0.294  adjusted loss = 0.294  adv prob = 0.250000   acc = 0.932
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_test_epoch_75.csv
logged to wandb
Current lr: 0.000010


Epoch [76]:
Training:
Average incurred loss: 0.077  
Average sample loss: 0.077  
Average acc: 0.985  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2332]:	loss = 0.034  exp loss = 0.034  adjusted loss = 0.034  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 122]:	loss = 0.331  exp loss = 0.309  adjusted loss = 0.309  adv prob = 0.250000   acc = 0.885
  waterbird_complete95 = 1, forest2water2 = 0  [n = 38]:	loss = 0.684  exp loss = 0.615  adjusted loss = 0.615  adv prob = 0.250000   acc = 0.632
  waterbird_complete95 = 1, forest2water2 = 1  [n = 708]:	loss = 0.144  exp loss = 0.121  adjusted loss = 0.121  adv prob = 0.250000   acc = 0.973
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_train_epoch_76.csv
logged to wandb
Average incurred loss: 0.071  
Average sample loss: 0.071  
Average acc: 0.990  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 1166]:	loss = 0.033  exp loss = 0.031  adjusted loss = 0.031  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 62]:	loss = 0.312  exp loss = 0.347  adjusted loss = 0.347  adv prob = 0.250000   acc = 0.935
  waterbird_complete95 = 1, forest2water2 = 0  [n = 18]:	loss = 0.581  exp loss = 0.568  adjusted loss = 0.568  adv prob = 0.250000   acc = 0.722
  waterbird_complete95 = 1, forest2water2 = 1  [n = 349]:	loss = 0.129  exp loss = 0.118  adjusted loss = 0.118  adv prob = 0.250000   acc = 0.980

Validation:
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_val_epoch_76.csv
logged to wandb
Average incurred loss: 0.479  
Average sample loss: 0.476  
Average acc: 0.764  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.049  exp loss = 0.045  adjusted loss = 0.045  adv prob = 0.250000   acc = 0.996
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.645  exp loss = 0.622  adjusted loss = 0.622  adv prob = 0.250000   acc = 0.633
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.623  exp loss = 1.721  adjusted loss = 1.721  adv prob = 0.250000   acc = 0.241
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.264  exp loss = 0.278  adjusted loss = 0.278  adv prob = 0.250000   acc = 0.932
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_test_epoch_76.csv
logged to wandb
Current lr: 0.000010


Epoch [77]:
Training:
Average incurred loss: 0.072  
Average sample loss: 0.072  
Average acc: 0.989  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2340]:	loss = 0.033  exp loss = 0.033  adjusted loss = 0.033  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 129]:	loss = 0.297  exp loss = 0.297  adjusted loss = 0.297  adv prob = 0.250000   acc = 0.907
  waterbird_complete95 = 1, forest2water2 = 0  [n = 40]:	loss = 0.645  exp loss = 0.491  adjusted loss = 0.491  adv prob = 0.250000   acc = 0.675
  waterbird_complete95 = 1, forest2water2 = 1  [n = 691]:	loss = 0.131  exp loss = 0.111  adjusted loss = 0.111  adv prob = 0.250000   acc = 0.987
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_train_epoch_77.csv
logged to wandb
Average incurred loss: 0.074  
Average sample loss: 0.074  
Average acc: 0.987  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 1158]:	loss = 0.032  exp loss = 0.030  adjusted loss = 0.030  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 55]:	loss = 0.322  exp loss = 0.366  adjusted loss = 0.366  adv prob = 0.250000   acc = 0.873
  waterbird_complete95 = 1, forest2water2 = 0  [n = 16]:	loss = 0.567  exp loss = 0.603  adjusted loss = 0.603  adv prob = 0.250000   acc = 0.688
  waterbird_complete95 = 1, forest2water2 = 1  [n = 366]:	loss = 0.148  exp loss = 0.133  adjusted loss = 0.133  adv prob = 0.250000   acc = 0.978

Validation:
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_val_epoch_77.csv
logged to wandb
Average incurred loss: 0.477  
Average sample loss: 0.474  
Average acc: 0.768  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.045  exp loss = 0.041  adjusted loss = 0.041  adv prob = 0.250000   acc = 0.996
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.619  exp loss = 0.595  adjusted loss = 0.595  adv prob = 0.250000   acc = 0.652
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.697  exp loss = 1.802  adjusted loss = 1.802  adv prob = 0.250000   acc = 0.218
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.280  exp loss = 0.295  adjusted loss = 0.295  adv prob = 0.250000   acc = 0.925
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_test_epoch_77.csv
logged to wandb
Current lr: 0.000010


Epoch [78]:
Training:
Average incurred loss: 0.074  
Average sample loss: 0.074  
Average acc: 0.989  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2331]:	loss = 0.032  exp loss = 0.030  adjusted loss = 0.030  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 119]:	loss = 0.304  exp loss = 0.378  adjusted loss = 0.378  adv prob = 0.250000   acc = 0.899
  waterbird_complete95 = 1, forest2water2 = 0  [n = 43]:	loss = 0.541  exp loss = 0.507  adjusted loss = 0.507  adv prob = 0.250000   acc = 0.767
  waterbird_complete95 = 1, forest2water2 = 1  [n = 707]:	loss = 0.142  exp loss = 0.124  adjusted loss = 0.124  adv prob = 0.250000   acc = 0.982
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_train_epoch_78.csv
logged to wandb
Average incurred loss: 0.068  
Average sample loss: 0.068  
Average acc: 0.991  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 1167]:	loss = 0.034  exp loss = 0.032  adjusted loss = 0.032  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 65]:	loss = 0.264  exp loss = 0.314  adjusted loss = 0.314  adv prob = 0.250000   acc = 0.923
  waterbird_complete95 = 1, forest2water2 = 0  [n = 13]:	loss = 0.717  exp loss = 0.722  adjusted loss = 0.722  adv prob = 0.250000   acc = 0.615
  waterbird_complete95 = 1, forest2water2 = 1  [n = 350]:	loss = 0.123  exp loss = 0.117  adjusted loss = 0.117  adv prob = 0.250000   acc = 0.986

Validation:
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_val_epoch_78.csv
logged to wandb
Average incurred loss: 0.481  
Average sample loss: 0.478  
Average acc: 0.764  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.050  exp loss = 0.045  adjusted loss = 0.045  adv prob = 0.250000   acc = 0.996
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.660  exp loss = 0.637  adjusted loss = 0.637  adv prob = 0.250000   acc = 0.627
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.597  exp loss = 1.693  adjusted loss = 1.693  adv prob = 0.250000   acc = 0.256
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.252  exp loss = 0.265  adjusted loss = 0.265  adv prob = 0.250000   acc = 0.940
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_test_epoch_78.csv
logged to wandb
Current lr: 0.000010


Epoch [79]:
Training:
Average incurred loss: 0.069  
Average sample loss: 0.069  
Average acc: 0.991  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2353]:	loss = 0.032  exp loss = 0.032  adjusted loss = 0.032  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 128]:	loss = 0.324  exp loss = 0.415  adjusted loss = 0.415  adv prob = 0.250000   acc = 0.922
  waterbird_complete95 = 1, forest2water2 = 0  [n = 35]:	loss = 0.575  exp loss = 0.658  adjusted loss = 0.658  adv prob = 0.250000   acc = 0.714
  waterbird_complete95 = 1, forest2water2 = 1  [n = 684]:	loss = 0.124  exp loss = 0.113  adjusted loss = 0.113  adv prob = 0.250000   acc = 0.985
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_train_epoch_79.csv
logged to wandb
Average incurred loss: 0.071  
Average sample loss: 0.071  
Average acc: 0.987  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 1145]:	loss = 0.030  exp loss = 0.028  adjusted loss = 0.028  adv prob = 0.250000   acc = 0.999
  waterbird_complete95 = 0, forest2water2 = 1  [n = 56]:	loss = 0.241  exp loss = 0.242  adjusted loss = 0.242  adv prob = 0.250000   acc = 0.929
  waterbird_complete95 = 1, forest2water2 = 0  [n = 21]:	loss = 0.613  exp loss = 0.585  adjusted loss = 0.585  adv prob = 0.250000   acc = 0.714
  waterbird_complete95 = 1, forest2water2 = 1  [n = 373]:	loss = 0.143  exp loss = 0.141  adjusted loss = 0.141  adv prob = 0.250000   acc = 0.973

Validation:
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_val_epoch_79.csv
logged to wandb
Average incurred loss: 0.469  
Average sample loss: 0.466  
Average acc: 0.776  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.040  exp loss = 0.037  adjusted loss = 0.037  adv prob = 0.250000   acc = 0.996
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.576  exp loss = 0.554  adjusted loss = 0.554  adv prob = 0.250000   acc = 0.685
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.774  exp loss = 1.889  adjusted loss = 1.889  adv prob = 0.250000   acc = 0.195
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.296  exp loss = 0.312  adjusted loss = 0.312  adv prob = 0.250000   acc = 0.902
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_test_epoch_79.csv
logged to wandb
Current lr: 0.000010


Epoch [80]:
Training:
Average incurred loss: 0.071  
Average sample loss: 0.071  
Average acc: 0.988  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2336]:	loss = 0.031  exp loss = 0.031  adjusted loss = 0.031  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 135]:	loss = 0.309  exp loss = 0.348  adjusted loss = 0.348  adv prob = 0.250000   acc = 0.889
  waterbird_complete95 = 1, forest2water2 = 0  [n = 36]:	loss = 0.660  exp loss = 0.630  adjusted loss = 0.630  adv prob = 0.250000   acc = 0.667
  waterbird_complete95 = 1, forest2water2 = 1  [n = 693]:	loss = 0.129  exp loss = 0.110  adjusted loss = 0.110  adv prob = 0.250000   acc = 0.984
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_train_epoch_80.csv
logged to wandb
Average incurred loss: 0.068  
Average sample loss: 0.068  
Average acc: 0.991  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 1162]:	loss = 0.031  exp loss = 0.032  adjusted loss = 0.032  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 49]:	loss = 0.297  exp loss = 0.386  adjusted loss = 0.386  adv prob = 0.250000   acc = 0.898
  waterbird_complete95 = 1, forest2water2 = 0  [n = 20]:	loss = 0.528  exp loss = 0.520  adjusted loss = 0.520  adv prob = 0.250000   acc = 0.750
  waterbird_complete95 = 1, forest2water2 = 1  [n = 364]:	loss = 0.127  exp loss = 0.119  adjusted loss = 0.119  adv prob = 0.250000   acc = 0.986

Validation:
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_val_epoch_80.csv
logged to wandb
Average incurred loss: 0.494  
Average sample loss: 0.491  
Average acc: 0.752  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.050  exp loss = 0.046  adjusted loss = 0.046  adv prob = 0.250000   acc = 0.991
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.696  exp loss = 0.669  adjusted loss = 0.669  adv prob = 0.250000   acc = 0.599
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.600  exp loss = 1.696  adjusted loss = 1.696  adv prob = 0.250000   acc = 0.256
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.239  exp loss = 0.252  adjusted loss = 0.252  adv prob = 0.250000   acc = 0.947
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_test_epoch_80.csv
logged to wandb
Current lr: 0.000010


Epoch [81]:
Training:
Average incurred loss: 0.068  
Average sample loss: 0.068  
Average acc: 0.991  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2312]:	loss = 0.029  exp loss = 0.030  adjusted loss = 0.030  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 127]:	loss = 0.279  exp loss = 0.262  adjusted loss = 0.262  adv prob = 0.250000   acc = 0.937
  waterbird_complete95 = 1, forest2water2 = 0  [n = 41]:	loss = 0.532  exp loss = 0.514  adjusted loss = 0.514  adv prob = 0.250000   acc = 0.756
  waterbird_complete95 = 1, forest2water2 = 1  [n = 720]:	loss = 0.129  exp loss = 0.115  adjusted loss = 0.115  adv prob = 0.250000   acc = 0.985
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_train_epoch_81.csv
logged to wandb
Average incurred loss: 0.072  
Average sample loss: 0.072  
Average acc: 0.990  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 1186]:	loss = 0.035  exp loss = 0.037  adjusted loss = 0.037  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 57]:	loss = 0.289  exp loss = 0.291  adjusted loss = 0.291  adv prob = 0.250000   acc = 0.947
  waterbird_complete95 = 1, forest2water2 = 0  [n = 15]:	loss = 0.769  exp loss = 0.633  adjusted loss = 0.633  adv prob = 0.250000   acc = 0.600
  waterbird_complete95 = 1, forest2water2 = 1  [n = 337]:	loss = 0.138  exp loss = 0.111  adjusted loss = 0.111  adv prob = 0.250000   acc = 0.979

Validation:
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_val_epoch_81.csv
logged to wandb
Average incurred loss: 0.496  
Average sample loss: 0.493  
Average acc: 0.753  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.051  exp loss = 0.047  adjusted loss = 0.047  adv prob = 0.250000   acc = 0.994
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.709  exp loss = 0.684  adjusted loss = 0.684  adv prob = 0.250000   acc = 0.594
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.577  exp loss = 1.673  adjusted loss = 1.673  adv prob = 0.250000   acc = 0.263
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.233  exp loss = 0.244  adjusted loss = 0.244  adv prob = 0.250000   acc = 0.955
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_test_epoch_81.csv
logged to wandb
Current lr: 0.000010


Epoch [82]:
Training:
Average incurred loss: 0.067  
Average sample loss: 0.067  
Average acc: 0.992  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2348]:	loss = 0.031  exp loss = 0.030  adjusted loss = 0.030  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 122]:	loss = 0.307  exp loss = 0.274  adjusted loss = 0.274  adv prob = 0.250000   acc = 0.926
  waterbird_complete95 = 1, forest2water2 = 0  [n = 36]:	loss = 0.514  exp loss = 0.411  adjusted loss = 0.411  adv prob = 0.250000   acc = 0.833
  waterbird_complete95 = 1, forest2water2 = 1  [n = 694]:	loss = 0.122  exp loss = 0.124  adjusted loss = 0.124  adv prob = 0.250000   acc = 0.983
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_train_epoch_82.csv
logged to wandb
Average incurred loss: 0.071  
Average sample loss: 0.071  
Average acc: 0.987  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 1150]:	loss = 0.029  exp loss = 0.028  adjusted loss = 0.028  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 62]:	loss = 0.255  exp loss = 0.249  adjusted loss = 0.249  adv prob = 0.250000   acc = 0.935
  waterbird_complete95 = 1, forest2water2 = 0  [n = 20]:	loss = 0.718  exp loss = 0.633  adjusted loss = 0.633  adv prob = 0.250000   acc = 0.550
  waterbird_complete95 = 1, forest2water2 = 1  [n = 363]:	loss = 0.138  exp loss = 0.132  adjusted loss = 0.132  adv prob = 0.250000   acc = 0.978

Validation:
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_val_epoch_82.csv
logged to wandb
Average incurred loss: 0.471  
Average sample loss: 0.468  
Average acc: 0.780  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.041  exp loss = 0.037  adjusted loss = 0.037  adv prob = 0.250000   acc = 0.996
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.600  exp loss = 0.578  adjusted loss = 0.578  adv prob = 0.250000   acc = 0.680
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.724  exp loss = 1.834  adjusted loss = 1.834  adv prob = 0.250000   acc = 0.226
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.277  exp loss = 0.292  adjusted loss = 0.292  adv prob = 0.250000   acc = 0.925
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_test_epoch_82.csv
logged to wandb
Current lr: 0.000010


Epoch [83]:
Training:
Average incurred loss: 0.067  
Average sample loss: 0.067  
Average acc: 0.990  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2351]:	loss = 0.031  exp loss = 0.030  adjusted loss = 0.030  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 125]:	loss = 0.269  exp loss = 0.311  adjusted loss = 0.311  adv prob = 0.250000   acc = 0.952
  waterbird_complete95 = 1, forest2water2 = 0  [n = 43]:	loss = 0.574  exp loss = 0.607  adjusted loss = 0.607  adv prob = 0.250000   acc = 0.651
  waterbird_complete95 = 1, forest2water2 = 1  [n = 681]:	loss = 0.121  exp loss = 0.113  adjusted loss = 0.113  adv prob = 0.250000   acc = 0.985
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_train_epoch_83.csv
logged to wandb
Average incurred loss: 0.068  
Average sample loss: 0.068  
Average acc: 0.991  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 1147]:	loss = 0.028  exp loss = 0.027  adjusted loss = 0.027  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 59]:	loss = 0.325  exp loss = 0.327  adjusted loss = 0.327  adv prob = 0.250000   acc = 0.932
  waterbird_complete95 = 1, forest2water2 = 0  [n = 13]:	loss = 0.506  exp loss = 0.520  adjusted loss = 0.520  adv prob = 0.250000   acc = 0.769
  waterbird_complete95 = 1, forest2water2 = 1  [n = 376]:	loss = 0.135  exp loss = 0.138  adjusted loss = 0.138  adv prob = 0.250000   acc = 0.981

Validation:
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_val_epoch_83.csv
logged to wandb
Average incurred loss: 0.466  
Average sample loss: 0.463  
Average acc: 0.776  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.041  exp loss = 0.037  adjusted loss = 0.037  adv prob = 0.250000   acc = 0.996
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.587  exp loss = 0.565  adjusted loss = 0.565  adv prob = 0.250000   acc = 0.678
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.725  exp loss = 1.837  adjusted loss = 1.837  adv prob = 0.250000   acc = 0.203
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.281  exp loss = 0.295  adjusted loss = 0.295  adv prob = 0.250000   acc = 0.925
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_test_epoch_83.csv
logged to wandb
Current lr: 0.000010


Epoch [84]:
Training:
Average incurred loss: 0.067  
Average sample loss: 0.067  
Average acc: 0.990  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2317]:	loss = 0.029  exp loss = 0.032  adjusted loss = 0.032  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 130]:	loss = 0.284  exp loss = 0.278  adjusted loss = 0.278  adv prob = 0.250000   acc = 0.938
  waterbird_complete95 = 1, forest2water2 = 0  [n = 41]:	loss = 0.558  exp loss = 0.575  adjusted loss = 0.575  adv prob = 0.250000   acc = 0.707
  waterbird_complete95 = 1, forest2water2 = 1  [n = 712]:	loss = 0.123  exp loss = 0.103  adjusted loss = 0.103  adv prob = 0.250000   acc = 0.986
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_train_epoch_84.csv
logged to wandb
Average incurred loss: 0.064  
Average sample loss: 0.064  
Average acc: 0.992  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 1181]:	loss = 0.031  exp loss = 0.031  adjusted loss = 0.031  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 54]:	loss = 0.278  exp loss = 0.226  adjusted loss = 0.226  adv prob = 0.250000   acc = 0.963
  waterbird_complete95 = 1, forest2water2 = 0  [n = 15]:	loss = 0.569  exp loss = 0.561  adjusted loss = 0.561  adv prob = 0.250000   acc = 0.667
  waterbird_complete95 = 1, forest2water2 = 1  [n = 345]:	loss = 0.120  exp loss = 0.109  adjusted loss = 0.109  adv prob = 0.250000   acc = 0.986

Validation:
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_val_epoch_84.csv
logged to wandb
Average incurred loss: 0.483  
Average sample loss: 0.480  
Average acc: 0.764  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.047  exp loss = 0.042  adjusted loss = 0.042  adv prob = 0.250000   acc = 0.996
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.664  exp loss = 0.641  adjusted loss = 0.641  adv prob = 0.250000   acc = 0.629
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.622  exp loss = 1.724  adjusted loss = 1.724  adv prob = 0.250000   acc = 0.256
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.243  exp loss = 0.255  adjusted loss = 0.255  adv prob = 0.250000   acc = 0.932
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_test_epoch_84.csv
logged to wandb
Current lr: 0.000010


Epoch [85]:
Training:
Average incurred loss: 0.066  
Average sample loss: 0.066  
Average acc: 0.989  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2353]:	loss = 0.030  exp loss = 0.029  adjusted loss = 0.029  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 121]:	loss = 0.289  exp loss = 0.249  adjusted loss = 0.249  adv prob = 0.250000   acc = 0.884
  waterbird_complete95 = 1, forest2water2 = 0  [n = 32]:	loss = 0.624  exp loss = 0.566  adjusted loss = 0.566  adv prob = 0.250000   acc = 0.719
  waterbird_complete95 = 1, forest2water2 = 1  [n = 694]:	loss = 0.122  exp loss = 0.111  adjusted loss = 0.111  adv prob = 0.250000   acc = 0.984
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_train_epoch_85.csv
logged to wandb
Average incurred loss: 0.066  
Average sample loss: 0.066  
Average acc: 0.991  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 1145]:	loss = 0.028  exp loss = 0.028  adjusted loss = 0.028  adv prob = 0.250000   acc = 0.999
  waterbird_complete95 = 0, forest2water2 = 1  [n = 63]:	loss = 0.271  exp loss = 0.283  adjusted loss = 0.283  adv prob = 0.250000   acc = 0.937
  waterbird_complete95 = 1, forest2water2 = 0  [n = 24]:	loss = 0.416  exp loss = 0.457  adjusted loss = 0.457  adv prob = 0.250000   acc = 0.792
  waterbird_complete95 = 1, forest2water2 = 1  [n = 363]:	loss = 0.126  exp loss = 0.099  adjusted loss = 0.099  adv prob = 0.250000   acc = 0.986

Validation:
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_val_epoch_85.csv
logged to wandb
Average incurred loss: 0.476  
Average sample loss: 0.472  
Average acc: 0.772  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.044  exp loss = 0.040  adjusted loss = 0.040  adv prob = 0.250000   acc = 0.996
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.634  exp loss = 0.610  adjusted loss = 0.610  adv prob = 0.250000   acc = 0.652
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.659  exp loss = 1.759  adjusted loss = 1.759  adv prob = 0.250000   acc = 0.248
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.255  exp loss = 0.267  adjusted loss = 0.267  adv prob = 0.250000   acc = 0.932
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_test_epoch_85.csv
logged to wandb
Current lr: 0.000010


Epoch [86]:
Training:
Average incurred loss: 0.065  
Average sample loss: 0.065  
Average acc: 0.992  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2335]:	loss = 0.029  exp loss = 0.028  adjusted loss = 0.028  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 115]:	loss = 0.281  exp loss = 0.369  adjusted loss = 0.369  adv prob = 0.250000   acc = 0.948
  waterbird_complete95 = 1, forest2water2 = 0  [n = 35]:	loss = 0.593  exp loss = 0.733  adjusted loss = 0.733  adv prob = 0.250000   acc = 0.743
  waterbird_complete95 = 1, forest2water2 = 1  [n = 715]:	loss = 0.124  exp loss = 0.110  adjusted loss = 0.110  adv prob = 0.250000   acc = 0.983
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_train_epoch_86.csv
logged to wandb
Average incurred loss: 0.065  
Average sample loss: 0.065  
Average acc: 0.991  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 1163]:	loss = 0.030  exp loss = 0.029  adjusted loss = 0.029  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 69]:	loss = 0.247  exp loss = 0.330  adjusted loss = 0.330  adv prob = 0.250000   acc = 0.928
  waterbird_complete95 = 1, forest2water2 = 0  [n = 21]:	loss = 0.518  exp loss = 0.546  adjusted loss = 0.546  adv prob = 0.250000   acc = 0.762
  waterbird_complete95 = 1, forest2water2 = 1  [n = 342]:	loss = 0.116  exp loss = 0.103  adjusted loss = 0.103  adv prob = 0.250000   acc = 0.988

Validation:
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_val_epoch_86.csv
logged to wandb
Average incurred loss: 0.481  
Average sample loss: 0.478  
Average acc: 0.766  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.045  exp loss = 0.041  adjusted loss = 0.041  adv prob = 0.250000   acc = 0.996
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.650  exp loss = 0.626  adjusted loss = 0.626  adv prob = 0.250000   acc = 0.637
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.652  exp loss = 1.758  adjusted loss = 1.758  adv prob = 0.250000   acc = 0.241
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.249  exp loss = 0.262  adjusted loss = 0.262  adv prob = 0.250000   acc = 0.940
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_test_epoch_86.csv
logged to wandb
Current lr: 0.000010


Epoch [87]:
Training:
Average incurred loss: 0.064  
Average sample loss: 0.064  
Average acc: 0.992  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2329]:	loss = 0.028  exp loss = 0.029  adjusted loss = 0.029  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 129]:	loss = 0.282  exp loss = 0.270  adjusted loss = 0.270  adv prob = 0.250000   acc = 0.930
  waterbird_complete95 = 1, forest2water2 = 0  [n = 29]:	loss = 0.483  exp loss = 0.533  adjusted loss = 0.533  adv prob = 0.250000   acc = 0.828
  waterbird_complete95 = 1, forest2water2 = 1  [n = 713]:	loss = 0.125  exp loss = 0.112  adjusted loss = 0.112  adv prob = 0.250000   acc = 0.985
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_train_epoch_87.csv
logged to wandb
Average incurred loss: 0.065  
Average sample loss: 0.065  
Average acc: 0.987  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 1169]:	loss = 0.029  exp loss = 0.029  adjusted loss = 0.029  adv prob = 0.250000   acc = 0.999
  waterbird_complete95 = 0, forest2water2 = 1  [n = 55]:	loss = 0.308  exp loss = 0.358  adjusted loss = 0.358  adv prob = 0.250000   acc = 0.891
  waterbird_complete95 = 1, forest2water2 = 0  [n = 27]:	loss = 0.566  exp loss = 0.607  adjusted loss = 0.607  adv prob = 0.250000   acc = 0.704
  waterbird_complete95 = 1, forest2water2 = 1  [n = 344]:	loss = 0.109  exp loss = 0.105  adjusted loss = 0.105  adv prob = 0.250000   acc = 0.985

Validation:
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_val_epoch_87.csv
logged to wandb
Average incurred loss: 0.482  
Average sample loss: 0.479  
Average acc: 0.764  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.046  exp loss = 0.041  adjusted loss = 0.041  adv prob = 0.250000   acc = 0.996
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.660  exp loss = 0.635  adjusted loss = 0.635  adv prob = 0.250000   acc = 0.629
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.629  exp loss = 1.735  adjusted loss = 1.735  adv prob = 0.250000   acc = 0.256
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.242  exp loss = 0.254  adjusted loss = 0.254  adv prob = 0.250000   acc = 0.932
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_test_epoch_87.csv
logged to wandb
Current lr: 0.000010


Epoch [88]:
Training:
Average incurred loss: 0.063  
Average sample loss: 0.063  
Average acc: 0.991  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2319]:	loss = 0.027  exp loss = 0.026  adjusted loss = 0.026  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 133]:	loss = 0.277  exp loss = 0.244  adjusted loss = 0.244  adv prob = 0.250000   acc = 0.925
  waterbird_complete95 = 1, forest2water2 = 0  [n = 38]:	loss = 0.575  exp loss = 0.515  adjusted loss = 0.515  adv prob = 0.250000   acc = 0.658
  waterbird_complete95 = 1, forest2water2 = 1  [n = 710]:	loss = 0.113  exp loss = 0.117  adjusted loss = 0.117  adv prob = 0.250000   acc = 0.992
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_train_epoch_88.csv
logged to wandb
Average incurred loss: 0.062  
Average sample loss: 0.062  
Average acc: 0.992  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 1179]:	loss = 0.029  exp loss = 0.029  adjusted loss = 0.029  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 51]:	loss = 0.258  exp loss = 0.256  adjusted loss = 0.256  adv prob = 0.250000   acc = 0.980
  waterbird_complete95 = 1, forest2water2 = 0  [n = 18]:	loss = 0.460  exp loss = 0.476  adjusted loss = 0.476  adv prob = 0.250000   acc = 0.944
  waterbird_complete95 = 1, forest2water2 = 1  [n = 347]:	loss = 0.126  exp loss = 0.123  adjusted loss = 0.123  adv prob = 0.250000   acc = 0.968

Validation:
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_val_epoch_88.csv
logged to wandb
Average incurred loss: 0.478  
Average sample loss: 0.474  
Average acc: 0.770  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.044  exp loss = 0.040  adjusted loss = 0.040  adv prob = 0.250000   acc = 0.996
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.647  exp loss = 0.624  adjusted loss = 0.624  adv prob = 0.250000   acc = 0.642
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.639  exp loss = 1.741  adjusted loss = 1.741  adv prob = 0.250000   acc = 0.263
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.245  exp loss = 0.257  adjusted loss = 0.257  adv prob = 0.250000   acc = 0.932
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_test_epoch_88.csv
logged to wandb
Current lr: 0.000010


Epoch [89]:
Training:
Average incurred loss: 0.065  
Average sample loss: 0.065  
Average acc: 0.990  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2351]:	loss = 0.029  exp loss = 0.027  adjusted loss = 0.027  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 123]:	loss = 0.284  exp loss = 0.293  adjusted loss = 0.293  adv prob = 0.250000   acc = 0.943
  waterbird_complete95 = 1, forest2water2 = 0  [n = 36]:	loss = 0.550  exp loss = 0.522  adjusted loss = 0.522  adv prob = 0.250000   acc = 0.778
  waterbird_complete95 = 1, forest2water2 = 1  [n = 690]:	loss = 0.126  exp loss = 0.118  adjusted loss = 0.118  adv prob = 0.250000   acc = 0.974
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_train_epoch_89.csv
logged to wandb
Average incurred loss: 0.064  
Average sample loss: 0.064  
Average acc: 0.992  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 1147]:	loss = 0.026  exp loss = 0.026  adjusted loss = 0.026  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 61]:	loss = 0.269  exp loss = 0.257  adjusted loss = 0.257  adv prob = 0.250000   acc = 0.951
  waterbird_complete95 = 1, forest2water2 = 0  [n = 20]:	loss = 0.596  exp loss = 0.540  adjusted loss = 0.540  adv prob = 0.250000   acc = 0.750
  waterbird_complete95 = 1, forest2water2 = 1  [n = 367]:	loss = 0.119  exp loss = 0.107  adjusted loss = 0.107  adv prob = 0.250000   acc = 0.989

Validation:
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_val_epoch_89.csv
logged to wandb
Average incurred loss: 0.477  
Average sample loss: 0.474  
Average acc: 0.772  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.042  exp loss = 0.038  adjusted loss = 0.038  adv prob = 0.250000   acc = 0.996
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.632  exp loss = 0.608  adjusted loss = 0.608  adv prob = 0.250000   acc = 0.655
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.689  exp loss = 1.798  adjusted loss = 1.798  adv prob = 0.250000   acc = 0.241
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.253  exp loss = 0.267  adjusted loss = 0.267  adv prob = 0.250000   acc = 0.932
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_test_epoch_89.csv
logged to wandb
Current lr: 0.000010


Epoch [90]:
Training:
Average incurred loss: 0.063  
Average sample loss: 0.063  
Average acc: 0.990  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2320]:	loss = 0.028  exp loss = 0.030  adjusted loss = 0.030  adv prob = 0.250000   acc = 0.999
  waterbird_complete95 = 0, forest2water2 = 1  [n = 130]:	loss = 0.258  exp loss = 0.246  adjusted loss = 0.246  adv prob = 0.250000   acc = 0.946
  waterbird_complete95 = 1, forest2water2 = 0  [n = 32]:	loss = 0.621  exp loss = 0.565  adjusted loss = 0.565  adv prob = 0.250000   acc = 0.750
  waterbird_complete95 = 1, forest2water2 = 1  [n = 718]:	loss = 0.119  exp loss = 0.101  adjusted loss = 0.101  adv prob = 0.250000   acc = 0.982
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_train_epoch_90.csv
logged to wandb
Average incurred loss: 0.060  
Average sample loss: 0.060  
Average acc: 0.991  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 1178]:	loss = 0.029  exp loss = 0.031  adjusted loss = 0.031  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 54]:	loss = 0.258  exp loss = 0.255  adjusted loss = 0.255  adv prob = 0.250000   acc = 0.926
  waterbird_complete95 = 1, forest2water2 = 0  [n = 24]:	loss = 0.494  exp loss = 0.527  adjusted loss = 0.527  adv prob = 0.250000   acc = 0.750
  waterbird_complete95 = 1, forest2water2 = 1  [n = 339]:	loss = 0.103  exp loss = 0.095  adjusted loss = 0.095  adv prob = 0.250000   acc = 0.988

Validation:
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_val_epoch_90.csv
logged to wandb
Average incurred loss: 0.497  
Average sample loss: 0.494  
Average acc: 0.746  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.050  exp loss = 0.045  adjusted loss = 0.045  adv prob = 0.250000   acc = 0.991
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.727  exp loss = 0.699  adjusted loss = 0.699  adv prob = 0.250000   acc = 0.577
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.550  exp loss = 1.641  adjusted loss = 1.641  adv prob = 0.250000   acc = 0.271
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.213  exp loss = 0.222  adjusted loss = 0.222  adv prob = 0.250000   acc = 0.955
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_test_epoch_90.csv
logged to wandb
Current lr: 0.000010


Epoch [91]:
Training:
Average incurred loss: 0.059  
Average sample loss: 0.059  
Average acc: 0.993  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2373]:	loss = 0.030  exp loss = 0.032  adjusted loss = 0.032  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 115]:	loss = 0.253  exp loss = 0.250  adjusted loss = 0.250  adv prob = 0.250000   acc = 0.957
  waterbird_complete95 = 1, forest2water2 = 0  [n = 37]:	loss = 0.471  exp loss = 0.465  adjusted loss = 0.465  adv prob = 0.250000   acc = 0.811
  waterbird_complete95 = 1, forest2water2 = 1  [n = 675]:	loss = 0.106  exp loss = 0.104  adjusted loss = 0.104  adv prob = 0.250000   acc = 0.988
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_train_epoch_91.csv
logged to wandb
Average incurred loss: 0.060  
Average sample loss: 0.060  
Average acc: 0.992  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 1125]:	loss = 0.022  exp loss = 0.023  adjusted loss = 0.023  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 69]:	loss = 0.231  exp loss = 0.273  adjusted loss = 0.273  adv prob = 0.250000   acc = 0.957
  waterbird_complete95 = 1, forest2water2 = 0  [n = 19]:	loss = 0.582  exp loss = 0.597  adjusted loss = 0.597  adv prob = 0.250000   acc = 0.684
  waterbird_complete95 = 1, forest2water2 = 1  [n = 382]:	loss = 0.114  exp loss = 0.104  adjusted loss = 0.104  adv prob = 0.250000   acc = 0.992

Validation:
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_val_epoch_91.csv
logged to wandb
Average incurred loss: 0.462  
Average sample loss: 0.458  
Average acc: 0.786  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.039  exp loss = 0.035  adjusted loss = 0.035  adv prob = 0.250000   acc = 0.996
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.582  exp loss = 0.561  adjusted loss = 0.561  adv prob = 0.250000   acc = 0.689
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.721  exp loss = 1.829  adjusted loss = 1.829  adv prob = 0.250000   acc = 0.241
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.269  exp loss = 0.283  adjusted loss = 0.283  adv prob = 0.250000   acc = 0.932
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_test_epoch_91.csv
logged to wandb
Current lr: 0.000010


Epoch [92]:
Training:
Average incurred loss: 0.059  
Average sample loss: 0.059  
Average acc: 0.993  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2347]:	loss = 0.028  exp loss = 0.024  adjusted loss = 0.024  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 111]:	loss = 0.269  exp loss = 0.286  adjusted loss = 0.286  adv prob = 0.250000   acc = 0.946
  waterbird_complete95 = 1, forest2water2 = 0  [n = 34]:	loss = 0.492  exp loss = 0.477  adjusted loss = 0.477  adv prob = 0.250000   acc = 0.824
  waterbird_complete95 = 1, forest2water2 = 1  [n = 708]:	loss = 0.107  exp loss = 0.100  adjusted loss = 0.100  adv prob = 0.250000   acc = 0.986
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_train_epoch_92.csv
logged to wandb
Average incurred loss: 0.063  
Average sample loss: 0.063  
Average acc: 0.991  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 1151]:	loss = 0.027  exp loss = 0.026  adjusted loss = 0.026  adv prob = 0.250000   acc = 0.999
  waterbird_complete95 = 0, forest2water2 = 1  [n = 73]:	loss = 0.228  exp loss = 0.256  adjusted loss = 0.256  adv prob = 0.250000   acc = 0.973
  waterbird_complete95 = 1, forest2water2 = 0  [n = 22]:	loss = 0.497  exp loss = 0.460  adjusted loss = 0.460  adv prob = 0.250000   acc = 0.818
  waterbird_complete95 = 1, forest2water2 = 1  [n = 349]:	loss = 0.123  exp loss = 0.111  adjusted loss = 0.111  adv prob = 0.250000   acc = 0.980

Validation:
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_val_epoch_92.csv
logged to wandb
Average incurred loss: 0.473  
Average sample loss: 0.470  
Average acc: 0.778  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.040  exp loss = 0.036  adjusted loss = 0.036  adv prob = 0.250000   acc = 0.996
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.619  exp loss = 0.596  adjusted loss = 0.596  adv prob = 0.250000   acc = 0.670
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.704  exp loss = 1.807  adjusted loss = 1.807  adv prob = 0.250000   acc = 0.241
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.255  exp loss = 0.267  adjusted loss = 0.267  adv prob = 0.250000   acc = 0.932
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_test_epoch_92.csv
logged to wandb
Current lr: 0.000010


Epoch [93]:
Training:
Average incurred loss: 0.062  
Average sample loss: 0.062  
Average acc: 0.990  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2331]:	loss = 0.028  exp loss = 0.026  adjusted loss = 0.026  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 120]:	loss = 0.263  exp loss = 0.278  adjusted loss = 0.278  adv prob = 0.250000   acc = 0.942
  waterbird_complete95 = 1, forest2water2 = 0  [n = 39]:	loss = 0.527  exp loss = 0.505  adjusted loss = 0.505  adv prob = 0.250000   acc = 0.692
  waterbird_complete95 = 1, forest2water2 = 1  [n = 710]:	loss = 0.116  exp loss = 0.097  adjusted loss = 0.097  adv prob = 0.250000   acc = 0.985
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_train_epoch_93.csv
logged to wandb
Average incurred loss: 0.059  
Average sample loss: 0.059  
Average acc: 0.994  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 1167]:	loss = 0.027  exp loss = 0.026  adjusted loss = 0.026  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 64]:	loss = 0.266  exp loss = 0.299  adjusted loss = 0.299  adv prob = 0.250000   acc = 0.953
  waterbird_complete95 = 1, forest2water2 = 0  [n = 17]:	loss = 0.442  exp loss = 0.448  adjusted loss = 0.448  adv prob = 0.250000   acc = 0.824
  waterbird_complete95 = 1, forest2water2 = 1  [n = 347]:	loss = 0.109  exp loss = 0.101  adjusted loss = 0.101  adv prob = 0.250000   acc = 0.991

Validation:
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_val_epoch_93.csv
logged to wandb
Average incurred loss: 0.472  
Average sample loss: 0.468  
Average acc: 0.773  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.042  exp loss = 0.038  adjusted loss = 0.038  adv prob = 0.250000   acc = 0.996
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.636  exp loss = 0.614  adjusted loss = 0.614  adv prob = 0.250000   acc = 0.652
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.635  exp loss = 1.734  adjusted loss = 1.734  adv prob = 0.250000   acc = 0.256
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.240  exp loss = 0.251  adjusted loss = 0.251  adv prob = 0.250000   acc = 0.932
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_test_epoch_93.csv
logged to wandb
Current lr: 0.000010


Epoch [94]:
Training:
Average incurred loss: 0.059  
Average sample loss: 0.059  
Average acc: 0.993  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2335]:	loss = 0.026  exp loss = 0.025  adjusted loss = 0.025  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 121]:	loss = 0.257  exp loss = 0.299  adjusted loss = 0.299  adv prob = 0.250000   acc = 0.942
  waterbird_complete95 = 1, forest2water2 = 0  [n = 34]:	loss = 0.476  exp loss = 0.456  adjusted loss = 0.456  adv prob = 0.250000   acc = 0.765
  waterbird_complete95 = 1, forest2water2 = 1  [n = 710]:	loss = 0.114  exp loss = 0.102  adjusted loss = 0.102  adv prob = 0.250000   acc = 0.987
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_train_epoch_94.csv
logged to wandb
Average incurred loss: 0.057  
Average sample loss: 0.057  
Average acc: 0.995  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 1163]:	loss = 0.026  exp loss = 0.024  adjusted loss = 0.024  adv prob = 0.250000   acc = 0.999
  waterbird_complete95 = 0, forest2water2 = 1  [n = 63]:	loss = 0.235  exp loss = 0.242  adjusted loss = 0.242  adv prob = 0.250000   acc = 0.984
  waterbird_complete95 = 1, forest2water2 = 0  [n = 22]:	loss = 0.489  exp loss = 0.461  adjusted loss = 0.461  adv prob = 0.250000   acc = 0.818
  waterbird_complete95 = 1, forest2water2 = 1  [n = 347]:	loss = 0.100  exp loss = 0.095  adjusted loss = 0.095  adv prob = 0.250000   acc = 0.994

Validation:
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_val_epoch_94.csv
logged to wandb
Average incurred loss: 0.471  
Average sample loss: 0.468  
Average acc: 0.779  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.039  exp loss = 0.036  adjusted loss = 0.036  adv prob = 0.250000   acc = 0.996
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.616  exp loss = 0.594  adjusted loss = 0.594  adv prob = 0.250000   acc = 0.670
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.699  exp loss = 1.805  adjusted loss = 1.805  adv prob = 0.250000   acc = 0.248
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.250  exp loss = 0.261  adjusted loss = 0.261  adv prob = 0.250000   acc = 0.932
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_test_epoch_94.csv
logged to wandb
Current lr: 0.000010


Epoch [95]:
Training:
Average incurred loss: 0.060  
Average sample loss: 0.060  
Average acc: 0.990  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2337]:	loss = 0.028  exp loss = 0.028  adjusted loss = 0.028  adv prob = 0.250000   acc = 0.999
  waterbird_complete95 = 0, forest2water2 = 1  [n = 120]:	loss = 0.236  exp loss = 0.218  adjusted loss = 0.218  adv prob = 0.250000   acc = 0.950
  waterbird_complete95 = 1, forest2water2 = 0  [n = 42]:	loss = 0.519  exp loss = 0.479  adjusted loss = 0.479  adv prob = 0.250000   acc = 0.738
  waterbird_complete95 = 1, forest2water2 = 1  [n = 701]:	loss = 0.110  exp loss = 0.089  adjusted loss = 0.089  adv prob = 0.250000   acc = 0.983
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_train_epoch_95.csv
logged to wandb
Average incurred loss: 0.055  
Average sample loss: 0.055  
Average acc: 0.994  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 1161]:	loss = 0.025  exp loss = 0.025  adjusted loss = 0.025  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 64]:	loss = 0.265  exp loss = 0.289  adjusted loss = 0.289  adv prob = 0.250000   acc = 0.922
  waterbird_complete95 = 1, forest2water2 = 0  [n = 14]:	loss = 0.421  exp loss = 0.432  adjusted loss = 0.432  adv prob = 0.250000   acc = 0.857
  waterbird_complete95 = 1, forest2water2 = 1  [n = 356]:	loss = 0.101  exp loss = 0.083  adjusted loss = 0.083  adv prob = 0.250000   acc = 0.992

Validation:
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_val_epoch_95.csv
logged to wandb
Average incurred loss: 0.484  
Average sample loss: 0.481  
Average acc: 0.761  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.046  exp loss = 0.042  adjusted loss = 0.042  adv prob = 0.250000   acc = 0.996
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.687  exp loss = 0.662  adjusted loss = 0.662  adv prob = 0.250000   acc = 0.612
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.576  exp loss = 1.673  adjusted loss = 1.673  adv prob = 0.250000   acc = 0.271
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.220  exp loss = 0.230  adjusted loss = 0.230  adv prob = 0.250000   acc = 0.955
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_test_epoch_95.csv
logged to wandb
Current lr: 0.000010


Epoch [96]:
Training:
Average incurred loss: 0.059  
Average sample loss: 0.059  
Average acc: 0.993  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2345]:	loss = 0.028  exp loss = 0.028  adjusted loss = 0.028  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 116]:	loss = 0.230  exp loss = 0.265  adjusted loss = 0.265  adv prob = 0.250000   acc = 0.957
  waterbird_complete95 = 1, forest2water2 = 0  [n = 32]:	loss = 0.483  exp loss = 0.468  adjusted loss = 0.468  adv prob = 0.250000   acc = 0.781
  waterbird_complete95 = 1, forest2water2 = 1  [n = 707]:	loss = 0.116  exp loss = 0.090  adjusted loss = 0.090  adv prob = 0.250000   acc = 0.983
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_train_epoch_96.csv
logged to wandb
Average incurred loss: 0.061  
Average sample loss: 0.060  
Average acc: 0.989  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 1153]:	loss = 0.024  exp loss = 0.023  adjusted loss = 0.023  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 68]:	loss = 0.239  exp loss = 0.224  adjusted loss = 0.224  adv prob = 0.250000   acc = 0.926
  waterbird_complete95 = 1, forest2water2 = 0  [n = 24]:	loss = 0.508  exp loss = 0.535  adjusted loss = 0.535  adv prob = 0.250000   acc = 0.750
  waterbird_complete95 = 1, forest2water2 = 1  [n = 350]:	loss = 0.116  exp loss = 0.111  adjusted loss = 0.111  adv prob = 0.250000   acc = 0.983

Validation:
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_val_epoch_96.csv
logged to wandb
Average incurred loss: 0.470  
Average sample loss: 0.466  
Average acc: 0.782  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.039  exp loss = 0.035  adjusted loss = 0.035  adv prob = 0.250000   acc = 0.996
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.613  exp loss = 0.590  adjusted loss = 0.590  adv prob = 0.250000   acc = 0.678
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.702  exp loss = 1.810  adjusted loss = 1.810  adv prob = 0.250000   acc = 0.248
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.251  exp loss = 0.263  adjusted loss = 0.263  adv prob = 0.250000   acc = 0.932
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_test_epoch_96.csv
logged to wandb
Current lr: 0.000010


Epoch [97]:
Training:
Average incurred loss: 0.056  
Average sample loss: 0.056  
Average acc: 0.994  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2326]:	loss = 0.025  exp loss = 0.021  adjusted loss = 0.021  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 116]:	loss = 0.248  exp loss = 0.244  adjusted loss = 0.244  adv prob = 0.250000   acc = 0.948
  waterbird_complete95 = 1, forest2water2 = 0  [n = 34]:	loss = 0.486  exp loss = 0.478  adjusted loss = 0.478  adv prob = 0.250000   acc = 0.824
  waterbird_complete95 = 1, forest2water2 = 1  [n = 724]:	loss = 0.103  exp loss = 0.095  adjusted loss = 0.095  adv prob = 0.250000   acc = 0.992
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_train_epoch_97.csv
logged to wandb
Average incurred loss: 0.058  
Average sample loss: 0.059  
Average acc: 0.991  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 1172]:	loss = 0.027  exp loss = 0.024  adjusted loss = 0.024  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 68]:	loss = 0.233  exp loss = 0.202  adjusted loss = 0.202  adv prob = 0.250000   acc = 0.926
  waterbird_complete95 = 1, forest2water2 = 0  [n = 22]:	loss = 0.372  exp loss = 0.399  adjusted loss = 0.399  adv prob = 0.250000   acc = 0.955
  waterbird_complete95 = 1, forest2water2 = 1  [n = 333]:	loss = 0.113  exp loss = 0.124  adjusted loss = 0.124  adv prob = 0.250000   acc = 0.976

Validation:
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_val_epoch_97.csv
logged to wandb
Average incurred loss: 0.465  
Average sample loss: 0.462  
Average acc: 0.783  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.037  exp loss = 0.033  adjusted loss = 0.033  adv prob = 0.250000   acc = 0.996
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.593  exp loss = 0.570  adjusted loss = 0.570  adv prob = 0.250000   acc = 0.682
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.732  exp loss = 1.848  adjusted loss = 1.848  adv prob = 0.250000   acc = 0.241
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.258  exp loss = 0.271  adjusted loss = 0.271  adv prob = 0.250000   acc = 0.932
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_test_epoch_97.csv
logged to wandb
Current lr: 0.000010


Epoch [98]:
Training:
Average incurred loss: 0.055  
Average sample loss: 0.055  
Average acc: 0.994  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2343]:	loss = 0.025  exp loss = 0.024  adjusted loss = 0.024  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 123]:	loss = 0.222  exp loss = 0.236  adjusted loss = 0.236  adv prob = 0.250000   acc = 0.992
  waterbird_complete95 = 1, forest2water2 = 0  [n = 39]:	loss = 0.502  exp loss = 0.441  adjusted loss = 0.441  adv prob = 0.250000   acc = 0.718
  waterbird_complete95 = 1, forest2water2 = 1  [n = 695]:	loss = 0.099  exp loss = 0.102  adjusted loss = 0.102  adv prob = 0.250000   acc = 0.990
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_train_epoch_98.csv
logged to wandb
Average incurred loss: 0.057  
Average sample loss: 0.057  
Average acc: 0.993  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 1155]:	loss = 0.025  exp loss = 0.025  adjusted loss = 0.025  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 61]:	loss = 0.245  exp loss = 0.293  adjusted loss = 0.293  adv prob = 0.250000   acc = 0.951
  waterbird_complete95 = 1, forest2water2 = 0  [n = 17]:	loss = 0.321  exp loss = 0.354  adjusted loss = 0.354  adv prob = 0.250000   acc = 0.941
  waterbird_complete95 = 1, forest2water2 = 1  [n = 362]:	loss = 0.114  exp loss = 0.104  adjusted loss = 0.104  adv prob = 0.250000   acc = 0.981

Validation:
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_val_epoch_98.csv
logged to wandb
Average incurred loss: 0.481  
Average sample loss: 0.478  
Average acc: 0.770  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.041  exp loss = 0.037  adjusted loss = 0.037  adv prob = 0.250000   acc = 0.996
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.655  exp loss = 0.630  adjusted loss = 0.630  adv prob = 0.250000   acc = 0.642
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.666  exp loss = 1.766  adjusted loss = 1.766  adv prob = 0.250000   acc = 0.263
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.233  exp loss = 0.244  adjusted loss = 0.244  adv prob = 0.250000   acc = 0.932
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_test_epoch_98.csv
logged to wandb
Current lr: 0.000010


Epoch [99]:
Training:
Average incurred loss: 0.056  
Average sample loss: 0.056  
Average acc: 0.994  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2347]:	loss = 0.026  exp loss = 0.025  adjusted loss = 0.025  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 129]:	loss = 0.246  exp loss = 0.246  adjusted loss = 0.246  adv prob = 0.250000   acc = 0.946
  waterbird_complete95 = 1, forest2water2 = 0  [n = 31]:	loss = 0.508  exp loss = 0.498  adjusted loss = 0.498  adv prob = 0.250000   acc = 0.742
  waterbird_complete95 = 1, forest2water2 = 1  [n = 693]:	loss = 0.101  exp loss = 0.097  adjusted loss = 0.097  adv prob = 0.250000   acc = 0.993
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_train_epoch_99.csv
logged to wandb
Average incurred loss: 0.060  
Average sample loss: 0.060  
Average acc: 0.991  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 1151]:	loss = 0.024  exp loss = 0.026  adjusted loss = 0.026  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 55]:	loss = 0.282  exp loss = 0.338  adjusted loss = 0.338  adv prob = 0.250000   acc = 0.873
  waterbird_complete95 = 1, forest2water2 = 0  [n = 25]:	loss = 0.497  exp loss = 0.482  adjusted loss = 0.482  adv prob = 0.250000   acc = 0.760
  waterbird_complete95 = 1, forest2water2 = 1  [n = 364]:	loss = 0.111  exp loss = 0.094  adjusted loss = 0.094  adv prob = 0.250000   acc = 0.995

Validation:
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_val_epoch_99.csv
logged to wandb
Average incurred loss: 0.484  
Average sample loss: 0.480  
Average acc: 0.763  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.043  exp loss = 0.039  adjusted loss = 0.039  adv prob = 0.250000   acc = 0.996
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.679  exp loss = 0.655  adjusted loss = 0.655  adv prob = 0.250000   acc = 0.618
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.610  exp loss = 1.705  adjusted loss = 1.705  adv prob = 0.250000   acc = 0.263
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.220  exp loss = 0.230  adjusted loss = 0.230  adv prob = 0.250000   acc = 0.955
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_test_epoch_99.csv
logged to wandb
Current lr: 0.000010


Epoch [100]:
Training:
Average incurred loss: 0.058  
Average sample loss: 0.058  
Average acc: 0.991  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2312]:	loss = 0.024  exp loss = 0.021  adjusted loss = 0.021  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 124]:	loss = 0.243  exp loss = 0.242  adjusted loss = 0.242  adv prob = 0.250000   acc = 0.927
  waterbird_complete95 = 1, forest2water2 = 0  [n = 37]:	loss = 0.510  exp loss = 0.538  adjusted loss = 0.538  adv prob = 0.250000   acc = 0.703
  waterbird_complete95 = 1, forest2water2 = 1  [n = 727]:	loss = 0.112  exp loss = 0.118  adjusted loss = 0.118  adv prob = 0.250000   acc = 0.986
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_train_epoch_100.csv
logged to wandb
Average incurred loss: 0.055  
Average sample loss: 0.055  
Average acc: 0.995  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 1186]:	loss = 0.027  exp loss = 0.026  adjusted loss = 0.026  adv prob = 0.250000   acc = 0.999
  waterbird_complete95 = 0, forest2water2 = 1  [n = 60]:	loss = 0.243  exp loss = 0.269  adjusted loss = 0.269  adv prob = 0.250000   acc = 0.983
  waterbird_complete95 = 1, forest2water2 = 0  [n = 19]:	loss = 0.468  exp loss = 0.473  adjusted loss = 0.473  adv prob = 0.250000   acc = 0.789
  waterbird_complete95 = 1, forest2water2 = 1  [n = 330]:	loss = 0.095  exp loss = 0.094  adjusted loss = 0.094  adv prob = 0.250000   acc = 0.994

Validation:
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_val_epoch_100.csv
logged to wandb
Average incurred loss: 0.480  
Average sample loss: 0.476  
Average acc: 0.767  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.043  exp loss = 0.040  adjusted loss = 0.040  adv prob = 0.250000   acc = 0.996
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.674  exp loss = 0.651  adjusted loss = 0.651  adv prob = 0.250000   acc = 0.624
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.593  exp loss = 1.693  adjusted loss = 1.693  adv prob = 0.250000   acc = 0.286
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.217  exp loss = 0.225  adjusted loss = 0.225  adv prob = 0.250000   acc = 0.947
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_test_epoch_100.csv
logged to wandb
Current lr: 0.000010


Epoch [101]:
Training:
Average incurred loss: 0.056  
Average sample loss: 0.056  
Average acc: 0.995  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2337]:	loss = 0.026  exp loss = 0.026  adjusted loss = 0.026  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 117]:	loss = 0.237  exp loss = 0.238  adjusted loss = 0.238  adv prob = 0.250000   acc = 0.949
  waterbird_complete95 = 1, forest2water2 = 0  [n = 31]:	loss = 0.467  exp loss = 0.420  adjusted loss = 0.420  adv prob = 0.250000   acc = 0.774
  waterbird_complete95 = 1, forest2water2 = 1  [n = 715]:	loss = 0.106  exp loss = 0.092  adjusted loss = 0.092  adv prob = 0.250000   acc = 0.994
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_train_epoch_101.csv
logged to wandb
Average incurred loss: 0.056  
Average sample loss: 0.056  
Average acc: 0.993  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 1161]:	loss = 0.024  exp loss = 0.023  adjusted loss = 0.023  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 67]:	loss = 0.271  exp loss = 0.267  adjusted loss = 0.267  adv prob = 0.250000   acc = 0.955
  waterbird_complete95 = 1, forest2water2 = 0  [n = 25]:	loss = 0.365  exp loss = 0.388  adjusted loss = 0.388  adv prob = 0.250000   acc = 0.920
  waterbird_complete95 = 1, forest2water2 = 1  [n = 342]:	loss = 0.103  exp loss = 0.100  adjusted loss = 0.100  adv prob = 0.250000   acc = 0.982

Validation:
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_val_epoch_101.csv
logged to wandb
Average incurred loss: 0.475  
Average sample loss: 0.472  
Average acc: 0.775  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.040  exp loss = 0.036  adjusted loss = 0.036  adv prob = 0.250000   acc = 0.996
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.646  exp loss = 0.623  adjusted loss = 0.623  adv prob = 0.250000   acc = 0.652
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.651  exp loss = 1.750  adjusted loss = 1.750  adv prob = 0.250000   acc = 0.263
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.229  exp loss = 0.239  adjusted loss = 0.239  adv prob = 0.250000   acc = 0.940
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_test_epoch_101.csv
logged to wandb
Current lr: 0.000010


Epoch [102]:
Training:
Average incurred loss: 0.054  
Average sample loss: 0.054  
Average acc: 0.993  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2318]:	loss = 0.023  exp loss = 0.023  adjusted loss = 0.023  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 134]:	loss = 0.232  exp loss = 0.236  adjusted loss = 0.236  adv prob = 0.250000   acc = 0.955
  waterbird_complete95 = 1, forest2water2 = 0  [n = 33]:	loss = 0.435  exp loss = 0.402  adjusted loss = 0.402  adv prob = 0.250000   acc = 0.848
  waterbird_complete95 = 1, forest2water2 = 1  [n = 715]:	loss = 0.104  exp loss = 0.103  adjusted loss = 0.103  adv prob = 0.250000   acc = 0.983
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_train_epoch_102.csv
logged to wandb
Average incurred loss: 0.055  
Average sample loss: 0.055  
Average acc: 0.992  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 1180]:	loss = 0.026  exp loss = 0.026  adjusted loss = 0.026  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 50]:	loss = 0.241  exp loss = 0.245  adjusted loss = 0.245  adv prob = 0.250000   acc = 0.940
  waterbird_complete95 = 1, forest2water2 = 0  [n = 23]:	loss = 0.515  exp loss = 0.453  adjusted loss = 0.453  adv prob = 0.250000   acc = 0.783
  waterbird_complete95 = 1, forest2water2 = 1  [n = 342]:	loss = 0.099  exp loss = 0.096  adjusted loss = 0.096  adv prob = 0.250000   acc = 0.985

Validation:
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_val_epoch_102.csv
logged to wandb
Average incurred loss: 0.480  
Average sample loss: 0.477  
Average acc: 0.768  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.042  exp loss = 0.038  adjusted loss = 0.038  adv prob = 0.250000   acc = 0.996
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.665  exp loss = 0.641  adjusted loss = 0.641  adv prob = 0.250000   acc = 0.631
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.627  exp loss = 1.730  adjusted loss = 1.730  adv prob = 0.250000   acc = 0.263
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.223  exp loss = 0.233  adjusted loss = 0.233  adv prob = 0.250000   acc = 0.955
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_test_epoch_102.csv
logged to wandb
Current lr: 0.000010


Epoch [103]:
Training:
Average incurred loss: 0.052  
Average sample loss: 0.052  
Average acc: 0.995  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2368]:	loss = 0.025  exp loss = 0.022  adjusted loss = 0.022  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 120]:	loss = 0.244  exp loss = 0.205  adjusted loss = 0.205  adv prob = 0.250000   acc = 0.950
  waterbird_complete95 = 1, forest2water2 = 0  [n = 34]:	loss = 0.471  exp loss = 0.481  adjusted loss = 0.481  adv prob = 0.250000   acc = 0.824
  waterbird_complete95 = 1, forest2water2 = 1  [n = 678]:	loss = 0.093  exp loss = 0.094  adjusted loss = 0.094  adv prob = 0.250000   acc = 0.996
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_train_epoch_103.csv
logged to wandb
Average incurred loss: 0.057  
Average sample loss: 0.057  
Average acc: 0.992  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 1130]:	loss = 0.021  exp loss = 0.023  adjusted loss = 0.023  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 64]:	loss = 0.189  exp loss = 0.197  adjusted loss = 0.197  adv prob = 0.250000   acc = 0.969
  waterbird_complete95 = 1, forest2water2 = 0  [n = 22]:	loss = 0.507  exp loss = 0.543  adjusted loss = 0.543  adv prob = 0.250000   acc = 0.773
  waterbird_complete95 = 1, forest2water2 = 1  [n = 379]:	loss = 0.116  exp loss = 0.096  adjusted loss = 0.096  adv prob = 0.250000   acc = 0.984

Validation:
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_val_epoch_103.csv
logged to wandb
Average incurred loss: 0.476  
Average sample loss: 0.472  
Average acc: 0.777  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.038  exp loss = 0.035  adjusted loss = 0.035  adv prob = 0.250000   acc = 0.996
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.632  exp loss = 0.610  adjusted loss = 0.610  adv prob = 0.250000   acc = 0.663
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.699  exp loss = 1.808  adjusted loss = 1.808  adv prob = 0.250000   acc = 0.256
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.238  exp loss = 0.249  adjusted loss = 0.249  adv prob = 0.250000   acc = 0.932
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_test_epoch_103.csv
logged to wandb
Current lr: 0.000010


Epoch [104]:
Training:
Average incurred loss: 0.054  
Average sample loss: 0.054  
Average acc: 0.995  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2331]:	loss = 0.024  exp loss = 0.024  adjusted loss = 0.024  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 131]:	loss = 0.234  exp loss = 0.243  adjusted loss = 0.243  adv prob = 0.250000   acc = 0.969
  waterbird_complete95 = 1, forest2water2 = 0  [n = 36]:	loss = 0.431  exp loss = 0.497  adjusted loss = 0.497  adv prob = 0.250000   acc = 0.833
  waterbird_complete95 = 1, forest2water2 = 1  [n = 702]:	loss = 0.102  exp loss = 0.090  adjusted loss = 0.090  adv prob = 0.250000   acc = 0.990
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_train_epoch_104.csv
logged to wandb
Average incurred loss: 0.054  
Average sample loss: 0.054  
Average acc: 0.994  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 1167]:	loss = 0.026  exp loss = 0.026  adjusted loss = 0.026  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 53]:	loss = 0.236  exp loss = 0.220  adjusted loss = 0.220  adv prob = 0.250000   acc = 0.943
  waterbird_complete95 = 1, forest2water2 = 0  [n = 20]:	loss = 0.443  exp loss = 0.413  adjusted loss = 0.413  adv prob = 0.250000   acc = 0.850
  waterbird_complete95 = 1, forest2water2 = 1  [n = 355]:	loss = 0.099  exp loss = 0.095  adjusted loss = 0.095  adv prob = 0.250000   acc = 0.989

Validation:
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_val_epoch_104.csv
logged to wandb
Average incurred loss: 0.478  
Average sample loss: 0.475  
Average acc: 0.774  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.039  exp loss = 0.035  adjusted loss = 0.035  adv prob = 0.250000   acc = 0.996
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.646  exp loss = 0.622  adjusted loss = 0.622  adv prob = 0.250000   acc = 0.652
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.680  exp loss = 1.786  adjusted loss = 1.786  adv prob = 0.250000   acc = 0.256
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.232  exp loss = 0.241  adjusted loss = 0.241  adv prob = 0.250000   acc = 0.940
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_test_epoch_104.csv
logged to wandb
Current lr: 0.000010


Epoch [105]:
Training:
Average incurred loss: 0.054  
Average sample loss: 0.054  
Average acc: 0.995  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2333]:	loss = 0.023  exp loss = 0.021  adjusted loss = 0.021  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 119]:	loss = 0.235  exp loss = 0.197  adjusted loss = 0.197  adv prob = 0.250000   acc = 0.975
  waterbird_complete95 = 1, forest2water2 = 0  [n = 39]:	loss = 0.487  exp loss = 0.553  adjusted loss = 0.553  adv prob = 0.250000   acc = 0.795
  waterbird_complete95 = 1, forest2water2 = 1  [n = 709]:	loss = 0.100  exp loss = 0.099  adjusted loss = 0.099  adv prob = 0.250000   acc = 0.994
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_train_epoch_105.csv
logged to wandb
Average incurred loss: 0.052  
Average sample loss: 0.052  
Average acc: 0.995  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 1165]:	loss = 0.024  exp loss = 0.022  adjusted loss = 0.022  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 65]:	loss = 0.244  exp loss = 0.249  adjusted loss = 0.249  adv prob = 0.250000   acc = 0.954
  waterbird_complete95 = 1, forest2water2 = 0  [n = 17]:	loss = 0.378  exp loss = 0.454  adjusted loss = 0.454  adv prob = 0.250000   acc = 0.882
  waterbird_complete95 = 1, forest2water2 = 1  [n = 348]:	loss = 0.097  exp loss = 0.086  adjusted loss = 0.086  adv prob = 0.250000   acc = 0.991

Validation:
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_val_epoch_105.csv
logged to wandb
Average incurred loss: 0.475  
Average sample loss: 0.472  
Average acc: 0.778  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.039  exp loss = 0.035  adjusted loss = 0.035  adv prob = 0.250000   acc = 0.996
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.640  exp loss = 0.617  adjusted loss = 0.617  adv prob = 0.250000   acc = 0.663
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.676  exp loss = 1.778  adjusted loss = 1.778  adv prob = 0.250000   acc = 0.263
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.231  exp loss = 0.242  adjusted loss = 0.242  adv prob = 0.250000   acc = 0.932
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_test_epoch_105.csv
logged to wandb
Current lr: 0.000010


Epoch [106]:
Training:
Average incurred loss: 0.052  
Average sample loss: 0.052  
Average acc: 0.995  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2305]:	loss = 0.022  exp loss = 0.023  adjusted loss = 0.023  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 123]:	loss = 0.206  exp loss = 0.216  adjusted loss = 0.216  adv prob = 0.250000   acc = 0.976
  waterbird_complete95 = 1, forest2water2 = 0  [n = 40]:	loss = 0.447  exp loss = 0.368  adjusted loss = 0.368  adv prob = 0.250000   acc = 0.850
  waterbird_complete95 = 1, forest2water2 = 1  [n = 732]:	loss = 0.097  exp loss = 0.091  adjusted loss = 0.091  adv prob = 0.250000   acc = 0.992
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_train_epoch_106.csv
logged to wandb
Average incurred loss: 0.049  
Average sample loss: 0.049  
Average acc: 0.994  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 1193]:	loss = 0.026  exp loss = 0.026  adjusted loss = 0.026  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 61]:	loss = 0.225  exp loss = 0.269  adjusted loss = 0.269  adv prob = 0.250000   acc = 0.951
  waterbird_complete95 = 1, forest2water2 = 0  [n = 16]:	loss = 0.398  exp loss = 0.384  adjusted loss = 0.384  adv prob = 0.250000   acc = 0.812
  waterbird_complete95 = 1, forest2water2 = 1  [n = 325]:	loss = 0.083  exp loss = 0.078  adjusted loss = 0.078  adv prob = 0.250000   acc = 0.991

Validation:
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_val_epoch_106.csv
logged to wandb
Average incurred loss: 0.491  
Average sample loss: 0.488  
Average acc: 0.759  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.044  exp loss = 0.040  adjusted loss = 0.040  adv prob = 0.250000   acc = 0.996
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.713  exp loss = 0.688  adjusted loss = 0.688  adv prob = 0.250000   acc = 0.599
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.573  exp loss = 1.670  adjusted loss = 1.670  adv prob = 0.250000   acc = 0.293
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.203  exp loss = 0.211  adjusted loss = 0.211  adv prob = 0.250000   acc = 0.955
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_test_epoch_106.csv
logged to wandb
Current lr: 0.000010


Epoch [107]:
Training:
Average incurred loss: 0.055  
Average sample loss: 0.055  
Average acc: 0.994  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2322]:	loss = 0.024  exp loss = 0.027  adjusted loss = 0.027  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 120]:	loss = 0.229  exp loss = 0.334  adjusted loss = 0.334  adv prob = 0.250000   acc = 0.950
  waterbird_complete95 = 1, forest2water2 = 0  [n = 43]:	loss = 0.430  exp loss = 0.363  adjusted loss = 0.363  adv prob = 0.250000   acc = 0.814
  waterbird_complete95 = 1, forest2water2 = 1  [n = 715]:	loss = 0.102  exp loss = 0.071  adjusted loss = 0.071  adv prob = 0.250000   acc = 0.993
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_train_epoch_107.csv
logged to wandb
Average incurred loss: 0.048  
Average sample loss: 0.048  
Average acc: 0.995  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 1176]:	loss = 0.024  exp loss = 0.024  adjusted loss = 0.024  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 64]:	loss = 0.232  exp loss = 0.290  adjusted loss = 0.290  adv prob = 0.250000   acc = 0.953
  waterbird_complete95 = 1, forest2water2 = 0  [n = 13]:	loss = 0.403  exp loss = 0.387  adjusted loss = 0.387  adv prob = 0.250000   acc = 0.769
  waterbird_complete95 = 1, forest2water2 = 1  [n = 342]:	loss = 0.085  exp loss = 0.078  adjusted loss = 0.078  adv prob = 0.250000   acc = 0.994

Validation:
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_val_epoch_107.csv
logged to wandb
Average incurred loss: 0.480  
Average sample loss: 0.477  
Average acc: 0.770  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.041  exp loss = 0.037  adjusted loss = 0.037  adv prob = 0.250000   acc = 0.996
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.673  exp loss = 0.650  adjusted loss = 0.650  adv prob = 0.250000   acc = 0.631
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.610  exp loss = 1.713  adjusted loss = 1.713  adv prob = 0.250000   acc = 0.278
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.213  exp loss = 0.223  adjusted loss = 0.223  adv prob = 0.250000   acc = 0.955
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_test_epoch_107.csv
logged to wandb
Current lr: 0.000010


Epoch [108]:
Training:
Average incurred loss: 0.052  
Average sample loss: 0.052  
Average acc: 0.995  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2328]:	loss = 0.023  exp loss = 0.026  adjusted loss = 0.026  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 127]:	loss = 0.211  exp loss = 0.224  adjusted loss = 0.224  adv prob = 0.250000   acc = 0.984
  waterbird_complete95 = 1, forest2water2 = 0  [n = 37]:	loss = 0.401  exp loss = 0.335  adjusted loss = 0.335  adv prob = 0.250000   acc = 0.892
  waterbird_complete95 = 1, forest2water2 = 1  [n = 708]:	loss = 0.100  exp loss = 0.079  adjusted loss = 0.079  adv prob = 0.250000   acc = 0.987
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_train_epoch_108.csv
logged to wandb
Average incurred loss: 0.050  
Average sample loss: 0.050  
Average acc: 0.994  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 1170]:	loss = 0.023  exp loss = 0.020  adjusted loss = 0.020  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 57]:	loss = 0.238  exp loss = 0.192  adjusted loss = 0.192  adv prob = 0.250000   acc = 0.965
  waterbird_complete95 = 1, forest2water2 = 0  [n = 19]:	loss = 0.415  exp loss = 0.357  adjusted loss = 0.357  adv prob = 0.250000   acc = 0.842
  waterbird_complete95 = 1, forest2water2 = 1  [n = 349]:	loss = 0.090  exp loss = 0.085  adjusted loss = 0.085  adv prob = 0.250000   acc = 0.989

Validation:
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_val_epoch_108.csv
logged to wandb
Average incurred loss: 0.464  
Average sample loss: 0.460  
Average acc: 0.785  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.035  exp loss = 0.032  adjusted loss = 0.032  adv prob = 0.250000   acc = 0.996
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.602  exp loss = 0.581  adjusted loss = 0.581  adv prob = 0.250000   acc = 0.680
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.707  exp loss = 1.815  adjusted loss = 1.815  adv prob = 0.250000   acc = 0.263
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.241  exp loss = 0.251  adjusted loss = 0.251  adv prob = 0.250000   acc = 0.932
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_test_epoch_108.csv
logged to wandb
Current lr: 0.000010


Epoch [109]:
Training:
Average incurred loss: 0.050  
Average sample loss: 0.050  
Average acc: 0.995  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2330]:	loss = 0.022  exp loss = 0.020  adjusted loss = 0.020  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 129]:	loss = 0.226  exp loss = 0.188  adjusted loss = 0.188  adv prob = 0.250000   acc = 0.946
  waterbird_complete95 = 1, forest2water2 = 0  [n = 42]:	loss = 0.344  exp loss = 0.365  adjusted loss = 0.365  adv prob = 0.250000   acc = 0.905
  waterbird_complete95 = 1, forest2water2 = 1  [n = 699]:	loss = 0.093  exp loss = 0.101  adjusted loss = 0.101  adv prob = 0.250000   acc = 0.993
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_train_epoch_109.csv
logged to wandb
Average incurred loss: 0.057  
Average sample loss: 0.057  
Average acc: 0.991  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 1168]:	loss = 0.024  exp loss = 0.024  adjusted loss = 0.024  adv prob = 0.250000   acc = 0.999
  waterbird_complete95 = 0, forest2water2 = 1  [n = 55]:	loss = 0.250  exp loss = 0.257  adjusted loss = 0.257  adv prob = 0.250000   acc = 0.964
  waterbird_complete95 = 1, forest2water2 = 0  [n = 14]:	loss = 0.683  exp loss = 0.592  adjusted loss = 0.592  adv prob = 0.250000   acc = 0.500
  waterbird_complete95 = 1, forest2water2 = 1  [n = 358]:	loss = 0.109  exp loss = 0.086  adjusted loss = 0.086  adv prob = 0.250000   acc = 0.989

Validation:
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_val_epoch_109.csv
logged to wandb
Average incurred loss: 0.486  
Average sample loss: 0.482  
Average acc: 0.765  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.042  exp loss = 0.038  adjusted loss = 0.038  adv prob = 0.250000   acc = 0.994
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.693  exp loss = 0.667  adjusted loss = 0.667  adv prob = 0.250000   acc = 0.616
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.594  exp loss = 1.691  adjusted loss = 1.691  adv prob = 0.250000   acc = 0.293
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.205  exp loss = 0.213  adjusted loss = 0.213  adv prob = 0.250000   acc = 0.955
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_test_epoch_109.csv
logged to wandb
Current lr: 0.000010


Epoch [110]:
Training:
Average incurred loss: 0.048  
Average sample loss: 0.048  
Average acc: 0.997  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2321]:	loss = 0.021  exp loss = 0.021  adjusted loss = 0.021  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 128]:	loss = 0.191  exp loss = 0.163  adjusted loss = 0.163  adv prob = 0.250000   acc = 0.984
  waterbird_complete95 = 1, forest2water2 = 0  [n = 38]:	loss = 0.406  exp loss = 0.422  adjusted loss = 0.422  adv prob = 0.250000   acc = 0.895
  waterbird_complete95 = 1, forest2water2 = 1  [n = 713]:	loss = 0.090  exp loss = 0.081  adjusted loss = 0.081  adv prob = 0.250000   acc = 0.997
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_train_epoch_110.csv
logged to wandb
Average incurred loss: 0.051  
Average sample loss: 0.051  
Average acc: 0.994  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 1177]:	loss = 0.024  exp loss = 0.022  adjusted loss = 0.022  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 56]:	loss = 0.236  exp loss = 0.202  adjusted loss = 0.202  adv prob = 0.250000   acc = 0.964
  waterbird_complete95 = 1, forest2water2 = 0  [n = 18]:	loss = 0.400  exp loss = 0.471  adjusted loss = 0.471  adv prob = 0.250000   acc = 0.833
  waterbird_complete95 = 1, forest2water2 = 1  [n = 344]:	loss = 0.096  exp loss = 0.094  adjusted loss = 0.094  adv prob = 0.250000   acc = 0.988

Validation:
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_val_epoch_110.csv
logged to wandb
Average incurred loss: 0.467  
Average sample loss: 0.463  
Average acc: 0.783  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.037  exp loss = 0.034  adjusted loss = 0.034  adv prob = 0.250000   acc = 0.996
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.621  exp loss = 0.599  adjusted loss = 0.599  adv prob = 0.250000   acc = 0.672
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.670  exp loss = 1.773  adjusted loss = 1.773  adv prob = 0.250000   acc = 0.271
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.230  exp loss = 0.241  adjusted loss = 0.241  adv prob = 0.250000   acc = 0.940
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_test_epoch_110.csv
logged to wandb
Current lr: 0.000010


Epoch [111]:
Training:
Average incurred loss: 0.053  
Average sample loss: 0.053  
Average acc: 0.993  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2366]:	loss = 0.025  exp loss = 0.022  adjusted loss = 0.022  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 124]:	loss = 0.252  exp loss = 0.213  adjusted loss = 0.213  adv prob = 0.250000   acc = 0.927
  waterbird_complete95 = 1, forest2water2 = 0  [n = 44]:	loss = 0.383  exp loss = 0.346  adjusted loss = 0.346  adv prob = 0.250000   acc = 0.864
  waterbird_complete95 = 1, forest2water2 = 1  [n = 666]:	loss = 0.096  exp loss = 0.096  adjusted loss = 0.096  adv prob = 0.250000   acc = 0.992
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_train_epoch_111.csv
logged to wandb
Average incurred loss: 0.045  
Average sample loss: 0.045  
Average acc: 0.994  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 1132]:	loss = 0.017  exp loss = 0.017  adjusted loss = 0.017  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 60]:	loss = 0.154  exp loss = 0.160  adjusted loss = 0.160  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 0  [n = 12]:	loss = 0.509  exp loss = 0.420  adjusted loss = 0.420  adv prob = 0.250000   acc = 0.667
  waterbird_complete95 = 1, forest2water2 = 1  [n = 391]:	loss = 0.095  exp loss = 0.083  adjusted loss = 0.083  adv prob = 0.250000   acc = 0.985

Validation:
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_val_epoch_111.csv
logged to wandb
Average incurred loss: 0.458  
Average sample loss: 0.455  
Average acc: 0.789  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.033  exp loss = 0.030  adjusted loss = 0.030  adv prob = 0.250000   acc = 0.996
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.567  exp loss = 0.546  adjusted loss = 0.546  adv prob = 0.250000   acc = 0.700
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.775  exp loss = 1.889  adjusted loss = 1.889  adv prob = 0.250000   acc = 0.241
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.256  exp loss = 0.268  adjusted loss = 0.268  adv prob = 0.250000   acc = 0.925
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_test_epoch_111.csv
logged to wandb
Current lr: 0.000010


Epoch [112]:
Training:
Average incurred loss: 0.047  
Average sample loss: 0.047  
Average acc: 0.997  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2339]:	loss = 0.022  exp loss = 0.019  adjusted loss = 0.019  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 128]:	loss = 0.203  exp loss = 0.181  adjusted loss = 0.181  adv prob = 0.250000   acc = 0.984
  waterbird_complete95 = 1, forest2water2 = 0  [n = 36]:	loss = 0.399  exp loss = 0.385  adjusted loss = 0.385  adv prob = 0.250000   acc = 0.861
  waterbird_complete95 = 1, forest2water2 = 1  [n = 697]:	loss = 0.086  exp loss = 0.081  adjusted loss = 0.081  adv prob = 0.250000   acc = 0.996
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_train_epoch_112.csv
logged to wandb
Average incurred loss: 0.050  
Average sample loss: 0.050  
Average acc: 0.994  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 1159]:	loss = 0.022  exp loss = 0.021  adjusted loss = 0.021  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 56]:	loss = 0.206  exp loss = 0.216  adjusted loss = 0.216  adv prob = 0.250000   acc = 0.982
  waterbird_complete95 = 1, forest2water2 = 0  [n = 20]:	loss = 0.416  exp loss = 0.444  adjusted loss = 0.444  adv prob = 0.250000   acc = 0.850
  waterbird_complete95 = 1, forest2water2 = 1  [n = 360]:	loss = 0.093  exp loss = 0.083  adjusted loss = 0.083  adv prob = 0.250000   acc = 0.986

Validation:
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_val_epoch_112.csv
logged to wandb
Average incurred loss: 0.474  
Average sample loss: 0.471  
Average acc: 0.778  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.038  exp loss = 0.034  adjusted loss = 0.034  adv prob = 0.250000   acc = 0.996
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.644  exp loss = 0.620  adjusted loss = 0.620  adv prob = 0.250000   acc = 0.661
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.664  exp loss = 1.773  adjusted loss = 1.773  adv prob = 0.250000   acc = 0.271
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.223  exp loss = 0.231  adjusted loss = 0.231  adv prob = 0.250000   acc = 0.932
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_test_epoch_112.csv
logged to wandb
Current lr: 0.000010


Epoch [113]:
Training:
Average incurred loss: 0.050  
Average sample loss: 0.050  
Average acc: 0.993  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2351]:	loss = 0.023  exp loss = 0.021  adjusted loss = 0.021  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 116]:	loss = 0.225  exp loss = 0.280  adjusted loss = 0.280  adv prob = 0.250000   acc = 0.957
  waterbird_complete95 = 1, forest2water2 = 0  [n = 41]:	loss = 0.454  exp loss = 0.395  adjusted loss = 0.395  adv prob = 0.250000   acc = 0.805
  waterbird_complete95 = 1, forest2water2 = 1  [n = 692]:	loss = 0.090  exp loss = 0.075  adjusted loss = 0.075  adv prob = 0.250000   acc = 0.988
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_train_epoch_113.csv
logged to wandb
Average incurred loss: 0.046  
Average sample loss: 0.046  
Average acc: 0.999  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 1147]:	loss = 0.021  exp loss = 0.020  adjusted loss = 0.020  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 68]:	loss = 0.161  exp loss = 0.176  adjusted loss = 0.176  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 0  [n = 15]:	loss = 0.275  exp loss = 0.317  adjusted loss = 0.317  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 365]:	loss = 0.094  exp loss = 0.080  adjusted loss = 0.080  adv prob = 0.250000   acc = 0.995

Validation:
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_val_epoch_113.csv
logged to wandb
Average incurred loss: 0.470  
Average sample loss: 0.466  
Average acc: 0.781  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.036  exp loss = 0.032  adjusted loss = 0.032  adv prob = 0.250000   acc = 0.996
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.618  exp loss = 0.595  adjusted loss = 0.595  adv prob = 0.250000   acc = 0.672
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.712  exp loss = 1.823  adjusted loss = 1.823  adv prob = 0.250000   acc = 0.263
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.233  exp loss = 0.242  adjusted loss = 0.242  adv prob = 0.250000   acc = 0.932
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_test_epoch_113.csv
logged to wandb
Current lr: 0.000010


Epoch [114]:
Training:
Average incurred loss: 0.051  
Average sample loss: 0.051  
Average acc: 0.994  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2354]:	loss = 0.023  exp loss = 0.022  adjusted loss = 0.022  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 131]:	loss = 0.246  exp loss = 0.228  adjusted loss = 0.228  adv prob = 0.250000   acc = 0.939
  waterbird_complete95 = 1, forest2water2 = 0  [n = 37]:	loss = 0.406  exp loss = 0.483  adjusted loss = 0.483  adv prob = 0.250000   acc = 0.865
  waterbird_complete95 = 1, forest2water2 = 1  [n = 678]:	loss = 0.090  exp loss = 0.086  adjusted loss = 0.086  adv prob = 0.250000   acc = 0.994
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_train_epoch_114.csv
logged to wandb
Average incurred loss: 0.048  
Average sample loss: 0.048  
Average acc: 0.996  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 1144]:	loss = 0.021  exp loss = 0.019  adjusted loss = 0.019  adv prob = 0.250000   acc = 0.999
  waterbird_complete95 = 0, forest2water2 = 1  [n = 53]:	loss = 0.163  exp loss = 0.166  adjusted loss = 0.166  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 0  [n = 19]:	loss = 0.461  exp loss = 0.504  adjusted loss = 0.504  adv prob = 0.250000   acc = 0.842
  waterbird_complete95 = 1, forest2water2 = 1  [n = 379]:	loss = 0.094  exp loss = 0.082  adjusted loss = 0.082  adv prob = 0.250000   acc = 0.995

Validation:
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_val_epoch_114.csv
logged to wandb
Average incurred loss: 0.454  
Average sample loss: 0.450  
Average acc: 0.794  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.033  exp loss = 0.030  adjusted loss = 0.030  adv prob = 0.250000   acc = 0.996
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.567  exp loss = 0.546  adjusted loss = 0.546  adv prob = 0.250000   acc = 0.704
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.746  exp loss = 1.864  adjusted loss = 1.864  adv prob = 0.250000   acc = 0.263
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.248  exp loss = 0.258  adjusted loss = 0.258  adv prob = 0.250000   acc = 0.932
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_test_epoch_114.csv
logged to wandb
Current lr: 0.000010


Epoch [115]:
Training:
Average incurred loss: 0.049  
Average sample loss: 0.049  
Average acc: 0.995  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2337]:	loss = 0.021  exp loss = 0.022  adjusted loss = 0.022  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 114]:	loss = 0.225  exp loss = 0.252  adjusted loss = 0.252  adv prob = 0.250000   acc = 0.965
  waterbird_complete95 = 1, forest2water2 = 0  [n = 38]:	loss = 0.389  exp loss = 0.367  adjusted loss = 0.367  adv prob = 0.250000   acc = 0.842
  waterbird_complete95 = 1, forest2water2 = 1  [n = 711]:	loss = 0.094  exp loss = 0.077  adjusted loss = 0.077  adv prob = 0.250000   acc = 0.990
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_train_epoch_115.csv
logged to wandb
Average incurred loss: 0.048  
Average sample loss: 0.048  
Average acc: 0.994  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 1161]:	loss = 0.021  exp loss = 0.019  adjusted loss = 0.019  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 70]:	loss = 0.208  exp loss = 0.172  adjusted loss = 0.172  adv prob = 0.250000   acc = 0.943
  waterbird_complete95 = 1, forest2water2 = 0  [n = 18]:	loss = 0.377  exp loss = 0.354  adjusted loss = 0.354  adv prob = 0.250000   acc = 0.833
  waterbird_complete95 = 1, forest2water2 = 1  [n = 346]:	loss = 0.086  exp loss = 0.090  adjusted loss = 0.090  adv prob = 0.250000   acc = 0.991

Validation:
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_val_epoch_115.csv
logged to wandb
Average incurred loss: 0.469  
Average sample loss: 0.466  
Average acc: 0.784  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.036  exp loss = 0.032  adjusted loss = 0.032  adv prob = 0.250000   acc = 0.996
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.624  exp loss = 0.602  adjusted loss = 0.602  adv prob = 0.250000   acc = 0.676
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.692  exp loss = 1.805  adjusted loss = 1.805  adv prob = 0.250000   acc = 0.263
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.225  exp loss = 0.234  adjusted loss = 0.234  adv prob = 0.250000   acc = 0.940
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_test_epoch_115.csv
logged to wandb
Current lr: 0.000010


Epoch [116]:
Training:
Average incurred loss: 0.049  
Average sample loss: 0.049  
Average acc: 0.995  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2318]:	loss = 0.021  exp loss = 0.019  adjusted loss = 0.019  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 127]:	loss = 0.209  exp loss = 0.168  adjusted loss = 0.168  adv prob = 0.250000   acc = 0.969
  waterbird_complete95 = 1, forest2water2 = 0  [n = 41]:	loss = 0.443  exp loss = 0.498  adjusted loss = 0.498  adv prob = 0.250000   acc = 0.805
  waterbird_complete95 = 1, forest2water2 = 1  [n = 714]:	loss = 0.091  exp loss = 0.086  adjusted loss = 0.086  adv prob = 0.250000   acc = 0.996
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_train_epoch_116.csv
logged to wandb
Average incurred loss: 0.045  
Average sample loss: 0.045  
Average acc: 0.995  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 1180]:	loss = 0.023  exp loss = 0.022  adjusted loss = 0.022  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 57]:	loss = 0.206  exp loss = 0.164  adjusted loss = 0.164  adv prob = 0.250000   acc = 0.965
  waterbird_complete95 = 1, forest2water2 = 0  [n = 15]:	loss = 0.312  exp loss = 0.355  adjusted loss = 0.355  adv prob = 0.250000   acc = 0.933
  waterbird_complete95 = 1, forest2water2 = 1  [n = 343]:	loss = 0.083  exp loss = 0.078  adjusted loss = 0.078  adv prob = 0.250000   acc = 0.985

Validation:
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_val_epoch_116.csv
logged to wandb
Average incurred loss: 0.479  
Average sample loss: 0.476  
Average acc: 0.772  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.038  exp loss = 0.034  adjusted loss = 0.034  adv prob = 0.250000   acc = 0.996
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.664  exp loss = 0.641  adjusted loss = 0.641  adv prob = 0.250000   acc = 0.639
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.651  exp loss = 1.755  adjusted loss = 1.755  adv prob = 0.250000   acc = 0.278
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.210  exp loss = 0.219  adjusted loss = 0.219  adv prob = 0.250000   acc = 0.947
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_test_epoch_116.csv
logged to wandb
Current lr: 0.000010


Epoch [117]:
Training:
Average incurred loss: 0.048  
Average sample loss: 0.048  
Average acc: 0.995  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2331]:	loss = 0.021  exp loss = 0.019  adjusted loss = 0.019  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 114]:	loss = 0.216  exp loss = 0.189  adjusted loss = 0.189  adv prob = 0.250000   acc = 0.956
  waterbird_complete95 = 1, forest2water2 = 0  [n = 33]:	loss = 0.427  exp loss = 0.457  adjusted loss = 0.457  adv prob = 0.250000   acc = 0.848
  waterbird_complete95 = 1, forest2water2 = 1  [n = 722]:	loss = 0.093  exp loss = 0.074  adjusted loss = 0.074  adv prob = 0.250000   acc = 0.992
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_train_epoch_117.csv
logged to wandb
Average incurred loss: 0.047  
Average sample loss: 0.047  
Average acc: 0.998  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 1167]:	loss = 0.022  exp loss = 0.023  adjusted loss = 0.023  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 70]:	loss = 0.202  exp loss = 0.203  adjusted loss = 0.203  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 0  [n = 23]:	loss = 0.326  exp loss = 0.324  adjusted loss = 0.324  adv prob = 0.250000   acc = 0.957
  waterbird_complete95 = 1, forest2water2 = 1  [n = 335]:	loss = 0.083  exp loss = 0.073  adjusted loss = 0.073  adv prob = 0.250000   acc = 0.994

Validation:
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_val_epoch_117.csv
logged to wandb
Average incurred loss: 0.474  
Average sample loss: 0.471  
Average acc: 0.776  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.038  exp loss = 0.035  adjusted loss = 0.035  adv prob = 0.250000   acc = 0.996
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.659  exp loss = 0.635  adjusted loss = 0.635  adv prob = 0.250000   acc = 0.644
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.620  exp loss = 1.717  adjusted loss = 1.717  adv prob = 0.250000   acc = 0.293
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.211  exp loss = 0.218  adjusted loss = 0.218  adv prob = 0.250000   acc = 0.947
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_test_epoch_117.csv
logged to wandb
Current lr: 0.000010


Epoch [118]:
Training:
Average incurred loss: 0.049  
Average sample loss: 0.049  
Average acc: 0.995  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2331]:	loss = 0.021  exp loss = 0.016  adjusted loss = 0.016  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 120]:	loss = 0.209  exp loss = 0.150  adjusted loss = 0.150  adv prob = 0.250000   acc = 0.975
  waterbird_complete95 = 1, forest2water2 = 0  [n = 34]:	loss = 0.390  exp loss = 0.381  adjusted loss = 0.381  adv prob = 0.250000   acc = 0.882
  waterbird_complete95 = 1, forest2water2 = 1  [n = 715]:	loss = 0.095  exp loss = 0.108  adjusted loss = 0.108  adv prob = 0.250000   acc = 0.987
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_train_epoch_118.csv
logged to wandb
Average incurred loss: 0.045  
Average sample loss: 0.045  
Average acc: 0.996  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 1167]:	loss = 0.023  exp loss = 0.019  adjusted loss = 0.019  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 64]:	loss = 0.162  exp loss = 0.166  adjusted loss = 0.166  adv prob = 0.250000   acc = 0.984
  waterbird_complete95 = 1, forest2water2 = 0  [n = 22]:	loss = 0.318  exp loss = 0.355  adjusted loss = 0.355  adv prob = 0.250000   acc = 0.909
  waterbird_complete95 = 1, forest2water2 = 1  [n = 342]:	loss = 0.083  exp loss = 0.082  adjusted loss = 0.082  adv prob = 0.250000   acc = 0.991

Validation:
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_val_epoch_118.csv
logged to wandb
Average incurred loss: 0.459  
Average sample loss: 0.456  
Average acc: 0.790  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.032  exp loss = 0.029  adjusted loss = 0.029  adv prob = 0.250000   acc = 0.996
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.579  exp loss = 0.558  adjusted loss = 0.558  adv prob = 0.250000   acc = 0.697
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.758  exp loss = 1.871  adjusted loss = 1.871  adv prob = 0.250000   acc = 0.256
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.241  exp loss = 0.251  adjusted loss = 0.251  adv prob = 0.250000   acc = 0.925
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_test_epoch_118.csv
logged to wandb
Current lr: 0.000010


Epoch [119]:
Training:
Average incurred loss: 0.046  
Average sample loss: 0.046  
Average acc: 0.996  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2330]:	loss = 0.020  exp loss = 0.019  adjusted loss = 0.019  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 122]:	loss = 0.204  exp loss = 0.180  adjusted loss = 0.180  adv prob = 0.250000   acc = 0.967
  waterbird_complete95 = 1, forest2water2 = 0  [n = 33]:	loss = 0.411  exp loss = 0.453  adjusted loss = 0.453  adv prob = 0.250000   acc = 0.788
  waterbird_complete95 = 1, forest2water2 = 1  [n = 715]:	loss = 0.084  exp loss = 0.083  adjusted loss = 0.083  adv prob = 0.250000   acc = 0.996
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_train_epoch_119.csv
logged to wandb
Average incurred loss: 0.042  
Average sample loss: 0.042  
Average acc: 0.999  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 1168]:	loss = 0.019  exp loss = 0.020  adjusted loss = 0.020  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 62]:	loss = 0.218  exp loss = 0.237  adjusted loss = 0.237  adv prob = 0.250000   acc = 0.968
  waterbird_complete95 = 1, forest2water2 = 0  [n = 23]:	loss = 0.292  exp loss = 0.310  adjusted loss = 0.310  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 342]:	loss = 0.071  exp loss = 0.070  adjusted loss = 0.070  adv prob = 0.250000   acc = 1.000

Validation:
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_val_epoch_119.csv
logged to wandb
Average incurred loss: 0.476  
Average sample loss: 0.472  
Average acc: 0.777  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.038  exp loss = 0.034  adjusted loss = 0.034  adv prob = 0.250000   acc = 0.996
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.660  exp loss = 0.637  adjusted loss = 0.637  adv prob = 0.250000   acc = 0.650
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.637  exp loss = 1.736  adjusted loss = 1.736  adv prob = 0.250000   acc = 0.286
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.209  exp loss = 0.216  adjusted loss = 0.216  adv prob = 0.250000   acc = 0.947
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_test_epoch_119.csv
logged to wandb
Current lr: 0.000010


Epoch [120]:
Training:
Average incurred loss: 0.047  
Average sample loss: 0.047  
Average acc: 0.997  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2330]:	loss = 0.021  exp loss = 0.022  adjusted loss = 0.022  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 124]:	loss = 0.200  exp loss = 0.212  adjusted loss = 0.212  adv prob = 0.250000   acc = 0.984
  waterbird_complete95 = 1, forest2water2 = 0  [n = 40]:	loss = 0.413  exp loss = 0.362  adjusted loss = 0.362  adv prob = 0.250000   acc = 0.875
  waterbird_complete95 = 1, forest2water2 = 1  [n = 706]:	loss = 0.085  exp loss = 0.075  adjusted loss = 0.075  adv prob = 0.250000   acc = 0.997
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_train_epoch_120.csv
logged to wandb
Average incurred loss: 0.045  
Average sample loss: 0.045  
Average acc: 0.997  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 1168]:	loss = 0.022  exp loss = 0.018  adjusted loss = 0.018  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 60]:	loss = 0.202  exp loss = 0.189  adjusted loss = 0.189  adv prob = 0.250000   acc = 0.983
  waterbird_complete95 = 1, forest2water2 = 0  [n = 16]:	loss = 0.330  exp loss = 0.335  adjusted loss = 0.335  adv prob = 0.250000   acc = 0.938
  waterbird_complete95 = 1, forest2water2 = 1  [n = 351]:	loss = 0.084  exp loss = 0.089  adjusted loss = 0.089  adv prob = 0.250000   acc = 0.991

Validation:
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_val_epoch_120.csv
logged to wandb
Average incurred loss: 0.457  
Average sample loss: 0.454  
Average acc: 0.791  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.030  exp loss = 0.027  adjusted loss = 0.027  adv prob = 0.250000   acc = 0.996
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.559  exp loss = 0.537  adjusted loss = 0.537  adv prob = 0.250000   acc = 0.704
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.809  exp loss = 1.927  adjusted loss = 1.927  adv prob = 0.250000   acc = 0.248
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.251  exp loss = 0.261  adjusted loss = 0.261  adv prob = 0.250000   acc = 0.925
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_test_epoch_120.csv
logged to wandb
Current lr: 0.000010


Epoch [121]:
Training:
Average incurred loss: 0.046  
Average sample loss: 0.046  
Average acc: 0.995  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2318]:	loss = 0.020  exp loss = 0.020  adjusted loss = 0.020  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 125]:	loss = 0.185  exp loss = 0.180  adjusted loss = 0.180  adv prob = 0.250000   acc = 0.976
  waterbird_complete95 = 1, forest2water2 = 0  [n = 42]:	loss = 0.430  exp loss = 0.464  adjusted loss = 0.464  adv prob = 0.250000   acc = 0.857
  waterbird_complete95 = 1, forest2water2 = 1  [n = 715]:	loss = 0.083  exp loss = 0.074  adjusted loss = 0.074  adv prob = 0.250000   acc = 0.992
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_train_epoch_121.csv
logged to wandb
Average incurred loss: 0.045  
Average sample loss: 0.045  
Average acc: 0.997  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 1180]:	loss = 0.021  exp loss = 0.021  adjusted loss = 0.021  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 59]:	loss = 0.261  exp loss = 0.264  adjusted loss = 0.264  adv prob = 0.250000   acc = 0.949
  waterbird_complete95 = 1, forest2water2 = 0  [n = 14]:	loss = 0.247  exp loss = 0.300  adjusted loss = 0.300  adv prob = 0.250000   acc = 0.929
  waterbird_complete95 = 1, forest2water2 = 1  [n = 342]:	loss = 0.079  exp loss = 0.082  adjusted loss = 0.082  adv prob = 0.250000   acc = 0.997

Validation:
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_val_epoch_121.csv
logged to wandb
Average incurred loss: 0.469  
Average sample loss: 0.466  
Average acc: 0.782  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.036  exp loss = 0.033  adjusted loss = 0.033  adv prob = 0.250000   acc = 0.996
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.640  exp loss = 0.618  adjusted loss = 0.618  adv prob = 0.250000   acc = 0.663
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.645  exp loss = 1.747  adjusted loss = 1.747  adv prob = 0.250000   acc = 0.286
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.212  exp loss = 0.220  adjusted loss = 0.220  adv prob = 0.250000   acc = 0.947
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_test_epoch_121.csv
logged to wandb
Current lr: 0.000010


Epoch [122]:
Training:
Average incurred loss: 0.044  
Average sample loss: 0.044  
Average acc: 0.997  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2327]:	loss = 0.020  exp loss = 0.019  adjusted loss = 0.019  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 132]:	loss = 0.190  exp loss = 0.210  adjusted loss = 0.210  adv prob = 0.250000   acc = 0.985
  waterbird_complete95 = 1, forest2water2 = 0  [n = 36]:	loss = 0.372  exp loss = 0.368  adjusted loss = 0.368  adv prob = 0.250000   acc = 0.889
  waterbird_complete95 = 1, forest2water2 = 1  [n = 705]:	loss = 0.080  exp loss = 0.080  adjusted loss = 0.080  adv prob = 0.250000   acc = 0.996
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_train_epoch_122.csv
logged to wandb
Average incurred loss: 0.046  
Average sample loss: 0.046  
Average acc: 0.996  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 1171]:	loss = 0.021  exp loss = 0.019  adjusted loss = 0.019  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 52]:	loss = 0.229  exp loss = 0.200  adjusted loss = 0.200  adv prob = 0.250000   acc = 0.962
  waterbird_complete95 = 1, forest2water2 = 0  [n = 20]:	loss = 0.369  exp loss = 0.351  adjusted loss = 0.351  adv prob = 0.250000   acc = 0.800
  waterbird_complete95 = 1, forest2water2 = 1  [n = 352]:	loss = 0.085  exp loss = 0.082  adjusted loss = 0.082  adv prob = 0.250000   acc = 0.997

Validation:
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_val_epoch_122.csv
logged to wandb
Average incurred loss: 0.462  
Average sample loss: 0.458  
Average acc: 0.788  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.033  exp loss = 0.030  adjusted loss = 0.030  adv prob = 0.250000   acc = 0.996
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.607  exp loss = 0.586  adjusted loss = 0.586  adv prob = 0.250000   acc = 0.678
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.694  exp loss = 1.807  adjusted loss = 1.807  adv prob = 0.250000   acc = 0.286
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.223  exp loss = 0.231  adjusted loss = 0.231  adv prob = 0.250000   acc = 0.947
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_test_epoch_122.csv
logged to wandb
Current lr: 0.000010


Epoch [123]:
Training:
Average incurred loss: 0.047  
Average sample loss: 0.047  
Average acc: 0.995  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2328]:	loss = 0.020  exp loss = 0.020  adjusted loss = 0.020  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 135]:	loss = 0.199  exp loss = 0.207  adjusted loss = 0.207  adv prob = 0.250000   acc = 0.985
  waterbird_complete95 = 1, forest2water2 = 0  [n = 42]:	loss = 0.384  exp loss = 0.361  adjusted loss = 0.361  adv prob = 0.250000   acc = 0.810
  waterbird_complete95 = 1, forest2water2 = 1  [n = 695]:	loss = 0.086  exp loss = 0.077  adjusted loss = 0.077  adv prob = 0.250000   acc = 0.991
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_train_epoch_123.csv
logged to wandb
Average incurred loss: 0.040  
Average sample loss: 0.040  
Average acc: 0.997  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 1170]:	loss = 0.019  exp loss = 0.018  adjusted loss = 0.018  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 49]:	loss = 0.195  exp loss = 0.212  adjusted loss = 0.212  adv prob = 0.250000   acc = 0.959
  waterbird_complete95 = 1, forest2water2 = 0  [n = 14]:	loss = 0.298  exp loss = 0.304  adjusted loss = 0.304  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 362]:	loss = 0.079  exp loss = 0.068  adjusted loss = 0.068  adv prob = 0.250000   acc = 0.994

Validation:
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_val_epoch_123.csv
logged to wandb
Average incurred loss: 0.471  
Average sample loss: 0.468  
Average acc: 0.786  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.035  exp loss = 0.032  adjusted loss = 0.032  adv prob = 0.250000   acc = 0.996
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.637  exp loss = 0.614  adjusted loss = 0.614  adv prob = 0.250000   acc = 0.672
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.675  exp loss = 1.787  adjusted loss = 1.787  adv prob = 0.250000   acc = 0.286
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.214  exp loss = 0.222  adjusted loss = 0.222  adv prob = 0.250000   acc = 0.947
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_test_epoch_123.csv
logged to wandb
Current lr: 0.000010


Epoch [124]:
Training:
Average incurred loss: 0.043  
Average sample loss: 0.043  
Average acc: 0.997  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2349]:	loss = 0.020  exp loss = 0.018  adjusted loss = 0.018  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 120]:	loss = 0.205  exp loss = 0.158  adjusted loss = 0.158  adv prob = 0.250000   acc = 0.967
  waterbird_complete95 = 1, forest2water2 = 0  [n = 39]:	loss = 0.336  exp loss = 0.326  adjusted loss = 0.326  adv prob = 0.250000   acc = 0.846
  waterbird_complete95 = 1, forest2water2 = 1  [n = 692]:	loss = 0.075  exp loss = 0.082  adjusted loss = 0.082  adv prob = 0.250000   acc = 0.999
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_train_epoch_124.csv
logged to wandb
Average incurred loss: 0.046  
Average sample loss: 0.046  
Average acc: 0.997  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 1149]:	loss = 0.018  exp loss = 0.016  adjusted loss = 0.016  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 64]:	loss = 0.186  exp loss = 0.142  adjusted loss = 0.142  adv prob = 0.250000   acc = 0.984
  waterbird_complete95 = 1, forest2water2 = 0  [n = 17]:	loss = 0.334  exp loss = 0.360  adjusted loss = 0.360  adv prob = 0.250000   acc = 0.941
  waterbird_complete95 = 1, forest2water2 = 1  [n = 365]:	loss = 0.097  exp loss = 0.087  adjusted loss = 0.087  adv prob = 0.250000   acc = 0.992

Validation:
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_val_epoch_124.csv
logged to wandb
Average incurred loss: 0.451  
Average sample loss: 0.447  
Average acc: 0.794  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.028  exp loss = 0.026  adjusted loss = 0.026  adv prob = 0.250000   acc = 0.996
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.532  exp loss = 0.511  adjusted loss = 0.511  adv prob = 0.250000   acc = 0.712
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.840  exp loss = 1.963  adjusted loss = 1.963  adv prob = 0.250000   acc = 0.241
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.261  exp loss = 0.274  adjusted loss = 0.274  adv prob = 0.250000   acc = 0.925
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_test_epoch_124.csv
logged to wandb
Current lr: 0.000010


Epoch [125]:
Training:
Average incurred loss: 0.045  
Average sample loss: 0.045  
Average acc: 0.997  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2326]:	loss = 0.020  exp loss = 0.022  adjusted loss = 0.022  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 118]:	loss = 0.200  exp loss = 0.219  adjusted loss = 0.219  adv prob = 0.250000   acc = 0.983
  waterbird_complete95 = 1, forest2water2 = 0  [n = 37]:	loss = 0.379  exp loss = 0.322  adjusted loss = 0.322  adv prob = 0.250000   acc = 0.892
  waterbird_complete95 = 1, forest2water2 = 1  [n = 719]:	loss = 0.084  exp loss = 0.070  adjusted loss = 0.070  adv prob = 0.250000   acc = 0.996
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_train_epoch_125.csv
logged to wandb
Average incurred loss: 0.043  
Average sample loss: 0.043  
Average acc: 0.997  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 1172]:	loss = 0.020  exp loss = 0.020  adjusted loss = 0.020  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 66]:	loss = 0.198  exp loss = 0.271  adjusted loss = 0.271  adv prob = 0.250000   acc = 0.985
  waterbird_complete95 = 1, forest2water2 = 0  [n = 19]:	loss = 0.366  exp loss = 0.307  adjusted loss = 0.307  adv prob = 0.250000   acc = 0.842
  waterbird_complete95 = 1, forest2water2 = 1  [n = 338]:	loss = 0.075  exp loss = 0.060  adjusted loss = 0.060  adv prob = 0.250000   acc = 1.000

Validation:
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_val_epoch_125.csv
logged to wandb
Average incurred loss: 0.486  
Average sample loss: 0.482  
Average acc: 0.767  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.039  exp loss = 0.036  adjusted loss = 0.036  adv prob = 0.250000   acc = 0.994
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.701  exp loss = 0.678  adjusted loss = 0.678  adv prob = 0.250000   acc = 0.622
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.590  exp loss = 1.686  adjusted loss = 1.686  adv prob = 0.250000   acc = 0.293
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.191  exp loss = 0.197  adjusted loss = 0.197  adv prob = 0.250000   acc = 0.955
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_test_epoch_125.csv
logged to wandb
Current lr: 0.000010


Epoch [126]:
Training:
Average incurred loss: 0.045  
Average sample loss: 0.045  
Average acc: 0.996  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2345]:	loss = 0.020  exp loss = 0.020  adjusted loss = 0.020  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 120]:	loss = 0.187  exp loss = 0.228  adjusted loss = 0.228  adv prob = 0.250000   acc = 0.967
  waterbird_complete95 = 1, forest2water2 = 0  [n = 41]:	loss = 0.370  exp loss = 0.437  adjusted loss = 0.437  adv prob = 0.250000   acc = 0.878
  waterbird_complete95 = 1, forest2water2 = 1  [n = 694]:	loss = 0.083  exp loss = 0.078  adjusted loss = 0.078  adv prob = 0.250000   acc = 0.996
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_train_epoch_126.csv
logged to wandb
Average incurred loss: 0.042  
Average sample loss: 0.042  
Average acc: 0.997  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 1153]:	loss = 0.017  exp loss = 0.017  adjusted loss = 0.017  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 64]:	loss = 0.185  exp loss = 0.228  adjusted loss = 0.228  adv prob = 0.250000   acc = 0.984
  waterbird_complete95 = 1, forest2water2 = 0  [n = 15]:	loss = 0.371  exp loss = 0.386  adjusted loss = 0.386  adv prob = 0.250000   acc = 0.867
  waterbird_complete95 = 1, forest2water2 = 1  [n = 363]:	loss = 0.081  exp loss = 0.072  adjusted loss = 0.072  adv prob = 0.250000   acc = 0.994

Validation:
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_val_epoch_126.csv
logged to wandb
Average incurred loss: 0.464  
Average sample loss: 0.461  
Average acc: 0.787  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.034  exp loss = 0.031  adjusted loss = 0.031  adv prob = 0.250000   acc = 0.996
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.620  exp loss = 0.598  adjusted loss = 0.598  adv prob = 0.250000   acc = 0.678
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.676  exp loss = 1.784  adjusted loss = 1.784  adv prob = 0.250000   acc = 0.286
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.217  exp loss = 0.225  adjusted loss = 0.225  adv prob = 0.250000   acc = 0.940
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_test_epoch_126.csv
logged to wandb
Current lr: 0.000010


Epoch [127]:
Training:
Average incurred loss: 0.044  
Average sample loss: 0.044  
Average acc: 0.997  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2321]:	loss = 0.020  exp loss = 0.019  adjusted loss = 0.019  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 121]:	loss = 0.188  exp loss = 0.175  adjusted loss = 0.175  adv prob = 0.250000   acc = 0.983
  waterbird_complete95 = 1, forest2water2 = 0  [n = 38]:	loss = 0.316  exp loss = 0.294  adjusted loss = 0.294  adv prob = 0.250000   acc = 0.921
  waterbird_complete95 = 1, forest2water2 = 1  [n = 720]:	loss = 0.084  exp loss = 0.071  adjusted loss = 0.071  adv prob = 0.250000   acc = 0.996
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_train_epoch_127.csv
logged to wandb
Average incurred loss: 0.040  
Average sample loss: 0.040  
Average acc: 0.997  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 1177]:	loss = 0.019  exp loss = 0.018  adjusted loss = 0.018  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 63]:	loss = 0.188  exp loss = 0.187  adjusted loss = 0.187  adv prob = 0.250000   acc = 0.984
  waterbird_complete95 = 1, forest2water2 = 0  [n = 18]:	loss = 0.306  exp loss = 0.302  adjusted loss = 0.302  adv prob = 0.250000   acc = 0.889
  waterbird_complete95 = 1, forest2water2 = 1  [n = 337]:	loss = 0.070  exp loss = 0.068  adjusted loss = 0.068  adv prob = 0.250000   acc = 0.997

Validation:
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_val_epoch_127.csv
logged to wandb
Average incurred loss: 0.470  
Average sample loss: 0.467  
Average acc: 0.782  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.034  exp loss = 0.031  adjusted loss = 0.031  adv prob = 0.250000   acc = 0.996
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.637  exp loss = 0.615  adjusted loss = 0.615  adv prob = 0.250000   acc = 0.663
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.673  exp loss = 1.778  adjusted loss = 1.778  adv prob = 0.250000   acc = 0.286
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.213  exp loss = 0.221  adjusted loss = 0.221  adv prob = 0.250000   acc = 0.947
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_test_epoch_127.csv
logged to wandb
Current lr: 0.000010


Epoch [128]:
Training:
Average incurred loss: 0.042  
Average sample loss: 0.042  
Average acc: 0.996  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2327]:	loss = 0.019  exp loss = 0.017  adjusted loss = 0.017  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 127]:	loss = 0.179  exp loss = 0.191  adjusted loss = 0.191  adv prob = 0.250000   acc = 0.976
  waterbird_complete95 = 1, forest2water2 = 0  [n = 44]:	loss = 0.329  exp loss = 0.382  adjusted loss = 0.382  adv prob = 0.250000   acc = 0.864
  waterbird_complete95 = 1, forest2water2 = 1  [n = 702]:	loss = 0.078  exp loss = 0.072  adjusted loss = 0.072  adv prob = 0.250000   acc = 0.994
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_train_epoch_128.csv
logged to wandb
Average incurred loss: 0.042  
Average sample loss: 0.042  
Average acc: 0.998  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 1171]:	loss = 0.019  exp loss = 0.018  adjusted loss = 0.018  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 57]:	loss = 0.185  exp loss = 0.163  adjusted loss = 0.163  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 0  [n = 12]:	loss = 0.332  exp loss = 0.346  adjusted loss = 0.346  adv prob = 0.250000   acc = 0.917
  waterbird_complete95 = 1, forest2water2 = 1  [n = 355]:	loss = 0.084  exp loss = 0.076  adjusted loss = 0.076  adv prob = 0.250000   acc = 0.994

Validation:
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_val_epoch_128.csv
logged to wandb
Average incurred loss: 0.467  
Average sample loss: 0.464  
Average acc: 0.788  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.034  exp loss = 0.030  adjusted loss = 0.030  adv prob = 0.250000   acc = 0.996
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.618  exp loss = 0.597  adjusted loss = 0.597  adv prob = 0.250000   acc = 0.680
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.709  exp loss = 1.816  adjusted loss = 1.816  adv prob = 0.250000   acc = 0.286
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.219  exp loss = 0.227  adjusted loss = 0.227  adv prob = 0.250000   acc = 0.940
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_test_epoch_128.csv
logged to wandb
Current lr: 0.000010


Epoch [129]:
Training:
Average incurred loss: 0.044  
Average sample loss: 0.044  
Average acc: 0.996  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2311]:	loss = 0.018  exp loss = 0.020  adjusted loss = 0.020  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 128]:	loss = 0.190  exp loss = 0.197  adjusted loss = 0.197  adv prob = 0.250000   acc = 0.984
  waterbird_complete95 = 1, forest2water2 = 0  [n = 42]:	loss = 0.359  exp loss = 0.266  adjusted loss = 0.266  adv prob = 0.250000   acc = 0.833
  waterbird_complete95 = 1, forest2water2 = 1  [n = 719]:	loss = 0.081  exp loss = 0.068  adjusted loss = 0.068  adv prob = 0.250000   acc = 0.993
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_train_epoch_129.csv
logged to wandb
Average incurred loss: 0.042  
Average sample loss: 0.042  
Average acc: 0.996  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 1187]:	loss = 0.021  exp loss = 0.019  adjusted loss = 0.019  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 56]:	loss = 0.191  exp loss = 0.181  adjusted loss = 0.181  adv prob = 0.250000   acc = 0.946
  waterbird_complete95 = 1, forest2water2 = 0  [n = 14]:	loss = 0.427  exp loss = 0.413  adjusted loss = 0.413  adv prob = 0.250000   acc = 0.786
  waterbird_complete95 = 1, forest2water2 = 1  [n = 338]:	loss = 0.074  exp loss = 0.072  adjusted loss = 0.072  adv prob = 0.250000   acc = 1.000

Validation:
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_val_epoch_129.csv
logged to wandb
Average incurred loss: 0.465  
Average sample loss: 0.462  
Average acc: 0.787  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.032  exp loss = 0.029  adjusted loss = 0.029  adv prob = 0.250000   acc = 0.996
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.614  exp loss = 0.593  adjusted loss = 0.593  adv prob = 0.250000   acc = 0.678
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.709  exp loss = 1.818  adjusted loss = 1.818  adv prob = 0.250000   acc = 0.286
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.217  exp loss = 0.224  adjusted loss = 0.224  adv prob = 0.250000   acc = 0.940
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_test_epoch_129.csv
logged to wandb
Current lr: 0.000010


Epoch [130]:
Training:
Average incurred loss: 0.043  
Average sample loss: 0.043  
Average acc: 0.997  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2342]:	loss = 0.019  exp loss = 0.017  adjusted loss = 0.017  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 131]:	loss = 0.195  exp loss = 0.237  adjusted loss = 0.237  adv prob = 0.250000   acc = 0.985
  waterbird_complete95 = 1, forest2water2 = 0  [n = 41]:	loss = 0.328  exp loss = 0.376  adjusted loss = 0.376  adv prob = 0.250000   acc = 0.902
  waterbird_complete95 = 1, forest2water2 = 1  [n = 686]:	loss = 0.078  exp loss = 0.073  adjusted loss = 0.073  adv prob = 0.250000   acc = 0.994
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_train_epoch_130.csv
logged to wandb
Average incurred loss: 0.039  
Average sample loss: 0.039  
Average acc: 0.997  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 1156]:	loss = 0.017  exp loss = 0.016  adjusted loss = 0.016  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 53]:	loss = 0.149  exp loss = 0.135  adjusted loss = 0.135  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 0  [n = 15]:	loss = 0.351  exp loss = 0.335  adjusted loss = 0.335  adv prob = 0.250000   acc = 0.867
  waterbird_complete95 = 1, forest2water2 = 1  [n = 371]:	loss = 0.080  exp loss = 0.073  adjusted loss = 0.073  adv prob = 0.250000   acc = 0.992

Validation:
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_val_epoch_130.csv
logged to wandb
Average incurred loss: 0.458  
Average sample loss: 0.454  
Average acc: 0.791  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.031  exp loss = 0.028  adjusted loss = 0.028  adv prob = 0.250000   acc = 0.996
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.581  exp loss = 0.559  adjusted loss = 0.559  adv prob = 0.250000   acc = 0.695
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.747  exp loss = 1.861  adjusted loss = 1.861  adv prob = 0.250000   acc = 0.271
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.232  exp loss = 0.242  adjusted loss = 0.242  adv prob = 0.250000   acc = 0.932
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_test_epoch_130.csv
logged to wandb
Current lr: 0.000010


Epoch [131]:
Training:
Average incurred loss: 0.042  
Average sample loss: 0.042  
Average acc: 0.997  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2317]:	loss = 0.018  exp loss = 0.018  adjusted loss = 0.018  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 127]:	loss = 0.162  exp loss = 0.137  adjusted loss = 0.137  adv prob = 0.250000   acc = 0.992
  waterbird_complete95 = 1, forest2water2 = 0  [n = 40]:	loss = 0.345  exp loss = 0.328  adjusted loss = 0.328  adv prob = 0.250000   acc = 0.875
  waterbird_complete95 = 1, forest2water2 = 1  [n = 716]:	loss = 0.081  exp loss = 0.079  adjusted loss = 0.079  adv prob = 0.250000   acc = 0.996
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_train_epoch_131.csv
logged to wandb
Average incurred loss: 0.040  
Average sample loss: 0.040  
Average acc: 0.998  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 1181]:	loss = 0.021  exp loss = 0.022  adjusted loss = 0.022  adv prob = 0.250000   acc = 0.999
  waterbird_complete95 = 0, forest2water2 = 1  [n = 57]:	loss = 0.185  exp loss = 0.188  adjusted loss = 0.188  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 0  [n = 16]:	loss = 0.339  exp loss = 0.329  adjusted loss = 0.329  adv prob = 0.250000   acc = 0.875
  waterbird_complete95 = 1, forest2water2 = 1  [n = 341]:	loss = 0.070  exp loss = 0.060  adjusted loss = 0.060  adv prob = 0.250000   acc = 1.000

Validation:
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_val_epoch_131.csv
logged to wandb
Average incurred loss: 0.483  
Average sample loss: 0.480  
Average acc: 0.768  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.038  exp loss = 0.035  adjusted loss = 0.035  adv prob = 0.250000   acc = 0.994
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.694  exp loss = 0.670  adjusted loss = 0.670  adv prob = 0.250000   acc = 0.624
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.603  exp loss = 1.699  adjusted loss = 1.699  adv prob = 0.250000   acc = 0.293
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.191  exp loss = 0.197  adjusted loss = 0.197  adv prob = 0.250000   acc = 0.955
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_test_epoch_131.csv
logged to wandb
Current lr: 0.000010


Epoch [132]:
Training:
Average incurred loss: 0.042  
Average sample loss: 0.042  
Average acc: 0.998  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2330]:	loss = 0.019  exp loss = 0.018  adjusted loss = 0.018  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 128]:	loss = 0.179  exp loss = 0.161  adjusted loss = 0.161  adv prob = 0.250000   acc = 0.992
  waterbird_complete95 = 1, forest2water2 = 0  [n = 44]:	loss = 0.285  exp loss = 0.258  adjusted loss = 0.258  adv prob = 0.250000   acc = 0.977
  waterbird_complete95 = 1, forest2water2 = 1  [n = 698]:	loss = 0.080  exp loss = 0.066  adjusted loss = 0.066  adv prob = 0.250000   acc = 0.994
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_train_epoch_132.csv
logged to wandb
Average incurred loss: 0.041  
Average sample loss: 0.041  
Average acc: 0.997  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 1168]:	loss = 0.018  exp loss = 0.019  adjusted loss = 0.019  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 56]:	loss = 0.202  exp loss = 0.208  adjusted loss = 0.208  adv prob = 0.250000   acc = 0.982
  waterbird_complete95 = 1, forest2water2 = 0  [n = 12]:	loss = 0.371  exp loss = 0.339  adjusted loss = 0.339  adv prob = 0.250000   acc = 0.833
  waterbird_complete95 = 1, forest2water2 = 1  [n = 359]:	loss = 0.079  exp loss = 0.062  adjusted loss = 0.062  adv prob = 0.250000   acc = 0.994

Validation:
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_val_epoch_132.csv
logged to wandb
Average incurred loss: 0.476  
Average sample loss: 0.472  
Average acc: 0.776  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.036  exp loss = 0.032  adjusted loss = 0.032  adv prob = 0.250000   acc = 0.996
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.664  exp loss = 0.640  adjusted loss = 0.640  adv prob = 0.250000   acc = 0.648
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.638  exp loss = 1.737  adjusted loss = 1.737  adv prob = 0.250000   acc = 0.286
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.198  exp loss = 0.204  adjusted loss = 0.204  adv prob = 0.250000   acc = 0.947
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_test_epoch_132.csv
logged to wandb
Current lr: 0.000010


Epoch [133]:
Training:
Average incurred loss: 0.041  
Average sample loss: 0.041  
Average acc: 0.996  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2344]:	loss = 0.018  exp loss = 0.016  adjusted loss = 0.016  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 117]:	loss = 0.169  exp loss = 0.170  adjusted loss = 0.170  adv prob = 0.250000   acc = 0.983
  waterbird_complete95 = 1, forest2water2 = 0  [n = 37]:	loss = 0.433  exp loss = 0.508  adjusted loss = 0.508  adv prob = 0.250000   acc = 0.811
  waterbird_complete95 = 1, forest2water2 = 1  [n = 702]:	loss = 0.073  exp loss = 0.082  adjusted loss = 0.082  adv prob = 0.250000   acc = 0.996
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_train_epoch_133.csv
logged to wandb
Average incurred loss: 0.044  
Average sample loss: 0.044  
Average acc: 0.997  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 1154]:	loss = 0.018  exp loss = 0.015  adjusted loss = 0.015  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 67]:	loss = 0.211  exp loss = 0.153  adjusted loss = 0.153  adv prob = 0.250000   acc = 0.970
  waterbird_complete95 = 1, forest2water2 = 0  [n = 19]:	loss = 0.284  exp loss = 0.362  adjusted loss = 0.362  adv prob = 0.250000   acc = 0.895
  waterbird_complete95 = 1, forest2water2 = 1  [n = 355]:	loss = 0.084  exp loss = 0.081  adjusted loss = 0.081  adv prob = 0.250000   acc = 0.997

Validation:
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_val_epoch_133.csv
logged to wandb
Average incurred loss: 0.455  
Average sample loss: 0.451  
Average acc: 0.795  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.030  exp loss = 0.027  adjusted loss = 0.027  adv prob = 0.250000   acc = 0.996
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.569  exp loss = 0.549  adjusted loss = 0.549  adv prob = 0.250000   acc = 0.704
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.765  exp loss = 1.880  adjusted loss = 1.880  adv prob = 0.250000   acc = 0.271
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.235  exp loss = 0.243  adjusted loss = 0.243  adv prob = 0.250000   acc = 0.932
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_test_epoch_133.csv
logged to wandb
Current lr: 0.000010


Epoch [134]:
Training:
Average incurred loss: 0.041  
Average sample loss: 0.041  
Average acc: 0.997  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2327]:	loss = 0.019  exp loss = 0.014  adjusted loss = 0.014  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 128]:	loss = 0.173  exp loss = 0.162  adjusted loss = 0.162  adv prob = 0.250000   acc = 0.992
  waterbird_complete95 = 1, forest2water2 = 0  [n = 36]:	loss = 0.329  exp loss = 0.385  adjusted loss = 0.385  adv prob = 0.250000   acc = 0.917
  waterbird_complete95 = 1, forest2water2 = 1  [n = 709]:	loss = 0.076  exp loss = 0.098  adjusted loss = 0.098  adv prob = 0.250000   acc = 0.994
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_train_epoch_134.csv
logged to wandb
Average incurred loss: 0.043  
Average sample loss: 0.043  
Average acc: 0.996  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 1171]:	loss = 0.019  exp loss = 0.018  adjusted loss = 0.018  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 56]:	loss = 0.213  exp loss = 0.180  adjusted loss = 0.180  adv prob = 0.250000   acc = 0.964
  waterbird_complete95 = 1, forest2water2 = 0  [n = 20]:	loss = 0.293  exp loss = 0.295  adjusted loss = 0.295  adv prob = 0.250000   acc = 0.900
  waterbird_complete95 = 1, forest2water2 = 1  [n = 348]:	loss = 0.083  exp loss = 0.071  adjusted loss = 0.071  adv prob = 0.250000   acc = 0.991

Validation:
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_val_epoch_134.csv
logged to wandb
Average incurred loss: 0.474  
Average sample loss: 0.471  
Average acc: 0.776  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.035  exp loss = 0.032  adjusted loss = 0.032  adv prob = 0.250000   acc = 0.996
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.655  exp loss = 0.632  adjusted loss = 0.632  adv prob = 0.250000   acc = 0.646
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.658  exp loss = 1.755  adjusted loss = 1.755  adv prob = 0.250000   acc = 0.293
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.202  exp loss = 0.209  adjusted loss = 0.209  adv prob = 0.250000   acc = 0.947
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_test_epoch_134.csv
logged to wandb
Current lr: 0.000010


Epoch [135]:
Training:
Average incurred loss: 0.038  
Average sample loss: 0.038  
Average acc: 0.998  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2371]:	loss = 0.020  exp loss = 0.019  adjusted loss = 0.019  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 127]:	loss = 0.178  exp loss = 0.177  adjusted loss = 0.177  adv prob = 0.250000   acc = 0.976
  waterbird_complete95 = 1, forest2water2 = 0  [n = 35]:	loss = 0.267  exp loss = 0.272  adjusted loss = 0.272  adv prob = 0.250000   acc = 0.971
  waterbird_complete95 = 1, forest2water2 = 1  [n = 667]:	loss = 0.066  exp loss = 0.069  adjusted loss = 0.069  adv prob = 0.250000   acc = 0.997
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_train_epoch_135.csv
logged to wandb
Average incurred loss: 0.041  
Average sample loss: 0.041  
Average acc: 0.996  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 1127]:	loss = 0.015  exp loss = 0.014  adjusted loss = 0.014  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 57]:	loss = 0.124  exp loss = 0.125  adjusted loss = 0.125  adv prob = 0.250000   acc = 0.982
  waterbird_complete95 = 1, forest2water2 = 0  [n = 21]:	loss = 0.350  exp loss = 0.328  adjusted loss = 0.328  adv prob = 0.250000   acc = 0.857
  waterbird_complete95 = 1, forest2water2 = 1  [n = 390]:	loss = 0.087  exp loss = 0.074  adjusted loss = 0.074  adv prob = 0.250000   acc = 0.995

Validation:
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_val_epoch_135.csv
logged to wandb
Average incurred loss: 0.450  
Average sample loss: 0.446  
Average acc: 0.794  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.027  exp loss = 0.025  adjusted loss = 0.025  adv prob = 0.250000   acc = 0.996
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.533  exp loss = 0.512  adjusted loss = 0.512  adv prob = 0.250000   acc = 0.710
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.844  exp loss = 1.970  adjusted loss = 1.970  adv prob = 0.250000   acc = 0.248
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.253  exp loss = 0.262  adjusted loss = 0.262  adv prob = 0.250000   acc = 0.925
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_test_epoch_135.csv
logged to wandb
Current lr: 0.000010


Epoch [136]:
Training:
Average incurred loss: 0.038  
Average sample loss: 0.038  
Average acc: 0.998  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2343]:	loss = 0.018  exp loss = 0.016  adjusted loss = 0.016  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 121]:	loss = 0.176  exp loss = 0.143  adjusted loss = 0.143  adv prob = 0.250000   acc = 0.975
  waterbird_complete95 = 1, forest2water2 = 0  [n = 33]:	loss = 0.270  exp loss = 0.257  adjusted loss = 0.257  adv prob = 0.250000   acc = 0.909
  waterbird_complete95 = 1, forest2water2 = 1  [n = 703]:	loss = 0.071  exp loss = 0.068  adjusted loss = 0.068  adv prob = 0.250000   acc = 0.999
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_train_epoch_136.csv
logged to wandb
Average incurred loss: 0.042  
Average sample loss: 0.042  
Average acc: 0.997  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 1155]:	loss = 0.018  exp loss = 0.017  adjusted loss = 0.017  adv prob = 0.250000   acc = 0.999
  waterbird_complete95 = 0, forest2water2 = 1  [n = 63]:	loss = 0.164  exp loss = 0.173  adjusted loss = 0.173  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 0  [n = 23]:	loss = 0.376  exp loss = 0.334  adjusted loss = 0.334  adv prob = 0.250000   acc = 0.870
  waterbird_complete95 = 1, forest2water2 = 1  [n = 354]:	loss = 0.078  exp loss = 0.077  adjusted loss = 0.077  adv prob = 0.250000   acc = 0.997

Validation:
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_val_epoch_136.csv
logged to wandb
Average incurred loss: 0.455  
Average sample loss: 0.451  
Average acc: 0.793  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.031  exp loss = 0.028  adjusted loss = 0.028  adv prob = 0.250000   acc = 0.996
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.591  exp loss = 0.571  adjusted loss = 0.571  adv prob = 0.250000   acc = 0.693
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.704  exp loss = 1.812  adjusted loss = 1.812  adv prob = 0.250000   acc = 0.286
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.219  exp loss = 0.225  adjusted loss = 0.225  adv prob = 0.250000   acc = 0.940
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_test_epoch_136.csv
logged to wandb
Current lr: 0.000010


Epoch [137]:
Training:
Average incurred loss: 0.039  
Average sample loss: 0.039  
Average acc: 0.998  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2358]:	loss = 0.018  exp loss = 0.017  adjusted loss = 0.017  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 123]:	loss = 0.185  exp loss = 0.192  adjusted loss = 0.192  adv prob = 0.250000   acc = 0.984
  waterbird_complete95 = 1, forest2water2 = 0  [n = 37]:	loss = 0.338  exp loss = 0.343  adjusted loss = 0.343  adv prob = 0.250000   acc = 0.892
  waterbird_complete95 = 1, forest2water2 = 1  [n = 682]:	loss = 0.067  exp loss = 0.064  adjusted loss = 0.064  adv prob = 0.250000   acc = 0.997
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_train_epoch_137.csv
logged to wandb
Average incurred loss: 0.040  
Average sample loss: 0.040  
Average acc: 0.998  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 1140]:	loss = 0.016  exp loss = 0.015  adjusted loss = 0.015  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 61]:	loss = 0.157  exp loss = 0.150  adjusted loss = 0.150  adv prob = 0.250000   acc = 0.984
  waterbird_complete95 = 1, forest2water2 = 0  [n = 19]:	loss = 0.264  exp loss = 0.303  adjusted loss = 0.303  adv prob = 0.250000   acc = 0.947
  waterbird_complete95 = 1, forest2water2 = 1  [n = 375]:	loss = 0.083  exp loss = 0.072  adjusted loss = 0.072  adv prob = 0.250000   acc = 0.997

Validation:
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_val_epoch_137.csv
logged to wandb
Average incurred loss: 0.461  
Average sample loss: 0.458  
Average acc: 0.791  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.031  exp loss = 0.028  adjusted loss = 0.028  adv prob = 0.250000   acc = 0.996
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.601  exp loss = 0.580  adjusted loss = 0.580  adv prob = 0.250000   acc = 0.689
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.725  exp loss = 1.838  adjusted loss = 1.838  adv prob = 0.250000   acc = 0.286
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.219  exp loss = 0.226  adjusted loss = 0.226  adv prob = 0.250000   acc = 0.940
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_test_epoch_137.csv
logged to wandb
Current lr: 0.000010


Epoch [138]:
Training:
Average incurred loss: 0.040  
Average sample loss: 0.040  
Average acc: 0.997  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2345]:	loss = 0.019  exp loss = 0.018  adjusted loss = 0.018  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 116]:	loss = 0.185  exp loss = 0.192  adjusted loss = 0.192  adv prob = 0.250000   acc = 0.966
  waterbird_complete95 = 1, forest2water2 = 0  [n = 38]:	loss = 0.299  exp loss = 0.245  adjusted loss = 0.245  adv prob = 0.250000   acc = 0.895
  waterbird_complete95 = 1, forest2water2 = 1  [n = 701]:	loss = 0.074  exp loss = 0.065  adjusted loss = 0.065  adv prob = 0.250000   acc = 0.997
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_train_epoch_138.csv
logged to wandb
Average incurred loss: 0.040  
Average sample loss: 0.040  
Average acc: 0.999  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 1153]:	loss = 0.017  exp loss = 0.017  adjusted loss = 0.017  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 68]:	loss = 0.141  exp loss = 0.149  adjusted loss = 0.149  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 0  [n = 18]:	loss = 0.368  exp loss = 0.304  adjusted loss = 0.304  adv prob = 0.250000   acc = 0.889
  waterbird_complete95 = 1, forest2water2 = 1  [n = 356]:	loss = 0.080  exp loss = 0.067  adjusted loss = 0.067  adv prob = 0.250000   acc = 1.000

Validation:
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_val_epoch_138.csv
logged to wandb
Average incurred loss: 0.461  
Average sample loss: 0.457  
Average acc: 0.788  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.032  exp loss = 0.029  adjusted loss = 0.029  adv prob = 0.250000   acc = 0.996
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.613  exp loss = 0.593  adjusted loss = 0.593  adv prob = 0.250000   acc = 0.680
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.680  exp loss = 1.787  adjusted loss = 1.787  adv prob = 0.250000   acc = 0.286
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.210  exp loss = 0.218  adjusted loss = 0.218  adv prob = 0.250000   acc = 0.940
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_test_epoch_138.csv
logged to wandb
Current lr: 0.000010


Epoch [139]:
Training:
Average incurred loss: 0.037  
Average sample loss: 0.037  
Average acc: 0.998  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2314]:	loss = 0.016  exp loss = 0.016  adjusted loss = 0.016  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 127]:	loss = 0.156  exp loss = 0.158  adjusted loss = 0.158  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 0  [n = 40]:	loss = 0.309  exp loss = 0.299  adjusted loss = 0.299  adv prob = 0.250000   acc = 0.925
  waterbird_complete95 = 1, forest2water2 = 1  [n = 719]:	loss = 0.068  exp loss = 0.062  adjusted loss = 0.062  adv prob = 0.250000   acc = 0.997
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_train_epoch_139.csv
logged to wandb
Average incurred loss: 0.040  
Average sample loss: 0.040  
Average acc: 0.997  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 1184]:	loss = 0.020  exp loss = 0.018  adjusted loss = 0.018  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 57]:	loss = 0.188  exp loss = 0.212  adjusted loss = 0.212  adv prob = 0.250000   acc = 0.965
  waterbird_complete95 = 1, forest2water2 = 0  [n = 16]:	loss = 0.324  exp loss = 0.348  adjusted loss = 0.348  adv prob = 0.250000   acc = 0.875
  waterbird_complete95 = 1, forest2water2 = 1  [n = 338]:	loss = 0.073  exp loss = 0.071  adjusted loss = 0.071  adv prob = 0.250000   acc = 1.000

Validation:
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_val_epoch_139.csv
logged to wandb
Average incurred loss: 0.469  
Average sample loss: 0.465  
Average acc: 0.783  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.033  exp loss = 0.030  adjusted loss = 0.030  adv prob = 0.250000   acc = 0.996
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.635  exp loss = 0.613  adjusted loss = 0.613  adv prob = 0.250000   acc = 0.665
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.675  exp loss = 1.777  adjusted loss = 1.777  adv prob = 0.250000   acc = 0.286
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.206  exp loss = 0.213  adjusted loss = 0.213  adv prob = 0.250000   acc = 0.947
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_test_epoch_139.csv
logged to wandb
Current lr: 0.000010


Epoch [140]:
Training:
Average incurred loss: 0.037  
Average sample loss: 0.037  
Average acc: 0.999  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2336]:	loss = 0.017  exp loss = 0.016  adjusted loss = 0.016  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 123]:	loss = 0.148  exp loss = 0.160  adjusted loss = 0.160  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 0  [n = 41]:	loss = 0.294  exp loss = 0.244  adjusted loss = 0.244  adv prob = 0.250000   acc = 0.927
  waterbird_complete95 = 1, forest2water2 = 1  [n = 700]:	loss = 0.070  exp loss = 0.060  adjusted loss = 0.060  adv prob = 0.250000   acc = 0.999
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_train_epoch_140.csv
logged to wandb
Average incurred loss: 0.038  
Average sample loss: 0.038  
Average acc: 0.997  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 1162]:	loss = 0.017  exp loss = 0.018  adjusted loss = 0.018  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 61]:	loss = 0.186  exp loss = 0.264  adjusted loss = 0.264  adv prob = 0.250000   acc = 0.951
  waterbird_complete95 = 1, forest2water2 = 0  [n = 15]:	loss = 0.234  exp loss = 0.267  adjusted loss = 0.267  adv prob = 0.250000   acc = 0.933
  waterbird_complete95 = 1, forest2water2 = 1  [n = 357]:	loss = 0.070  exp loss = 0.061  adjusted loss = 0.061  adv prob = 0.250000   acc = 0.997

Validation:
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_val_epoch_140.csv
logged to wandb
Average incurred loss: 0.477  
Average sample loss: 0.474  
Average acc: 0.776  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.035  exp loss = 0.032  adjusted loss = 0.032  adv prob = 0.250000   acc = 0.996
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.667  exp loss = 0.643  adjusted loss = 0.643  adv prob = 0.250000   acc = 0.644
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.646  exp loss = 1.751  adjusted loss = 1.751  adv prob = 0.250000   acc = 0.293
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.194  exp loss = 0.199  adjusted loss = 0.199  adv prob = 0.250000   acc = 0.947
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_test_epoch_140.csv
logged to wandb
Current lr: 0.000010


Epoch [141]:
Training:
Average incurred loss: 0.037  
Average sample loss: 0.037  
Average acc: 0.997  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2330]:	loss = 0.017  exp loss = 0.017  adjusted loss = 0.017  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 130]:	loss = 0.179  exp loss = 0.170  adjusted loss = 0.170  adv prob = 0.250000   acc = 0.969
  waterbird_complete95 = 1, forest2water2 = 0  [n = 44]:	loss = 0.279  exp loss = 0.284  adjusted loss = 0.284  adv prob = 0.250000   acc = 0.932
  waterbird_complete95 = 1, forest2water2 = 1  [n = 696]:	loss = 0.062  exp loss = 0.057  adjusted loss = 0.057  adv prob = 0.250000   acc = 0.999
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_train_epoch_141.csv
logged to wandb
Average incurred loss: 0.037  
Average sample loss: 0.037  
Average acc: 0.999  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 1168]:	loss = 0.017  exp loss = 0.015  adjusted loss = 0.015  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 54]:	loss = 0.170  exp loss = 0.153  adjusted loss = 0.153  adv prob = 0.250000   acc = 0.963
  waterbird_complete95 = 1, forest2water2 = 0  [n = 12]:	loss = 0.281  exp loss = 0.297  adjusted loss = 0.297  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 361]:	loss = 0.077  exp loss = 0.070  adjusted loss = 0.070  adv prob = 0.250000   acc = 1.000

Validation:
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_val_epoch_141.csv
logged to wandb
Average incurred loss: 0.463  
Average sample loss: 0.459  
Average acc: 0.792  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.029  exp loss = 0.026  adjusted loss = 0.026  adv prob = 0.250000   acc = 0.996
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.597  exp loss = 0.576  adjusted loss = 0.576  adv prob = 0.250000   acc = 0.691
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.755  exp loss = 1.868  adjusted loss = 1.868  adv prob = 0.250000   acc = 0.286
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.219  exp loss = 0.225  adjusted loss = 0.225  adv prob = 0.250000   acc = 0.940
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_test_epoch_141.csv
logged to wandb
Current lr: 0.000010


Epoch [142]:
Training:
Average incurred loss: 0.036  
Average sample loss: 0.036  
Average acc: 0.998  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2344]:	loss = 0.017  exp loss = 0.015  adjusted loss = 0.015  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 123]:	loss = 0.157  exp loss = 0.167  adjusted loss = 0.167  adv prob = 0.250000   acc = 0.992
  waterbird_complete95 = 1, forest2water2 = 0  [n = 35]:	loss = 0.242  exp loss = 0.207  adjusted loss = 0.207  adv prob = 0.250000   acc = 0.943
  waterbird_complete95 = 1, forest2water2 = 1  [n = 698]:	loss = 0.067  exp loss = 0.067  adjusted loss = 0.067  adv prob = 0.250000   acc = 0.997
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_train_epoch_142.csv
logged to wandb
Average incurred loss: 0.039  
Average sample loss: 0.039  
Average acc: 0.994  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 1154]:	loss = 0.015  exp loss = 0.015  adjusted loss = 0.015  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 61]:	loss = 0.161  exp loss = 0.162  adjusted loss = 0.162  adv prob = 0.250000   acc = 0.984
  waterbird_complete95 = 1, forest2water2 = 0  [n = 21]:	loss = 0.444  exp loss = 0.310  adjusted loss = 0.310  adv prob = 0.250000   acc = 0.714
  waterbird_complete95 = 1, forest2water2 = 1  [n = 359]:	loss = 0.073  exp loss = 0.063  adjusted loss = 0.063  adv prob = 0.250000   acc = 0.994

Validation:
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_val_epoch_142.csv
logged to wandb
Average incurred loss: 0.462  
Average sample loss: 0.459  
Average acc: 0.792  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.031  exp loss = 0.028  adjusted loss = 0.028  adv prob = 0.250000   acc = 0.996
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.613  exp loss = 0.592  adjusted loss = 0.592  adv prob = 0.250000   acc = 0.689
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.701  exp loss = 1.817  adjusted loss = 1.817  adv prob = 0.250000   acc = 0.286
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.211  exp loss = 0.217  adjusted loss = 0.217  adv prob = 0.250000   acc = 0.947
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_test_epoch_142.csv
logged to wandb
Current lr: 0.000010


Epoch [143]:
Training:
Average incurred loss: 0.040  
Average sample loss: 0.040  
Average acc: 0.997  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2332]:	loss = 0.017  exp loss = 0.014  adjusted loss = 0.014  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 121]:	loss = 0.175  exp loss = 0.146  adjusted loss = 0.146  adv prob = 0.250000   acc = 0.983
  waterbird_complete95 = 1, forest2water2 = 0  [n = 38]:	loss = 0.361  exp loss = 0.364  adjusted loss = 0.364  adv prob = 0.250000   acc = 0.842
  waterbird_complete95 = 1, forest2water2 = 1  [n = 709]:	loss = 0.073  exp loss = 0.078  adjusted loss = 0.078  adv prob = 0.250000   acc = 0.996
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_train_epoch_143.csv
logged to wandb
Average incurred loss: 0.037  
Average sample loss: 0.037  
Average acc: 0.999  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 1166]:	loss = 0.018  exp loss = 0.017  adjusted loss = 0.017  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 63]:	loss = 0.152  exp loss = 0.158  adjusted loss = 0.158  adv prob = 0.250000   acc = 0.968
  waterbird_complete95 = 1, forest2water2 = 0  [n = 18]:	loss = 0.239  exp loss = 0.254  adjusted loss = 0.254  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 348]:	loss = 0.070  exp loss = 0.061  adjusted loss = 0.061  adv prob = 0.250000   acc = 1.000

Validation:
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_val_epoch_143.csv
logged to wandb
Average incurred loss: 0.462  
Average sample loss: 0.458  
Average acc: 0.791  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.031  exp loss = 0.028  adjusted loss = 0.028  adv prob = 0.250000   acc = 0.996
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.612  exp loss = 0.591  adjusted loss = 0.591  adv prob = 0.250000   acc = 0.685
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.701  exp loss = 1.810  adjusted loss = 1.810  adv prob = 0.250000   acc = 0.286
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.209  exp loss = 0.215  adjusted loss = 0.215  adv prob = 0.250000   acc = 0.947
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_test_epoch_143.csv
logged to wandb
Current lr: 0.000010


Epoch [144]:
Training:
Average incurred loss: 0.039  
Average sample loss: 0.039  
Average acc: 0.998  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2316]:	loss = 0.017  exp loss = 0.016  adjusted loss = 0.016  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 132]:	loss = 0.167  exp loss = 0.151  adjusted loss = 0.151  adv prob = 0.250000   acc = 0.992
  waterbird_complete95 = 1, forest2water2 = 0  [n = 38]:	loss = 0.292  exp loss = 0.361  adjusted loss = 0.361  adv prob = 0.250000   acc = 0.895
  waterbird_complete95 = 1, forest2water2 = 1  [n = 714]:	loss = 0.074  exp loss = 0.067  adjusted loss = 0.067  adv prob = 0.250000   acc = 0.999
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_train_epoch_144.csv
logged to wandb
Average incurred loss: 0.036  
Average sample loss: 0.036  
Average acc: 0.998  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 1182]:	loss = 0.018  exp loss = 0.016  adjusted loss = 0.016  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 52]:	loss = 0.159  exp loss = 0.151  adjusted loss = 0.151  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 0  [n = 18]:	loss = 0.255  exp loss = 0.273  adjusted loss = 0.273  adv prob = 0.250000   acc = 0.944
  waterbird_complete95 = 1, forest2water2 = 1  [n = 343]:	loss = 0.067  exp loss = 0.063  adjusted loss = 0.063  adv prob = 0.250000   acc = 0.994

Validation:
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_val_epoch_144.csv
logged to wandb
Average incurred loss: 0.462  
Average sample loss: 0.458  
Average acc: 0.794  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.030  exp loss = 0.027  adjusted loss = 0.027  adv prob = 0.250000   acc = 0.996
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.603  exp loss = 0.582  adjusted loss = 0.582  adv prob = 0.250000   acc = 0.693
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.731  exp loss = 1.844  adjusted loss = 1.844  adv prob = 0.250000   acc = 0.286
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.215  exp loss = 0.222  adjusted loss = 0.222  adv prob = 0.250000   acc = 0.947
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_test_epoch_144.csv
logged to wandb
Current lr: 0.000010


Epoch [145]:
Training:
Average incurred loss: 0.037  
Average sample loss: 0.037  
Average acc: 0.998  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2329]:	loss = 0.017  exp loss = 0.016  adjusted loss = 0.016  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 130]:	loss = 0.161  exp loss = 0.200  adjusted loss = 0.200  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 0  [n = 42]:	loss = 0.283  exp loss = 0.344  adjusted loss = 0.344  adv prob = 0.250000   acc = 0.929
  waterbird_complete95 = 1, forest2water2 = 1  [n = 699]:	loss = 0.065  exp loss = 0.057  adjusted loss = 0.057  adv prob = 0.250000   acc = 0.997
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_train_epoch_145.csv
logged to wandb
Average incurred loss: 0.036  
Average sample loss: 0.036  
Average acc: 0.999  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 1169]:	loss = 0.016  exp loss = 0.015  adjusted loss = 0.015  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 54]:	loss = 0.157  exp loss = 0.157  adjusted loss = 0.157  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 0  [n = 14]:	loss = 0.289  exp loss = 0.273  adjusted loss = 0.273  adv prob = 0.250000   acc = 0.929
  waterbird_complete95 = 1, forest2water2 = 1  [n = 358]:	loss = 0.071  exp loss = 0.071  adjusted loss = 0.071  adv prob = 0.250000   acc = 0.997

Validation:
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_val_epoch_145.csv
logged to wandb
Average incurred loss: 0.454  
Average sample loss: 0.450  
Average acc: 0.796  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.028  exp loss = 0.025  adjusted loss = 0.025  adv prob = 0.250000   acc = 0.996
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.570  exp loss = 0.550  adjusted loss = 0.550  adv prob = 0.250000   acc = 0.704
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.769  exp loss = 1.885  adjusted loss = 1.885  adv prob = 0.250000   acc = 0.278
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.226  exp loss = 0.233  adjusted loss = 0.233  adv prob = 0.250000   acc = 0.940
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_test_epoch_145.csv
logged to wandb
Current lr: 0.000010


Epoch [146]:
Training:
Average incurred loss: 0.037  
Average sample loss: 0.037  
Average acc: 0.997  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2360]:	loss = 0.018  exp loss = 0.019  adjusted loss = 0.019  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 120]:	loss = 0.179  exp loss = 0.207  adjusted loss = 0.207  adv prob = 0.250000   acc = 0.983
  waterbird_complete95 = 1, forest2water2 = 0  [n = 38]:	loss = 0.286  exp loss = 0.299  adjusted loss = 0.299  adv prob = 0.250000   acc = 0.947
  waterbird_complete95 = 1, forest2water2 = 1  [n = 682]:	loss = 0.066  exp loss = 0.049  adjusted loss = 0.049  adv prob = 0.250000   acc = 0.996
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_train_epoch_146.csv
logged to wandb
Average incurred loss: 0.035  
Average sample loss: 0.035  
Average acc: 0.999  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 1138]:	loss = 0.014  exp loss = 0.015  adjusted loss = 0.015  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 64]:	loss = 0.119  exp loss = 0.129  adjusted loss = 0.129  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 0  [n = 18]:	loss = 0.227  exp loss = 0.279  adjusted loss = 0.279  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 375]:	loss = 0.076  exp loss = 0.060  adjusted loss = 0.060  adv prob = 0.250000   acc = 0.995

Validation:
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_val_epoch_146.csv
logged to wandb
Average incurred loss: 0.463  
Average sample loss: 0.460  
Average acc: 0.790  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.031  exp loss = 0.028  adjusted loss = 0.028  adv prob = 0.250000   acc = 0.996
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.610  exp loss = 0.588  adjusted loss = 0.588  adv prob = 0.250000   acc = 0.682
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.719  exp loss = 1.829  adjusted loss = 1.829  adv prob = 0.250000   acc = 0.293
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.211  exp loss = 0.217  adjusted loss = 0.217  adv prob = 0.250000   acc = 0.940
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_test_epoch_146.csv
logged to wandb
Current lr: 0.000010


Epoch [147]:
Training:
Average incurred loss: 0.037  
Average sample loss: 0.037  
Average acc: 0.997  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2337]:	loss = 0.017  exp loss = 0.015  adjusted loss = 0.015  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 120]:	loss = 0.165  exp loss = 0.150  adjusted loss = 0.150  adv prob = 0.250000   acc = 0.983
  waterbird_complete95 = 1, forest2water2 = 0  [n = 41]:	loss = 0.276  exp loss = 0.327  adjusted loss = 0.327  adv prob = 0.250000   acc = 0.927
  waterbird_complete95 = 1, forest2water2 = 1  [n = 702]:	loss = 0.069  exp loss = 0.070  adjusted loss = 0.070  adv prob = 0.250000   acc = 0.996
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_train_epoch_147.csv
logged to wandb
Average incurred loss: 0.035  
Average sample loss: 0.034  
Average acc: 0.997  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 1161]:	loss = 0.015  exp loss = 0.015  adjusted loss = 0.015  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 64]:	loss = 0.152  exp loss = 0.154  adjusted loss = 0.154  adv prob = 0.250000   acc = 0.969
  waterbird_complete95 = 1, forest2water2 = 0  [n = 15]:	loss = 0.281  exp loss = 0.315  adjusted loss = 0.315  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 355]:	loss = 0.067  exp loss = 0.058  adjusted loss = 0.058  adv prob = 0.250000   acc = 0.994

Validation:
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_val_epoch_147.csv
logged to wandb
Average incurred loss: 0.469  
Average sample loss: 0.466  
Average acc: 0.782  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.032  exp loss = 0.029  adjusted loss = 0.029  adv prob = 0.250000   acc = 0.996
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.641  exp loss = 0.619  adjusted loss = 0.619  adv prob = 0.250000   acc = 0.661
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.676  exp loss = 1.786  adjusted loss = 1.786  adv prob = 0.250000   acc = 0.293
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.199  exp loss = 0.204  adjusted loss = 0.204  adv prob = 0.250000   acc = 0.947
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_test_epoch_147.csv
logged to wandb
Current lr: 0.000010


Epoch [148]:
Training:
Average incurred loss: 0.034  
Average sample loss: 0.034  
Average acc: 0.998  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2352]:	loss = 0.017  exp loss = 0.016  adjusted loss = 0.016  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 110]:	loss = 0.152  exp loss = 0.177  adjusted loss = 0.177  adv prob = 0.250000   acc = 0.973
  waterbird_complete95 = 1, forest2water2 = 0  [n = 35]:	loss = 0.180  exp loss = 0.198  adjusted loss = 0.198  adv prob = 0.250000   acc = 0.971
  waterbird_complete95 = 1, forest2water2 = 1  [n = 703]:	loss = 0.067  exp loss = 0.054  adjusted loss = 0.054  adv prob = 0.250000   acc = 0.996
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_train_epoch_148.csv
logged to wandb
Average incurred loss: 0.041  
Average sample loss: 0.041  
Average acc: 0.995  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 1146]:	loss = 0.016  exp loss = 0.016  adjusted loss = 0.016  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 74]:	loss = 0.159  exp loss = 0.154  adjusted loss = 0.154  adv prob = 0.250000   acc = 0.986
  waterbird_complete95 = 1, forest2water2 = 0  [n = 21]:	loss = 0.451  exp loss = 0.362  adjusted loss = 0.362  adv prob = 0.250000   acc = 0.762
  waterbird_complete95 = 1, forest2water2 = 1  [n = 354]:	loss = 0.074  exp loss = 0.063  adjusted loss = 0.063  adv prob = 0.250000   acc = 0.994

Validation:
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_val_epoch_148.csv
logged to wandb
Average incurred loss: 0.459  
Average sample loss: 0.456  
Average acc: 0.793  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.029  exp loss = 0.026  adjusted loss = 0.026  adv prob = 0.250000   acc = 0.996
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.601  exp loss = 0.579  adjusted loss = 0.579  adv prob = 0.250000   acc = 0.691
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.722  exp loss = 1.835  adjusted loss = 1.835  adv prob = 0.250000   acc = 0.286
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.210  exp loss = 0.216  adjusted loss = 0.216  adv prob = 0.250000   acc = 0.947
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_test_epoch_148.csv
logged to wandb
Current lr: 0.000010


Epoch [149]:
Training:
Average incurred loss: 0.034  
Average sample loss: 0.034  
Average acc: 0.998  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2351]:	loss = 0.017  exp loss = 0.018  adjusted loss = 0.018  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 124]:	loss = 0.149  exp loss = 0.146  adjusted loss = 0.146  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 0  [n = 38]:	loss = 0.283  exp loss = 0.299  adjusted loss = 0.299  adv prob = 0.250000   acc = 0.895
  waterbird_complete95 = 1, forest2water2 = 1  [n = 687]:	loss = 0.058  exp loss = 0.047  adjusted loss = 0.047  adv prob = 0.250000   acc = 0.999
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_train_epoch_149.csv
logged to wandb
Average incurred loss: 0.037  
Average sample loss: 0.037  
Average acc: 0.999  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 1147]:	loss = 0.015  exp loss = 0.014  adjusted loss = 0.014  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 60]:	loss = 0.140  exp loss = 0.192  adjusted loss = 0.192  adv prob = 0.250000   acc = 0.983
  waterbird_complete95 = 1, forest2water2 = 0  [n = 18]:	loss = 0.318  exp loss = 0.328  adjusted loss = 0.328  adv prob = 0.250000   acc = 0.944
  waterbird_complete95 = 1, forest2water2 = 1  [n = 370]:	loss = 0.075  exp loss = 0.067  adjusted loss = 0.067  adv prob = 0.250000   acc = 1.000

Validation:
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_val_epoch_149.csv
logged to wandb
Average incurred loss: 0.463  
Average sample loss: 0.459  
Average acc: 0.788  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.030  exp loss = 0.027  adjusted loss = 0.027  adv prob = 0.250000   acc = 0.996
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.619  exp loss = 0.597  adjusted loss = 0.597  adv prob = 0.250000   acc = 0.676
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.693  exp loss = 1.799  adjusted loss = 1.799  adv prob = 0.250000   acc = 0.293
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.204  exp loss = 0.210  adjusted loss = 0.210  adv prob = 0.250000   acc = 0.947
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_test_epoch_149.csv
logged to wandb
Current lr: 0.000010


Epoch [150]:
Training:
Average incurred loss: 0.036  
Average sample loss: 0.036  
Average acc: 0.998  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2361]:	loss = 0.018  exp loss = 0.018  adjusted loss = 0.018  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 119]:	loss = 0.156  exp loss = 0.165  adjusted loss = 0.165  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 0  [n = 32]:	loss = 0.257  exp loss = 0.295  adjusted loss = 0.295  adv prob = 0.250000   acc = 0.937
  waterbird_complete95 = 1, forest2water2 = 1  [n = 688]:	loss = 0.067  exp loss = 0.066  adjusted loss = 0.066  adv prob = 0.250000   acc = 0.996
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_train_epoch_150.csv
logged to wandb
Average incurred loss: 0.035  
Average sample loss: 0.035  
Average acc: 0.997  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 1137]:	loss = 0.014  exp loss = 0.013  adjusted loss = 0.013  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 65]:	loss = 0.135  exp loss = 0.134  adjusted loss = 0.134  adv prob = 0.250000   acc = 0.985
  waterbird_complete95 = 1, forest2water2 = 0  [n = 24]:	loss = 0.291  exp loss = 0.275  adjusted loss = 0.275  adv prob = 0.250000   acc = 0.917
  waterbird_complete95 = 1, forest2water2 = 1  [n = 369]:	loss = 0.067  exp loss = 0.065  adjusted loss = 0.065  adv prob = 0.250000   acc = 0.997

Validation:
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_val_epoch_150.csv
logged to wandb
Average incurred loss: 0.448  
Average sample loss: 0.444  
Average acc: 0.802  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.026  exp loss = 0.023  adjusted loss = 0.023  adv prob = 0.250000   acc = 0.998
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.541  exp loss = 0.521  adjusted loss = 0.521  adv prob = 0.250000   acc = 0.715
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.813  exp loss = 1.938  adjusted loss = 1.938  adv prob = 0.250000   acc = 0.286
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.236  exp loss = 0.244  adjusted loss = 0.244  adv prob = 0.250000   acc = 0.932
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_test_epoch_150.csv
logged to wandb
Current lr: 0.000010


Epoch [151]:
Training:
Average incurred loss: 0.033  
Average sample loss: 0.033  
Average acc: 0.999  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2360]:	loss = 0.017  exp loss = 0.016  adjusted loss = 0.016  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 126]:	loss = 0.152  exp loss = 0.147  adjusted loss = 0.147  adv prob = 0.250000   acc = 0.992
  waterbird_complete95 = 1, forest2water2 = 0  [n = 33]:	loss = 0.250  exp loss = 0.288  adjusted loss = 0.288  adv prob = 0.250000   acc = 0.939
  waterbird_complete95 = 1, forest2water2 = 1  [n = 681]:	loss = 0.059  exp loss = 0.050  adjusted loss = 0.050  adv prob = 0.250000   acc = 0.999
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_train_epoch_151.csv
logged to wandb
Average incurred loss: 0.036  
Average sample loss: 0.036  
Average acc: 0.998  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 1138]:	loss = 0.014  exp loss = 0.014  adjusted loss = 0.014  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 58]:	loss = 0.138  exp loss = 0.137  adjusted loss = 0.137  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 0  [n = 23]:	loss = 0.289  exp loss = 0.297  adjusted loss = 0.297  adv prob = 0.250000   acc = 0.913
  waterbird_complete95 = 1, forest2water2 = 1  [n = 376]:	loss = 0.072  exp loss = 0.061  adjusted loss = 0.061  adv prob = 0.250000   acc = 0.997

Validation:
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_val_epoch_151.csv
logged to wandb
Average incurred loss: 0.461  
Average sample loss: 0.458  
Average acc: 0.791  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.030  exp loss = 0.027  adjusted loss = 0.027  adv prob = 0.250000   acc = 0.996
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.613  exp loss = 0.591  adjusted loss = 0.591  adv prob = 0.250000   acc = 0.687
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.699  exp loss = 1.810  adjusted loss = 1.810  adv prob = 0.250000   acc = 0.286
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.206  exp loss = 0.212  adjusted loss = 0.212  adv prob = 0.250000   acc = 0.947
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_test_epoch_151.csv
logged to wandb
Current lr: 0.000010


Epoch [152]:
Training:
Average incurred loss: 0.035  
Average sample loss: 0.035  
Average acc: 0.998  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2327]:	loss = 0.016  exp loss = 0.016  adjusted loss = 0.016  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 130]:	loss = 0.145  exp loss = 0.160  adjusted loss = 0.160  adv prob = 0.250000   acc = 0.992
  waterbird_complete95 = 1, forest2water2 = 0  [n = 40]:	loss = 0.279  exp loss = 0.288  adjusted loss = 0.288  adv prob = 0.250000   acc = 0.925
  waterbird_complete95 = 1, forest2water2 = 1  [n = 703]:	loss = 0.064  exp loss = 0.062  adjusted loss = 0.062  adv prob = 0.250000   acc = 0.999
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_train_epoch_152.csv
logged to wandb
Average incurred loss: 0.036  
Average sample loss: 0.036  
Average acc: 0.997  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 1171]:	loss = 0.018  exp loss = 0.018  adjusted loss = 0.018  adv prob = 0.250000   acc = 0.999
  waterbird_complete95 = 0, forest2water2 = 1  [n = 54]:	loss = 0.157  exp loss = 0.169  adjusted loss = 0.169  adv prob = 0.250000   acc = 0.981
  waterbird_complete95 = 1, forest2water2 = 0  [n = 16]:	loss = 0.276  exp loss = 0.253  adjusted loss = 0.253  adv prob = 0.250000   acc = 0.875
  waterbird_complete95 = 1, forest2water2 = 1  [n = 354]:	loss = 0.064  exp loss = 0.057  adjusted loss = 0.057  adv prob = 0.250000   acc = 1.000

Validation:
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_val_epoch_152.csv
logged to wandb
Average incurred loss: 0.475  
Average sample loss: 0.472  
Average acc: 0.776  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.033  exp loss = 0.030  adjusted loss = 0.030  adv prob = 0.250000   acc = 0.996
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.669  exp loss = 0.644  adjusted loss = 0.644  adv prob = 0.250000   acc = 0.642
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.634  exp loss = 1.733  adjusted loss = 1.733  adv prob = 0.250000   acc = 0.308
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.189  exp loss = 0.193  adjusted loss = 0.193  adv prob = 0.250000   acc = 0.947
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_test_epoch_152.csv
logged to wandb
Current lr: 0.000010


Epoch [153]:
Training:
Average incurred loss: 0.035  
Average sample loss: 0.035  
Average acc: 0.998  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2322]:	loss = 0.015  exp loss = 0.014  adjusted loss = 0.014  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 112]:	loss = 0.153  exp loss = 0.190  adjusted loss = 0.190  adv prob = 0.250000   acc = 0.982
  waterbird_complete95 = 1, forest2water2 = 0  [n = 41]:	loss = 0.300  exp loss = 0.319  adjusted loss = 0.319  adv prob = 0.250000   acc = 0.951
  waterbird_complete95 = 1, forest2water2 = 1  [n = 725]:	loss = 0.066  exp loss = 0.056  adjusted loss = 0.056  adv prob = 0.250000   acc = 0.996
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_train_epoch_153.csv
logged to wandb
Average incurred loss: 0.037  
Average sample loss: 0.037  
Average acc: 0.997  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 1176]:	loss = 0.018  exp loss = 0.017  adjusted loss = 0.017  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 72]:	loss = 0.179  exp loss = 0.210  adjusted loss = 0.210  adv prob = 0.250000   acc = 0.972
  waterbird_complete95 = 1, forest2water2 = 0  [n = 15]:	loss = 0.230  exp loss = 0.267  adjusted loss = 0.267  adv prob = 0.250000   acc = 0.933
  waterbird_complete95 = 1, forest2water2 = 1  [n = 332]:	loss = 0.068  exp loss = 0.058  adjusted loss = 0.058  adv prob = 0.250000   acc = 0.994

Validation:
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_val_epoch_153.csv
logged to wandb
Average incurred loss: 0.471  
Average sample loss: 0.468  
Average acc: 0.778  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.034  exp loss = 0.031  adjusted loss = 0.031  adv prob = 0.250000   acc = 0.996
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.669  exp loss = 0.646  adjusted loss = 0.646  adv prob = 0.250000   acc = 0.644
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.602  exp loss = 1.699  adjusted loss = 1.699  adv prob = 0.250000   acc = 0.316
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.184  exp loss = 0.188  adjusted loss = 0.188  adv prob = 0.250000   acc = 0.947
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_test_epoch_153.csv
logged to wandb
Current lr: 0.000010


Epoch [154]:
Training:
Average incurred loss: 0.034  
Average sample loss: 0.034  
Average acc: 0.999  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2298]:	loss = 0.014  exp loss = 0.015  adjusted loss = 0.015  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 133]:	loss = 0.138  exp loss = 0.135  adjusted loss = 0.135  adv prob = 0.250000   acc = 0.992
  waterbird_complete95 = 1, forest2water2 = 0  [n = 40]:	loss = 0.240  exp loss = 0.199  adjusted loss = 0.199  adv prob = 0.250000   acc = 0.975
  waterbird_complete95 = 1, forest2water2 = 1  [n = 729]:	loss = 0.067  exp loss = 0.052  adjusted loss = 0.052  adv prob = 0.250000   acc = 0.997
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_train_epoch_154.csv
logged to wandb
Average incurred loss: 0.034  
Average sample loss: 0.034  
Average acc: 0.996  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 1200]:	loss = 0.019  exp loss = 0.020  adjusted loss = 0.020  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 51]:	loss = 0.182  exp loss = 0.266  adjusted loss = 0.266  adv prob = 0.250000   acc = 0.941
  waterbird_complete95 = 1, forest2water2 = 0  [n = 16]:	loss = 0.249  exp loss = 0.251  adjusted loss = 0.251  adv prob = 0.250000   acc = 0.875
  waterbird_complete95 = 1, forest2water2 = 1  [n = 328]:	loss = 0.056  exp loss = 0.049  adjusted loss = 0.049  adv prob = 0.250000   acc = 0.997

Validation:
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_val_epoch_154.csv
logged to wandb
Average incurred loss: 0.498  
Average sample loss: 0.495  
Average acc: 0.763  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.040  exp loss = 0.036  adjusted loss = 0.036  adv prob = 0.250000   acc = 0.994
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.763  exp loss = 0.737  adjusted loss = 0.737  adv prob = 0.250000   acc = 0.590
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.518  exp loss = 1.605  adjusted loss = 1.605  adv prob = 0.250000   acc = 0.361
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.160  exp loss = 0.162  adjusted loss = 0.162  adv prob = 0.250000   acc = 0.962
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_test_epoch_154.csv
logged to wandb
Current lr: 0.000010


Epoch [155]:
Training:
Average incurred loss: 0.035  
Average sample loss: 0.035  
Average acc: 0.998  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2343]:	loss = 0.016  exp loss = 0.015  adjusted loss = 0.015  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 135]:	loss = 0.149  exp loss = 0.131  adjusted loss = 0.131  adv prob = 0.250000   acc = 0.993
  waterbird_complete95 = 1, forest2water2 = 0  [n = 38]:	loss = 0.264  exp loss = 0.265  adjusted loss = 0.265  adv prob = 0.250000   acc = 0.895
  waterbird_complete95 = 1, forest2water2 = 1  [n = 684]:	loss = 0.062  exp loss = 0.051  adjusted loss = 0.051  adv prob = 0.250000   acc = 0.997
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_train_epoch_155.csv
logged to wandb
Average incurred loss: 0.034  
Average sample loss: 0.034  
Average acc: 0.998  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 1155]:	loss = 0.014  exp loss = 0.012  adjusted loss = 0.012  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 49]:	loss = 0.152  exp loss = 0.119  adjusted loss = 0.119  adv prob = 0.250000   acc = 0.980
  waterbird_complete95 = 1, forest2water2 = 0  [n = 18]:	loss = 0.228  exp loss = 0.215  adjusted loss = 0.215  adv prob = 0.250000   acc = 0.944
  waterbird_complete95 = 1, forest2water2 = 1  [n = 373]:	loss = 0.069  exp loss = 0.071  adjusted loss = 0.071  adv prob = 0.250000   acc = 0.997

Validation:
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_val_epoch_155.csv
logged to wandb
Average incurred loss: 0.445  
Average sample loss: 0.441  
Average acc: 0.805  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.024  exp loss = 0.021  adjusted loss = 0.021  adv prob = 0.250000   acc = 0.998
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.517  exp loss = 0.498  adjusted loss = 0.498  adv prob = 0.250000   acc = 0.732
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.866  exp loss = 1.996  adjusted loss = 1.996  adv prob = 0.250000   acc = 0.263
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.246  exp loss = 0.254  adjusted loss = 0.254  adv prob = 0.250000   acc = 0.925
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_test_epoch_155.csv
logged to wandb
Current lr: 0.000010


Epoch [156]:
Training:
Average incurred loss: 0.034  
Average sample loss: 0.034  
Average acc: 0.997  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2325]:	loss = 0.014  exp loss = 0.014  adjusted loss = 0.014  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 124]:	loss = 0.152  exp loss = 0.170  adjusted loss = 0.170  adv prob = 0.250000   acc = 0.984
  waterbird_complete95 = 1, forest2water2 = 0  [n = 38]:	loss = 0.276  exp loss = 0.280  adjusted loss = 0.280  adv prob = 0.250000   acc = 0.895
  waterbird_complete95 = 1, forest2water2 = 1  [n = 713]:	loss = 0.063  exp loss = 0.063  adjusted loss = 0.063  adv prob = 0.250000   acc = 0.996
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_train_epoch_156.csv
logged to wandb
Average incurred loss: 0.034  
Average sample loss: 0.034  
Average acc: 0.999  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 1173]:	loss = 0.016  exp loss = 0.015  adjusted loss = 0.015  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 60]:	loss = 0.156  exp loss = 0.165  adjusted loss = 0.165  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 0  [n = 18]:	loss = 0.232  exp loss = 0.233  adjusted loss = 0.233  adv prob = 0.250000   acc = 0.944
  waterbird_complete95 = 1, forest2water2 = 1  [n = 344]:	loss = 0.064  exp loss = 0.065  adjusted loss = 0.065  adv prob = 0.250000   acc = 0.997

Validation:
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_val_epoch_156.csv
logged to wandb
Average incurred loss: 0.465  
Average sample loss: 0.462  
Average acc: 0.791  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.029  exp loss = 0.026  adjusted loss = 0.026  adv prob = 0.250000   acc = 0.996
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.614  exp loss = 0.592  adjusted loss = 0.592  adv prob = 0.250000   acc = 0.685
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.736  exp loss = 1.851  adjusted loss = 1.851  adv prob = 0.250000   acc = 0.286
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.206  exp loss = 0.211  adjusted loss = 0.211  adv prob = 0.250000   acc = 0.947
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_test_epoch_156.csv
logged to wandb
Current lr: 0.000010


Epoch [157]:
Training:
Average incurred loss: 0.034  
Average sample loss: 0.034  
Average acc: 0.998  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2367]:	loss = 0.017  exp loss = 0.015  adjusted loss = 0.015  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 113]:	loss = 0.153  exp loss = 0.132  adjusted loss = 0.132  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 0  [n = 36]:	loss = 0.279  exp loss = 0.264  adjusted loss = 0.264  adv prob = 0.250000   acc = 0.889
  waterbird_complete95 = 1, forest2water2 = 1  [n = 684]:	loss = 0.062  exp loss = 0.063  adjusted loss = 0.063  adv prob = 0.250000   acc = 0.996
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_train_epoch_157.csv
logged to wandb
Average incurred loss: 0.034  
Average sample loss: 0.034  
Average acc: 1.000  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 1131]:	loss = 0.013  exp loss = 0.011  adjusted loss = 0.011  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 71]:	loss = 0.128  exp loss = 0.107  adjusted loss = 0.107  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 0  [n = 20]:	loss = 0.228  exp loss = 0.215  adjusted loss = 0.215  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 373]:	loss = 0.069  exp loss = 0.069  adjusted loss = 0.069  adv prob = 0.250000   acc = 1.000

Validation:
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_val_epoch_157.csv
logged to wandb
Average incurred loss: 0.442  
Average sample loss: 0.439  
Average acc: 0.807  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.024  exp loss = 0.022  adjusted loss = 0.022  adv prob = 0.250000   acc = 0.998
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.524  exp loss = 0.505  adjusted loss = 0.505  adv prob = 0.250000   acc = 0.727
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.830  exp loss = 1.959  adjusted loss = 1.959  adv prob = 0.250000   acc = 0.286
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.237  exp loss = 0.245  adjusted loss = 0.245  adv prob = 0.250000   acc = 0.932
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_test_epoch_157.csv
logged to wandb
Current lr: 0.000010


Epoch [158]:
Training:
Average incurred loss: 0.032  
Average sample loss: 0.032  
Average acc: 0.998  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2353]:	loss = 0.015  exp loss = 0.013  adjusted loss = 0.013  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 116]:	loss = 0.138  exp loss = 0.203  adjusted loss = 0.203  adv prob = 0.250000   acc = 0.983
  waterbird_complete95 = 1, forest2water2 = 0  [n = 36]:	loss = 0.309  exp loss = 0.302  adjusted loss = 0.302  adv prob = 0.250000   acc = 0.889
  waterbird_complete95 = 1, forest2water2 = 1  [n = 695]:	loss = 0.058  exp loss = 0.063  adjusted loss = 0.063  adv prob = 0.250000   acc = 0.999
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_train_epoch_158.csv
logged to wandb
Average incurred loss: 0.033  
Average sample loss: 0.033  
Average acc: 0.999  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 1145]:	loss = 0.014  exp loss = 0.014  adjusted loss = 0.014  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 68]:	loss = 0.130  exp loss = 0.152  adjusted loss = 0.152  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 0  [n = 20]:	loss = 0.255  exp loss = 0.245  adjusted loss = 0.245  adv prob = 0.250000   acc = 0.950
  waterbird_complete95 = 1, forest2water2 = 1  [n = 362]:	loss = 0.065  exp loss = 0.052  adjusted loss = 0.052  adv prob = 0.250000   acc = 0.997

Validation:
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_val_epoch_158.csv
logged to wandb
Average incurred loss: 0.466  
Average sample loss: 0.463  
Average acc: 0.785  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.031  exp loss = 0.028  adjusted loss = 0.028  adv prob = 0.250000   acc = 0.996
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.638  exp loss = 0.617  adjusted loss = 0.617  adv prob = 0.250000   acc = 0.670
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.667  exp loss = 1.769  adjusted loss = 1.769  adv prob = 0.250000   acc = 0.286
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.195  exp loss = 0.200  adjusted loss = 0.200  adv prob = 0.250000   acc = 0.947
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_test_epoch_158.csv
logged to wandb
Current lr: 0.000010


Epoch [159]:
Training:
Average incurred loss: 0.033  
Average sample loss: 0.033  
Average acc: 1.000  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2319]:	loss = 0.015  exp loss = 0.015  adjusted loss = 0.015  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 134]:	loss = 0.129  exp loss = 0.113  adjusted loss = 0.113  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 0  [n = 39]:	loss = 0.250  exp loss = 0.250  adjusted loss = 0.250  adv prob = 0.250000   acc = 0.974
  waterbird_complete95 = 1, forest2water2 = 1  [n = 708]:	loss = 0.059  exp loss = 0.049  adjusted loss = 0.049  adv prob = 0.250000   acc = 1.000
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_train_epoch_159.csv
logged to wandb
Average incurred loss: 0.033  
Average sample loss: 0.033  
Average acc: 0.999  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 1179]:	loss = 0.015  exp loss = 0.014  adjusted loss = 0.014  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 50]:	loss = 0.171  exp loss = 0.162  adjusted loss = 0.162  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 0  [n = 17]:	loss = 0.212  exp loss = 0.212  adjusted loss = 0.212  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 349]:	loss = 0.065  exp loss = 0.053  adjusted loss = 0.053  adv prob = 0.250000   acc = 0.997

Validation:
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_val_epoch_159.csv
logged to wandb
Average incurred loss: 0.475  
Average sample loss: 0.472  
Average acc: 0.779  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.033  exp loss = 0.029  adjusted loss = 0.029  adv prob = 0.250000   acc = 0.994
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.671  exp loss = 0.649  adjusted loss = 0.649  adv prob = 0.250000   acc = 0.648
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.638  exp loss = 1.739  adjusted loss = 1.739  adv prob = 0.250000   acc = 0.316
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.183  exp loss = 0.187  adjusted loss = 0.187  adv prob = 0.250000   acc = 0.947
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_test_epoch_159.csv
logged to wandb
Current lr: 0.000010


Epoch [160]:
Training:
Average incurred loss: 0.033  
Average sample loss: 0.033  
Average acc: 0.998  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2353]:	loss = 0.016  exp loss = 0.016  adjusted loss = 0.016  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 117]:	loss = 0.145  exp loss = 0.164  adjusted loss = 0.164  adv prob = 0.250000   acc = 0.991
  waterbird_complete95 = 1, forest2water2 = 0  [n = 36]:	loss = 0.226  exp loss = 0.223  adjusted loss = 0.223  adv prob = 0.250000   acc = 0.944
  waterbird_complete95 = 1, forest2water2 = 1  [n = 694]:	loss = 0.062  exp loss = 0.057  adjusted loss = 0.057  adv prob = 0.250000   acc = 0.997
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_train_epoch_160.csv
logged to wandb
Average incurred loss: 0.032  
Average sample loss: 0.032  
Average acc: 0.999  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 1145]:	loss = 0.014  exp loss = 0.014  adjusted loss = 0.014  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 67]:	loss = 0.108  exp loss = 0.120  adjusted loss = 0.120  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 0  [n = 20]:	loss = 0.303  exp loss = 0.260  adjusted loss = 0.260  adv prob = 0.250000   acc = 0.900
  waterbird_complete95 = 1, forest2water2 = 1  [n = 363]:	loss = 0.061  exp loss = 0.064  adjusted loss = 0.064  adv prob = 0.250000   acc = 1.000

Validation:
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_val_epoch_160.csv
logged to wandb
Average incurred loss: 0.456  
Average sample loss: 0.452  
Average acc: 0.795  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.026  exp loss = 0.024  adjusted loss = 0.024  adv prob = 0.250000   acc = 0.996
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.578  exp loss = 0.557  adjusted loss = 0.557  adv prob = 0.250000   acc = 0.697
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.777  exp loss = 1.894  adjusted loss = 1.894  adv prob = 0.250000   acc = 0.286
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.214  exp loss = 0.220  adjusted loss = 0.220  adv prob = 0.250000   acc = 0.940
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_test_epoch_160.csv
logged to wandb
Current lr: 0.000010


Epoch [161]:
Training:
Average incurred loss: 0.032  
Average sample loss: 0.032  
Average acc: 0.998  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2320]:	loss = 0.014  exp loss = 0.012  adjusted loss = 0.012  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 129]:	loss = 0.134  exp loss = 0.140  adjusted loss = 0.140  adv prob = 0.250000   acc = 0.992
  waterbird_complete95 = 1, forest2water2 = 0  [n = 39]:	loss = 0.209  exp loss = 0.241  adjusted loss = 0.241  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 712]:	loss = 0.063  exp loss = 0.064  adjusted loss = 0.064  adv prob = 0.250000   acc = 0.994
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_train_epoch_161.csv
logged to wandb
Average incurred loss: 0.033  
Average sample loss: 0.033  
Average acc: 0.998  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 1178]:	loss = 0.017  exp loss = 0.016  adjusted loss = 0.016  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 55]:	loss = 0.135  exp loss = 0.117  adjusted loss = 0.117  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 0  [n = 17]:	loss = 0.356  exp loss = 0.353  adjusted loss = 0.353  adv prob = 0.250000   acc = 0.882
  waterbird_complete95 = 1, forest2water2 = 1  [n = 345]:	loss = 0.056  exp loss = 0.050  adjusted loss = 0.050  adv prob = 0.250000   acc = 0.997

Validation:
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_val_epoch_161.csv
logged to wandb
Average incurred loss: 0.468  
Average sample loss: 0.465  
Average acc: 0.784  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.031  exp loss = 0.027  adjusted loss = 0.027  adv prob = 0.250000   acc = 0.996
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.645  exp loss = 0.622  adjusted loss = 0.622  adv prob = 0.250000   acc = 0.661
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.667  exp loss = 1.773  adjusted loss = 1.773  adv prob = 0.250000   acc = 0.308
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.189  exp loss = 0.193  adjusted loss = 0.193  adv prob = 0.250000   acc = 0.947
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_test_epoch_161.csv
logged to wandb
Current lr: 0.000010


Epoch [162]:
Training:
Average incurred loss: 0.032  
Average sample loss: 0.032  
Average acc: 0.999  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2318]:	loss = 0.014  exp loss = 0.014  adjusted loss = 0.014  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 131]:	loss = 0.134  exp loss = 0.150  adjusted loss = 0.150  adv prob = 0.250000   acc = 0.992
  waterbird_complete95 = 1, forest2water2 = 0  [n = 37]:	loss = 0.256  exp loss = 0.286  adjusted loss = 0.286  adv prob = 0.250000   acc = 0.973
  waterbird_complete95 = 1, forest2water2 = 1  [n = 714]:	loss = 0.059  exp loss = 0.058  adjusted loss = 0.058  adv prob = 0.250000   acc = 0.997
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_train_epoch_162.csv
logged to wandb
Average incurred loss: 0.030  
Average sample loss: 0.030  
Average acc: 1.000  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 1180]:	loss = 0.015  exp loss = 0.015  adjusted loss = 0.015  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 53]:	loss = 0.144  exp loss = 0.158  adjusted loss = 0.158  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 0  [n = 19]:	loss = 0.139  exp loss = 0.164  adjusted loss = 0.164  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 343]:	loss = 0.059  exp loss = 0.051  adjusted loss = 0.051  adv prob = 0.250000   acc = 1.000

Validation:
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_val_epoch_162.csv
logged to wandb
Average incurred loss: 0.473  
Average sample loss: 0.469  
Average acc: 0.780  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.031  exp loss = 0.028  adjusted loss = 0.028  adv prob = 0.250000   acc = 0.996
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.656  exp loss = 0.633  adjusted loss = 0.633  adv prob = 0.250000   acc = 0.652
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.667  exp loss = 1.770  adjusted loss = 1.770  adv prob = 0.250000   acc = 0.301
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.188  exp loss = 0.193  adjusted loss = 0.193  adv prob = 0.250000   acc = 0.947
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_test_epoch_162.csv
logged to wandb
Current lr: 0.000010


Epoch [163]:
Training:
Average incurred loss: 0.032  
Average sample loss: 0.032  
Average acc: 0.999  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2350]:	loss = 0.016  exp loss = 0.016  adjusted loss = 0.016  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 125]:	loss = 0.143  exp loss = 0.166  adjusted loss = 0.166  adv prob = 0.250000   acc = 0.992
  waterbird_complete95 = 1, forest2water2 = 0  [n = 39]:	loss = 0.222  exp loss = 0.194  adjusted loss = 0.194  adv prob = 0.250000   acc = 0.949
  waterbird_complete95 = 1, forest2water2 = 1  [n = 686]:	loss = 0.057  exp loss = 0.052  adjusted loss = 0.052  adv prob = 0.250000   acc = 1.000
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_train_epoch_163.csv
logged to wandb
Average incurred loss: 0.031  
Average sample loss: 0.031  
Average acc: 0.998  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 1148]:	loss = 0.013  exp loss = 0.012  adjusted loss = 0.012  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 59]:	loss = 0.118  exp loss = 0.130  adjusted loss = 0.130  adv prob = 0.250000   acc = 0.983
  waterbird_complete95 = 1, forest2water2 = 0  [n = 17]:	loss = 0.251  exp loss = 0.242  adjusted loss = 0.242  adv prob = 0.250000   acc = 0.941
  waterbird_complete95 = 1, forest2water2 = 1  [n = 371]:	loss = 0.063  exp loss = 0.060  adjusted loss = 0.060  adv prob = 0.250000   acc = 0.997

Validation:
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_val_epoch_163.csv
logged to wandb
Average incurred loss: 0.461  
Average sample loss: 0.458  
Average acc: 0.796  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.028  exp loss = 0.025  adjusted loss = 0.025  adv prob = 0.250000   acc = 0.996
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.602  exp loss = 0.580  adjusted loss = 0.580  adv prob = 0.250000   acc = 0.697
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.747  exp loss = 1.862  adjusted loss = 1.862  adv prob = 0.250000   acc = 0.293
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.206  exp loss = 0.211  adjusted loss = 0.211  adv prob = 0.250000   acc = 0.940
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_test_epoch_163.csv
logged to wandb
Current lr: 0.000010


Epoch [164]:
Training:
Average incurred loss: 0.032  
Average sample loss: 0.032  
Average acc: 0.998  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2321]:	loss = 0.014  exp loss = 0.015  adjusted loss = 0.015  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 124]:	loss = 0.122  exp loss = 0.141  adjusted loss = 0.141  adv prob = 0.250000   acc = 0.992
  waterbird_complete95 = 1, forest2water2 = 0  [n = 40]:	loss = 0.282  exp loss = 0.262  adjusted loss = 0.262  adv prob = 0.250000   acc = 0.900
  waterbird_complete95 = 1, forest2water2 = 1  [n = 715]:	loss = 0.062  exp loss = 0.048  adjusted loss = 0.048  adv prob = 0.250000   acc = 0.999
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_train_epoch_164.csv
logged to wandb
Average incurred loss: 0.031  
Average sample loss: 0.031  
Average acc: 0.999  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 1177]:	loss = 0.015  exp loss = 0.015  adjusted loss = 0.015  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 60]:	loss = 0.179  exp loss = 0.241  adjusted loss = 0.241  adv prob = 0.250000   acc = 0.967
  waterbird_complete95 = 1, forest2water2 = 0  [n = 16]:	loss = 0.186  exp loss = 0.203  adjusted loss = 0.203  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 342]:	loss = 0.050  exp loss = 0.047  adjusted loss = 0.047  adv prob = 0.250000   acc = 1.000

Validation:
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_val_epoch_164.csv
logged to wandb
Average incurred loss: 0.479  
Average sample loss: 0.475  
Average acc: 0.776  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.032  exp loss = 0.029  adjusted loss = 0.029  adv prob = 0.250000   acc = 0.996
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.680  exp loss = 0.654  adjusted loss = 0.654  adv prob = 0.250000   acc = 0.639
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.639  exp loss = 1.742  adjusted loss = 1.742  adv prob = 0.250000   acc = 0.316
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.180  exp loss = 0.183  adjusted loss = 0.183  adv prob = 0.250000   acc = 0.947
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_test_epoch_164.csv
logged to wandb
Current lr: 0.000010


Epoch [165]:
Training:
Average incurred loss: 0.030  
Average sample loss: 0.030  
Average acc: 0.999  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2346]:	loss = 0.015  exp loss = 0.014  adjusted loss = 0.014  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 117]:	loss = 0.117  exp loss = 0.115  adjusted loss = 0.115  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 0  [n = 33]:	loss = 0.226  exp loss = 0.216  adjusted loss = 0.216  adv prob = 0.250000   acc = 0.970
  waterbird_complete95 = 1, forest2water2 = 1  [n = 704]:	loss = 0.055  exp loss = 0.045  adjusted loss = 0.045  adv prob = 0.250000   acc = 0.999
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_train_epoch_165.csv
logged to wandb
Average incurred loss: 0.033  
Average sample loss: 0.033  
Average acc: 0.998  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 1152]:	loss = 0.014  exp loss = 0.014  adjusted loss = 0.014  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 67]:	loss = 0.131  exp loss = 0.144  adjusted loss = 0.144  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 0  [n = 23]:	loss = 0.204  exp loss = 0.166  adjusted loss = 0.166  adv prob = 0.250000   acc = 0.913
  waterbird_complete95 = 1, forest2water2 = 1  [n = 353]:	loss = 0.067  exp loss = 0.046  adjusted loss = 0.046  adv prob = 0.250000   acc = 0.997

Validation:
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_val_epoch_165.csv
logged to wandb
Average incurred loss: 0.473  
Average sample loss: 0.469  
Average acc: 0.780  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.031  exp loss = 0.028  adjusted loss = 0.028  adv prob = 0.250000   acc = 0.996
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.653  exp loss = 0.630  adjusted loss = 0.630  adv prob = 0.250000   acc = 0.655
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.676  exp loss = 1.787  adjusted loss = 1.787  adv prob = 0.250000   acc = 0.293
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.190  exp loss = 0.195  adjusted loss = 0.195  adv prob = 0.250000   acc = 0.947
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_test_epoch_165.csv
logged to wandb
Current lr: 0.000010


Epoch [166]:
Training:
Average incurred loss: 0.031  
Average sample loss: 0.031  
Average acc: 0.999  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2342]:	loss = 0.015  exp loss = 0.013  adjusted loss = 0.013  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 118]:	loss = 0.135  exp loss = 0.132  adjusted loss = 0.132  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 0  [n = 33]:	loss = 0.261  exp loss = 0.226  adjusted loss = 0.226  adv prob = 0.250000   acc = 0.939
  waterbird_complete95 = 1, forest2water2 = 1  [n = 707]:	loss = 0.058  exp loss = 0.058  adjusted loss = 0.058  adv prob = 0.250000   acc = 0.999
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_train_epoch_166.csv
logged to wandb
Average incurred loss: 0.032  
Average sample loss: 0.032  
Average acc: 0.999  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 1156]:	loss = 0.014  exp loss = 0.013  adjusted loss = 0.013  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 66]:	loss = 0.122  exp loss = 0.127  adjusted loss = 0.127  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 0  [n = 23]:	loss = 0.283  exp loss = 0.208  adjusted loss = 0.208  adv prob = 0.250000   acc = 0.913
  waterbird_complete95 = 1, forest2water2 = 1  [n = 350]:	loss = 0.055  exp loss = 0.054  adjusted loss = 0.054  adv prob = 0.250000   acc = 1.000

Validation:
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_val_epoch_166.csv
logged to wandb
Average incurred loss: 0.463  
Average sample loss: 0.460  
Average acc: 0.794  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.027  exp loss = 0.025  adjusted loss = 0.025  adv prob = 0.250000   acc = 0.996
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.605  exp loss = 0.582  adjusted loss = 0.582  adv prob = 0.250000   acc = 0.695
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.754  exp loss = 1.871  adjusted loss = 1.871  adv prob = 0.250000   acc = 0.286
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.207  exp loss = 0.212  adjusted loss = 0.212  adv prob = 0.250000   acc = 0.940
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_test_epoch_166.csv
logged to wandb
Current lr: 0.000010


Epoch [167]:
Training:
Average incurred loss: 0.032  
Average sample loss: 0.032  
Average acc: 0.998  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2329]:	loss = 0.014  exp loss = 0.014  adjusted loss = 0.014  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 124]:	loss = 0.132  exp loss = 0.136  adjusted loss = 0.136  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 0  [n = 43]:	loss = 0.249  exp loss = 0.219  adjusted loss = 0.219  adv prob = 0.250000   acc = 0.907
  waterbird_complete95 = 1, forest2water2 = 1  [n = 704]:	loss = 0.060  exp loss = 0.044  adjusted loss = 0.044  adv prob = 0.250000   acc = 0.996
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_train_epoch_167.csv
logged to wandb
Average incurred loss: 0.032  
Average sample loss: 0.032  
Average acc: 0.999  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 1169]:	loss = 0.016  exp loss = 0.013  adjusted loss = 0.013  adv prob = 0.250000   acc = 0.999
  waterbird_complete95 = 0, forest2water2 = 1  [n = 60]:	loss = 0.122  exp loss = 0.115  adjusted loss = 0.115  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 0  [n = 13]:	loss = 0.180  exp loss = 0.209  adjusted loss = 0.209  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 353]:	loss = 0.062  exp loss = 0.061  adjusted loss = 0.061  adv prob = 0.250000   acc = 1.000

Validation:
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_val_epoch_167.csv
logged to wandb
Average incurred loss: 0.454  
Average sample loss: 0.450  
Average acc: 0.798  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.025  exp loss = 0.022  adjusted loss = 0.022  adv prob = 0.250000   acc = 0.996
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.569  exp loss = 0.548  adjusted loss = 0.548  adv prob = 0.250000   acc = 0.706
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.795  exp loss = 1.916  adjusted loss = 1.916  adv prob = 0.250000   acc = 0.286
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.213  exp loss = 0.219  adjusted loss = 0.219  adv prob = 0.250000   acc = 0.940
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_test_epoch_167.csv
logged to wandb
Current lr: 0.000010


Epoch [168]:
Training:
Average incurred loss: 0.031  
Average sample loss: 0.031  
Average acc: 0.999  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2323]:	loss = 0.014  exp loss = 0.014  adjusted loss = 0.014  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 126]:	loss = 0.132  exp loss = 0.149  adjusted loss = 0.149  adv prob = 0.250000   acc = 0.992
  waterbird_complete95 = 1, forest2water2 = 0  [n = 37]:	loss = 0.266  exp loss = 0.244  adjusted loss = 0.244  adv prob = 0.250000   acc = 0.973
  waterbird_complete95 = 1, forest2water2 = 1  [n = 714]:	loss = 0.057  exp loss = 0.057  adjusted loss = 0.057  adv prob = 0.250000   acc = 0.999
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_train_epoch_168.csv
logged to wandb
Average incurred loss: 0.029  
Average sample loss: 0.029  
Average acc: 0.999  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 1175]:	loss = 0.015  exp loss = 0.013  adjusted loss = 0.013  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 58]:	loss = 0.119  exp loss = 0.132  adjusted loss = 0.132  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 0  [n = 19]:	loss = 0.258  exp loss = 0.224  adjusted loss = 0.224  adv prob = 0.250000   acc = 0.895
  waterbird_complete95 = 1, forest2water2 = 1  [n = 343]:	loss = 0.052  exp loss = 0.050  adjusted loss = 0.050  adv prob = 0.250000   acc = 1.000

Validation:
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_val_epoch_168.csv
logged to wandb
Average incurred loss: 0.463  
Average sample loss: 0.459  
Average acc: 0.789  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.029  exp loss = 0.026  adjusted loss = 0.026  adv prob = 0.250000   acc = 0.996
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.620  exp loss = 0.599  adjusted loss = 0.599  adv prob = 0.250000   acc = 0.680
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.704  exp loss = 1.811  adjusted loss = 1.811  adv prob = 0.250000   acc = 0.286
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.194  exp loss = 0.198  adjusted loss = 0.198  adv prob = 0.250000   acc = 0.947
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_test_epoch_168.csv
logged to wandb
Current lr: 0.000010


Epoch [169]:
Training:
Average incurred loss: 0.029  
Average sample loss: 0.029  
Average acc: 0.999  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2339]:	loss = 0.014  exp loss = 0.015  adjusted loss = 0.015  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 119]:	loss = 0.117  exp loss = 0.120  adjusted loss = 0.120  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 0  [n = 37]:	loss = 0.241  exp loss = 0.209  adjusted loss = 0.209  adv prob = 0.250000   acc = 0.946
  waterbird_complete95 = 1, forest2water2 = 1  [n = 705]:	loss = 0.054  exp loss = 0.054  adjusted loss = 0.054  adv prob = 0.250000   acc = 0.999
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_train_epoch_169.csv
logged to wandb
Average incurred loss: 0.033  
Average sample loss: 0.033  
Average acc: 0.999  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 1159]:	loss = 0.014  exp loss = 0.012  adjusted loss = 0.012  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 65]:	loss = 0.131  exp loss = 0.123  adjusted loss = 0.123  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 0  [n = 19]:	loss = 0.221  exp loss = 0.196  adjusted loss = 0.196  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 352]:	loss = 0.065  exp loss = 0.059  adjusted loss = 0.059  adv prob = 0.250000   acc = 0.994

Validation:
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_val_epoch_169.csv
logged to wandb
Average incurred loss: 0.456  
Average sample loss: 0.452  
Average acc: 0.797  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.027  exp loss = 0.024  adjusted loss = 0.024  adv prob = 0.250000   acc = 0.996
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.587  exp loss = 0.566  adjusted loss = 0.566  adv prob = 0.250000   acc = 0.702
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.752  exp loss = 1.867  adjusted loss = 1.867  adv prob = 0.250000   acc = 0.286
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.207  exp loss = 0.212  adjusted loss = 0.212  adv prob = 0.250000   acc = 0.947
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_test_epoch_169.csv
logged to wandb
Current lr: 0.000010


Epoch [170]:
Training:
Average incurred loss: 0.031  
Average sample loss: 0.031  
Average acc: 0.999  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2352]:	loss = 0.014  exp loss = 0.012  adjusted loss = 0.012  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 118]:	loss = 0.151  exp loss = 0.139  adjusted loss = 0.139  adv prob = 0.250000   acc = 0.983
  waterbird_complete95 = 1, forest2water2 = 0  [n = 36]:	loss = 0.245  exp loss = 0.215  adjusted loss = 0.215  adv prob = 0.250000   acc = 0.944
  waterbird_complete95 = 1, forest2water2 = 1  [n = 694]:	loss = 0.055  exp loss = 0.053  adjusted loss = 0.053  adv prob = 0.250000   acc = 1.000
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_train_epoch_170.csv
logged to wandb
Average incurred loss: 0.030  
Average sample loss: 0.030  
Average acc: 0.998  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 1146]:	loss = 0.013  exp loss = 0.012  adjusted loss = 0.012  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 66]:	loss = 0.141  exp loss = 0.132  adjusted loss = 0.132  adv prob = 0.250000   acc = 0.970
  waterbird_complete95 = 1, forest2water2 = 0  [n = 20]:	loss = 0.233  exp loss = 0.205  adjusted loss = 0.205  adv prob = 0.250000   acc = 0.950
  waterbird_complete95 = 1, forest2water2 = 1  [n = 363]:	loss = 0.053  exp loss = 0.050  adjusted loss = 0.050  adv prob = 0.250000   acc = 1.000

Validation:
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_val_epoch_170.csv
logged to wandb
Average incurred loss: 0.453  
Average sample loss: 0.450  
Average acc: 0.797  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.026  exp loss = 0.023  adjusted loss = 0.023  adv prob = 0.250000   acc = 0.996
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.576  exp loss = 0.556  adjusted loss = 0.556  adv prob = 0.250000   acc = 0.704
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.766  exp loss = 1.880  adjusted loss = 1.880  adv prob = 0.250000   acc = 0.286
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.210  exp loss = 0.216  adjusted loss = 0.216  adv prob = 0.250000   acc = 0.940
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_test_epoch_170.csv
logged to wandb
Current lr: 0.000010


Epoch [171]:
Training:
Average incurred loss: 0.031  
Average sample loss: 0.031  
Average acc: 0.998  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2325]:	loss = 0.014  exp loss = 0.015  adjusted loss = 0.015  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 123]:	loss = 0.136  exp loss = 0.159  adjusted loss = 0.159  adv prob = 0.250000   acc = 0.992
  waterbird_complete95 = 1, forest2water2 = 0  [n = 41]:	loss = 0.236  exp loss = 0.224  adjusted loss = 0.224  adv prob = 0.250000   acc = 0.951
  waterbird_complete95 = 1, forest2water2 = 1  [n = 711]:	loss = 0.058  exp loss = 0.050  adjusted loss = 0.050  adv prob = 0.250000   acc = 0.999
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_train_epoch_171.csv
logged to wandb
Average incurred loss: 0.031  
Average sample loss: 0.031  
Average acc: 0.999  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 1173]:	loss = 0.014  exp loss = 0.014  adjusted loss = 0.014  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 61]:	loss = 0.169  exp loss = 0.153  adjusted loss = 0.153  adv prob = 0.250000   acc = 0.984
  waterbird_complete95 = 1, forest2water2 = 0  [n = 15]:	loss = 0.241  exp loss = 0.224  adjusted loss = 0.224  adv prob = 0.250000   acc = 0.933
  waterbird_complete95 = 1, forest2water2 = 1  [n = 346]:	loss = 0.056  exp loss = 0.044  adjusted loss = 0.044  adv prob = 0.250000   acc = 1.000

Validation:
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_val_epoch_171.csv
logged to wandb
Average incurred loss: 0.479  
Average sample loss: 0.475  
Average acc: 0.776  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.033  exp loss = 0.030  adjusted loss = 0.030  adv prob = 0.250000   acc = 0.994
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.688  exp loss = 0.664  adjusted loss = 0.664  adv prob = 0.250000   acc = 0.637
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.613  exp loss = 1.706  adjusted loss = 1.706  adv prob = 0.250000   acc = 0.323
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.174  exp loss = 0.177  adjusted loss = 0.177  adv prob = 0.250000   acc = 0.955
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_test_epoch_171.csv
logged to wandb
Current lr: 0.000010


Epoch [172]:
Training:
Average incurred loss: 0.029  
Average sample loss: 0.029  
Average acc: 0.999  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2349]:	loss = 0.014  exp loss = 0.014  adjusted loss = 0.014  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 118]:	loss = 0.140  exp loss = 0.168  adjusted loss = 0.168  adv prob = 0.250000   acc = 0.992
  waterbird_complete95 = 1, forest2water2 = 0  [n = 29]:	loss = 0.206  exp loss = 0.168  adjusted loss = 0.168  adv prob = 0.250000   acc = 0.966
  waterbird_complete95 = 1, forest2water2 = 1  [n = 704]:	loss = 0.051  exp loss = 0.041  adjusted loss = 0.041  adv prob = 0.250000   acc = 0.999
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_train_epoch_172.csv
logged to wandb
Average incurred loss: 0.036  
Average sample loss: 0.036  
Average acc: 0.997  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 1149]:	loss = 0.015  exp loss = 0.012  adjusted loss = 0.012  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 66]:	loss = 0.163  exp loss = 0.139  adjusted loss = 0.139  adv prob = 0.250000   acc = 0.970
  waterbird_complete95 = 1, forest2water2 = 0  [n = 27]:	loss = 0.232  exp loss = 0.266  adjusted loss = 0.266  adv prob = 0.250000   acc = 0.926
  waterbird_complete95 = 1, forest2water2 = 1  [n = 353]:	loss = 0.066  exp loss = 0.054  adjusted loss = 0.054  adv prob = 0.250000   acc = 1.000

Validation:
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_val_epoch_172.csv
logged to wandb
Average incurred loss: 0.449  
Average sample loss: 0.445  
Average acc: 0.802  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.024  exp loss = 0.022  adjusted loss = 0.022  adv prob = 0.250000   acc = 0.996
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.547  exp loss = 0.528  adjusted loss = 0.528  adv prob = 0.250000   acc = 0.715
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.824  exp loss = 1.941  adjusted loss = 1.941  adv prob = 0.250000   acc = 0.286
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.223  exp loss = 0.229  adjusted loss = 0.229  adv prob = 0.250000   acc = 0.940
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_test_epoch_172.csv
logged to wandb
Current lr: 0.000010


Epoch [173]:
Training:
Average incurred loss: 0.030  
Average sample loss: 0.030  
Average acc: 0.999  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2317]:	loss = 0.013  exp loss = 0.013  adjusted loss = 0.013  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 119]:	loss = 0.129  exp loss = 0.130  adjusted loss = 0.130  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 0  [n = 37]:	loss = 0.227  exp loss = 0.254  adjusted loss = 0.254  adv prob = 0.250000   acc = 0.946
  waterbird_complete95 = 1, forest2water2 = 1  [n = 727]:	loss = 0.059  exp loss = 0.060  adjusted loss = 0.060  adv prob = 0.250000   acc = 1.000
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_train_epoch_173.csv
logged to wandb
Average incurred loss: 0.030  
Average sample loss: 0.030  
Average acc: 0.999  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 1181]:	loss = 0.015  exp loss = 0.016  adjusted loss = 0.016  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 65]:	loss = 0.143  exp loss = 0.169  adjusted loss = 0.169  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 0  [n = 19]:	loss = 0.167  exp loss = 0.184  adjusted loss = 0.184  adv prob = 0.250000   acc = 0.947
  waterbird_complete95 = 1, forest2water2 = 1  [n = 330]:	loss = 0.055  exp loss = 0.049  adjusted loss = 0.049  adv prob = 0.250000   acc = 1.000

Validation:
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_val_epoch_173.csv
logged to wandb
Average incurred loss: 0.484  
Average sample loss: 0.481  
Average acc: 0.771  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.034  exp loss = 0.031  adjusted loss = 0.031  adv prob = 0.250000   acc = 0.994
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.714  exp loss = 0.690  adjusted loss = 0.690  adv prob = 0.250000   acc = 0.618
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.576  exp loss = 1.668  adjusted loss = 1.668  adv prob = 0.250000   acc = 0.346
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.166  exp loss = 0.167  adjusted loss = 0.167  adv prob = 0.250000   acc = 0.955
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_test_epoch_173.csv
logged to wandb
Current lr: 0.000010


Epoch [174]:
Training:
Average incurred loss: 0.031  
Average sample loss: 0.031  
Average acc: 0.998  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2322]:	loss = 0.013  exp loss = 0.015  adjusted loss = 0.015  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 120]:	loss = 0.125  exp loss = 0.140  adjusted loss = 0.140  adv prob = 0.250000   acc = 0.983
  waterbird_complete95 = 1, forest2water2 = 0  [n = 37]:	loss = 0.208  exp loss = 0.177  adjusted loss = 0.177  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 721]:	loss = 0.061  exp loss = 0.055  adjusted loss = 0.055  adv prob = 0.250000   acc = 0.996
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_train_epoch_174.csv
logged to wandb
Average incurred loss: 0.029  
Average sample loss: 0.029  
Average acc: 0.999  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 1176]:	loss = 0.014  exp loss = 0.013  adjusted loss = 0.013  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 64]:	loss = 0.130  exp loss = 0.126  adjusted loss = 0.126  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 0  [n = 19]:	loss = 0.253  exp loss = 0.267  adjusted loss = 0.267  adv prob = 0.250000   acc = 0.947
  waterbird_complete95 = 1, forest2water2 = 1  [n = 336]:	loss = 0.051  exp loss = 0.051  adjusted loss = 0.051  adv prob = 0.250000   acc = 1.000

Validation:
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_val_epoch_174.csv
logged to wandb
Average incurred loss: 0.462  
Average sample loss: 0.459  
Average acc: 0.790  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.028  exp loss = 0.025  adjusted loss = 0.025  adv prob = 0.250000   acc = 0.996
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.619  exp loss = 0.598  adjusted loss = 0.598  adv prob = 0.250000   acc = 0.680
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.704  exp loss = 1.810  adjusted loss = 1.810  adv prob = 0.250000   acc = 0.293
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.194  exp loss = 0.197  adjusted loss = 0.197  adv prob = 0.250000   acc = 0.947
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_test_epoch_174.csv
logged to wandb
Current lr: 0.000010


Epoch [175]:
Training:
Average incurred loss: 0.030  
Average sample loss: 0.030  
Average acc: 0.999  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2332]:	loss = 0.013  exp loss = 0.013  adjusted loss = 0.013  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 122]:	loss = 0.140  exp loss = 0.113  adjusted loss = 0.113  adv prob = 0.250000   acc = 0.984
  waterbird_complete95 = 1, forest2water2 = 0  [n = 37]:	loss = 0.204  exp loss = 0.199  adjusted loss = 0.199  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 709]:	loss = 0.055  exp loss = 0.054  adjusted loss = 0.054  adv prob = 0.250000   acc = 0.997
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_train_epoch_175.csv
logged to wandb
Average incurred loss: 0.031  
Average sample loss: 0.031  
Average acc: 0.999  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 1166]:	loss = 0.014  exp loss = 0.014  adjusted loss = 0.014  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 62]:	loss = 0.130  exp loss = 0.117  adjusted loss = 0.117  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 0  [n = 19]:	loss = 0.179  exp loss = 0.174  adjusted loss = 0.174  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 348]:	loss = 0.062  exp loss = 0.054  adjusted loss = 0.054  adv prob = 0.250000   acc = 0.994

Validation:
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_val_epoch_175.csv
logged to wandb
Average incurred loss: 0.468  
Average sample loss: 0.464  
Average acc: 0.789  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.029  exp loss = 0.026  adjusted loss = 0.026  adv prob = 0.250000   acc = 0.996
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.640  exp loss = 0.617  adjusted loss = 0.617  adv prob = 0.250000   acc = 0.672
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.688  exp loss = 1.792  adjusted loss = 1.792  adv prob = 0.250000   acc = 0.316
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.186  exp loss = 0.190  adjusted loss = 0.190  adv prob = 0.250000   acc = 0.947
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_test_epoch_175.csv
logged to wandb
Current lr: 0.000010


Epoch [176]:
Training:
Average incurred loss: 0.029  
Average sample loss: 0.029  
Average acc: 0.999  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2354]:	loss = 0.014  exp loss = 0.013  adjusted loss = 0.013  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 126]:	loss = 0.141  exp loss = 0.131  adjusted loss = 0.131  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 0  [n = 40]:	loss = 0.228  exp loss = 0.259  adjusted loss = 0.259  adv prob = 0.250000   acc = 0.950
  waterbird_complete95 = 1, forest2water2 = 1  [n = 680]:	loss = 0.051  exp loss = 0.045  adjusted loss = 0.045  adv prob = 0.250000   acc = 0.999
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_train_epoch_176.csv
logged to wandb
Average incurred loss: 0.031  
Average sample loss: 0.031  
Average acc: 0.999  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 1144]:	loss = 0.012  exp loss = 0.012  adjusted loss = 0.012  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 58]:	loss = 0.114  exp loss = 0.110  adjusted loss = 0.110  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 0  [n = 16]:	loss = 0.223  exp loss = 0.226  adjusted loss = 0.226  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 377]:	loss = 0.066  exp loss = 0.059  adjusted loss = 0.059  adv prob = 0.250000   acc = 0.997

Validation:
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_val_epoch_176.csv
logged to wandb
Average incurred loss: 0.455  
Average sample loss: 0.452  
Average acc: 0.797  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.026  exp loss = 0.024  adjusted loss = 0.024  adv prob = 0.250000   acc = 0.996
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.588  exp loss = 0.567  adjusted loss = 0.567  adv prob = 0.250000   acc = 0.702
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.749  exp loss = 1.859  adjusted loss = 1.859  adv prob = 0.250000   acc = 0.286
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.204  exp loss = 0.209  adjusted loss = 0.209  adv prob = 0.250000   acc = 0.947
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_test_epoch_176.csv
logged to wandb
Current lr: 0.000010


Epoch [177]:
Training:
Average incurred loss: 0.029  
Average sample loss: 0.029  
Average acc: 0.999  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2307]:	loss = 0.012  exp loss = 0.011  adjusted loss = 0.011  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 118]:	loss = 0.109  exp loss = 0.098  adjusted loss = 0.098  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 0  [n = 40]:	loss = 0.238  exp loss = 0.231  adjusted loss = 0.231  adv prob = 0.250000   acc = 0.950
  waterbird_complete95 = 1, forest2water2 = 1  [n = 735]:	loss = 0.058  exp loss = 0.058  adjusted loss = 0.058  adv prob = 0.250000   acc = 0.999
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_train_epoch_177.csv
logged to wandb
Average incurred loss: 0.028  
Average sample loss: 0.028  
Average acc: 1.000  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 1191]:	loss = 0.016  exp loss = 0.015  adjusted loss = 0.015  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 66]:	loss = 0.145  exp loss = 0.133  adjusted loss = 0.133  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 0  [n = 16]:	loss = 0.146  exp loss = 0.177  adjusted loss = 0.177  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 322]:	loss = 0.042  exp loss = 0.045  adjusted loss = 0.045  adv prob = 0.250000   acc = 1.000

Validation:
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_val_epoch_177.csv
logged to wandb
Average incurred loss: 0.466  
Average sample loss: 0.463  
Average acc: 0.786  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.030  exp loss = 0.027  adjusted loss = 0.027  adv prob = 0.250000   acc = 0.996
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.652  exp loss = 0.629  adjusted loss = 0.629  adv prob = 0.250000   acc = 0.659
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.632  exp loss = 1.735  adjusted loss = 1.735  adv prob = 0.250000   acc = 0.331
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.180  exp loss = 0.182  adjusted loss = 0.182  adv prob = 0.250000   acc = 0.947
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_test_epoch_177.csv
logged to wandb
Current lr: 0.000010


Epoch [178]:
Training:
Average incurred loss: 0.028  
Average sample loss: 0.028  
Average acc: 1.000  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2352]:	loss = 0.014  exp loss = 0.013  adjusted loss = 0.013  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 118]:	loss = 0.133  exp loss = 0.114  adjusted loss = 0.114  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 0  [n = 39]:	loss = 0.214  exp loss = 0.188  adjusted loss = 0.188  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 691]:	loss = 0.049  exp loss = 0.042  adjusted loss = 0.042  adv prob = 0.250000   acc = 0.999
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_train_epoch_178.csv
logged to wandb
Average incurred loss: 0.035  
Average sample loss: 0.035  
Average acc: 0.997  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 1146]:	loss = 0.013  exp loss = 0.011  adjusted loss = 0.011  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 66]:	loss = 0.110  exp loss = 0.096  adjusted loss = 0.096  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 0  [n = 17]:	loss = 0.283  exp loss = 0.273  adjusted loss = 0.273  adv prob = 0.250000   acc = 0.882
  waterbird_complete95 = 1, forest2water2 = 1  [n = 366]:	loss = 0.077  exp loss = 0.077  adjusted loss = 0.077  adv prob = 0.250000   acc = 0.992

Validation:
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_val_epoch_178.csv
logged to wandb
Average incurred loss: 0.443  
Average sample loss: 0.440  
Average acc: 0.811  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.021  exp loss = 0.019  adjusted loss = 0.019  adv prob = 0.250000   acc = 0.998
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.503  exp loss = 0.484  adjusted loss = 0.484  adv prob = 0.250000   acc = 0.740
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.918  exp loss = 2.050  adjusted loss = 2.050  adv prob = 0.250000   acc = 0.278
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.242  exp loss = 0.248  adjusted loss = 0.248  adv prob = 0.250000   acc = 0.932
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_test_epoch_178.csv
logged to wandb
Current lr: 0.000010


Epoch [179]:
Training:
Average incurred loss: 0.028  
Average sample loss: 0.028  
Average acc: 0.999  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2347]:	loss = 0.014  exp loss = 0.013  adjusted loss = 0.013  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 131]:	loss = 0.133  exp loss = 0.113  adjusted loss = 0.113  adv prob = 0.250000   acc = 0.985
  waterbird_complete95 = 1, forest2water2 = 0  [n = 38]:	loss = 0.171  exp loss = 0.184  adjusted loss = 0.184  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 684]:	loss = 0.049  exp loss = 0.045  adjusted loss = 0.045  adv prob = 0.250000   acc = 1.000
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_train_epoch_179.csv
logged to wandb
Average incurred loss: 0.031  
Average sample loss: 0.031  
Average acc: 1.000  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 1151]:	loss = 0.012  exp loss = 0.011  adjusted loss = 0.011  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 53]:	loss = 0.115  exp loss = 0.115  adjusted loss = 0.115  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 0  [n = 18]:	loss = 0.247  exp loss = 0.248  adjusted loss = 0.248  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 373]:	loss = 0.067  exp loss = 0.056  adjusted loss = 0.056  adv prob = 0.250000   acc = 1.000

Validation:
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_val_epoch_179.csv
logged to wandb
Average incurred loss: 0.448  
Average sample loss: 0.445  
Average acc: 0.803  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.023  exp loss = 0.021  adjusted loss = 0.021  adv prob = 0.250000   acc = 0.996
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.542  exp loss = 0.523  adjusted loss = 0.523  adv prob = 0.250000   acc = 0.721
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.839  exp loss = 1.963  adjusted loss = 1.963  adv prob = 0.250000   acc = 0.278
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.223  exp loss = 0.229  adjusted loss = 0.229  adv prob = 0.250000   acc = 0.940
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_test_epoch_179.csv
logged to wandb
Current lr: 0.000010


Epoch [180]:
Training:
Average incurred loss: 0.030  
Average sample loss: 0.030  
Average acc: 0.999  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2328]:	loss = 0.013  exp loss = 0.015  adjusted loss = 0.015  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 115]:	loss = 0.116  exp loss = 0.148  adjusted loss = 0.148  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 0  [n = 39]:	loss = 0.233  exp loss = 0.204  adjusted loss = 0.204  adv prob = 0.250000   acc = 0.974
  waterbird_complete95 = 1, forest2water2 = 1  [n = 718]:	loss = 0.058  exp loss = 0.045  adjusted loss = 0.045  adv prob = 0.250000   acc = 0.997
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_train_epoch_180.csv
logged to wandb
Average incurred loss: 0.029  
Average sample loss: 0.029  
Average acc: 0.999  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 1170]:	loss = 0.014  exp loss = 0.014  adjusted loss = 0.014  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 69]:	loss = 0.158  exp loss = 0.167  adjusted loss = 0.167  adv prob = 0.250000   acc = 0.971
  waterbird_complete95 = 1, forest2water2 = 0  [n = 17]:	loss = 0.177  exp loss = 0.182  adjusted loss = 0.182  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 339]:	loss = 0.049  exp loss = 0.040  adjusted loss = 0.040  adv prob = 0.250000   acc = 1.000

Validation:
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_val_epoch_180.csv
logged to wandb
Average incurred loss: 0.471  
Average sample loss: 0.468  
Average acc: 0.782  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.029  exp loss = 0.026  adjusted loss = 0.026  adv prob = 0.250000   acc = 0.996
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.651  exp loss = 0.628  adjusted loss = 0.628  adv prob = 0.250000   acc = 0.659
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.682  exp loss = 1.792  adjusted loss = 1.792  adv prob = 0.250000   acc = 0.301
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.181  exp loss = 0.184  adjusted loss = 0.184  adv prob = 0.250000   acc = 0.947
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_test_epoch_180.csv
logged to wandb
Current lr: 0.000010


Epoch [181]:
Training:
Average incurred loss: 0.028  
Average sample loss: 0.028  
Average acc: 1.000  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2349]:	loss = 0.014  exp loss = 0.015  adjusted loss = 0.015  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 129]:	loss = 0.120  exp loss = 0.150  adjusted loss = 0.150  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 0  [n = 30]:	loss = 0.218  exp loss = 0.161  adjusted loss = 0.161  adv prob = 0.250000   acc = 0.967
  waterbird_complete95 = 1, forest2water2 = 1  [n = 692]:	loss = 0.052  exp loss = 0.036  adjusted loss = 0.036  adv prob = 0.250000   acc = 1.000
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_train_epoch_181.csv
logged to wandb
Average incurred loss: 0.029  
Average sample loss: 0.029  
Average acc: 0.999  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 1149]:	loss = 0.012  exp loss = 0.013  adjusted loss = 0.013  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 55]:	loss = 0.122  exp loss = 0.127  adjusted loss = 0.127  adv prob = 0.250000   acc = 0.982
  waterbird_complete95 = 1, forest2water2 = 0  [n = 26]:	loss = 0.254  exp loss = 0.244  adjusted loss = 0.244  adv prob = 0.250000   acc = 0.962
  waterbird_complete95 = 1, forest2water2 = 1  [n = 365]:	loss = 0.053  exp loss = 0.045  adjusted loss = 0.045  adv prob = 0.250000   acc = 1.000

Validation:
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_val_epoch_181.csv
logged to wandb
Average incurred loss: 0.459  
Average sample loss: 0.456  
Average acc: 0.792  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.027  exp loss = 0.024  adjusted loss = 0.024  adv prob = 0.250000   acc = 0.996
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.610  exp loss = 0.588  adjusted loss = 0.588  adv prob = 0.250000   acc = 0.687
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.715  exp loss = 1.823  adjusted loss = 1.823  adv prob = 0.250000   acc = 0.293
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.194  exp loss = 0.198  adjusted loss = 0.198  adv prob = 0.250000   acc = 0.947
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_test_epoch_181.csv
logged to wandb
Current lr: 0.000010


Epoch [182]:
Training:
Average incurred loss: 0.029  
Average sample loss: 0.029  
Average acc: 1.000  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2323]:	loss = 0.013  exp loss = 0.013  adjusted loss = 0.013  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 124]:	loss = 0.114  exp loss = 0.121  adjusted loss = 0.121  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 0  [n = 43]:	loss = 0.186  exp loss = 0.226  adjusted loss = 0.226  adv prob = 0.250000   acc = 0.977
  waterbird_complete95 = 1, forest2water2 = 1  [n = 710]:	loss = 0.055  exp loss = 0.044  adjusted loss = 0.044  adv prob = 0.250000   acc = 1.000
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_train_epoch_182.csv
logged to wandb
Average incurred loss: 0.027  
Average sample loss: 0.027  
Average acc: 1.000  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 1175]:	loss = 0.013  exp loss = 0.013  adjusted loss = 0.013  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 60]:	loss = 0.116  exp loss = 0.132  adjusted loss = 0.132  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 0  [n = 13]:	loss = 0.202  exp loss = 0.227  adjusted loss = 0.227  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 347]:	loss = 0.051  exp loss = 0.050  adjusted loss = 0.050  adv prob = 0.250000   acc = 1.000

Validation:
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_val_epoch_182.csv
logged to wandb
Average incurred loss: 0.464  
Average sample loss: 0.460  
Average acc: 0.791  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.028  exp loss = 0.025  adjusted loss = 0.025  adv prob = 0.250000   acc = 0.996
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.626  exp loss = 0.604  adjusted loss = 0.604  adv prob = 0.250000   acc = 0.678
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.700  exp loss = 1.808  adjusted loss = 1.808  adv prob = 0.250000   acc = 0.308
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.190  exp loss = 0.193  adjusted loss = 0.193  adv prob = 0.250000   acc = 0.947
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_test_epoch_182.csv
logged to wandb
Current lr: 0.000010


Epoch [183]:
Training:
Average incurred loss: 0.028  
Average sample loss: 0.028  
Average acc: 0.999  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2321]:	loss = 0.013  exp loss = 0.013  adjusted loss = 0.013  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 125]:	loss = 0.111  exp loss = 0.118  adjusted loss = 0.118  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 0  [n = 39]:	loss = 0.209  exp loss = 0.193  adjusted loss = 0.193  adv prob = 0.250000   acc = 0.974
  waterbird_complete95 = 1, forest2water2 = 1  [n = 715]:	loss = 0.054  exp loss = 0.043  adjusted loss = 0.043  adv prob = 0.250000   acc = 0.999
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_train_epoch_183.csv
logged to wandb
Average incurred loss: 0.027  
Average sample loss: 0.027  
Average acc: 1.000  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 1177]:	loss = 0.014  exp loss = 0.013  adjusted loss = 0.013  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 59]:	loss = 0.129  exp loss = 0.159  adjusted loss = 0.159  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 0  [n = 17]:	loss = 0.160  exp loss = 0.150  adjusted loss = 0.150  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 342]:	loss = 0.047  exp loss = 0.046  adjusted loss = 0.046  adv prob = 0.250000   acc = 1.000

Validation:
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_val_epoch_183.csv
logged to wandb
Average incurred loss: 0.466  
Average sample loss: 0.463  
Average acc: 0.787  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.028  exp loss = 0.025  adjusted loss = 0.025  adv prob = 0.250000   acc = 0.996
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.640  exp loss = 0.618  adjusted loss = 0.618  adv prob = 0.250000   acc = 0.667
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.681  exp loss = 1.784  adjusted loss = 1.784  adv prob = 0.250000   acc = 0.316
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.183  exp loss = 0.185  adjusted loss = 0.185  adv prob = 0.250000   acc = 0.947
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_test_epoch_183.csv
logged to wandb
Current lr: 0.000010


Epoch [184]:
Training:
Average incurred loss: 0.028  
Average sample loss: 0.028  
Average acc: 0.999  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2339]:	loss = 0.013  exp loss = 0.011  adjusted loss = 0.011  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 121]:	loss = 0.118  exp loss = 0.086  adjusted loss = 0.086  adv prob = 0.250000   acc = 0.992
  waterbird_complete95 = 1, forest2water2 = 0  [n = 38]:	loss = 0.222  exp loss = 0.227  adjusted loss = 0.227  adv prob = 0.250000   acc = 0.974
  waterbird_complete95 = 1, forest2water2 = 1  [n = 702]:	loss = 0.053  exp loss = 0.047  adjusted loss = 0.047  adv prob = 0.250000   acc = 0.997
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_train_epoch_184.csv
logged to wandb
Average incurred loss: 0.029  
Average sample loss: 0.029  
Average acc: 0.999  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 1159]:	loss = 0.011  exp loss = 0.011  adjusted loss = 0.011  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 63]:	loss = 0.144  exp loss = 0.122  adjusted loss = 0.122  adv prob = 0.250000   acc = 0.984
  waterbird_complete95 = 1, forest2water2 = 0  [n = 18]:	loss = 0.201  exp loss = 0.214  adjusted loss = 0.214  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 355]:	loss = 0.056  exp loss = 0.052  adjusted loss = 0.052  adv prob = 0.250000   acc = 1.000

Validation:
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_val_epoch_184.csv
logged to wandb
Average incurred loss: 0.461  
Average sample loss: 0.457  
Average acc: 0.791  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.026  exp loss = 0.023  adjusted loss = 0.023  adv prob = 0.250000   acc = 0.996
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.611  exp loss = 0.591  adjusted loss = 0.591  adv prob = 0.250000   acc = 0.680
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.726  exp loss = 1.836  adjusted loss = 1.836  adv prob = 0.250000   acc = 0.308
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.193  exp loss = 0.195  adjusted loss = 0.195  adv prob = 0.250000   acc = 0.947
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_test_epoch_184.csv
logged to wandb
Current lr: 0.000010


Epoch [185]:
Training:
Average incurred loss: 0.028  
Average sample loss: 0.028  
Average acc: 1.000  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2312]:	loss = 0.012  exp loss = 0.010  adjusted loss = 0.010  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 128]:	loss = 0.112  exp loss = 0.113  adjusted loss = 0.113  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 0  [n = 40]:	loss = 0.243  exp loss = 0.262  adjusted loss = 0.262  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 720]:	loss = 0.052  exp loss = 0.051  adjusted loss = 0.051  adv prob = 0.250000   acc = 0.999
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_train_epoch_185.csv
logged to wandb
Average incurred loss: 0.027  
Average sample loss: 0.027  
Average acc: 0.999  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 1186]:	loss = 0.014  exp loss = 0.012  adjusted loss = 0.012  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 56]:	loss = 0.121  exp loss = 0.102  adjusted loss = 0.102  adv prob = 0.250000   acc = 0.982
  waterbird_complete95 = 1, forest2water2 = 0  [n = 16]:	loss = 0.155  exp loss = 0.223  adjusted loss = 0.223  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 337]:	loss = 0.049  exp loss = 0.048  adjusted loss = 0.048  adv prob = 0.250000   acc = 0.997

Validation:
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_val_epoch_185.csv
logged to wandb
Average incurred loss: 0.470  
Average sample loss: 0.466  
Average acc: 0.785  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.027  exp loss = 0.024  adjusted loss = 0.024  adv prob = 0.250000   acc = 0.996
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.635  exp loss = 0.612  adjusted loss = 0.612  adv prob = 0.250000   acc = 0.667
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.723  exp loss = 1.830  adjusted loss = 1.830  adv prob = 0.250000   acc = 0.293
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.189  exp loss = 0.192  adjusted loss = 0.192  adv prob = 0.250000   acc = 0.947
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_test_epoch_185.csv
logged to wandb
Current lr: 0.000010


Epoch [186]:
Training:
Average incurred loss: 0.027  
Average sample loss: 0.027  
Average acc: 0.999  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2330]:	loss = 0.013  exp loss = 0.010  adjusted loss = 0.010  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 112]:	loss = 0.103  exp loss = 0.095  adjusted loss = 0.095  adv prob = 0.250000   acc = 0.991
  waterbird_complete95 = 1, forest2water2 = 0  [n = 38]:	loss = 0.217  exp loss = 0.273  adjusted loss = 0.273  adv prob = 0.250000   acc = 0.974
  waterbird_complete95 = 1, forest2water2 = 1  [n = 720]:	loss = 0.053  exp loss = 0.054  adjusted loss = 0.054  adv prob = 0.250000   acc = 1.000
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_train_epoch_186.csv
logged to wandb
Average incurred loss: 0.028  
Average sample loss: 0.028  
Average acc: 0.999  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 1168]:	loss = 0.015  exp loss = 0.013  adjusted loss = 0.013  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 72]:	loss = 0.105  exp loss = 0.160  adjusted loss = 0.160  adv prob = 0.250000   acc = 0.986
  waterbird_complete95 = 1, forest2water2 = 0  [n = 18]:	loss = 0.174  exp loss = 0.218  adjusted loss = 0.218  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 337]:	loss = 0.048  exp loss = 0.051  adjusted loss = 0.051  adv prob = 0.250000   acc = 1.000

Validation:
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_val_epoch_186.csv
logged to wandb
Average incurred loss: 0.455  
Average sample loss: 0.452  
Average acc: 0.800  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.025  exp loss = 0.023  adjusted loss = 0.023  adv prob = 0.250000   acc = 0.996
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.592  exp loss = 0.570  adjusted loss = 0.570  adv prob = 0.250000   acc = 0.704
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.745  exp loss = 1.858  adjusted loss = 1.858  adv prob = 0.250000   acc = 0.301
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.198  exp loss = 0.201  adjusted loss = 0.201  adv prob = 0.250000   acc = 0.947
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_test_epoch_186.csv
logged to wandb
Current lr: 0.000010


Epoch [187]:
Training:
Average incurred loss: 0.025  
Average sample loss: 0.025  
Average acc: 1.000  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2355]:	loss = 0.012  exp loss = 0.012  adjusted loss = 0.012  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 118]:	loss = 0.131  exp loss = 0.144  adjusted loss = 0.144  adv prob = 0.250000   acc = 0.992
  waterbird_complete95 = 1, forest2water2 = 0  [n = 27]:	loss = 0.197  exp loss = 0.198  adjusted loss = 0.198  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 700]:	loss = 0.044  exp loss = 0.042  adjusted loss = 0.042  adv prob = 0.250000   acc = 1.000
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_train_epoch_187.csv
logged to wandb
Average incurred loss: 0.029  
Average sample loss: 0.029  
Average acc: 0.999  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 1143]:	loss = 0.012  exp loss = 0.012  adjusted loss = 0.012  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 66]:	loss = 0.110  exp loss = 0.123  adjusted loss = 0.123  adv prob = 0.250000   acc = 0.985
  waterbird_complete95 = 1, forest2water2 = 0  [n = 29]:	loss = 0.206  exp loss = 0.181  adjusted loss = 0.181  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 357]:	loss = 0.054  exp loss = 0.041  adjusted loss = 0.041  adv prob = 0.250000   acc = 1.000

Validation:
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_val_epoch_187.csv
logged to wandb
Average incurred loss: 0.462  
Average sample loss: 0.458  
Average acc: 0.790  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.027  exp loss = 0.025  adjusted loss = 0.025  adv prob = 0.250000   acc = 0.996
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.624  exp loss = 0.603  adjusted loss = 0.603  adv prob = 0.250000   acc = 0.676
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.691  exp loss = 1.798  adjusted loss = 1.798  adv prob = 0.250000   acc = 0.308
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.188  exp loss = 0.191  adjusted loss = 0.191  adv prob = 0.250000   acc = 0.947
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_test_epoch_187.csv
logged to wandb
Current lr: 0.000010


Epoch [188]:
Training:
Average incurred loss: 0.028  
Average sample loss: 0.028  
Average acc: 0.998  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2358]:	loss = 0.014  exp loss = 0.013  adjusted loss = 0.013  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 119]:	loss = 0.139  exp loss = 0.130  adjusted loss = 0.130  adv prob = 0.250000   acc = 0.983
  waterbird_complete95 = 1, forest2water2 = 0  [n = 36]:	loss = 0.154  exp loss = 0.143  adjusted loss = 0.143  adv prob = 0.250000   acc = 0.972
  waterbird_complete95 = 1, forest2water2 = 1  [n = 687]:	loss = 0.052  exp loss = 0.041  adjusted loss = 0.041  adv prob = 0.250000   acc = 0.997
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_train_epoch_188.csv
logged to wandb
Average incurred loss: 0.029  
Average sample loss: 0.029  
Average acc: 0.999  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 1140]:	loss = 0.010  exp loss = 0.010  adjusted loss = 0.010  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 65]:	loss = 0.092  exp loss = 0.099  adjusted loss = 0.099  adv prob = 0.250000   acc = 0.985
  waterbird_complete95 = 1, forest2water2 = 0  [n = 20]:	loss = 0.271  exp loss = 0.237  adjusted loss = 0.237  adv prob = 0.250000   acc = 0.950
  waterbird_complete95 = 1, forest2water2 = 1  [n = 370]:	loss = 0.061  exp loss = 0.056  adjusted loss = 0.056  adv prob = 0.250000   acc = 1.000

Validation:
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_val_epoch_188.csv
logged to wandb
Average incurred loss: 0.455  
Average sample loss: 0.452  
Average acc: 0.800  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.024  exp loss = 0.021  adjusted loss = 0.021  adv prob = 0.250000   acc = 0.996
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.570  exp loss = 0.551  adjusted loss = 0.551  adv prob = 0.250000   acc = 0.710
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.813  exp loss = 1.933  adjusted loss = 1.933  adv prob = 0.250000   acc = 0.286
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.210  exp loss = 0.214  adjusted loss = 0.214  adv prob = 0.250000   acc = 0.940
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_test_epoch_188.csv
logged to wandb
Current lr: 0.000010


Epoch [189]:
Training:
Average incurred loss: 0.028  
Average sample loss: 0.028  
Average acc: 0.999  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2330]:	loss = 0.012  exp loss = 0.015  adjusted loss = 0.015  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 123]:	loss = 0.130  exp loss = 0.121  adjusted loss = 0.121  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 0  [n = 39]:	loss = 0.203  exp loss = 0.192  adjusted loss = 0.192  adv prob = 0.250000   acc = 0.974
  waterbird_complete95 = 1, forest2water2 = 1  [n = 708]:	loss = 0.051  exp loss = 0.039  adjusted loss = 0.039  adv prob = 0.250000   acc = 0.999
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_train_epoch_189.csv
logged to wandb
Average incurred loss: 0.027  
Average sample loss: 0.027  
Average acc: 0.999  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 1168]:	loss = 0.013  exp loss = 0.013  adjusted loss = 0.013  adv prob = 0.250000   acc = 0.999
  waterbird_complete95 = 0, forest2water2 = 1  [n = 61]:	loss = 0.113  exp loss = 0.109  adjusted loss = 0.109  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 0  [n = 17]:	loss = 0.182  exp loss = 0.177  adjusted loss = 0.177  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 349]:	loss = 0.052  exp loss = 0.044  adjusted loss = 0.044  adv prob = 0.250000   acc = 1.000

Validation:
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_val_epoch_189.csv
logged to wandb
Average incurred loss: 0.470  
Average sample loss: 0.467  
Average acc: 0.785  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.029  exp loss = 0.026  adjusted loss = 0.026  adv prob = 0.250000   acc = 0.996
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.660  exp loss = 0.637  adjusted loss = 0.637  adv prob = 0.250000   acc = 0.657
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.649  exp loss = 1.746  adjusted loss = 1.746  adv prob = 0.250000   acc = 0.331
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.177  exp loss = 0.179  adjusted loss = 0.179  adv prob = 0.250000   acc = 0.947
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_test_epoch_189.csv
logged to wandb
Current lr: 0.000010


Epoch [190]:
Training:
Average incurred loss: 0.026  
Average sample loss: 0.026  
Average acc: 1.000  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2347]:	loss = 0.012  exp loss = 0.012  adjusted loss = 0.012  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 128]:	loss = 0.121  exp loss = 0.126  adjusted loss = 0.126  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 0  [n = 42]:	loss = 0.183  exp loss = 0.146  adjusted loss = 0.146  adv prob = 0.250000   acc = 0.976
  waterbird_complete95 = 1, forest2water2 = 1  [n = 683]:	loss = 0.045  exp loss = 0.044  adjusted loss = 0.044  adv prob = 0.250000   acc = 1.000
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_train_epoch_190.csv
logged to wandb
Average incurred loss: 0.027  
Average sample loss: 0.027  
Average acc: 0.999  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 1151]:	loss = 0.012  exp loss = 0.011  adjusted loss = 0.011  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 56]:	loss = 0.102  exp loss = 0.104  adjusted loss = 0.104  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 0  [n = 14]:	loss = 0.276  exp loss = 0.259  adjusted loss = 0.259  adv prob = 0.250000   acc = 0.929
  waterbird_complete95 = 1, forest2water2 = 1  [n = 374]:	loss = 0.056  exp loss = 0.059  adjusted loss = 0.059  adv prob = 0.250000   acc = 1.000

Validation:
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_val_epoch_190.csv
logged to wandb
Average incurred loss: 0.446  
Average sample loss: 0.442  
Average acc: 0.809  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.022  exp loss = 0.019  adjusted loss = 0.019  adv prob = 0.250000   acc = 0.998
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.527  exp loss = 0.510  adjusted loss = 0.510  adv prob = 0.250000   acc = 0.734
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.871  exp loss = 1.997  adjusted loss = 1.997  adv prob = 0.250000   acc = 0.286
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.224  exp loss = 0.228  adjusted loss = 0.228  adv prob = 0.250000   acc = 0.932
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_test_epoch_190.csv
logged to wandb
Current lr: 0.000010


Epoch [191]:
Training:
Average incurred loss: 0.025  
Average sample loss: 0.025  
Average acc: 1.000  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2340]:	loss = 0.013  exp loss = 0.013  adjusted loss = 0.013  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 115]:	loss = 0.100  exp loss = 0.109  adjusted loss = 0.109  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 0  [n = 36]:	loss = 0.189  exp loss = 0.171  adjusted loss = 0.171  adv prob = 0.250000   acc = 0.972
  waterbird_complete95 = 1, forest2water2 = 1  [n = 709]:	loss = 0.048  exp loss = 0.042  adjusted loss = 0.042  adv prob = 0.250000   acc = 1.000
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_train_epoch_191.csv
logged to wandb
Average incurred loss: 0.028  
Average sample loss: 0.028  
Average acc: 1.000  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 1158]:	loss = 0.013  exp loss = 0.011  adjusted loss = 0.011  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 69]:	loss = 0.122  exp loss = 0.116  adjusted loss = 0.116  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 0  [n = 20]:	loss = 0.197  exp loss = 0.208  adjusted loss = 0.208  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 348]:	loss = 0.052  exp loss = 0.051  adjusted loss = 0.051  adv prob = 0.250000   acc = 1.000

Validation:
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_val_epoch_191.csv
logged to wandb
Average incurred loss: 0.456  
Average sample loss: 0.453  
Average acc: 0.797  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.024  exp loss = 0.022  adjusted loss = 0.022  adv prob = 0.250000   acc = 0.996
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.583  exp loss = 0.562  adjusted loss = 0.562  adv prob = 0.250000   acc = 0.702
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.781  exp loss = 1.899  adjusted loss = 1.899  adv prob = 0.250000   acc = 0.293
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.203  exp loss = 0.206  adjusted loss = 0.206  adv prob = 0.250000   acc = 0.940
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_test_epoch_191.csv
logged to wandb
Current lr: 0.000010


Epoch [192]:
Training:
Average incurred loss: 0.025  
Average sample loss: 0.025  
Average acc: 0.999  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2370]:	loss = 0.013  exp loss = 0.013  adjusted loss = 0.013  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 114]:	loss = 0.107  exp loss = 0.083  adjusted loss = 0.083  adv prob = 0.250000   acc = 0.991
  waterbird_complete95 = 1, forest2water2 = 0  [n = 35]:	loss = 0.175  exp loss = 0.167  adjusted loss = 0.167  adv prob = 0.250000   acc = 0.943
  waterbird_complete95 = 1, forest2water2 = 1  [n = 681]:	loss = 0.046  exp loss = 0.041  adjusted loss = 0.041  adv prob = 0.250000   acc = 0.999
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_train_epoch_192.csv
logged to wandb
Average incurred loss: 0.028  
Average sample loss: 0.028  
Average acc: 0.999  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 1128]:	loss = 0.010  exp loss = 0.009  adjusted loss = 0.009  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 70]:	loss = 0.096  exp loss = 0.084  adjusted loss = 0.084  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 0  [n = 21]:	loss = 0.232  exp loss = 0.239  adjusted loss = 0.239  adv prob = 0.250000   acc = 0.952
  waterbird_complete95 = 1, forest2water2 = 1  [n = 376]:	loss = 0.059  exp loss = 0.061  adjusted loss = 0.061  adv prob = 0.250000   acc = 0.997

Validation:
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_val_epoch_192.csv
logged to wandb
Average incurred loss: 0.441  
Average sample loss: 0.437  
Average acc: 0.811  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.021  exp loss = 0.019  adjusted loss = 0.019  adv prob = 0.250000   acc = 0.998
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.519  exp loss = 0.500  adjusted loss = 0.500  adv prob = 0.250000   acc = 0.738
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.858  exp loss = 1.982  adjusted loss = 1.982  adv prob = 0.250000   acc = 0.286
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.225  exp loss = 0.229  adjusted loss = 0.229  adv prob = 0.250000   acc = 0.932
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_test_epoch_192.csv
logged to wandb
Current lr: 0.000010


Epoch [193]:
Training:
Average incurred loss: 0.028  
Average sample loss: 0.028  
Average acc: 0.999  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2329]:	loss = 0.013  exp loss = 0.012  adjusted loss = 0.012  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 124]:	loss = 0.121  exp loss = 0.114  adjusted loss = 0.114  adv prob = 0.250000   acc = 0.984
  waterbird_complete95 = 1, forest2water2 = 0  [n = 37]:	loss = 0.190  exp loss = 0.180  adjusted loss = 0.180  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 710]:	loss = 0.052  exp loss = 0.049  adjusted loss = 0.049  adv prob = 0.250000   acc = 1.000
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_train_epoch_193.csv
logged to wandb
Average incurred loss: 0.023  
Average sample loss: 0.023  
Average acc: 0.999  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 1169]:	loss = 0.012  exp loss = 0.011  adjusted loss = 0.011  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 60]:	loss = 0.110  exp loss = 0.107  adjusted loss = 0.107  adv prob = 0.250000   acc = 0.983
  waterbird_complete95 = 1, forest2water2 = 0  [n = 19]:	loss = 0.181  exp loss = 0.187  adjusted loss = 0.187  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 347]:	loss = 0.039  exp loss = 0.038  adjusted loss = 0.038  adv prob = 0.250000   acc = 1.000

Validation:
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_val_epoch_193.csv
logged to wandb
Average incurred loss: 0.456  
Average sample loss: 0.452  
Average acc: 0.794  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.026  exp loss = 0.023  adjusted loss = 0.023  adv prob = 0.250000   acc = 0.996
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.604  exp loss = 0.583  adjusted loss = 0.583  adv prob = 0.250000   acc = 0.689
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.709  exp loss = 1.814  adjusted loss = 1.814  adv prob = 0.250000   acc = 0.301
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.191  exp loss = 0.193  adjusted loss = 0.193  adv prob = 0.250000   acc = 0.947
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_test_epoch_193.csv
logged to wandb
Current lr: 0.000010


Epoch [194]:
Training:
Average incurred loss: 0.026  
Average sample loss: 0.026  
Average acc: 1.000  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2319]:	loss = 0.011  exp loss = 0.011  adjusted loss = 0.011  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 131]:	loss = 0.119  exp loss = 0.110  adjusted loss = 0.110  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 0  [n = 38]:	loss = 0.167  exp loss = 0.191  adjusted loss = 0.191  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 712]:	loss = 0.051  exp loss = 0.045  adjusted loss = 0.045  adv prob = 0.250000   acc = 1.000
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_train_epoch_194.csv
logged to wandb
Average incurred loss: 0.024  
Average sample loss: 0.024  
Average acc: 0.999  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 1179]:	loss = 0.012  exp loss = 0.011  adjusted loss = 0.011  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 53]:	loss = 0.127  exp loss = 0.139  adjusted loss = 0.139  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 0  [n = 18]:	loss = 0.163  exp loss = 0.162  adjusted loss = 0.162  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 345]:	loss = 0.043  exp loss = 0.036  adjusted loss = 0.036  adv prob = 0.250000   acc = 0.997

Validation:
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_val_epoch_194.csv
logged to wandb
Average incurred loss: 0.470  
Average sample loss: 0.467  
Average acc: 0.785  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.029  exp loss = 0.026  adjusted loss = 0.026  adv prob = 0.250000   acc = 0.996
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.663  exp loss = 0.639  adjusted loss = 0.639  adv prob = 0.250000   acc = 0.655
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.642  exp loss = 1.739  adjusted loss = 1.739  adv prob = 0.250000   acc = 0.338
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.173  exp loss = 0.174  adjusted loss = 0.174  adv prob = 0.250000   acc = 0.947
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_test_epoch_194.csv
logged to wandb
Current lr: 0.000010


Epoch [195]:
Training:
Average incurred loss: 0.025  
Average sample loss: 0.025  
Average acc: 0.999  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2345]:	loss = 0.012  exp loss = 0.012  adjusted loss = 0.012  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 110]:	loss = 0.107  exp loss = 0.084  adjusted loss = 0.084  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 0  [n = 35]:	loss = 0.164  exp loss = 0.211  adjusted loss = 0.211  adv prob = 0.250000   acc = 0.971
  waterbird_complete95 = 1, forest2water2 = 1  [n = 710]:	loss = 0.048  exp loss = 0.051  adjusted loss = 0.051  adv prob = 0.250000   acc = 0.997
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_train_epoch_195.csv
logged to wandb
Average incurred loss: 0.025  
Average sample loss: 0.025  
Average acc: 0.999  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 1153]:	loss = 0.011  exp loss = 0.011  adjusted loss = 0.011  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 74]:	loss = 0.115  exp loss = 0.107  adjusted loss = 0.107  adv prob = 0.250000   acc = 0.986
  waterbird_complete95 = 1, forest2water2 = 0  [n = 21]:	loss = 0.203  exp loss = 0.170  adjusted loss = 0.170  adv prob = 0.250000   acc = 0.952
  waterbird_complete95 = 1, forest2water2 = 1  [n = 347]:	loss = 0.043  exp loss = 0.041  adjusted loss = 0.041  adv prob = 0.250000   acc = 1.000

Validation:
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_val_epoch_195.csv
logged to wandb
Average incurred loss: 0.465  
Average sample loss: 0.461  
Average acc: 0.790  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.026  exp loss = 0.024  adjusted loss = 0.024  adv prob = 0.250000   acc = 0.996
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.622  exp loss = 0.600  adjusted loss = 0.600  adv prob = 0.250000   acc = 0.678
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.729  exp loss = 1.839  adjusted loss = 1.839  adv prob = 0.250000   acc = 0.301
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.188  exp loss = 0.191  adjusted loss = 0.191  adv prob = 0.250000   acc = 0.947
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_test_epoch_195.csv
logged to wandb
Current lr: 0.000010


Epoch [196]:
Training:
Average incurred loss: 0.026  
Average sample loss: 0.026  
Average acc: 0.999  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2336]:	loss = 0.012  exp loss = 0.011  adjusted loss = 0.011  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 119]:	loss = 0.116  exp loss = 0.137  adjusted loss = 0.137  adv prob = 0.250000   acc = 0.992
  waterbird_complete95 = 1, forest2water2 = 0  [n = 39]:	loss = 0.175  exp loss = 0.160  adjusted loss = 0.160  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 706]:	loss = 0.047  exp loss = 0.049  adjusted loss = 0.049  adv prob = 0.250000   acc = 0.999
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_train_epoch_196.csv
logged to wandb
Average incurred loss: 0.026  
Average sample loss: 0.026  
Average acc: 0.999  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 1162]:	loss = 0.012  exp loss = 0.012  adjusted loss = 0.012  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 65]:	loss = 0.107  exp loss = 0.113  adjusted loss = 0.113  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 0  [n = 17]:	loss = 0.225  exp loss = 0.163  adjusted loss = 0.163  adv prob = 0.250000   acc = 0.941
  waterbird_complete95 = 1, forest2water2 = 1  [n = 351]:	loss = 0.048  exp loss = 0.044  adjusted loss = 0.044  adv prob = 0.250000   acc = 1.000

Validation:
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_val_epoch_196.csv
logged to wandb
Average incurred loss: 0.467  
Average sample loss: 0.463  
Average acc: 0.786  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.027  exp loss = 0.024  adjusted loss = 0.024  adv prob = 0.250000   acc = 0.996
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.639  exp loss = 0.616  adjusted loss = 0.616  adv prob = 0.250000   acc = 0.665
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.694  exp loss = 1.805  adjusted loss = 1.805  adv prob = 0.250000   acc = 0.316
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.182  exp loss = 0.184  adjusted loss = 0.184  adv prob = 0.250000   acc = 0.947
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_test_epoch_196.csv
logged to wandb
Current lr: 0.000010


Epoch [197]:
Training:
Average incurred loss: 0.027  
Average sample loss: 0.027  
Average acc: 1.000  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2324]:	loss = 0.012  exp loss = 0.012  adjusted loss = 0.012  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 124]:	loss = 0.116  exp loss = 0.109  adjusted loss = 0.109  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 0  [n = 40]:	loss = 0.187  exp loss = 0.156  adjusted loss = 0.156  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 712]:	loss = 0.051  exp loss = 0.044  adjusted loss = 0.044  adv prob = 0.250000   acc = 1.000
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_train_epoch_197.csv
logged to wandb
Average incurred loss: 0.024  
Average sample loss: 0.024  
Average acc: 1.000  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 1174]:	loss = 0.012  exp loss = 0.011  adjusted loss = 0.011  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 60]:	loss = 0.102  exp loss = 0.094  adjusted loss = 0.094  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 0  [n = 16]:	loss = 0.132  exp loss = 0.138  adjusted loss = 0.138  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 345]:	loss = 0.044  exp loss = 0.040  adjusted loss = 0.040  adv prob = 0.250000   acc = 1.000

Validation:
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_val_epoch_197.csv
logged to wandb
Average incurred loss: 0.458  
Average sample loss: 0.454  
Average acc: 0.798  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.024  exp loss = 0.022  adjusted loss = 0.022  adv prob = 0.250000   acc = 0.996
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.589  exp loss = 0.566  adjusted loss = 0.566  adv prob = 0.250000   acc = 0.704
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.782  exp loss = 1.901  adjusted loss = 1.901  adv prob = 0.250000   acc = 0.293
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.199  exp loss = 0.203  adjusted loss = 0.203  adv prob = 0.250000   acc = 0.940
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_test_epoch_197.csv
logged to wandb
Current lr: 0.000010


Epoch [198]:
Training:
Average incurred loss: 0.024  
Average sample loss: 0.024  
Average acc: 1.000  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2341]:	loss = 0.012  exp loss = 0.011  adjusted loss = 0.011  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 112]:	loss = 0.097  exp loss = 0.108  adjusted loss = 0.108  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 0  [n = 36]:	loss = 0.161  exp loss = 0.138  adjusted loss = 0.138  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 711]:	loss = 0.047  exp loss = 0.041  adjusted loss = 0.041  adv prob = 0.250000   acc = 0.999
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_train_epoch_198.csv
logged to wandb
Average incurred loss: 0.023  
Average sample loss: 0.023  
Average acc: 1.000  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 1157]:	loss = 0.011  exp loss = 0.012  adjusted loss = 0.012  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 72]:	loss = 0.097  exp loss = 0.096  adjusted loss = 0.096  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 0  [n = 20]:	loss = 0.134  exp loss = 0.146  adjusted loss = 0.146  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 346]:	loss = 0.043  exp loss = 0.038  adjusted loss = 0.038  adv prob = 0.250000   acc = 1.000

Validation:
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_val_epoch_198.csv
logged to wandb
Average incurred loss: 0.455  
Average sample loss: 0.452  
Average acc: 0.796  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.025  exp loss = 0.022  adjusted loss = 0.022  adv prob = 0.250000   acc = 0.996
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.595  exp loss = 0.575  adjusted loss = 0.575  adv prob = 0.250000   acc = 0.695
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.738  exp loss = 1.847  adjusted loss = 1.847  adv prob = 0.250000   acc = 0.301
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.194  exp loss = 0.196  adjusted loss = 0.196  adv prob = 0.250000   acc = 0.947
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_test_epoch_198.csv
logged to wandb
Current lr: 0.000010


Epoch [199]:
Training:
Average incurred loss: 0.025  
Average sample loss: 0.025  
Average acc: 1.000  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2343]:	loss = 0.012  exp loss = 0.013  adjusted loss = 0.013  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 120]:	loss = 0.110  exp loss = 0.156  adjusted loss = 0.156  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 0  [n = 37]:	loss = 0.181  exp loss = 0.158  adjusted loss = 0.158  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 700]:	loss = 0.046  exp loss = 0.035  adjusted loss = 0.035  adv prob = 0.250000   acc = 0.999
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_train_epoch_199.csv
logged to wandb
Average incurred loss: 0.029  
Average sample loss: 0.029  
Average acc: 0.999  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 1155]:	loss = 0.012  exp loss = 0.013  adjusted loss = 0.013  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 64]:	loss = 0.142  exp loss = 0.140  adjusted loss = 0.140  adv prob = 0.250000   acc = 0.984
  waterbird_complete95 = 1, forest2water2 = 0  [n = 19]:	loss = 0.194  exp loss = 0.176  adjusted loss = 0.176  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 357]:	loss = 0.052  exp loss = 0.044  adjusted loss = 0.044  adv prob = 0.250000   acc = 1.000

Validation:
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_val_epoch_199.csv
logged to wandb
Average incurred loss: 0.468  
Average sample loss: 0.465  
Average acc: 0.788  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.027  exp loss = 0.024  adjusted loss = 0.024  adv prob = 0.250000   acc = 0.996
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.641  exp loss = 0.620  adjusted loss = 0.620  adv prob = 0.250000   acc = 0.665
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.701  exp loss = 1.804  adjusted loss = 1.804  adv prob = 0.250000   acc = 0.331
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.180  exp loss = 0.181  adjusted loss = 0.181  adv prob = 0.250000   acc = 0.947
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_test_epoch_199.csv
logged to wandb
Current lr: 0.000010


Epoch [200]:
Training:
Average incurred loss: 0.025  
Average sample loss: 0.025  
Average acc: 1.000  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2330]:	loss = 0.011  exp loss = 0.012  adjusted loss = 0.012  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 121]:	loss = 0.099  exp loss = 0.129  adjusted loss = 0.129  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 0  [n = 35]:	loss = 0.183  exp loss = 0.186  adjusted loss = 0.186  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 714]:	loss = 0.051  exp loss = 0.038  adjusted loss = 0.038  adv prob = 0.250000   acc = 0.999
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_train_epoch_200.csv
logged to wandb
Average incurred loss: 0.024  
Average sample loss: 0.024  
Average acc: 0.999  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 1168]:	loss = 0.012  exp loss = 0.012  adjusted loss = 0.012  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 63]:	loss = 0.115  exp loss = 0.107  adjusted loss = 0.107  adv prob = 0.250000   acc = 0.984
  waterbird_complete95 = 1, forest2water2 = 0  [n = 21]:	loss = 0.154  exp loss = 0.162  adjusted loss = 0.162  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 343]:	loss = 0.038  exp loss = 0.035  adjusted loss = 0.035  adv prob = 0.250000   acc = 1.000

Validation:
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_val_epoch_200.csv
logged to wandb
Average incurred loss: 0.464  
Average sample loss: 0.461  
Average acc: 0.789  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.028  exp loss = 0.025  adjusted loss = 0.025  adv prob = 0.250000   acc = 0.996
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.637  exp loss = 0.615  adjusted loss = 0.615  adv prob = 0.250000   acc = 0.672
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.676  exp loss = 1.777  adjusted loss = 1.777  adv prob = 0.250000   acc = 0.316
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.181  exp loss = 0.182  adjusted loss = 0.182  adv prob = 0.250000   acc = 0.947
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_test_epoch_200.csv
logged to wandb
Current lr: 0.000010


Epoch [201]:
Training:
Average incurred loss: 0.026  
Average sample loss: 0.026  
Average acc: 1.000  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2327]:	loss = 0.011  exp loss = 0.010  adjusted loss = 0.010  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 120]:	loss = 0.103  exp loss = 0.115  adjusted loss = 0.115  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 0  [n = 34]:	loss = 0.185  exp loss = 0.208  adjusted loss = 0.208  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 719]:	loss = 0.052  exp loss = 0.048  adjusted loss = 0.048  adv prob = 0.250000   acc = 0.999
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_train_epoch_201.csv
logged to wandb
Average incurred loss: 0.025  
Average sample loss: 0.025  
Average acc: 1.000  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 1171]:	loss = 0.013  exp loss = 0.013  adjusted loss = 0.013  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 64]:	loss = 0.108  exp loss = 0.117  adjusted loss = 0.117  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 0  [n = 22]:	loss = 0.156  exp loss = 0.187  adjusted loss = 0.187  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 338]:	loss = 0.044  exp loss = 0.036  adjusted loss = 0.036  adv prob = 0.250000   acc = 1.000

Validation:
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_val_epoch_201.csv
logged to wandb
Average incurred loss: 0.468  
Average sample loss: 0.464  
Average acc: 0.787  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.026  exp loss = 0.024  adjusted loss = 0.024  adv prob = 0.250000   acc = 0.996
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.636  exp loss = 0.612  adjusted loss = 0.612  adv prob = 0.250000   acc = 0.670
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.716  exp loss = 1.822  adjusted loss = 1.822  adv prob = 0.250000   acc = 0.308
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.182  exp loss = 0.184  adjusted loss = 0.184  adv prob = 0.250000   acc = 0.947
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_test_epoch_201.csv
logged to wandb
Current lr: 0.000010


Epoch [202]:
Training:
Average incurred loss: 0.026  
Average sample loss: 0.026  
Average acc: 0.999  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2331]:	loss = 0.011  exp loss = 0.011  adjusted loss = 0.011  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 112]:	loss = 0.104  exp loss = 0.110  adjusted loss = 0.110  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 0  [n = 39]:	loss = 0.193  exp loss = 0.188  adjusted loss = 0.188  adv prob = 0.250000   acc = 0.974
  waterbird_complete95 = 1, forest2water2 = 1  [n = 718]:	loss = 0.050  exp loss = 0.045  adjusted loss = 0.045  adv prob = 0.250000   acc = 0.999
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_train_epoch_202.csv
logged to wandb
Average incurred loss: 0.023  
Average sample loss: 0.023  
Average acc: 0.999  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 1167]:	loss = 0.011  exp loss = 0.011  adjusted loss = 0.011  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 72]:	loss = 0.112  exp loss = 0.109  adjusted loss = 0.109  adv prob = 0.250000   acc = 0.986
  waterbird_complete95 = 1, forest2water2 = 0  [n = 17]:	loss = 0.091  exp loss = 0.124  adjusted loss = 0.124  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 339]:	loss = 0.041  exp loss = 0.041  adjusted loss = 0.041  adv prob = 0.250000   acc = 1.000

Validation:
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_val_epoch_202.csv
logged to wandb
Average incurred loss: 0.463  
Average sample loss: 0.460  
Average acc: 0.792  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.026  exp loss = 0.023  adjusted loss = 0.023  adv prob = 0.250000   acc = 0.996
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.618  exp loss = 0.597  adjusted loss = 0.597  adv prob = 0.250000   acc = 0.682
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.734  exp loss = 1.844  adjusted loss = 1.844  adv prob = 0.250000   acc = 0.308
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.187  exp loss = 0.190  adjusted loss = 0.190  adv prob = 0.250000   acc = 0.947
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_test_epoch_202.csv
logged to wandb
Current lr: 0.000010


Epoch [203]:
Training:
Average incurred loss: 0.023  
Average sample loss: 0.023  
Average acc: 1.000  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2336]:	loss = 0.011  exp loss = 0.011  adjusted loss = 0.011  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 116]:	loss = 0.085  exp loss = 0.103  adjusted loss = 0.103  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 0  [n = 35]:	loss = 0.151  exp loss = 0.160  adjusted loss = 0.160  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 713]:	loss = 0.046  exp loss = 0.040  adjusted loss = 0.040  adv prob = 0.250000   acc = 0.999
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_train_epoch_203.csv
logged to wandb
Average incurred loss: 0.027  
Average sample loss: 0.027  
Average acc: 0.999  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 1162]:	loss = 0.012  exp loss = 0.011  adjusted loss = 0.011  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 68]:	loss = 0.140  exp loss = 0.127  adjusted loss = 0.127  adv prob = 0.250000   acc = 0.985
  waterbird_complete95 = 1, forest2water2 = 0  [n = 21]:	loss = 0.143  exp loss = 0.149  adjusted loss = 0.149  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 344]:	loss = 0.049  exp loss = 0.042  adjusted loss = 0.042  adv prob = 0.250000   acc = 1.000

Validation:
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_val_epoch_203.csv
logged to wandb
Average incurred loss: 0.460  
Average sample loss: 0.457  
Average acc: 0.796  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.026  exp loss = 0.023  adjusted loss = 0.023  adv prob = 0.250000   acc = 0.996
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.617  exp loss = 0.598  adjusted loss = 0.598  adv prob = 0.250000   acc = 0.682
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.713  exp loss = 1.819  adjusted loss = 1.819  adv prob = 0.250000   acc = 0.331
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.185  exp loss = 0.187  adjusted loss = 0.187  adv prob = 0.250000   acc = 0.955
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_test_epoch_203.csv
logged to wandb
Current lr: 0.000010


Epoch [204]:
Training:
Average incurred loss: 0.025  
Average sample loss: 0.025  
Average acc: 0.999  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2323]:	loss = 0.012  exp loss = 0.011  adjusted loss = 0.011  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 121]:	loss = 0.107  exp loss = 0.094  adjusted loss = 0.094  adv prob = 0.250000   acc = 0.992
  waterbird_complete95 = 1, forest2water2 = 0  [n = 40]:	loss = 0.173  exp loss = 0.171  adjusted loss = 0.171  adv prob = 0.250000   acc = 0.975
  waterbird_complete95 = 1, forest2water2 = 1  [n = 716]:	loss = 0.048  exp loss = 0.038  adjusted loss = 0.038  adv prob = 0.250000   acc = 0.999
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_train_epoch_204.csv
logged to wandb
Average incurred loss: 0.023  
Average sample loss: 0.023  
Average acc: 1.000  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 1175]:	loss = 0.011  exp loss = 0.011  adjusted loss = 0.011  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 63]:	loss = 0.125  exp loss = 0.144  adjusted loss = 0.144  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 0  [n = 16]:	loss = 0.160  exp loss = 0.173  adjusted loss = 0.173  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 341]:	loss = 0.036  exp loss = 0.038  adjusted loss = 0.038  adv prob = 0.250000   acc = 1.000

Validation:
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_val_epoch_204.csv
logged to wandb
Average incurred loss: 0.461  
Average sample loss: 0.458  
Average acc: 0.793  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.025  exp loss = 0.023  adjusted loss = 0.023  adv prob = 0.250000   acc = 0.996
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.616  exp loss = 0.595  adjusted loss = 0.595  adv prob = 0.250000   acc = 0.682
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.724  exp loss = 1.829  adjusted loss = 1.829  adv prob = 0.250000   acc = 0.316
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.186  exp loss = 0.188  adjusted loss = 0.188  adv prob = 0.250000   acc = 0.947
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_test_epoch_204.csv
logged to wandb
Current lr: 0.000010


Epoch [205]:
Training:
Average incurred loss: 0.026  
Average sample loss: 0.026  
Average acc: 0.999  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2362]:	loss = 0.012  exp loss = 0.013  adjusted loss = 0.013  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 126]:	loss = 0.112  exp loss = 0.107  adjusted loss = 0.107  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 0  [n = 37]:	loss = 0.197  exp loss = 0.193  adjusted loss = 0.193  adv prob = 0.250000   acc = 0.946
  waterbird_complete95 = 1, forest2water2 = 1  [n = 675]:	loss = 0.048  exp loss = 0.044  adjusted loss = 0.044  adv prob = 0.250000   acc = 0.999
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_train_epoch_205.csv
logged to wandb
Average incurred loss: 0.027  
Average sample loss: 0.027  
Average acc: 0.999  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 1136]:	loss = 0.010  exp loss = 0.011  adjusted loss = 0.011  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 58]:	loss = 0.101  exp loss = 0.116  adjusted loss = 0.116  adv prob = 0.250000   acc = 0.983
  waterbird_complete95 = 1, forest2water2 = 0  [n = 19]:	loss = 0.250  exp loss = 0.193  adjusted loss = 0.193  adv prob = 0.250000   acc = 0.947
  waterbird_complete95 = 1, forest2water2 = 1  [n = 382]:	loss = 0.056  exp loss = 0.043  adjusted loss = 0.043  adv prob = 0.250000   acc = 1.000

Validation:
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_val_epoch_205.csv
logged to wandb
Average incurred loss: 0.462  
Average sample loss: 0.458  
Average acc: 0.796  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.024  exp loss = 0.021  adjusted loss = 0.021  adv prob = 0.250000   acc = 0.996
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.600  exp loss = 0.577  adjusted loss = 0.577  adv prob = 0.250000   acc = 0.697
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.785  exp loss = 1.904  adjusted loss = 1.904  adv prob = 0.250000   acc = 0.293
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.193  exp loss = 0.196  adjusted loss = 0.196  adv prob = 0.250000   acc = 0.947
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_test_epoch_205.csv
logged to wandb
Current lr: 0.000010


Epoch [206]:
Training:
Average incurred loss: 0.024  
Average sample loss: 0.024  
Average acc: 1.000  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2322]:	loss = 0.011  exp loss = 0.011  adjusted loss = 0.011  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 121]:	loss = 0.108  exp loss = 0.082  adjusted loss = 0.082  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 0  [n = 35]:	loss = 0.173  exp loss = 0.154  adjusted loss = 0.154  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 722]:	loss = 0.046  exp loss = 0.047  adjusted loss = 0.047  adv prob = 0.250000   acc = 1.000
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_train_epoch_206.csv
logged to wandb
Average incurred loss: 0.025  
Average sample loss: 0.025  
Average acc: 0.999  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 1176]:	loss = 0.012  exp loss = 0.012  adjusted loss = 0.012  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 63]:	loss = 0.128  exp loss = 0.131  adjusted loss = 0.131  adv prob = 0.250000   acc = 0.968
  waterbird_complete95 = 1, forest2water2 = 0  [n = 21]:	loss = 0.174  exp loss = 0.151  adjusted loss = 0.151  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 335]:	loss = 0.039  exp loss = 0.036  adjusted loss = 0.036  adv prob = 0.250000   acc = 1.000

Validation:
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_val_epoch_206.csv
logged to wandb
Average incurred loss: 0.470  
Average sample loss: 0.466  
Average acc: 0.788  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.026  exp loss = 0.023  adjusted loss = 0.023  adv prob = 0.250000   acc = 0.996
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.642  exp loss = 0.618  adjusted loss = 0.618  adv prob = 0.250000   acc = 0.670
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.714  exp loss = 1.823  adjusted loss = 1.823  adv prob = 0.250000   acc = 0.316
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.179  exp loss = 0.180  adjusted loss = 0.180  adv prob = 0.250000   acc = 0.947
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_test_epoch_206.csv
logged to wandb
Current lr: 0.000010


Epoch [207]:
Training:
Average incurred loss: 0.024  
Average sample loss: 0.024  
Average acc: 0.999  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2314]:	loss = 0.010  exp loss = 0.009  adjusted loss = 0.009  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 124]:	loss = 0.083  exp loss = 0.095  adjusted loss = 0.095  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 0  [n = 38]:	loss = 0.182  exp loss = 0.150  adjusted loss = 0.150  adv prob = 0.250000   acc = 0.974
  waterbird_complete95 = 1, forest2water2 = 1  [n = 724]:	loss = 0.048  exp loss = 0.037  adjusted loss = 0.037  adv prob = 0.250000   acc = 0.999
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_train_epoch_207.csv
logged to wandb
Average incurred loss: 0.021  
Average sample loss: 0.021  
Average acc: 1.000  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 1184]:	loss = 0.012  exp loss = 0.012  adjusted loss = 0.012  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 60]:	loss = 0.095  exp loss = 0.094  adjusted loss = 0.094  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 0  [n = 18]:	loss = 0.129  exp loss = 0.129  adjusted loss = 0.129  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 333]:	loss = 0.035  exp loss = 0.035  adjusted loss = 0.035  adv prob = 0.250000   acc = 1.000

Validation:
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_val_epoch_207.csv
logged to wandb
Average incurred loss: 0.464  
Average sample loss: 0.460  
Average acc: 0.791  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.026  exp loss = 0.023  adjusted loss = 0.023  adv prob = 0.250000   acc = 0.996
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.632  exp loss = 0.609  adjusted loss = 0.609  adv prob = 0.250000   acc = 0.672
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.695  exp loss = 1.799  adjusted loss = 1.799  adv prob = 0.250000   acc = 0.331
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.178  exp loss = 0.179  adjusted loss = 0.179  adv prob = 0.250000   acc = 0.947
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_test_epoch_207.csv
logged to wandb
Current lr: 0.000010


Epoch [208]:
Training:
Average incurred loss: 0.024  
Average sample loss: 0.024  
Average acc: 1.000  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2346]:	loss = 0.012  exp loss = 0.012  adjusted loss = 0.012  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 123]:	loss = 0.112  exp loss = 0.117  adjusted loss = 0.117  adv prob = 0.250000   acc = 0.992
  waterbird_complete95 = 1, forest2water2 = 0  [n = 35]:	loss = 0.146  exp loss = 0.138  adjusted loss = 0.138  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 696]:	loss = 0.043  exp loss = 0.036  adjusted loss = 0.036  adv prob = 0.250000   acc = 1.000
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_train_epoch_208.csv
logged to wandb
Average incurred loss: 0.022  
Average sample loss: 0.022  
Average acc: 0.999  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 1152]:	loss = 0.010  exp loss = 0.010  adjusted loss = 0.010  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 61]:	loss = 0.093  exp loss = 0.100  adjusted loss = 0.100  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 0  [n = 21]:	loss = 0.186  exp loss = 0.173  adjusted loss = 0.173  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 361]:	loss = 0.042  exp loss = 0.035  adjusted loss = 0.035  adv prob = 0.250000   acc = 0.997

Validation:
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_val_epoch_208.csv
logged to wandb
Average incurred loss: 0.464  
Average sample loss: 0.460  
Average acc: 0.791  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.025  exp loss = 0.022  adjusted loss = 0.022  adv prob = 0.250000   acc = 0.996
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.616  exp loss = 0.595  adjusted loss = 0.595  adv prob = 0.250000   acc = 0.680
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.749  exp loss = 1.862  adjusted loss = 1.862  adv prob = 0.250000   acc = 0.301
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.186  exp loss = 0.188  adjusted loss = 0.188  adv prob = 0.250000   acc = 0.947
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_test_epoch_208.csv
logged to wandb
Current lr: 0.000010


Epoch [209]:
Training:
Average incurred loss: 0.023  
Average sample loss: 0.023  
Average acc: 1.000  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2366]:	loss = 0.011  exp loss = 0.010  adjusted loss = 0.010  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 120]:	loss = 0.116  exp loss = 0.096  adjusted loss = 0.096  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 0  [n = 34]:	loss = 0.152  exp loss = 0.181  adjusted loss = 0.181  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 680]:	loss = 0.039  exp loss = 0.036  adjusted loss = 0.036  adv prob = 0.250000   acc = 1.000
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_train_epoch_209.csv
logged to wandb
Average incurred loss: 0.026  
Average sample loss: 0.026  
Average acc: 0.999  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 1132]:	loss = 0.010  exp loss = 0.009  adjusted loss = 0.009  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 64]:	loss = 0.078  exp loss = 0.084  adjusted loss = 0.084  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 0  [n = 22]:	loss = 0.211  exp loss = 0.166  adjusted loss = 0.166  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 377]:	loss = 0.054  exp loss = 0.049  adjusted loss = 0.049  adv prob = 0.250000   acc = 0.997

Validation:
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_val_epoch_209.csv
logged to wandb
Average incurred loss: 0.452  
Average sample loss: 0.448  
Average acc: 0.807  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.021  exp loss = 0.019  adjusted loss = 0.019  adv prob = 0.250000   acc = 0.998
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.555  exp loss = 0.534  adjusted loss = 0.534  adv prob = 0.250000   acc = 0.723
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.844  exp loss = 1.970  adjusted loss = 1.970  adv prob = 0.250000   acc = 0.293
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.207  exp loss = 0.210  adjusted loss = 0.210  adv prob = 0.250000   acc = 0.947
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_test_epoch_209.csv
logged to wandb
Current lr: 0.000010


Epoch [210]:
Training:
Average incurred loss: 0.024  
Average sample loss: 0.024  
Average acc: 0.999  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2328]:	loss = 0.011  exp loss = 0.011  adjusted loss = 0.011  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 119]:	loss = 0.098  exp loss = 0.101  adjusted loss = 0.101  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 0  [n = 33]:	loss = 0.205  exp loss = 0.172  adjusted loss = 0.172  adv prob = 0.250000   acc = 0.970
  waterbird_complete95 = 1, forest2water2 = 1  [n = 720]:	loss = 0.048  exp loss = 0.046  adjusted loss = 0.046  adv prob = 0.250000   acc = 0.997
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_train_epoch_210.csv
logged to wandb
Average incurred loss: 0.022  
Average sample loss: 0.022  
Average acc: 1.000  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 1170]:	loss = 0.011  exp loss = 0.011  adjusted loss = 0.011  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 65]:	loss = 0.102  exp loss = 0.101  adjusted loss = 0.101  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 0  [n = 23]:	loss = 0.151  exp loss = 0.143  adjusted loss = 0.143  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 337]:	loss = 0.037  exp loss = 0.035  adjusted loss = 0.035  adv prob = 0.250000   acc = 1.000

Validation:
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_val_epoch_210.csv
logged to wandb
Average incurred loss: 0.462  
Average sample loss: 0.459  
Average acc: 0.791  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.026  exp loss = 0.023  adjusted loss = 0.023  adv prob = 0.250000   acc = 0.996
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.630  exp loss = 0.608  adjusted loss = 0.608  adv prob = 0.250000   acc = 0.672
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.692  exp loss = 1.795  adjusted loss = 1.795  adv prob = 0.250000   acc = 0.331
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.180  exp loss = 0.181  adjusted loss = 0.181  adv prob = 0.250000   acc = 0.955
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_test_epoch_210.csv
logged to wandb
Current lr: 0.000010


Epoch [211]:
Training:
Average incurred loss: 0.023  
Average sample loss: 0.023  
Average acc: 1.000  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2331]:	loss = 0.011  exp loss = 0.010  adjusted loss = 0.010  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 125]:	loss = 0.105  exp loss = 0.086  adjusted loss = 0.086  adv prob = 0.250000   acc = 0.992
  waterbird_complete95 = 1, forest2water2 = 0  [n = 38]:	loss = 0.160  exp loss = 0.148  adjusted loss = 0.148  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 706]:	loss = 0.043  exp loss = 0.038  adjusted loss = 0.038  adv prob = 0.250000   acc = 1.000
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_train_epoch_211.csv
logged to wandb
Average incurred loss: 0.025  
Average sample loss: 0.025  
Average acc: 0.999  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 1167]:	loss = 0.012  exp loss = 0.010  adjusted loss = 0.010  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 59]:	loss = 0.123  exp loss = 0.186  adjusted loss = 0.186  adv prob = 0.250000   acc = 0.966
  waterbird_complete95 = 1, forest2water2 = 0  [n = 18]:	loss = 0.187  exp loss = 0.167  adjusted loss = 0.167  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 351]:	loss = 0.043  exp loss = 0.039  adjusted loss = 0.039  adv prob = 0.250000   acc = 1.000

Validation:
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_val_epoch_211.csv
logged to wandb
Average incurred loss: 0.464  
Average sample loss: 0.460  
Average acc: 0.792  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.025  exp loss = 0.022  adjusted loss = 0.022  adv prob = 0.250000   acc = 0.996
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.618  exp loss = 0.594  adjusted loss = 0.594  adv prob = 0.250000   acc = 0.685
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.741  exp loss = 1.853  adjusted loss = 1.853  adv prob = 0.250000   acc = 0.301
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.187  exp loss = 0.188  adjusted loss = 0.188  adv prob = 0.250000   acc = 0.947
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_test_epoch_211.csv
logged to wandb
Current lr: 0.000010


Epoch [212]:
Training:
Average incurred loss: 0.023  
Average sample loss: 0.023  
Average acc: 1.000  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2347]:	loss = 0.011  exp loss = 0.009  adjusted loss = 0.009  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 114]:	loss = 0.107  exp loss = 0.084  adjusted loss = 0.084  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 0  [n = 38]:	loss = 0.131  exp loss = 0.145  adjusted loss = 0.145  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 701]:	loss = 0.043  exp loss = 0.046  adjusted loss = 0.046  adv prob = 0.250000   acc = 1.000
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_train_epoch_212.csv
logged to wandb
Average incurred loss: 0.025  
Average sample loss: 0.025  
Average acc: 0.999  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 1151]:	loss = 0.010  exp loss = 0.010  adjusted loss = 0.010  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 70]:	loss = 0.093  exp loss = 0.086  adjusted loss = 0.086  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 0  [n = 18]:	loss = 0.160  exp loss = 0.160  adjusted loss = 0.160  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 356]:	loss = 0.054  exp loss = 0.054  adjusted loss = 0.054  adv prob = 0.250000   acc = 0.997

Validation:
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_val_epoch_212.csv
logged to wandb
Average incurred loss: 0.454  
Average sample loss: 0.450  
Average acc: 0.802  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.022  exp loss = 0.020  adjusted loss = 0.020  adv prob = 0.250000   acc = 0.996
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.570  exp loss = 0.548  adjusted loss = 0.548  adv prob = 0.250000   acc = 0.712
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.820  exp loss = 1.940  adjusted loss = 1.940  adv prob = 0.250000   acc = 0.293
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.201  exp loss = 0.204  adjusted loss = 0.204  adv prob = 0.250000   acc = 0.947
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_test_epoch_212.csv
logged to wandb
Current lr: 0.000010


Epoch [213]:
Training:
Average incurred loss: 0.024  
Average sample loss: 0.024  
Average acc: 0.999  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2347]:	loss = 0.012  exp loss = 0.010  adjusted loss = 0.010  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 125]:	loss = 0.101  exp loss = 0.102  adjusted loss = 0.102  adv prob = 0.250000   acc = 0.992
  waterbird_complete95 = 1, forest2water2 = 0  [n = 31]:	loss = 0.173  exp loss = 0.134  adjusted loss = 0.134  adv prob = 0.250000   acc = 0.968
  waterbird_complete95 = 1, forest2water2 = 1  [n = 697]:	loss = 0.044  exp loss = 0.039  adjusted loss = 0.039  adv prob = 0.250000   acc = 1.000
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_train_epoch_213.csv
logged to wandb
Average incurred loss: 0.025  
Average sample loss: 0.025  
Average acc: 0.999  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 1151]:	loss = 0.010  exp loss = 0.011  adjusted loss = 0.011  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 59]:	loss = 0.121  exp loss = 0.104  adjusted loss = 0.104  adv prob = 0.250000   acc = 0.966
  waterbird_complete95 = 1, forest2water2 = 0  [n = 25]:	loss = 0.161  exp loss = 0.151  adjusted loss = 0.151  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 360]:	loss = 0.048  exp loss = 0.036  adjusted loss = 0.036  adv prob = 0.250000   acc = 1.000

Validation:
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_val_epoch_213.csv
logged to wandb
Average incurred loss: 0.467  
Average sample loss: 0.464  
Average acc: 0.792  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.026  exp loss = 0.023  adjusted loss = 0.023  adv prob = 0.250000   acc = 0.996
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.641  exp loss = 0.620  adjusted loss = 0.620  adv prob = 0.250000   acc = 0.672
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.700  exp loss = 1.800  adjusted loss = 1.800  adv prob = 0.250000   acc = 0.338
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.176  exp loss = 0.177  adjusted loss = 0.177  adv prob = 0.250000   acc = 0.955
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_test_epoch_213.csv
logged to wandb
Current lr: 0.000010


Epoch [214]:
Training:
Average incurred loss: 0.022  
Average sample loss: 0.022  
Average acc: 1.000  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2337]:	loss = 0.010  exp loss = 0.010  adjusted loss = 0.010  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 120]:	loss = 0.088  exp loss = 0.090  adjusted loss = 0.090  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 0  [n = 38]:	loss = 0.142  exp loss = 0.151  adjusted loss = 0.151  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 705]:	loss = 0.042  exp loss = 0.038  adjusted loss = 0.038  adv prob = 0.250000   acc = 1.000
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_train_epoch_214.csv
logged to wandb
Average incurred loss: 0.022  
Average sample loss: 0.022  
Average acc: 1.000  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 1161]:	loss = 0.010  exp loss = 0.011  adjusted loss = 0.011  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 64]:	loss = 0.084  exp loss = 0.100  adjusted loss = 0.100  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 0  [n = 18]:	loss = 0.181  exp loss = 0.184  adjusted loss = 0.184  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 352]:	loss = 0.042  exp loss = 0.036  adjusted loss = 0.036  adv prob = 0.250000   acc = 1.000

Validation:
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_val_epoch_214.csv
logged to wandb
Average incurred loss: 0.463  
Average sample loss: 0.460  
Average acc: 0.791  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.025  exp loss = 0.022  adjusted loss = 0.022  adv prob = 0.250000   acc = 0.996
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.619  exp loss = 0.597  adjusted loss = 0.597  adv prob = 0.250000   acc = 0.676
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.739  exp loss = 1.845  adjusted loss = 1.845  adv prob = 0.250000   acc = 0.316
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.183  exp loss = 0.184  adjusted loss = 0.184  adv prob = 0.250000   acc = 0.947
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_test_epoch_214.csv
logged to wandb
Current lr: 0.000010


Epoch [215]:
Training:
Average incurred loss: 0.023  
Average sample loss: 0.023  
Average acc: 1.000  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2344]:	loss = 0.011  exp loss = 0.011  adjusted loss = 0.011  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 123]:	loss = 0.116  exp loss = 0.108  adjusted loss = 0.108  adv prob = 0.250000   acc = 0.992
  waterbird_complete95 = 1, forest2water2 = 0  [n = 31]:	loss = 0.141  exp loss = 0.171  adjusted loss = 0.171  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 702]:	loss = 0.042  exp loss = 0.031  adjusted loss = 0.031  adv prob = 0.250000   acc = 1.000
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_train_epoch_215.csv
logged to wandb
Average incurred loss: 0.025  
Average sample loss: 0.025  
Average acc: 1.000  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 1154]:	loss = 0.011  exp loss = 0.011  adjusted loss = 0.011  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 61]:	loss = 0.091  exp loss = 0.088  adjusted loss = 0.088  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 0  [n = 25]:	loss = 0.217  exp loss = 0.181  adjusted loss = 0.181  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 355]:	loss = 0.047  exp loss = 0.037  adjusted loss = 0.037  adv prob = 0.250000   acc = 1.000

Validation:
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_val_epoch_215.csv
logged to wandb
Average incurred loss: 0.459  
Average sample loss: 0.455  
Average acc: 0.796  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.024  exp loss = 0.021  adjusted loss = 0.021  adv prob = 0.250000   acc = 0.996
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.605  exp loss = 0.584  adjusted loss = 0.584  adv prob = 0.250000   acc = 0.693
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.744  exp loss = 1.852  adjusted loss = 1.852  adv prob = 0.250000   acc = 0.308
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.187  exp loss = 0.189  adjusted loss = 0.189  adv prob = 0.250000   acc = 0.947
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_test_epoch_215.csv
logged to wandb
Current lr: 0.000010


Epoch [216]:
Training:
Average incurred loss: 0.023  
Average sample loss: 0.023  
Average acc: 1.000  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2341]:	loss = 0.011  exp loss = 0.010  adjusted loss = 0.010  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 130]:	loss = 0.108  exp loss = 0.099  adjusted loss = 0.099  adv prob = 0.250000   acc = 0.992
  waterbird_complete95 = 1, forest2water2 = 0  [n = 38]:	loss = 0.162  exp loss = 0.156  adjusted loss = 0.156  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 691]:	loss = 0.042  exp loss = 0.034  adjusted loss = 0.034  adv prob = 0.250000   acc = 1.000
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_train_epoch_216.csv
logged to wandb
Average incurred loss: 0.024  
Average sample loss: 0.024  
Average acc: 0.999  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 1157]:	loss = 0.011  exp loss = 0.010  adjusted loss = 0.010  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 54]:	loss = 0.083  exp loss = 0.088  adjusted loss = 0.088  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 0  [n = 18]:	loss = 0.190  exp loss = 0.184  adjusted loss = 0.184  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 366]:	loss = 0.047  exp loss = 0.046  adjusted loss = 0.046  adv prob = 0.250000   acc = 0.997

Validation:
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_val_epoch_216.csv
logged to wandb
Average incurred loss: 0.457  
Average sample loss: 0.454  
Average acc: 0.802  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.023  exp loss = 0.020  adjusted loss = 0.020  adv prob = 0.250000   acc = 0.996
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.583  exp loss = 0.562  adjusted loss = 0.562  adv prob = 0.250000   acc = 0.712
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.802  exp loss = 1.917  adjusted loss = 1.917  adv prob = 0.250000   acc = 0.293
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.196  exp loss = 0.199  adjusted loss = 0.199  adv prob = 0.250000   acc = 0.947
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_test_epoch_216.csv
logged to wandb
Current lr: 0.000010


Epoch [217]:
Training:
Average incurred loss: 0.021  
Average sample loss: 0.021  
Average acc: 1.000  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2341]:	loss = 0.010  exp loss = 0.009  adjusted loss = 0.009  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 118]:	loss = 0.090  exp loss = 0.062  adjusted loss = 0.062  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 0  [n = 34]:	loss = 0.145  exp loss = 0.186  adjusted loss = 0.186  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 707]:	loss = 0.040  exp loss = 0.041  adjusted loss = 0.041  adv prob = 0.250000   acc = 1.000
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_train_epoch_217.csv
logged to wandb
Average incurred loss: 0.022  
Average sample loss: 0.022  
Average acc: 0.999  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 1157]:	loss = 0.009  exp loss = 0.009  adjusted loss = 0.009  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 66]:	loss = 0.096  exp loss = 0.092  adjusted loss = 0.092  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 0  [n = 22]:	loss = 0.211  exp loss = 0.226  adjusted loss = 0.226  adv prob = 0.250000   acc = 0.955
  waterbird_complete95 = 1, forest2water2 = 1  [n = 350]:	loss = 0.040  exp loss = 0.040  adjusted loss = 0.040  adv prob = 0.250000   acc = 0.997

Validation:
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_val_epoch_217.csv
logged to wandb
Average incurred loss: 0.451  
Average sample loss: 0.447  
Average acc: 0.807  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.021  exp loss = 0.019  adjusted loss = 0.019  adv prob = 0.250000   acc = 0.998
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.549  exp loss = 0.527  adjusted loss = 0.527  adv prob = 0.250000   acc = 0.723
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.859  exp loss = 1.982  adjusted loss = 1.982  adv prob = 0.250000   acc = 0.293
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.209  exp loss = 0.211  adjusted loss = 0.211  adv prob = 0.250000   acc = 0.940
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_test_epoch_217.csv
logged to wandb
Current lr: 0.000010


Epoch [218]:
Training:
Average incurred loss: 0.022  
Average sample loss: 0.022  
Average acc: 1.000  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2341]:	loss = 0.011  exp loss = 0.012  adjusted loss = 0.012  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 132]:	loss = 0.097  exp loss = 0.103  adjusted loss = 0.103  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 0  [n = 37]:	loss = 0.164  exp loss = 0.161  adjusted loss = 0.161  adv prob = 0.250000   acc = 0.973
  waterbird_complete95 = 1, forest2water2 = 1  [n = 690]:	loss = 0.040  exp loss = 0.035  adjusted loss = 0.035  adv prob = 0.250000   acc = 1.000
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_train_epoch_218.csv
logged to wandb
Average incurred loss: 0.021  
Average sample loss: 0.021  
Average acc: 1.000  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 1157]:	loss = 0.009  exp loss = 0.009  adjusted loss = 0.009  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 52]:	loss = 0.088  exp loss = 0.093  adjusted loss = 0.093  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 0  [n = 19]:	loss = 0.175  exp loss = 0.159  adjusted loss = 0.159  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 367]:	loss = 0.040  exp loss = 0.037  adjusted loss = 0.037  adv prob = 0.250000   acc = 1.000

Validation:
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_val_epoch_218.csv
logged to wandb
Average incurred loss: 0.460  
Average sample loss: 0.456  
Average acc: 0.793  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.025  exp loss = 0.022  adjusted loss = 0.022  adv prob = 0.250000   acc = 0.996
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.616  exp loss = 0.593  adjusted loss = 0.593  adv prob = 0.250000   acc = 0.680
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.718  exp loss = 1.821  adjusted loss = 1.821  adv prob = 0.250000   acc = 0.323
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.182  exp loss = 0.182  adjusted loss = 0.182  adv prob = 0.250000   acc = 0.947
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_test_epoch_218.csv
logged to wandb
Current lr: 0.000010


Epoch [219]:
Training:
Average incurred loss: 0.021  
Average sample loss: 0.021  
Average acc: 1.000  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2338]:	loss = 0.010  exp loss = 0.009  adjusted loss = 0.009  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 122]:	loss = 0.089  exp loss = 0.086  adjusted loss = 0.086  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 0  [n = 36]:	loss = 0.164  exp loss = 0.151  adjusted loss = 0.151  adv prob = 0.250000   acc = 0.972
  waterbird_complete95 = 1, forest2water2 = 1  [n = 704]:	loss = 0.038  exp loss = 0.040  adjusted loss = 0.040  adv prob = 0.250000   acc = 1.000
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_train_epoch_219.csv
logged to wandb
Average incurred loss: 0.023  
Average sample loss: 0.023  
Average acc: 0.999  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 1160]:	loss = 0.010  exp loss = 0.009  adjusted loss = 0.009  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 62]:	loss = 0.117  exp loss = 0.105  adjusted loss = 0.105  adv prob = 0.250000   acc = 0.984
  waterbird_complete95 = 1, forest2water2 = 0  [n = 20]:	loss = 0.145  exp loss = 0.156  adjusted loss = 0.156  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 353]:	loss = 0.045  exp loss = 0.042  adjusted loss = 0.042  adv prob = 0.250000   acc = 1.000

Validation:
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_val_epoch_219.csv
logged to wandb
Average incurred loss: 0.455  
Average sample loss: 0.451  
Average acc: 0.804  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.022  exp loss = 0.020  adjusted loss = 0.020  adv prob = 0.250000   acc = 0.998
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.577  exp loss = 0.557  adjusted loss = 0.557  adv prob = 0.250000   acc = 0.712
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.800  exp loss = 1.915  adjusted loss = 1.915  adv prob = 0.250000   acc = 0.301
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.198  exp loss = 0.199  adjusted loss = 0.199  adv prob = 0.250000   acc = 0.947
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_test_epoch_219.csv
logged to wandb
Current lr: 0.000010


Epoch [220]:
Training:
Average incurred loss: 0.022  
Average sample loss: 0.022  
Average acc: 1.000  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2334]:	loss = 0.011  exp loss = 0.009  adjusted loss = 0.009  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 127]:	loss = 0.094  exp loss = 0.087  adjusted loss = 0.087  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 0  [n = 40]:	loss = 0.146  exp loss = 0.156  adjusted loss = 0.156  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 699]:	loss = 0.040  exp loss = 0.040  adjusted loss = 0.040  adv prob = 0.250000   acc = 1.000
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_train_epoch_220.csv
logged to wandb
Average incurred loss: 0.023  
Average sample loss: 0.023  
Average acc: 0.999  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 1164]:	loss = 0.010  exp loss = 0.010  adjusted loss = 0.010  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 57]:	loss = 0.096  exp loss = 0.109  adjusted loss = 0.109  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 0  [n = 16]:	loss = 0.125  exp loss = 0.124  adjusted loss = 0.124  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 358]:	loss = 0.048  exp loss = 0.045  adjusted loss = 0.045  adv prob = 0.250000   acc = 0.994

Validation:
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_val_epoch_220.csv
logged to wandb
Average incurred loss: 0.459  
Average sample loss: 0.455  
Average acc: 0.796  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.024  exp loss = 0.021  adjusted loss = 0.021  adv prob = 0.250000   acc = 0.996
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.605  exp loss = 0.584  adjusted loss = 0.584  adv prob = 0.250000   acc = 0.691
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.746  exp loss = 1.852  adjusted loss = 1.852  adv prob = 0.250000   acc = 0.308
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.185  exp loss = 0.186  adjusted loss = 0.186  adv prob = 0.250000   acc = 0.947
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_test_epoch_220.csv
logged to wandb
Current lr: 0.000010


Epoch [221]:
Training:
Average incurred loss: 0.025  
Average sample loss: 0.025  
Average acc: 1.000  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2337]:	loss = 0.011  exp loss = 0.010  adjusted loss = 0.010  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 121]:	loss = 0.108  exp loss = 0.107  adjusted loss = 0.107  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 0  [n = 42]:	loss = 0.172  exp loss = 0.168  adjusted loss = 0.168  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 700]:	loss = 0.049  exp loss = 0.037  adjusted loss = 0.037  adv prob = 0.250000   acc = 1.000
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_train_epoch_221.csv
logged to wandb
Average incurred loss: 0.018  
Average sample loss: 0.018  
Average acc: 1.000  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 1161]:	loss = 0.009  exp loss = 0.010  adjusted loss = 0.010  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 63]:	loss = 0.076  exp loss = 0.084  adjusted loss = 0.084  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 0  [n = 14]:	loss = 0.137  exp loss = 0.144  adjusted loss = 0.144  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 357]:	loss = 0.034  exp loss = 0.031  adjusted loss = 0.031  adv prob = 0.250000   acc = 1.000

Validation:
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_val_epoch_221.csv
logged to wandb
Average incurred loss: 0.455  
Average sample loss: 0.451  
Average acc: 0.802  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.022  exp loss = 0.020  adjusted loss = 0.020  adv prob = 0.250000   acc = 0.996
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.575  exp loss = 0.553  adjusted loss = 0.553  adv prob = 0.250000   acc = 0.712
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.809  exp loss = 1.923  adjusted loss = 1.923  adv prob = 0.250000   acc = 0.293
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.199  exp loss = 0.201  adjusted loss = 0.201  adv prob = 0.250000   acc = 0.947
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_test_epoch_221.csv
logged to wandb
Current lr: 0.000010


Epoch [222]:
Training:
Average incurred loss: 0.023  
Average sample loss: 0.023  
Average acc: 1.000  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2341]:	loss = 0.011  exp loss = 0.009  adjusted loss = 0.009  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 134]:	loss = 0.101  exp loss = 0.089  adjusted loss = 0.089  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 0  [n = 31]:	loss = 0.176  exp loss = 0.165  adjusted loss = 0.165  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 694]:	loss = 0.045  exp loss = 0.051  adjusted loss = 0.051  adv prob = 0.250000   acc = 1.000
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_train_epoch_222.csv
logged to wandb
Average incurred loss: 0.020  
Average sample loss: 0.020  
Average acc: 1.000  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 1157]:	loss = 0.009  exp loss = 0.009  adjusted loss = 0.009  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 50]:	loss = 0.080  exp loss = 0.080  adjusted loss = 0.080  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 0  [n = 25]:	loss = 0.166  exp loss = 0.179  adjusted loss = 0.179  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 363]:	loss = 0.037  exp loss = 0.034  adjusted loss = 0.034  adv prob = 0.250000   acc = 1.000

Validation:
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_val_epoch_222.csv
logged to wandb
Average incurred loss: 0.461  
Average sample loss: 0.457  
Average acc: 0.798  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.024  exp loss = 0.022  adjusted loss = 0.022  adv prob = 0.250000   acc = 0.996
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.615  exp loss = 0.592  adjusted loss = 0.592  adv prob = 0.250000   acc = 0.693
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.729  exp loss = 1.840  adjusted loss = 1.840  adv prob = 0.250000   acc = 0.323
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.183  exp loss = 0.184  adjusted loss = 0.184  adv prob = 0.250000   acc = 0.947
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_test_epoch_222.csv
logged to wandb
Current lr: 0.000010


Epoch [223]:
Training:
Average incurred loss: 0.023  
Average sample loss: 0.023  
Average acc: 1.000  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2331]:	loss = 0.010  exp loss = 0.010  adjusted loss = 0.010  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 117]:	loss = 0.086  exp loss = 0.097  adjusted loss = 0.097  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 0  [n = 40]:	loss = 0.177  exp loss = 0.193  adjusted loss = 0.193  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 712]:	loss = 0.043  exp loss = 0.037  adjusted loss = 0.037  adv prob = 0.250000   acc = 0.999
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_train_epoch_223.csv
logged to wandb
Average incurred loss: 0.023  
Average sample loss: 0.023  
Average acc: 0.999  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 1167]:	loss = 0.010  exp loss = 0.010  adjusted loss = 0.010  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 67]:	loss = 0.119  exp loss = 0.146  adjusted loss = 0.146  adv prob = 0.250000   acc = 0.985
  waterbird_complete95 = 1, forest2water2 = 0  [n = 16]:	loss = 0.139  exp loss = 0.151  adjusted loss = 0.151  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 345]:	loss = 0.042  exp loss = 0.037  adjusted loss = 0.037  adv prob = 0.250000   acc = 1.000

Validation:
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_val_epoch_223.csv
logged to wandb
Average incurred loss: 0.468  
Average sample loss: 0.465  
Average acc: 0.790  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.024  exp loss = 0.021  adjusted loss = 0.021  adv prob = 0.250000   acc = 0.996
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.631  exp loss = 0.607  adjusted loss = 0.607  adv prob = 0.250000   acc = 0.674
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.749  exp loss = 1.861  adjusted loss = 1.861  adv prob = 0.250000   acc = 0.316
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.181  exp loss = 0.182  adjusted loss = 0.182  adv prob = 0.250000   acc = 0.947
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_test_epoch_223.csv
logged to wandb
Current lr: 0.000010


Epoch [224]:
Training:
Average incurred loss: 0.022  
Average sample loss: 0.022  
Average acc: 0.999  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2325]:	loss = 0.010  exp loss = 0.011  adjusted loss = 0.011  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 113]:	loss = 0.082  exp loss = 0.082  adjusted loss = 0.082  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 0  [n = 34]:	loss = 0.201  exp loss = 0.153  adjusted loss = 0.153  adv prob = 0.250000   acc = 0.971
  waterbird_complete95 = 1, forest2water2 = 1  [n = 728]:	loss = 0.043  exp loss = 0.031  adjusted loss = 0.031  adv prob = 0.250000   acc = 0.999
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_train_epoch_224.csv
logged to wandb
Average incurred loss: 0.021  
Average sample loss: 0.021  
Average acc: 1.000  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 1173]:	loss = 0.010  exp loss = 0.009  adjusted loss = 0.009  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 71]:	loss = 0.098  exp loss = 0.124  adjusted loss = 0.124  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 0  [n = 22]:	loss = 0.121  exp loss = 0.123  adjusted loss = 0.123  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 329]:	loss = 0.035  exp loss = 0.031  adjusted loss = 0.031  adv prob = 0.250000   acc = 1.000

Validation:
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_val_epoch_224.csv
logged to wandb
Average incurred loss: 0.465  
Average sample loss: 0.461  
Average acc: 0.793  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.025  exp loss = 0.022  adjusted loss = 0.022  adv prob = 0.250000   acc = 0.996
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.629  exp loss = 0.608  adjusted loss = 0.608  adv prob = 0.250000   acc = 0.680
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.720  exp loss = 1.823  adjusted loss = 1.823  adv prob = 0.250000   acc = 0.323
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.179  exp loss = 0.179  adjusted loss = 0.179  adv prob = 0.250000   acc = 0.947
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_test_epoch_224.csv
logged to wandb
Current lr: 0.000010


Epoch [225]:
Training:
Average incurred loss: 0.022  
Average sample loss: 0.022  
Average acc: 1.000  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2323]:	loss = 0.010  exp loss = 0.009  adjusted loss = 0.009  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 114]:	loss = 0.105  exp loss = 0.144  adjusted loss = 0.144  adv prob = 0.250000   acc = 0.991
  waterbird_complete95 = 1, forest2water2 = 0  [n = 37]:	loss = 0.148  exp loss = 0.134  adjusted loss = 0.134  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 726]:	loss = 0.041  exp loss = 0.037  adjusted loss = 0.037  adv prob = 0.250000   acc = 1.000
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_train_epoch_225.csv
logged to wandb
Average incurred loss: 0.023  
Average sample loss: 0.023  
Average acc: 0.999  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 1175]:	loss = 0.011  exp loss = 0.009  adjusted loss = 0.009  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 70]:	loss = 0.123  exp loss = 0.146  adjusted loss = 0.146  adv prob = 0.250000   acc = 0.971
  waterbird_complete95 = 1, forest2water2 = 0  [n = 19]:	loss = 0.134  exp loss = 0.130  adjusted loss = 0.130  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 331]:	loss = 0.038  exp loss = 0.038  adjusted loss = 0.038  adv prob = 0.250000   acc = 1.000

Validation:
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_val_epoch_225.csv
logged to wandb
Average incurred loss: 0.456  
Average sample loss: 0.452  
Average acc: 0.800  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.022  exp loss = 0.020  adjusted loss = 0.020  adv prob = 0.250000   acc = 0.996
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.585  exp loss = 0.564  adjusted loss = 0.564  adv prob = 0.250000   acc = 0.704
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.791  exp loss = 1.904  adjusted loss = 1.904  adv prob = 0.250000   acc = 0.301
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.191  exp loss = 0.192  adjusted loss = 0.192  adv prob = 0.250000   acc = 0.947
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_test_epoch_225.csv
logged to wandb
Current lr: 0.000010


Epoch [226]:
Training:
Average incurred loss: 0.021  
Average sample loss: 0.021  
Average acc: 1.000  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2329]:	loss = 0.009  exp loss = 0.009  adjusted loss = 0.009  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 123]:	loss = 0.092  exp loss = 0.083  adjusted loss = 0.083  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 0  [n = 37]:	loss = 0.140  exp loss = 0.164  adjusted loss = 0.164  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 711]:	loss = 0.039  exp loss = 0.036  adjusted loss = 0.036  adv prob = 0.250000   acc = 1.000
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_train_epoch_226.csv
logged to wandb
Average incurred loss: 0.021  
Average sample loss: 0.021  
Average acc: 1.000  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 1169]:	loss = 0.010  exp loss = 0.011  adjusted loss = 0.011  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 61]:	loss = 0.086  exp loss = 0.086  adjusted loss = 0.086  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 0  [n = 19]:	loss = 0.145  exp loss = 0.141  adjusted loss = 0.141  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 346]:	loss = 0.039  exp loss = 0.030  adjusted loss = 0.030  adv prob = 0.250000   acc = 1.000

Validation:
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_val_epoch_226.csv
logged to wandb
Average incurred loss: 0.470  
Average sample loss: 0.467  
Average acc: 0.792  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.025  exp loss = 0.023  adjusted loss = 0.023  adv prob = 0.250000   acc = 0.996
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.648  exp loss = 0.625  adjusted loss = 0.625  adv prob = 0.250000   acc = 0.670
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.704  exp loss = 1.806  adjusted loss = 1.806  adv prob = 0.250000   acc = 0.353
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.174  exp loss = 0.174  adjusted loss = 0.174  adv prob = 0.250000   acc = 0.947
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_test_epoch_226.csv
logged to wandb
Current lr: 0.000010


Epoch [227]:
Training:
Average incurred loss: 0.023  
Average sample loss: 0.023  
Average acc: 1.000  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2361]:	loss = 0.012  exp loss = 0.016  adjusted loss = 0.016  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 113]:	loss = 0.090  exp loss = 0.091  adjusted loss = 0.091  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 0  [n = 37]:	loss = 0.144  exp loss = 0.126  adjusted loss = 0.126  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 689]:	loss = 0.044  exp loss = 0.033  adjusted loss = 0.033  adv prob = 0.250000   acc = 0.999
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_train_epoch_227.csv
logged to wandb
Average incurred loss: 0.021  
Average sample loss: 0.021  
Average acc: 0.999  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 1137]:	loss = 0.008  exp loss = 0.007  adjusted loss = 0.007  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 71]:	loss = 0.075  exp loss = 0.075  adjusted loss = 0.075  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 0  [n = 19]:	loss = 0.149  exp loss = 0.152  adjusted loss = 0.152  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 368]:	loss = 0.044  exp loss = 0.043  adjusted loss = 0.043  adv prob = 0.250000   acc = 0.997

Validation:
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_val_epoch_227.csv
logged to wandb
Average incurred loss: 0.443  
Average sample loss: 0.439  
Average acc: 0.813  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.020  exp loss = 0.017  adjusted loss = 0.017  adv prob = 0.250000   acc = 0.998
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.523  exp loss = 0.504  adjusted loss = 0.504  adv prob = 0.250000   acc = 0.742
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.875  exp loss = 2.000  adjusted loss = 2.000  adv prob = 0.250000   acc = 0.286
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.217  exp loss = 0.220  adjusted loss = 0.220  adv prob = 0.250000   acc = 0.940
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_test_epoch_227.csv
logged to wandb
Current lr: 0.000010


Epoch [228]:
Training:
Average incurred loss: 0.021  
Average sample loss: 0.021  
Average acc: 1.000  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2313]:	loss = 0.009  exp loss = 0.010  adjusted loss = 0.010  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 130]:	loss = 0.095  exp loss = 0.155  adjusted loss = 0.155  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 0  [n = 39]:	loss = 0.141  exp loss = 0.124  adjusted loss = 0.124  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 718]:	loss = 0.040  exp loss = 0.036  adjusted loss = 0.036  adv prob = 0.250000   acc = 1.000
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_train_epoch_228.csv
logged to wandb
Average incurred loss: 0.020  
Average sample loss: 0.020  
Average acc: 1.000  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 1185]:	loss = 0.010  exp loss = 0.010  adjusted loss = 0.010  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 54]:	loss = 0.092  exp loss = 0.105  adjusted loss = 0.105  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 0  [n = 17]:	loss = 0.172  exp loss = 0.132  adjusted loss = 0.132  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 339]:	loss = 0.034  exp loss = 0.032  adjusted loss = 0.032  adv prob = 0.250000   acc = 1.000

Validation:
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_val_epoch_228.csv
logged to wandb
Average incurred loss: 0.473  
Average sample loss: 0.469  
Average acc: 0.791  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.026  exp loss = 0.023  adjusted loss = 0.023  adv prob = 0.250000   acc = 0.996
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.660  exp loss = 0.636  adjusted loss = 0.636  adv prob = 0.250000   acc = 0.663
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.688  exp loss = 1.789  adjusted loss = 1.789  adv prob = 0.250000   acc = 0.361
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.170  exp loss = 0.170  adjusted loss = 0.170  adv prob = 0.250000   acc = 0.947
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_test_epoch_228.csv
logged to wandb
Current lr: 0.000010


Epoch [229]:
Training:
Average incurred loss: 0.020  
Average sample loss: 0.020  
Average acc: 1.000  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2358]:	loss = 0.010  exp loss = 0.009  adjusted loss = 0.009  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 114]:	loss = 0.099  exp loss = 0.092  adjusted loss = 0.092  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 0  [n = 37]:	loss = 0.129  exp loss = 0.119  adjusted loss = 0.119  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 691]:	loss = 0.037  exp loss = 0.035  adjusted loss = 0.035  adv prob = 0.250000   acc = 1.000
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_train_epoch_229.csv
logged to wandb
Average incurred loss: 0.021  
Average sample loss: 0.021  
Average acc: 1.000  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 1140]:	loss = 0.009  exp loss = 0.008  adjusted loss = 0.008  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 70]:	loss = 0.072  exp loss = 0.080  adjusted loss = 0.080  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 0  [n = 19]:	loss = 0.136  exp loss = 0.137  adjusted loss = 0.137  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 366]:	loss = 0.045  exp loss = 0.038  adjusted loss = 0.038  adv prob = 0.250000   acc = 1.000

Validation:
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_val_epoch_229.csv
logged to wandb
Average incurred loss: 0.449  
Average sample loss: 0.445  
Average acc: 0.811  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.023  exp loss = 0.020  adjusted loss = 0.020  adv prob = 0.250000   acc = 0.996
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.575  exp loss = 0.555  adjusted loss = 0.555  adv prob = 0.250000   acc = 0.727
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.760  exp loss = 1.870  adjusted loss = 1.870  adv prob = 0.250000   acc = 0.316
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.191  exp loss = 0.191  adjusted loss = 0.191  adv prob = 0.250000   acc = 0.947
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_test_epoch_229.csv
logged to wandb
Current lr: 0.000010


Epoch [230]:
Training:
Average incurred loss: 0.020  
Average sample loss: 0.020  
Average acc: 1.000  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2349]:	loss = 0.010  exp loss = 0.011  adjusted loss = 0.011  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 115]:	loss = 0.086  exp loss = 0.100  adjusted loss = 0.100  adv prob = 0.250000   acc = 0.991
  waterbird_complete95 = 1, forest2water2 = 0  [n = 38]:	loss = 0.146  exp loss = 0.110  adjusted loss = 0.110  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 698]:	loss = 0.037  exp loss = 0.032  adjusted loss = 0.032  adv prob = 0.250000   acc = 1.000
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_train_epoch_230.csv
logged to wandb
Average incurred loss: 0.021  
Average sample loss: 0.021  
Average acc: 1.000  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 1149]:	loss = 0.009  exp loss = 0.009  adjusted loss = 0.009  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 69]:	loss = 0.085  exp loss = 0.091  adjusted loss = 0.091  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 0  [n = 18]:	loss = 0.144  exp loss = 0.122  adjusted loss = 0.122  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 359]:	loss = 0.041  exp loss = 0.035  adjusted loss = 0.035  adv prob = 0.250000   acc = 1.000

Validation:
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_val_epoch_230.csv
logged to wandb
Average incurred loss: 0.462  
Average sample loss: 0.458  
Average acc: 0.801  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.023  exp loss = 0.021  adjusted loss = 0.021  adv prob = 0.250000   acc = 0.996
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.611  exp loss = 0.589  adjusted loss = 0.589  adv prob = 0.250000   acc = 0.697
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.756  exp loss = 1.868  adjusted loss = 1.868  adv prob = 0.250000   acc = 0.331
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.182  exp loss = 0.182  adjusted loss = 0.182  adv prob = 0.250000   acc = 0.947
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_test_epoch_230.csv
logged to wandb
Current lr: 0.000010


Epoch [231]:
Training:
Average incurred loss: 0.021  
Average sample loss: 0.021  
Average acc: 1.000  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2339]:	loss = 0.010  exp loss = 0.011  adjusted loss = 0.011  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 126]:	loss = 0.089  exp loss = 0.119  adjusted loss = 0.119  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 0  [n = 40]:	loss = 0.136  exp loss = 0.129  adjusted loss = 0.129  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 695]:	loss = 0.040  exp loss = 0.031  adjusted loss = 0.031  adv prob = 0.250000   acc = 1.000
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_train_epoch_231.csv
logged to wandb
Average incurred loss: 0.021  
Average sample loss: 0.021  
Average acc: 1.000  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 1159]:	loss = 0.009  exp loss = 0.008  adjusted loss = 0.008  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 58]:	loss = 0.109  exp loss = 0.099  adjusted loss = 0.099  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 0  [n = 16]:	loss = 0.160  exp loss = 0.127  adjusted loss = 0.127  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 362]:	loss = 0.038  exp loss = 0.038  adjusted loss = 0.038  adv prob = 0.250000   acc = 1.000

Validation:
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_val_epoch_231.csv
logged to wandb
Average incurred loss: 0.453  
Average sample loss: 0.449  
Average acc: 0.809  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.021  exp loss = 0.018  adjusted loss = 0.018  adv prob = 0.250000   acc = 0.996
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.564  exp loss = 0.544  adjusted loss = 0.544  adv prob = 0.250000   acc = 0.730
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.834  exp loss = 1.952  adjusted loss = 1.952  adv prob = 0.250000   acc = 0.301
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.200  exp loss = 0.202  adjusted loss = 0.202  adv prob = 0.250000   acc = 0.940
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_test_epoch_231.csv
logged to wandb
Current lr: 0.000010


Epoch [232]:
Training:
Average incurred loss: 0.022  
Average sample loss: 0.022  
Average acc: 1.000  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2326]:	loss = 0.010  exp loss = 0.009  adjusted loss = 0.009  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 130]:	loss = 0.094  exp loss = 0.076  adjusted loss = 0.076  adv prob = 0.250000   acc = 0.992
  waterbird_complete95 = 1, forest2water2 = 0  [n = 38]:	loss = 0.143  exp loss = 0.139  adjusted loss = 0.139  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 706]:	loss = 0.042  exp loss = 0.037  adjusted loss = 0.037  adv prob = 0.250000   acc = 1.000
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_train_epoch_232.csv
logged to wandb
Average incurred loss: 0.019  
Average sample loss: 0.019  
Average acc: 1.000  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 1172]:	loss = 0.010  exp loss = 0.010  adjusted loss = 0.010  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 54]:	loss = 0.080  exp loss = 0.086  adjusted loss = 0.086  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 0  [n = 18]:	loss = 0.126  exp loss = 0.119  adjusted loss = 0.119  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 351]:	loss = 0.034  exp loss = 0.034  adjusted loss = 0.034  adv prob = 0.250000   acc = 1.000

Validation:
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_val_epoch_232.csv
logged to wandb
Average incurred loss: 0.470  
Average sample loss: 0.466  
Average acc: 0.793  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.025  exp loss = 0.022  adjusted loss = 0.022  adv prob = 0.250000   acc = 0.996
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.651  exp loss = 0.629  adjusted loss = 0.629  adv prob = 0.250000   acc = 0.667
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.698  exp loss = 1.798  adjusted loss = 1.798  adv prob = 0.250000   acc = 0.361
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.169  exp loss = 0.168  adjusted loss = 0.168  adv prob = 0.250000   acc = 0.955
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_test_epoch_232.csv
logged to wandb
Current lr: 0.000010


Epoch [233]:
Training:
Average incurred loss: 0.021  
Average sample loss: 0.021  
Average acc: 1.000  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2332]:	loss = 0.009  exp loss = 0.009  adjusted loss = 0.009  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 126]:	loss = 0.098  exp loss = 0.110  adjusted loss = 0.110  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 0  [n = 35]:	loss = 0.158  exp loss = 0.153  adjusted loss = 0.153  adv prob = 0.250000   acc = 0.971
  waterbird_complete95 = 1, forest2water2 = 1  [n = 707]:	loss = 0.039  exp loss = 0.032  adjusted loss = 0.032  adv prob = 0.250000   acc = 1.000
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_train_epoch_233.csv
logged to wandb
Average incurred loss: 0.019  
Average sample loss: 0.019  
Average acc: 1.000  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 1166]:	loss = 0.009  exp loss = 0.009  adjusted loss = 0.009  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 58]:	loss = 0.064  exp loss = 0.078  adjusted loss = 0.078  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 0  [n = 21]:	loss = 0.145  exp loss = 0.163  adjusted loss = 0.163  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 350]:	loss = 0.036  exp loss = 0.034  adjusted loss = 0.034  adv prob = 0.250000   acc = 1.000

Validation:
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_val_epoch_233.csv
logged to wandb
Average incurred loss: 0.466  
Average sample loss: 0.462  
Average acc: 0.796  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.022  exp loss = 0.020  adjusted loss = 0.020  adv prob = 0.250000   acc = 0.996
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.604  exp loss = 0.582  adjusted loss = 0.582  adv prob = 0.250000   acc = 0.695
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.815  exp loss = 1.933  adjusted loss = 1.933  adv prob = 0.250000   acc = 0.301
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.191  exp loss = 0.192  adjusted loss = 0.192  adv prob = 0.250000   acc = 0.947
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_test_epoch_233.csv
logged to wandb
Current lr: 0.000010


Epoch [234]:
Training:
Average incurred loss: 0.021  
Average sample loss: 0.021  
Average acc: 1.000  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2333]:	loss = 0.010  exp loss = 0.009  adjusted loss = 0.009  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 126]:	loss = 0.082  exp loss = 0.085  adjusted loss = 0.085  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 0  [n = 34]:	loss = 0.170  exp loss = 0.142  adjusted loss = 0.142  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 707]:	loss = 0.039  exp loss = 0.030  adjusted loss = 0.030  adv prob = 0.250000   acc = 1.000
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_train_epoch_234.csv
logged to wandb
Average incurred loss: 0.021  
Average sample loss: 0.021  
Average acc: 0.999  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 1165]:	loss = 0.010  exp loss = 0.009  adjusted loss = 0.009  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 58]:	loss = 0.095  exp loss = 0.102  adjusted loss = 0.102  adv prob = 0.250000   acc = 0.983
  waterbird_complete95 = 1, forest2water2 = 0  [n = 22]:	loss = 0.123  exp loss = 0.121  adjusted loss = 0.121  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 350]:	loss = 0.039  exp loss = 0.037  adjusted loss = 0.037  adv prob = 0.250000   acc = 1.000

Validation:
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_val_epoch_234.csv
logged to wandb
Average incurred loss: 0.458  
Average sample loss: 0.454  
Average acc: 0.802  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.022  exp loss = 0.020  adjusted loss = 0.020  adv prob = 0.250000   acc = 0.996
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.589  exp loss = 0.568  adjusted loss = 0.568  adv prob = 0.250000   acc = 0.708
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.796  exp loss = 1.909  adjusted loss = 1.909  adv prob = 0.250000   acc = 0.301
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.189  exp loss = 0.192  adjusted loss = 0.192  adv prob = 0.250000   acc = 0.947
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_test_epoch_234.csv
logged to wandb
Current lr: 0.000010


Epoch [235]:
Training:
Average incurred loss: 0.021  
Average sample loss: 0.021  
Average acc: 1.000  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2337]:	loss = 0.009  exp loss = 0.009  adjusted loss = 0.009  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 126]:	loss = 0.100  exp loss = 0.089  adjusted loss = 0.089  adv prob = 0.250000   acc = 0.992
  waterbird_complete95 = 1, forest2water2 = 0  [n = 31]:	loss = 0.184  exp loss = 0.181  adjusted loss = 0.181  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 706]:	loss = 0.038  exp loss = 0.033  adjusted loss = 0.033  adv prob = 0.250000   acc = 1.000
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_train_epoch_235.csv
logged to wandb
Average incurred loss: 0.020  
Average sample loss: 0.020  
Average acc: 1.000  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 1161]:	loss = 0.010  exp loss = 0.009  adjusted loss = 0.009  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 58]:	loss = 0.078  exp loss = 0.093  adjusted loss = 0.093  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 0  [n = 25]:	loss = 0.112  exp loss = 0.125  adjusted loss = 0.125  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 351]:	loss = 0.038  exp loss = 0.034  adjusted loss = 0.034  adv prob = 0.250000   acc = 1.000

Validation:
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_val_epoch_235.csv
logged to wandb
Average incurred loss: 0.461  
Average sample loss: 0.458  
Average acc: 0.799  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.023  exp loss = 0.021  adjusted loss = 0.021  adv prob = 0.250000   acc = 0.996
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.614  exp loss = 0.592  adjusted loss = 0.592  adv prob = 0.250000   acc = 0.689
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.745  exp loss = 1.853  adjusted loss = 1.853  adv prob = 0.250000   acc = 0.346
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.181  exp loss = 0.180  adjusted loss = 0.180  adv prob = 0.250000   acc = 0.947
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_test_epoch_235.csv
logged to wandb
Current lr: 0.000010


Epoch [236]:
Training:
Average incurred loss: 0.023  
Average sample loss: 0.023  
Average acc: 0.999  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2337]:	loss = 0.010  exp loss = 0.010  adjusted loss = 0.010  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 127]:	loss = 0.113  exp loss = 0.124  adjusted loss = 0.124  adv prob = 0.250000   acc = 0.984
  waterbird_complete95 = 1, forest2water2 = 0  [n = 37]:	loss = 0.135  exp loss = 0.130  adjusted loss = 0.130  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 699]:	loss = 0.042  exp loss = 0.037  adjusted loss = 0.037  adv prob = 0.250000   acc = 1.000
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_train_epoch_236.csv
logged to wandb
Average incurred loss: 0.022  
Average sample loss: 0.022  
Average acc: 0.999  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 1161]:	loss = 0.009  exp loss = 0.010  adjusted loss = 0.010  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 57]:	loss = 0.083  exp loss = 0.102  adjusted loss = 0.102  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 0  [n = 19]:	loss = 0.168  exp loss = 0.141  adjusted loss = 0.141  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 358]:	loss = 0.046  exp loss = 0.032  adjusted loss = 0.032  adv prob = 0.250000   acc = 0.994

Validation:
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_val_epoch_236.csv
logged to wandb
Average incurred loss: 0.460  
Average sample loss: 0.457  
Average acc: 0.800  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.024  exp loss = 0.021  adjusted loss = 0.021  adv prob = 0.250000   acc = 0.996
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.620  exp loss = 0.599  adjusted loss = 0.599  adv prob = 0.250000   acc = 0.687
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.719  exp loss = 1.830  adjusted loss = 1.830  adv prob = 0.250000   acc = 0.353
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.176  exp loss = 0.176  adjusted loss = 0.176  adv prob = 0.250000   acc = 0.955
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_test_epoch_236.csv
logged to wandb
Current lr: 0.000010


Epoch [237]:
Training:
Average incurred loss: 0.019  
Average sample loss: 0.019  
Average acc: 1.000  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2353]:	loss = 0.010  exp loss = 0.010  adjusted loss = 0.010  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 128]:	loss = 0.092  exp loss = 0.080  adjusted loss = 0.080  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 0  [n = 35]:	loss = 0.124  exp loss = 0.126  adjusted loss = 0.126  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 684]:	loss = 0.034  exp loss = 0.027  adjusted loss = 0.027  adv prob = 0.250000   acc = 1.000
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_train_epoch_237.csv
logged to wandb
Average incurred loss: 0.024  
Average sample loss: 0.024  
Average acc: 0.999  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 1145]:	loss = 0.009  exp loss = 0.009  adjusted loss = 0.009  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 56]:	loss = 0.085  exp loss = 0.065  adjusted loss = 0.065  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 0  [n = 21]:	loss = 0.148  exp loss = 0.158  adjusted loss = 0.158  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 373]:	loss = 0.055  exp loss = 0.042  adjusted loss = 0.042  adv prob = 0.250000   acc = 0.995

Validation:
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_val_epoch_237.csv
logged to wandb
Average incurred loss: 0.456  
Average sample loss: 0.453  
Average acc: 0.806  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.021  exp loss = 0.019  adjusted loss = 0.019  adv prob = 0.250000   acc = 0.996
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.578  exp loss = 0.557  adjusted loss = 0.557  adv prob = 0.250000   acc = 0.719
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.818  exp loss = 1.943  adjusted loss = 1.943  adv prob = 0.250000   acc = 0.301
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.196  exp loss = 0.197  adjusted loss = 0.197  adv prob = 0.250000   acc = 0.947
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_test_epoch_237.csv
logged to wandb
Current lr: 0.000010


Epoch [238]:
Training:
Average incurred loss: 0.020  
Average sample loss: 0.020  
Average acc: 1.000  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2332]:	loss = 0.009  exp loss = 0.008  adjusted loss = 0.008  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 122]:	loss = 0.091  exp loss = 0.066  adjusted loss = 0.066  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 0  [n = 42]:	loss = 0.120  exp loss = 0.106  adjusted loss = 0.106  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 704]:	loss = 0.037  exp loss = 0.036  adjusted loss = 0.036  adv prob = 0.250000   acc = 1.000
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_train_epoch_238.csv
logged to wandb
Average incurred loss: 0.020  
Average sample loss: 0.020  
Average acc: 1.000  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 1166]:	loss = 0.009  exp loss = 0.010  adjusted loss = 0.010  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 62]:	loss = 0.082  exp loss = 0.077  adjusted loss = 0.077  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 0  [n = 14]:	loss = 0.118  exp loss = 0.113  adjusted loss = 0.113  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 353]:	loss = 0.038  exp loss = 0.031  adjusted loss = 0.031  adv prob = 0.250000   acc = 1.000

Validation:
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_val_epoch_238.csv
logged to wandb
Average incurred loss: 0.465  
Average sample loss: 0.462  
Average acc: 0.796  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.025  exp loss = 0.022  adjusted loss = 0.022  adv prob = 0.250000   acc = 0.996
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.641  exp loss = 0.618  adjusted loss = 0.618  adv prob = 0.250000   acc = 0.674
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.691  exp loss = 1.795  adjusted loss = 1.795  adv prob = 0.250000   acc = 0.361
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.171  exp loss = 0.170  adjusted loss = 0.170  adv prob = 0.250000   acc = 0.955
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_test_epoch_238.csv
logged to wandb
Current lr: 0.000010


Epoch [239]:
Training:
Average incurred loss: 0.019  
Average sample loss: 0.019  
Average acc: 1.000  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2348]:	loss = 0.009  exp loss = 0.009  adjusted loss = 0.009  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 107]:	loss = 0.100  exp loss = 0.097  adjusted loss = 0.097  adv prob = 0.250000   acc = 0.991
  waterbird_complete95 = 1, forest2water2 = 0  [n = 37]:	loss = 0.140  exp loss = 0.118  adjusted loss = 0.118  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 708]:	loss = 0.036  exp loss = 0.034  adjusted loss = 0.034  adv prob = 0.250000   acc = 1.000
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_train_epoch_239.csv
logged to wandb
Average incurred loss: 0.021  
Average sample loss: 0.021  
Average acc: 0.999  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 1150]:	loss = 0.009  exp loss = 0.009  adjusted loss = 0.009  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 77]:	loss = 0.081  exp loss = 0.103  adjusted loss = 0.103  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 0  [n = 19]:	loss = 0.136  exp loss = 0.125  adjusted loss = 0.125  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 349]:	loss = 0.040  exp loss = 0.032  adjusted loss = 0.032  adv prob = 0.250000   acc = 0.997

Validation:
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_val_epoch_239.csv
logged to wandb
Average incurred loss: 0.465  
Average sample loss: 0.462  
Average acc: 0.795  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.023  exp loss = 0.021  adjusted loss = 0.021  adv prob = 0.250000   acc = 0.996
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.625  exp loss = 0.604  adjusted loss = 0.604  adv prob = 0.250000   acc = 0.678
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.744  exp loss = 1.854  adjusted loss = 1.854  adv prob = 0.250000   acc = 0.338
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.180  exp loss = 0.180  adjusted loss = 0.180  adv prob = 0.250000   acc = 0.955
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_test_epoch_239.csv
logged to wandb
Current lr: 0.000010


Epoch [240]:
Training:
Average incurred loss: 0.020  
Average sample loss: 0.020  
Average acc: 1.000  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2365]:	loss = 0.010  exp loss = 0.010  adjusted loss = 0.010  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 118]:	loss = 0.100  exp loss = 0.115  adjusted loss = 0.115  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 0  [n = 38]:	loss = 0.117  exp loss = 0.112  adjusted loss = 0.112  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 679]:	loss = 0.035  exp loss = 0.026  adjusted loss = 0.026  adv prob = 0.250000   acc = 1.000
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_train_epoch_240.csv
logged to wandb
Average incurred loss: 0.023  
Average sample loss: 0.023  
Average acc: 1.000  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 1133]:	loss = 0.009  exp loss = 0.008  adjusted loss = 0.008  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 66]:	loss = 0.092  exp loss = 0.094  adjusted loss = 0.094  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 0  [n = 18]:	loss = 0.159  exp loss = 0.147  adjusted loss = 0.147  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 378]:	loss = 0.049  exp loss = 0.047  adjusted loss = 0.047  adv prob = 0.250000   acc = 1.000

Validation:
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_val_epoch_240.csv
logged to wandb
Average incurred loss: 0.444  
Average sample loss: 0.440  
Average acc: 0.821  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.018  exp loss = 0.016  adjusted loss = 0.016  adv prob = 0.250000   acc = 0.998
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.505  exp loss = 0.486  adjusted loss = 0.486  adv prob = 0.250000   acc = 0.764
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.945  exp loss = 2.076  adjusted loss = 2.076  adv prob = 0.250000   acc = 0.286
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.225  exp loss = 0.228  adjusted loss = 0.228  adv prob = 0.250000   acc = 0.932
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_test_epoch_240.csv
logged to wandb
Current lr: 0.000010


Epoch [241]:
Training:
Average incurred loss: 0.022  
Average sample loss: 0.022  
Average acc: 1.000  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2339]:	loss = 0.010  exp loss = 0.008  adjusted loss = 0.008  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 120]:	loss = 0.098  exp loss = 0.099  adjusted loss = 0.099  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 0  [n = 35]:	loss = 0.146  exp loss = 0.179  adjusted loss = 0.179  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 706]:	loss = 0.042  exp loss = 0.046  adjusted loss = 0.046  adv prob = 0.250000   acc = 1.000
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_train_epoch_241.csv
logged to wandb
Average incurred loss: 0.020  
Average sample loss: 0.020  
Average acc: 1.000  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 1159]:	loss = 0.010  exp loss = 0.009  adjusted loss = 0.009  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 64]:	loss = 0.078  exp loss = 0.084  adjusted loss = 0.084  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 0  [n = 21]:	loss = 0.117  exp loss = 0.108  adjusted loss = 0.108  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 351]:	loss = 0.039  exp loss = 0.037  adjusted loss = 0.037  adv prob = 0.250000   acc = 1.000

Validation:
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_val_epoch_241.csv
logged to wandb
Average incurred loss: 0.462  
Average sample loss: 0.458  
Average acc: 0.801  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.022  exp loss = 0.020  adjusted loss = 0.020  adv prob = 0.250000   acc = 0.996
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.604  exp loss = 0.580  adjusted loss = 0.580  adv prob = 0.250000   acc = 0.704
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.787  exp loss = 1.904  adjusted loss = 1.904  adv prob = 0.250000   acc = 0.308
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.182  exp loss = 0.182  adjusted loss = 0.182  adv prob = 0.250000   acc = 0.947
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_test_epoch_241.csv
logged to wandb
Current lr: 0.000010


Epoch [242]:
Training:
Average incurred loss: 0.020  
Average sample loss: 0.020  
Average acc: 1.000  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2335]:	loss = 0.009  exp loss = 0.010  adjusted loss = 0.010  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 127]:	loss = 0.088  exp loss = 0.098  adjusted loss = 0.098  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 0  [n = 35]:	loss = 0.150  exp loss = 0.149  adjusted loss = 0.149  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 703]:	loss = 0.037  exp loss = 0.031  adjusted loss = 0.031  adv prob = 0.250000   acc = 1.000
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_train_epoch_242.csv
logged to wandb
Average incurred loss: 0.020  
Average sample loss: 0.020  
Average acc: 1.000  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 1163]:	loss = 0.009  exp loss = 0.009  adjusted loss = 0.009  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 57]:	loss = 0.089  exp loss = 0.084  adjusted loss = 0.084  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 0  [n = 21]:	loss = 0.094  exp loss = 0.106  adjusted loss = 0.106  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 354]:	loss = 0.041  exp loss = 0.038  adjusted loss = 0.038  adv prob = 0.250000   acc = 1.000

Validation:
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_val_epoch_242.csv
logged to wandb
Average incurred loss: 0.456  
Average sample loss: 0.452  
Average acc: 0.804  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.021  exp loss = 0.019  adjusted loss = 0.019  adv prob = 0.250000   acc = 0.996
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.586  exp loss = 0.564  adjusted loss = 0.564  adv prob = 0.250000   acc = 0.712
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.793  exp loss = 1.904  adjusted loss = 1.904  adv prob = 0.250000   acc = 0.308
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.190  exp loss = 0.191  adjusted loss = 0.191  adv prob = 0.250000   acc = 0.947
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_test_epoch_242.csv
logged to wandb
Current lr: 0.000010


Epoch [243]:
Training:
Average incurred loss: 0.019  
Average sample loss: 0.019  
Average acc: 1.000  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2347]:	loss = 0.009  exp loss = 0.008  adjusted loss = 0.008  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 133]:	loss = 0.085  exp loss = 0.068  adjusted loss = 0.068  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 0  [n = 38]:	loss = 0.130  exp loss = 0.141  adjusted loss = 0.141  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 682]:	loss = 0.034  exp loss = 0.037  adjusted loss = 0.037  adv prob = 0.250000   acc = 1.000
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_train_epoch_243.csv
logged to wandb
Average incurred loss: 0.017  
Average sample loss: 0.018  
Average acc: 1.000  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 1151]:	loss = 0.007  exp loss = 0.008  adjusted loss = 0.008  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 51]:	loss = 0.068  exp loss = 0.066  adjusted loss = 0.066  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 0  [n = 18]:	loss = 0.147  exp loss = 0.158  adjusted loss = 0.158  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 375]:	loss = 0.035  exp loss = 0.035  adjusted loss = 0.035  adv prob = 0.250000   acc = 1.000

Validation:
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_val_epoch_243.csv
logged to wandb
Average incurred loss: 0.461  
Average sample loss: 0.457  
Average acc: 0.796  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.022  exp loss = 0.020  adjusted loss = 0.020  adv prob = 0.250000   acc = 0.996
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.603  exp loss = 0.581  adjusted loss = 0.581  adv prob = 0.250000   acc = 0.693
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.779  exp loss = 1.886  adjusted loss = 1.886  adv prob = 0.250000   acc = 0.308
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.184  exp loss = 0.183  adjusted loss = 0.183  adv prob = 0.250000   acc = 0.947
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_test_epoch_243.csv
logged to wandb
Current lr: 0.000010


Epoch [244]:
Training:
Average incurred loss: 0.019  
Average sample loss: 0.019  
Average acc: 1.000  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2338]:	loss = 0.009  exp loss = 0.009  adjusted loss = 0.009  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 113]:	loss = 0.090  exp loss = 0.078  adjusted loss = 0.078  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 0  [n = 40]:	loss = 0.135  exp loss = 0.126  adjusted loss = 0.126  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 709]:	loss = 0.034  exp loss = 0.034  adjusted loss = 0.034  adv prob = 0.250000   acc = 1.000
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_train_epoch_244.csv
logged to wandb
Average incurred loss: 0.021  
Average sample loss: 0.021  
Average acc: 1.000  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 1160]:	loss = 0.009  exp loss = 0.009  adjusted loss = 0.009  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 71]:	loss = 0.089  exp loss = 0.083  adjusted loss = 0.083  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 0  [n = 16]:	loss = 0.167  exp loss = 0.162  adjusted loss = 0.162  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 348]:	loss = 0.038  exp loss = 0.039  adjusted loss = 0.039  adv prob = 0.250000   acc = 1.000

Validation:
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_val_epoch_244.csv
logged to wandb
Average incurred loss: 0.461  
Average sample loss: 0.457  
Average acc: 0.799  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.022  exp loss = 0.019  adjusted loss = 0.019  adv prob = 0.250000   acc = 0.996
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.600  exp loss = 0.579  adjusted loss = 0.579  adv prob = 0.250000   acc = 0.702
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.789  exp loss = 1.907  adjusted loss = 1.907  adv prob = 0.250000   acc = 0.301
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.183  exp loss = 0.183  adjusted loss = 0.183  adv prob = 0.250000   acc = 0.947
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_test_epoch_244.csv
logged to wandb
Current lr: 0.000010


Epoch [245]:
Training:
Average incurred loss: 0.021  
Average sample loss: 0.021  
Average acc: 1.000  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2325]:	loss = 0.010  exp loss = 0.009  adjusted loss = 0.009  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 124]:	loss = 0.095  exp loss = 0.109  adjusted loss = 0.109  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 0  [n = 36]:	loss = 0.120  exp loss = 0.119  adjusted loss = 0.119  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 715]:	loss = 0.040  exp loss = 0.037  adjusted loss = 0.037  adv prob = 0.250000   acc = 1.000
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_train_epoch_245.csv
logged to wandb
Average incurred loss: 0.019  
Average sample loss: 0.019  
Average acc: 1.000  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 1173]:	loss = 0.009  exp loss = 0.008  adjusted loss = 0.008  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 60]:	loss = 0.088  exp loss = 0.081  adjusted loss = 0.081  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 0  [n = 20]:	loss = 0.128  exp loss = 0.146  adjusted loss = 0.146  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 342]:	loss = 0.033  exp loss = 0.032  adjusted loss = 0.032  adv prob = 0.250000   acc = 1.000

Validation:
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_val_epoch_245.csv
logged to wandb
Average incurred loss: 0.457  
Average sample loss: 0.454  
Average acc: 0.803  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.021  exp loss = 0.019  adjusted loss = 0.019  adv prob = 0.250000   acc = 0.996
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.586  exp loss = 0.565  adjusted loss = 0.565  adv prob = 0.250000   acc = 0.712
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.809  exp loss = 1.928  adjusted loss = 1.928  adv prob = 0.250000   acc = 0.301
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.188  exp loss = 0.188  adjusted loss = 0.188  adv prob = 0.250000   acc = 0.947
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_test_epoch_245.csv
logged to wandb
Current lr: 0.000010


Epoch [246]:
Training:
Average incurred loss: 0.020  
Average sample loss: 0.020  
Average acc: 1.000  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2351]:	loss = 0.010  exp loss = 0.008  adjusted loss = 0.008  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 121]:	loss = 0.095  exp loss = 0.080  adjusted loss = 0.080  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 0  [n = 40]:	loss = 0.125  exp loss = 0.140  adjusted loss = 0.140  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 688]:	loss = 0.036  exp loss = 0.040  adjusted loss = 0.040  adv prob = 0.250000   acc = 1.000
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_train_epoch_246.csv
logged to wandb
Average incurred loss: 0.018  
Average sample loss: 0.018  
Average acc: 1.000  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 1147]:	loss = 0.007  exp loss = 0.008  adjusted loss = 0.008  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 63]:	loss = 0.058  exp loss = 0.064  adjusted loss = 0.064  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 0  [n = 16]:	loss = 0.144  exp loss = 0.159  adjusted loss = 0.159  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 369]:	loss = 0.038  exp loss = 0.032  adjusted loss = 0.032  adv prob = 0.250000   acc = 1.000

Validation:
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_val_epoch_246.csv
logged to wandb
Average incurred loss: 0.456  
Average sample loss: 0.453  
Average acc: 0.803  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.022  exp loss = 0.020  adjusted loss = 0.020  adv prob = 0.250000   acc = 0.996
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.597  exp loss = 0.574  adjusted loss = 0.574  adv prob = 0.250000   acc = 0.706
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.762  exp loss = 1.876  adjusted loss = 1.876  adv prob = 0.250000   acc = 0.323
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.184  exp loss = 0.183  adjusted loss = 0.183  adv prob = 0.250000   acc = 0.947
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_test_epoch_246.csv
logged to wandb
Current lr: 0.000010


Epoch [247]:
Training:
Average incurred loss: 0.020  
Average sample loss: 0.020  
Average acc: 0.999  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2345]:	loss = 0.009  exp loss = 0.008  adjusted loss = 0.008  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 121]:	loss = 0.097  exp loss = 0.071  adjusted loss = 0.071  adv prob = 0.250000   acc = 0.992
  waterbird_complete95 = 1, forest2water2 = 0  [n = 35]:	loss = 0.113  exp loss = 0.105  adjusted loss = 0.105  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 699]:	loss = 0.036  exp loss = 0.031  adjusted loss = 0.031  adv prob = 0.250000   acc = 1.000
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_train_epoch_247.csv
logged to wandb
Average incurred loss: 0.020  
Average sample loss: 0.020  
Average acc: 1.000  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 1153]:	loss = 0.009  exp loss = 0.008  adjusted loss = 0.008  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 63]:	loss = 0.097  exp loss = 0.100  adjusted loss = 0.100  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 0  [n = 21]:	loss = 0.115  exp loss = 0.114  adjusted loss = 0.114  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 358]:	loss = 0.038  exp loss = 0.035  adjusted loss = 0.035  adv prob = 0.250000   acc = 1.000

Validation:
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_val_epoch_247.csv
logged to wandb
Average incurred loss: 0.457  
Average sample loss: 0.453  
Average acc: 0.805  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.021  exp loss = 0.018  adjusted loss = 0.018  adv prob = 0.250000   acc = 0.996
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.576  exp loss = 0.555  adjusted loss = 0.555  adv prob = 0.250000   acc = 0.717
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.836  exp loss = 1.963  adjusted loss = 1.963  adv prob = 0.250000   acc = 0.301
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.193  exp loss = 0.192  adjusted loss = 0.192  adv prob = 0.250000   acc = 0.947
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_test_epoch_247.csv
logged to wandb
Current lr: 0.000010


Epoch [248]:
Training:
Average incurred loss: 0.019  
Average sample loss: 0.019  
Average acc: 1.000  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2333]:	loss = 0.009  exp loss = 0.008  adjusted loss = 0.008  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 125]:	loss = 0.083  exp loss = 0.100  adjusted loss = 0.100  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 0  [n = 35]:	loss = 0.123  exp loss = 0.103  adjusted loss = 0.103  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 707]:	loss = 0.035  exp loss = 0.029  adjusted loss = 0.029  adv prob = 0.250000   acc = 1.000
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_train_epoch_248.csv
logged to wandb
Average incurred loss: 0.020  
Average sample loss: 0.020  
Average acc: 1.000  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 1165]:	loss = 0.009  exp loss = 0.010  adjusted loss = 0.010  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 59]:	loss = 0.077  exp loss = 0.083  adjusted loss = 0.083  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 0  [n = 21]:	loss = 0.135  exp loss = 0.118  adjusted loss = 0.118  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 350]:	loss = 0.039  exp loss = 0.029  adjusted loss = 0.029  adv prob = 0.250000   acc = 1.000

Validation:
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_val_epoch_248.csv
logged to wandb
Average incurred loss: 0.463  
Average sample loss: 0.460  
Average acc: 0.799  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.023  exp loss = 0.021  adjusted loss = 0.021  adv prob = 0.250000   acc = 0.996
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.623  exp loss = 0.602  adjusted loss = 0.602  adv prob = 0.250000   acc = 0.685
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.736  exp loss = 1.841  adjusted loss = 1.841  adv prob = 0.250000   acc = 0.353
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.175  exp loss = 0.174  adjusted loss = 0.174  adv prob = 0.250000   acc = 0.955
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_test_epoch_248.csv
logged to wandb
Current lr: 0.000010


Epoch [249]:
Training:
Average incurred loss: 0.020  
Average sample loss: 0.020  
Average acc: 1.000  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2330]:	loss = 0.009  exp loss = 0.009  adjusted loss = 0.009  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 130]:	loss = 0.082  exp loss = 0.085  adjusted loss = 0.085  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 0  [n = 39]:	loss = 0.132  exp loss = 0.152  adjusted loss = 0.152  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 701]:	loss = 0.037  exp loss = 0.029  adjusted loss = 0.029  adv prob = 0.250000   acc = 1.000
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_train_epoch_249.csv
logged to wandb
Average incurred loss: 0.020  
Average sample loss: 0.020  
Average acc: 1.000  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 1168]:	loss = 0.009  exp loss = 0.008  adjusted loss = 0.008  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 54]:	loss = 0.088  exp loss = 0.072  adjusted loss = 0.072  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 0  [n = 17]:	loss = 0.115  exp loss = 0.128  adjusted loss = 0.128  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 356]:	loss = 0.040  exp loss = 0.038  adjusted loss = 0.038  adv prob = 0.250000   acc = 1.000

Validation:
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_val_epoch_249.csv
logged to wandb
Average incurred loss: 0.450  
Average sample loss: 0.446  
Average acc: 0.811  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.019  exp loss = 0.017  adjusted loss = 0.017  adv prob = 0.250000   acc = 0.998
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.551  exp loss = 0.532  adjusted loss = 0.532  adv prob = 0.250000   acc = 0.732
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.857  exp loss = 1.975  adjusted loss = 1.975  adv prob = 0.250000   acc = 0.301
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.201  exp loss = 0.202  adjusted loss = 0.202  adv prob = 0.250000   acc = 0.940
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_test_epoch_249.csv
logged to wandb
Current lr: 0.000010


Epoch [250]:
Training:
Average incurred loss: 0.020  
Average sample loss: 0.020  
Average acc: 1.000  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2355]:	loss = 0.010  exp loss = 0.009  adjusted loss = 0.009  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 127]:	loss = 0.101  exp loss = 0.086  adjusted loss = 0.086  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 0  [n = 36]:	loss = 0.148  exp loss = 0.121  adjusted loss = 0.121  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 682]:	loss = 0.036  exp loss = 0.030  adjusted loss = 0.030  adv prob = 0.250000   acc = 1.000
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_train_epoch_250.csv
logged to wandb
Average incurred loss: 0.019  
Average sample loss: 0.019  
Average acc: 1.000  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 1143]:	loss = 0.008  exp loss = 0.007  adjusted loss = 0.007  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 57]:	loss = 0.069  exp loss = 0.059  adjusted loss = 0.059  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 0  [n = 20]:	loss = 0.132  exp loss = 0.136  adjusted loss = 0.136  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 375]:	loss = 0.041  exp loss = 0.034  adjusted loss = 0.034  adv prob = 0.250000   acc = 1.000

Validation:
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_val_epoch_250.csv
logged to wandb
Average incurred loss: 0.453  
Average sample loss: 0.449  
Average acc: 0.809  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.020  exp loss = 0.017  adjusted loss = 0.017  adv prob = 0.250000   acc = 0.996
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.558  exp loss = 0.537  adjusted loss = 0.537  adv prob = 0.250000   acc = 0.732
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.864  exp loss = 1.986  adjusted loss = 1.986  adv prob = 0.250000   acc = 0.293
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.198  exp loss = 0.199  adjusted loss = 0.199  adv prob = 0.250000   acc = 0.940
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_test_epoch_250.csv
logged to wandb
Current lr: 0.000010


Epoch [251]:
Training:
Average incurred loss: 0.020  
Average sample loss: 0.020  
Average acc: 0.999  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2347]:	loss = 0.010  exp loss = 0.012  adjusted loss = 0.012  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 131]:	loss = 0.096  exp loss = 0.147  adjusted loss = 0.147  adv prob = 0.250000   acc = 0.992
  waterbird_complete95 = 1, forest2water2 = 0  [n = 34]:	loss = 0.118  exp loss = 0.122  adjusted loss = 0.122  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 688]:	loss = 0.036  exp loss = 0.031  adjusted loss = 0.031  adv prob = 0.250000   acc = 1.000
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_train_epoch_251.csv
logged to wandb
Average incurred loss: 0.021  
Average sample loss: 0.021  
Average acc: 1.000  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 1151]:	loss = 0.008  exp loss = 0.008  adjusted loss = 0.008  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 53]:	loss = 0.093  exp loss = 0.084  adjusted loss = 0.084  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 0  [n = 22]:	loss = 0.153  exp loss = 0.164  adjusted loss = 0.164  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 369]:	loss = 0.041  exp loss = 0.039  adjusted loss = 0.039  adv prob = 0.250000   acc = 1.000

Validation:
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_val_epoch_251.csv
logged to wandb
Average incurred loss: 0.454  
Average sample loss: 0.451  
Average acc: 0.807  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.020  exp loss = 0.018  adjusted loss = 0.018  adv prob = 0.250000   acc = 0.996
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.570  exp loss = 0.549  adjusted loss = 0.549  adv prob = 0.250000   acc = 0.725
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.834  exp loss = 1.950  adjusted loss = 1.950  adv prob = 0.250000   acc = 0.301
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.194  exp loss = 0.194  adjusted loss = 0.194  adv prob = 0.250000   acc = 0.940
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_test_epoch_251.csv
logged to wandb
Current lr: 0.000010


Epoch [252]:
Training:
Average incurred loss: 0.019  
Average sample loss: 0.019  
Average acc: 1.000  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2326]:	loss = 0.009  exp loss = 0.010  adjusted loss = 0.010  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 123]:	loss = 0.074  exp loss = 0.082  adjusted loss = 0.082  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 0  [n = 39]:	loss = 0.150  exp loss = 0.147  adjusted loss = 0.147  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 712]:	loss = 0.036  exp loss = 0.031  adjusted loss = 0.031  adv prob = 0.250000   acc = 1.000
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_train_epoch_252.csv
logged to wandb
Average incurred loss: 0.021  
Average sample loss: 0.021  
Average acc: 1.000  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 1172]:	loss = 0.010  exp loss = 0.009  adjusted loss = 0.009  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 61]:	loss = 0.083  exp loss = 0.084  adjusted loss = 0.084  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 0  [n = 17]:	loss = 0.120  exp loss = 0.115  adjusted loss = 0.115  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 345]:	loss = 0.043  exp loss = 0.037  adjusted loss = 0.037  adv prob = 0.250000   acc = 1.000

Validation:
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_val_epoch_252.csv
logged to wandb
Average incurred loss: 0.462  
Average sample loss: 0.459  
Average acc: 0.798  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.022  exp loss = 0.019  adjusted loss = 0.019  adv prob = 0.250000   acc = 0.996
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.606  exp loss = 0.584  adjusted loss = 0.584  adv prob = 0.250000   acc = 0.695
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.787  exp loss = 1.893  adjusted loss = 1.893  adv prob = 0.250000   acc = 0.316
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.182  exp loss = 0.182  adjusted loss = 0.182  adv prob = 0.250000   acc = 0.947
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_test_epoch_252.csv
logged to wandb
Current lr: 0.000010


Epoch [253]:
Training:
Average incurred loss: 0.019  
Average sample loss: 0.019  
Average acc: 1.000  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2336]:	loss = 0.009  exp loss = 0.008  adjusted loss = 0.008  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 126]:	loss = 0.074  exp loss = 0.088  adjusted loss = 0.088  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 0  [n = 36]:	loss = 0.119  exp loss = 0.128  adjusted loss = 0.128  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 702]:	loss = 0.038  exp loss = 0.034  adjusted loss = 0.034  adv prob = 0.250000   acc = 1.000
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_train_epoch_253.csv
logged to wandb
Average incurred loss: 0.018  
Average sample loss: 0.019  
Average acc: 1.000  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 1162]:	loss = 0.008  exp loss = 0.008  adjusted loss = 0.008  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 58]:	loss = 0.092  exp loss = 0.094  adjusted loss = 0.094  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 0  [n = 20]:	loss = 0.169  exp loss = 0.151  adjusted loss = 0.151  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 355]:	loss = 0.032  exp loss = 0.030  adjusted loss = 0.030  adv prob = 0.250000   acc = 1.000

Validation:
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_val_epoch_253.csv
logged to wandb
Average incurred loss: 0.464  
Average sample loss: 0.460  
Average acc: 0.799  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.023  exp loss = 0.021  adjusted loss = 0.021  adv prob = 0.250000   acc = 0.996
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.624  exp loss = 0.604  adjusted loss = 0.604  adv prob = 0.250000   acc = 0.687
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.737  exp loss = 1.842  adjusted loss = 1.842  adv prob = 0.250000   acc = 0.353
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.173  exp loss = 0.172  adjusted loss = 0.172  adv prob = 0.250000   acc = 0.947
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_test_epoch_253.csv
logged to wandb
Current lr: 0.000010


Epoch [254]:
Training:
Average incurred loss: 0.018  
Average sample loss: 0.018  
Average acc: 1.000  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2359]:	loss = 0.009  exp loss = 0.008  adjusted loss = 0.008  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 116]:	loss = 0.082  exp loss = 0.084  adjusted loss = 0.084  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 0  [n = 38]:	loss = 0.147  exp loss = 0.130  adjusted loss = 0.130  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 687]:	loss = 0.031  exp loss = 0.029  adjusted loss = 0.029  adv prob = 0.250000   acc = 1.000
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_train_epoch_254.csv
logged to wandb
Average incurred loss: 0.018  
Average sample loss: 0.018  
Average acc: 1.000  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 1139]:	loss = 0.008  exp loss = 0.008  adjusted loss = 0.008  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 68]:	loss = 0.050  exp loss = 0.058  adjusted loss = 0.058  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 0  [n = 18]:	loss = 0.117  exp loss = 0.117  adjusted loss = 0.117  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 370]:	loss = 0.039  exp loss = 0.033  adjusted loss = 0.033  adv prob = 0.250000   acc = 1.000

Validation:
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_val_epoch_254.csv
logged to wandb
Average incurred loss: 0.450  
Average sample loss: 0.446  
Average acc: 0.813  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.020  exp loss = 0.018  adjusted loss = 0.018  adv prob = 0.250000   acc = 0.996
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.559  exp loss = 0.539  adjusted loss = 0.539  adv prob = 0.250000   acc = 0.736
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.835  exp loss = 1.950  adjusted loss = 1.950  adv prob = 0.250000   acc = 0.316
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.194  exp loss = 0.193  adjusted loss = 0.193  adv prob = 0.250000   acc = 0.940
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_test_epoch_254.csv
logged to wandb
Current lr: 0.000010


Epoch [255]:
Training:
Average incurred loss: 0.019  
Average sample loss: 0.019  
Average acc: 1.000  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2331]:	loss = 0.009  exp loss = 0.008  adjusted loss = 0.008  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 124]:	loss = 0.068  exp loss = 0.063  adjusted loss = 0.063  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 0  [n = 42]:	loss = 0.123  exp loss = 0.121  adjusted loss = 0.121  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 703]:	loss = 0.035  exp loss = 0.038  adjusted loss = 0.038  adv prob = 0.250000   acc = 1.000
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_train_epoch_255.csv
logged to wandb
Average incurred loss: 0.020  
Average sample loss: 0.020  
Average acc: 1.000  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 1167]:	loss = 0.009  exp loss = 0.008  adjusted loss = 0.008  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 60]:	loss = 0.097  exp loss = 0.092  adjusted loss = 0.092  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 0  [n = 14]:	loss = 0.183  exp loss = 0.154  adjusted loss = 0.154  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 354]:	loss = 0.039  exp loss = 0.030  adjusted loss = 0.030  adv prob = 0.250000   acc = 1.000

Validation:
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_val_epoch_255.csv
logged to wandb
Average incurred loss: 0.466  
Average sample loss: 0.462  
Average acc: 0.801  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.022  exp loss = 0.020  adjusted loss = 0.020  adv prob = 0.250000   acc = 0.996
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.624  exp loss = 0.601  adjusted loss = 0.601  adv prob = 0.250000   acc = 0.691
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.761  exp loss = 1.870  adjusted loss = 1.870  adv prob = 0.250000   acc = 0.346
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.174  exp loss = 0.173  adjusted loss = 0.173  adv prob = 0.250000   acc = 0.955
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_test_epoch_255.csv
logged to wandb
Current lr: 0.000010


Epoch [256]:
Training:
Average incurred loss: 0.018  
Average sample loss: 0.018  
Average acc: 1.000  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2347]:	loss = 0.009  exp loss = 0.008  adjusted loss = 0.008  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 126]:	loss = 0.078  exp loss = 0.072  adjusted loss = 0.072  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 0  [n = 29]:	loss = 0.107  exp loss = 0.110  adjusted loss = 0.110  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 698]:	loss = 0.032  exp loss = 0.026  adjusted loss = 0.026  adv prob = 0.250000   acc = 1.000
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_train_epoch_256.csv
logged to wandb
Average incurred loss: 0.018  
Average sample loss: 0.018  
Average acc: 0.999  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 1151]:	loss = 0.008  exp loss = 0.007  adjusted loss = 0.007  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 58]:	loss = 0.064  exp loss = 0.065  adjusted loss = 0.065  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 0  [n = 27]:	loss = 0.127  exp loss = 0.131  adjusted loss = 0.131  adv prob = 0.250000   acc = 0.963
  waterbird_complete95 = 1, forest2water2 = 1  [n = 359]:	loss = 0.034  exp loss = 0.032  adjusted loss = 0.032  adv prob = 0.250000   acc = 1.000

Validation:
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_val_epoch_256.csv
logged to wandb
Average incurred loss: 0.450  
Average sample loss: 0.446  
Average acc: 0.814  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.019  exp loss = 0.016  adjusted loss = 0.016  adv prob = 0.250000   acc = 0.998
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.538  exp loss = 0.518  adjusted loss = 0.518  adv prob = 0.250000   acc = 0.742
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.898  exp loss = 2.026  adjusted loss = 2.026  adv prob = 0.250000   acc = 0.293
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.207  exp loss = 0.208  adjusted loss = 0.208  adv prob = 0.250000   acc = 0.940
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_test_epoch_256.csv
logged to wandb
Current lr: 0.000010


Epoch [257]:
Training:
Average incurred loss: 0.018  
Average sample loss: 0.018  
Average acc: 1.000  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2374]:	loss = 0.009  exp loss = 0.011  adjusted loss = 0.011  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 121]:	loss = 0.091  exp loss = 0.119  adjusted loss = 0.119  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 0  [n = 41]:	loss = 0.113  exp loss = 0.083  adjusted loss = 0.083  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 664]:	loss = 0.032  exp loss = 0.020  adjusted loss = 0.020  adv prob = 0.250000   acc = 1.000
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_train_epoch_257.csv
logged to wandb
Average incurred loss: 0.020  
Average sample loss: 0.020  
Average acc: 1.000  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 1124]:	loss = 0.007  exp loss = 0.007  adjusted loss = 0.007  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 63]:	loss = 0.070  exp loss = 0.081  adjusted loss = 0.081  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 0  [n = 15]:	loss = 0.159  exp loss = 0.131  adjusted loss = 0.131  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 393]:	loss = 0.043  exp loss = 0.040  adjusted loss = 0.040  adv prob = 0.250000   acc = 1.000

Validation:
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_val_epoch_257.csv
logged to wandb
Average incurred loss: 0.448  
Average sample loss: 0.444  
Average acc: 0.814  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.018  exp loss = 0.016  adjusted loss = 0.016  adv prob = 0.250000   acc = 0.998
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.540  exp loss = 0.521  adjusted loss = 0.521  adv prob = 0.250000   acc = 0.742
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.881  exp loss = 2.010  adjusted loss = 2.010  adv prob = 0.250000   acc = 0.293
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.205  exp loss = 0.206  adjusted loss = 0.206  adv prob = 0.250000   acc = 0.940
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_test_epoch_257.csv
logged to wandb
Current lr: 0.000010


Epoch [258]:
Training:
Average incurred loss: 0.018  
Average sample loss: 0.018  
Average acc: 1.000  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2334]:	loss = 0.008  exp loss = 0.008  adjusted loss = 0.008  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 117]:	loss = 0.072  exp loss = 0.078  adjusted loss = 0.078  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 0  [n = 35]:	loss = 0.139  exp loss = 0.123  adjusted loss = 0.123  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 714]:	loss = 0.036  exp loss = 0.036  adjusted loss = 0.036  adv prob = 0.250000   acc = 1.000
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_train_epoch_258.csv
logged to wandb
Average incurred loss: 0.016  
Average sample loss: 0.016  
Average acc: 1.000  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 1164]:	loss = 0.008  exp loss = 0.007  adjusted loss = 0.007  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 67]:	loss = 0.072  exp loss = 0.085  adjusted loss = 0.085  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 0  [n = 21]:	loss = 0.098  exp loss = 0.100  adjusted loss = 0.100  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 343]:	loss = 0.027  exp loss = 0.026  adjusted loss = 0.026  adv prob = 0.250000   acc = 1.000

Validation:
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_val_epoch_258.csv
logged to wandb
Average incurred loss: 0.467  
Average sample loss: 0.464  
Average acc: 0.799  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.023  exp loss = 0.021  adjusted loss = 0.021  adv prob = 0.250000   acc = 0.996
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.633  exp loss = 0.610  adjusted loss = 0.610  adv prob = 0.250000   acc = 0.685
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.739  exp loss = 1.844  adjusted loss = 1.844  adv prob = 0.250000   acc = 0.353
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.172  exp loss = 0.170  adjusted loss = 0.170  adv prob = 0.250000   acc = 0.955
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_test_epoch_258.csv
logged to wandb
Current lr: 0.000010


Epoch [259]:
Training:
Average incurred loss: 0.018  
Average sample loss: 0.018  
Average acc: 1.000  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2320]:	loss = 0.008  exp loss = 0.007  adjusted loss = 0.007  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 131]:	loss = 0.076  exp loss = 0.061  adjusted loss = 0.061  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 0  [n = 39]:	loss = 0.160  exp loss = 0.172  adjusted loss = 0.172  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 710]:	loss = 0.033  exp loss = 0.035  adjusted loss = 0.035  adv prob = 0.250000   acc = 1.000
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_train_epoch_259.csv
logged to wandb
Average incurred loss: 0.017  
Average sample loss: 0.017  
Average acc: 1.000  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 1178]:	loss = 0.008  exp loss = 0.008  adjusted loss = 0.008  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 53]:	loss = 0.070  exp loss = 0.082  adjusted loss = 0.082  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 0  [n = 17]:	loss = 0.073  exp loss = 0.101  adjusted loss = 0.101  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 347]:	loss = 0.034  exp loss = 0.033  adjusted loss = 0.033  adv prob = 0.250000   acc = 1.000

Validation:
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_val_epoch_259.csv
logged to wandb
Average incurred loss: 0.463  
Average sample loss: 0.460  
Average acc: 0.801  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.022  exp loss = 0.020  adjusted loss = 0.020  adv prob = 0.250000   acc = 0.996
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.617  exp loss = 0.597  adjusted loss = 0.597  adv prob = 0.250000   acc = 0.693
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.762  exp loss = 1.867  adjusted loss = 1.867  adv prob = 0.250000   acc = 0.346
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.176  exp loss = 0.174  adjusted loss = 0.174  adv prob = 0.250000   acc = 0.947
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_test_epoch_259.csv
logged to wandb
Current lr: 0.000010


Epoch [260]:
Training:
Average incurred loss: 0.018  
Average sample loss: 0.018  
Average acc: 1.000  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2326]:	loss = 0.009  exp loss = 0.008  adjusted loss = 0.008  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 127]:	loss = 0.076  exp loss = 0.078  adjusted loss = 0.078  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 0  [n = 37]:	loss = 0.105  exp loss = 0.111  adjusted loss = 0.111  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 710]:	loss = 0.036  exp loss = 0.026  adjusted loss = 0.026  adv prob = 0.250000   acc = 1.000
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_train_epoch_260.csv
logged to wandb
Average incurred loss: 0.016  
Average sample loss: 0.016  
Average acc: 1.000  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 1172]:	loss = 0.008  exp loss = 0.008  adjusted loss = 0.008  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 57]:	loss = 0.080  exp loss = 0.076  adjusted loss = 0.076  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 0  [n = 19]:	loss = 0.111  exp loss = 0.111  adjusted loss = 0.111  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 347]:	loss = 0.029  exp loss = 0.026  adjusted loss = 0.026  adv prob = 0.250000   acc = 1.000

Validation:
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_val_epoch_260.csv
logged to wandb
Average incurred loss: 0.463  
Average sample loss: 0.459  
Average acc: 0.805  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.021  exp loss = 0.019  adjusted loss = 0.019  adv prob = 0.250000   acc = 0.996
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.607  exp loss = 0.586  adjusted loss = 0.586  adv prob = 0.250000   acc = 0.704
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.790  exp loss = 1.901  adjusted loss = 1.901  adv prob = 0.250000   acc = 0.346
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.180  exp loss = 0.179  adjusted loss = 0.179  adv prob = 0.250000   acc = 0.947
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_test_epoch_260.csv
logged to wandb
Current lr: 0.000010


Epoch [261]:
Training:
Average incurred loss: 0.016  
Average sample loss: 0.016  
Average acc: 1.000  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2330]:	loss = 0.008  exp loss = 0.008  adjusted loss = 0.008  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 122]:	loss = 0.069  exp loss = 0.079  adjusted loss = 0.079  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 0  [n = 38]:	loss = 0.131  exp loss = 0.129  adjusted loss = 0.129  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 710]:	loss = 0.030  exp loss = 0.027  adjusted loss = 0.027  adv prob = 0.250000   acc = 1.000
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_train_epoch_261.csv
logged to wandb
Average incurred loss: 0.021  
Average sample loss: 0.021  
Average acc: 0.999  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 1168]:	loss = 0.010  exp loss = 0.009  adjusted loss = 0.009  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 62]:	loss = 0.113  exp loss = 0.079  adjusted loss = 0.079  adv prob = 0.250000   acc = 0.968
  waterbird_complete95 = 1, forest2water2 = 0  [n = 18]:	loss = 0.137  exp loss = 0.131  adjusted loss = 0.131  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 347]:	loss = 0.038  exp loss = 0.034  adjusted loss = 0.034  adv prob = 0.250000   acc = 1.000

Validation:
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_val_epoch_261.csv
logged to wandb
Average incurred loss: 0.459  
Average sample loss: 0.456  
Average acc: 0.807  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.021  exp loss = 0.018  adjusted loss = 0.018  adv prob = 0.250000   acc = 0.996
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.596  exp loss = 0.573  adjusted loss = 0.573  adv prob = 0.250000   acc = 0.715
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.799  exp loss = 1.909  adjusted loss = 1.909  adv prob = 0.250000   acc = 0.323
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.183  exp loss = 0.182  adjusted loss = 0.182  adv prob = 0.250000   acc = 0.947
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_test_epoch_261.csv
logged to wandb
Current lr: 0.000010


Epoch [262]:
Training:
Average incurred loss: 0.019  
Average sample loss: 0.019  
Average acc: 0.999  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2326]:	loss = 0.008  exp loss = 0.008  adjusted loss = 0.008  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 122]:	loss = 0.086  exp loss = 0.089  adjusted loss = 0.089  adv prob = 0.250000   acc = 0.984
  waterbird_complete95 = 1, forest2water2 = 0  [n = 38]:	loss = 0.129  exp loss = 0.108  adjusted loss = 0.108  adv prob = 0.250000   acc = 0.974
  waterbird_complete95 = 1, forest2water2 = 1  [n = 714]:	loss = 0.036  exp loss = 0.033  adjusted loss = 0.033  adv prob = 0.250000   acc = 1.000
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_train_epoch_262.csv
logged to wandb
Average incurred loss: 0.019  
Average sample loss: 0.019  
Average acc: 1.000  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 1172]:	loss = 0.009  exp loss = 0.008  adjusted loss = 0.008  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 62]:	loss = 0.085  exp loss = 0.105  adjusted loss = 0.105  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 0  [n = 18]:	loss = 0.114  exp loss = 0.110  adjusted loss = 0.110  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 343]:	loss = 0.037  exp loss = 0.036  adjusted loss = 0.036  adv prob = 0.250000   acc = 1.000

Validation:
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_val_epoch_262.csv
logged to wandb
Average incurred loss: 0.458  
Average sample loss: 0.454  
Average acc: 0.808  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.020  exp loss = 0.017  adjusted loss = 0.017  adv prob = 0.250000   acc = 0.996
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.578  exp loss = 0.557  adjusted loss = 0.557  adv prob = 0.250000   acc = 0.725
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.844  exp loss = 1.970  adjusted loss = 1.970  adv prob = 0.250000   acc = 0.301
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.189  exp loss = 0.190  adjusted loss = 0.190  adv prob = 0.250000   acc = 0.947
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_test_epoch_262.csv
logged to wandb
Current lr: 0.000010


Epoch [263]:
Training:
Average incurred loss: 0.018  
Average sample loss: 0.018  
Average acc: 0.999  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2359]:	loss = 0.009  exp loss = 0.008  adjusted loss = 0.008  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 118]:	loss = 0.096  exp loss = 0.115  adjusted loss = 0.115  adv prob = 0.250000   acc = 0.983
  waterbird_complete95 = 1, forest2water2 = 0  [n = 33]:	loss = 0.112  exp loss = 0.095  adjusted loss = 0.095  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 690]:	loss = 0.033  exp loss = 0.031  adjusted loss = 0.031  adv prob = 0.250000   acc = 1.000
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_train_epoch_263.csv
logged to wandb
Average incurred loss: 0.019  
Average sample loss: 0.019  
Average acc: 1.000  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 1139]:	loss = 0.008  exp loss = 0.008  adjusted loss = 0.008  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 66]:	loss = 0.065  exp loss = 0.091  adjusted loss = 0.091  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 0  [n = 23]:	loss = 0.132  exp loss = 0.101  adjusted loss = 0.101  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 367]:	loss = 0.038  exp loss = 0.034  adjusted loss = 0.034  adv prob = 0.250000   acc = 1.000

Validation:
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_val_epoch_263.csv
logged to wandb
Average incurred loss: 0.459  
Average sample loss: 0.455  
Average acc: 0.802  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.021  exp loss = 0.018  adjusted loss = 0.018  adv prob = 0.250000   acc = 0.996
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.596  exp loss = 0.574  adjusted loss = 0.574  adv prob = 0.250000   acc = 0.702
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.791  exp loss = 1.901  adjusted loss = 1.901  adv prob = 0.250000   acc = 0.331
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.183  exp loss = 0.182  adjusted loss = 0.182  adv prob = 0.250000   acc = 0.947
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_test_epoch_263.csv
logged to wandb
Current lr: 0.000010


Epoch [264]:
Training:
Average incurred loss: 0.019  
Average sample loss: 0.019  
Average acc: 1.000  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2334]:	loss = 0.009  exp loss = 0.008  adjusted loss = 0.008  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 129]:	loss = 0.085  exp loss = 0.082  adjusted loss = 0.082  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 0  [n = 39]:	loss = 0.122  exp loss = 0.110  adjusted loss = 0.110  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 698]:	loss = 0.035  exp loss = 0.025  adjusted loss = 0.025  adv prob = 0.250000   acc = 1.000
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_train_epoch_264.csv
logged to wandb
Average incurred loss: 0.018  
Average sample loss: 0.018  
Average acc: 1.000  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 1164]:	loss = 0.009  exp loss = 0.007  adjusted loss = 0.007  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 55]:	loss = 0.061  exp loss = 0.069  adjusted loss = 0.069  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 0  [n = 17]:	loss = 0.155  exp loss = 0.131  adjusted loss = 0.131  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 359]:	loss = 0.034  exp loss = 0.031  adjusted loss = 0.031  adv prob = 0.250000   acc = 1.000

Validation:
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_val_epoch_264.csv
logged to wandb
Average incurred loss: 0.459  
Average sample loss: 0.455  
Average acc: 0.805  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.021  exp loss = 0.018  adjusted loss = 0.018  adv prob = 0.250000   acc = 0.996
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.593  exp loss = 0.569  adjusted loss = 0.569  adv prob = 0.250000   acc = 0.710
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.805  exp loss = 1.916  adjusted loss = 1.916  adv prob = 0.250000   acc = 0.323
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.185  exp loss = 0.185  adjusted loss = 0.185  adv prob = 0.250000   acc = 0.947
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_test_epoch_264.csv
logged to wandb
Current lr: 0.000010


Epoch [265]:
Training:
Average incurred loss: 0.019  
Average sample loss: 0.019  
Average acc: 1.000  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2322]:	loss = 0.009  exp loss = 0.009  adjusted loss = 0.009  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 125]:	loss = 0.083  exp loss = 0.100  adjusted loss = 0.100  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 0  [n = 40]:	loss = 0.129  exp loss = 0.131  adjusted loss = 0.131  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 713]:	loss = 0.034  exp loss = 0.029  adjusted loss = 0.029  adv prob = 0.250000   acc = 1.000
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_train_epoch_265.csv
logged to wandb
Average incurred loss: 0.016  
Average sample loss: 0.016  
Average acc: 0.999  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 1176]:	loss = 0.008  exp loss = 0.008  adjusted loss = 0.008  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 59]:	loss = 0.054  exp loss = 0.057  adjusted loss = 0.057  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 0  [n = 16]:	loss = 0.118  exp loss = 0.125  adjusted loss = 0.125  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 344]:	loss = 0.031  exp loss = 0.032  adjusted loss = 0.032  adv prob = 0.250000   acc = 0.997

Validation:
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_val_epoch_265.csv
logged to wandb
Average incurred loss: 0.462  
Average sample loss: 0.459  
Average acc: 0.803  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.022  exp loss = 0.019  adjusted loss = 0.019  adv prob = 0.250000   acc = 0.996
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.617  exp loss = 0.596  adjusted loss = 0.596  adv prob = 0.250000   acc = 0.695
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.755  exp loss = 1.858  adjusted loss = 1.858  adv prob = 0.250000   acc = 0.361
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.175  exp loss = 0.174  adjusted loss = 0.174  adv prob = 0.250000   acc = 0.947
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_test_epoch_265.csv
logged to wandb
Current lr: 0.000010


Epoch [266]:
Training:
Average incurred loss: 0.018  
Average sample loss: 0.018  
Average acc: 1.000  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2350]:	loss = 0.009  exp loss = 0.007  adjusted loss = 0.007  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 114]:	loss = 0.082  exp loss = 0.080  adjusted loss = 0.080  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 0  [n = 40]:	loss = 0.111  exp loss = 0.092  adjusted loss = 0.092  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 696]:	loss = 0.035  exp loss = 0.032  adjusted loss = 0.032  adv prob = 0.250000   acc = 1.000
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_train_epoch_266.csv
logged to wandb
Average incurred loss: 0.017  
Average sample loss: 0.017  
Average acc: 1.000  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 1148]:	loss = 0.008  exp loss = 0.007  adjusted loss = 0.007  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 70]:	loss = 0.068  exp loss = 0.081  adjusted loss = 0.081  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 0  [n = 16]:	loss = 0.135  exp loss = 0.119  adjusted loss = 0.119  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 361]:	loss = 0.030  exp loss = 0.029  adjusted loss = 0.029  adv prob = 0.250000   acc = 1.000

Validation:
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_val_epoch_266.csv
logged to wandb
Average incurred loss: 0.451  
Average sample loss: 0.448  
Average acc: 0.813  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.019  exp loss = 0.017  adjusted loss = 0.017  adv prob = 0.250000   acc = 0.998
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.553  exp loss = 0.533  adjusted loss = 0.533  adv prob = 0.250000   acc = 0.738
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.867  exp loss = 1.990  adjusted loss = 1.990  adv prob = 0.250000   acc = 0.301
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.198  exp loss = 0.199  adjusted loss = 0.199  adv prob = 0.250000   acc = 0.940
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_test_epoch_266.csv
logged to wandb
Current lr: 0.000010


Epoch [267]:
Training:
Average incurred loss: 0.017  
Average sample loss: 0.017  
Average acc: 1.000  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2359]:	loss = 0.009  exp loss = 0.008  adjusted loss = 0.008  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 120]:	loss = 0.072  exp loss = 0.062  adjusted loss = 0.062  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 0  [n = 34]:	loss = 0.136  exp loss = 0.136  adjusted loss = 0.136  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 687]:	loss = 0.030  exp loss = 0.027  adjusted loss = 0.027  adv prob = 0.250000   acc = 1.000
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_train_epoch_267.csv
logged to wandb
Average incurred loss: 0.018  
Average sample loss: 0.018  
Average acc: 1.000  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 1139]:	loss = 0.007  exp loss = 0.007  adjusted loss = 0.007  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 64]:	loss = 0.058  exp loss = 0.057  adjusted loss = 0.057  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 0  [n = 22]:	loss = 0.103  exp loss = 0.099  adjusted loss = 0.099  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 370]:	loss = 0.038  exp loss = 0.030  adjusted loss = 0.030  adv prob = 0.250000   acc = 1.000

Validation:
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_val_epoch_267.csv
logged to wandb
Average incurred loss: 0.459  
Average sample loss: 0.455  
Average acc: 0.803  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.021  exp loss = 0.018  adjusted loss = 0.018  adv prob = 0.250000   acc = 0.996
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.593  exp loss = 0.571  adjusted loss = 0.571  adv prob = 0.250000   acc = 0.706
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.802  exp loss = 1.917  adjusted loss = 1.917  adv prob = 0.250000   acc = 0.323
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.183  exp loss = 0.183  adjusted loss = 0.183  adv prob = 0.250000   acc = 0.947
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_test_epoch_267.csv
logged to wandb
Current lr: 0.000010


Epoch [268]:
Training:
Average incurred loss: 0.018  
Average sample loss: 0.018  
Average acc: 1.000  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2309]:	loss = 0.007  exp loss = 0.007  adjusted loss = 0.007  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 128]:	loss = 0.077  exp loss = 0.065  adjusted loss = 0.065  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 0  [n = 38]:	loss = 0.156  exp loss = 0.159  adjusted loss = 0.159  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 725]:	loss = 0.035  exp loss = 0.037  adjusted loss = 0.037  adv prob = 0.250000   acc = 1.000
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_train_epoch_268.csv
logged to wandb
Average incurred loss: 0.016  
Average sample loss: 0.016  
Average acc: 1.000  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 1189]:	loss = 0.009  exp loss = 0.007  adjusted loss = 0.007  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 56]:	loss = 0.083  exp loss = 0.069  adjusted loss = 0.069  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 0  [n = 18]:	loss = 0.085  exp loss = 0.106  adjusted loss = 0.106  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 332]:	loss = 0.026  exp loss = 0.030  adjusted loss = 0.030  adv prob = 0.250000   acc = 1.000

Validation:
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_val_epoch_268.csv
logged to wandb
Average incurred loss: 0.455  
Average sample loss: 0.452  
Average acc: 0.806  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.021  exp loss = 0.019  adjusted loss = 0.019  adv prob = 0.250000   acc = 0.996
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.595  exp loss = 0.574  adjusted loss = 0.574  adv prob = 0.250000   acc = 0.708
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.765  exp loss = 1.869  adjusted loss = 1.869  adv prob = 0.250000   acc = 0.338
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.180  exp loss = 0.180  adjusted loss = 0.180  adv prob = 0.250000   acc = 0.947
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_test_epoch_268.csv
logged to wandb
Current lr: 0.000010


Epoch [269]:
Training:
Average incurred loss: 0.017  
Average sample loss: 0.017  
Average acc: 1.000  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2330]:	loss = 0.008  exp loss = 0.008  adjusted loss = 0.008  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 122]:	loss = 0.073  exp loss = 0.076  adjusted loss = 0.076  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 0  [n = 36]:	loss = 0.104  exp loss = 0.113  adjusted loss = 0.113  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 712]:	loss = 0.032  exp loss = 0.025  adjusted loss = 0.025  adv prob = 0.250000   acc = 1.000
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_train_epoch_269.csv
logged to wandb
Average incurred loss: 0.016  
Average sample loss: 0.016  
Average acc: 1.000  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 1168]:	loss = 0.009  exp loss = 0.008  adjusted loss = 0.008  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 62]:	loss = 0.055  exp loss = 0.066  adjusted loss = 0.066  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 0  [n = 20]:	loss = 0.097  exp loss = 0.095  adjusted loss = 0.095  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 345]:	loss = 0.029  exp loss = 0.026  adjusted loss = 0.026  adv prob = 0.250000   acc = 1.000

Validation:
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_val_epoch_269.csv
logged to wandb
Average incurred loss: 0.461  
Average sample loss: 0.458  
Average acc: 0.802  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.022  exp loss = 0.020  adjusted loss = 0.020  adv prob = 0.250000   acc = 0.996
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.622  exp loss = 0.603  adjusted loss = 0.603  adv prob = 0.250000   acc = 0.691
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.727  exp loss = 1.826  adjusted loss = 1.826  adv prob = 0.250000   acc = 0.361
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.172  exp loss = 0.170  adjusted loss = 0.170  adv prob = 0.250000   acc = 0.947
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_test_epoch_269.csv
logged to wandb
Current lr: 0.000010


Epoch [270]:
Training:
Average incurred loss: 0.017  
Average sample loss: 0.017  
Average acc: 1.000  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2310]:	loss = 0.007  exp loss = 0.008  adjusted loss = 0.008  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 121]:	loss = 0.069  exp loss = 0.074  adjusted loss = 0.074  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 0  [n = 43]:	loss = 0.140  exp loss = 0.108  adjusted loss = 0.108  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 726]:	loss = 0.034  exp loss = 0.023  adjusted loss = 0.023  adv prob = 0.250000   acc = 1.000
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_train_epoch_270.csv
logged to wandb
Average incurred loss: 0.017  
Average sample loss: 0.016  
Average acc: 1.000  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 1188]:	loss = 0.009  exp loss = 0.008  adjusted loss = 0.008  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 63]:	loss = 0.081  exp loss = 0.083  adjusted loss = 0.083  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 0  [n = 13]:	loss = 0.112  exp loss = 0.107  adjusted loss = 0.107  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 331]:	loss = 0.026  exp loss = 0.023  adjusted loss = 0.023  adv prob = 0.250000   acc = 1.000

Validation:
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_val_epoch_270.csv
logged to wandb
Average incurred loss: 0.469  
Average sample loss: 0.465  
Average acc: 0.797  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.023  exp loss = 0.020  adjusted loss = 0.020  adv prob = 0.250000   acc = 0.996
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.643  exp loss = 0.621  adjusted loss = 0.621  adv prob = 0.250000   acc = 0.680
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.725  exp loss = 1.822  adjusted loss = 1.822  adv prob = 0.250000   acc = 0.361
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.167  exp loss = 0.166  adjusted loss = 0.166  adv prob = 0.250000   acc = 0.947
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_test_epoch_270.csv
logged to wandb
Current lr: 0.000010


Epoch [271]:
Training:
Average incurred loss: 0.018  
Average sample loss: 0.018  
Average acc: 1.000  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2316]:	loss = 0.007  exp loss = 0.007  adjusted loss = 0.007  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 114]:	loss = 0.057  exp loss = 0.059  adjusted loss = 0.059  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 0  [n = 38]:	loss = 0.119  exp loss = 0.125  adjusted loss = 0.125  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 732]:	loss = 0.039  exp loss = 0.037  adjusted loss = 0.037  adv prob = 0.250000   acc = 0.999
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_train_epoch_271.csv
logged to wandb
Average incurred loss: 0.017  
Average sample loss: 0.017  
Average acc: 1.000  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 1182]:	loss = 0.009  exp loss = 0.009  adjusted loss = 0.009  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 70]:	loss = 0.079  exp loss = 0.090  adjusted loss = 0.090  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 0  [n = 18]:	loss = 0.097  exp loss = 0.089  adjusted loss = 0.089  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 325]:	loss = 0.025  exp loss = 0.023  adjusted loss = 0.023  adv prob = 0.250000   acc = 1.000

Validation:
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_val_epoch_271.csv
logged to wandb
Average incurred loss: 0.489  
Average sample loss: 0.485  
Average acc: 0.785  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.027  exp loss = 0.024  adjusted loss = 0.024  adv prob = 0.250000   acc = 0.994
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.729  exp loss = 0.704  adjusted loss = 0.704  adv prob = 0.250000   acc = 0.637
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.613  exp loss = 1.699  adjusted loss = 1.699  adv prob = 0.250000   acc = 0.391
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.146  exp loss = 0.144  adjusted loss = 0.144  adv prob = 0.250000   acc = 0.962
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_test_epoch_271.csv
logged to wandb
Current lr: 0.000010


Epoch [272]:
Training:
Average incurred loss: 0.016  
Average sample loss: 0.016  
Average acc: 1.000  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2338]:	loss = 0.007  exp loss = 0.008  adjusted loss = 0.008  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 125]:	loss = 0.073  exp loss = 0.065  adjusted loss = 0.065  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 0  [n = 35]:	loss = 0.103  exp loss = 0.108  adjusted loss = 0.108  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 702]:	loss = 0.032  exp loss = 0.029  adjusted loss = 0.029  adv prob = 0.250000   acc = 1.000
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_train_epoch_272.csv
logged to wandb
Average incurred loss: 0.015  
Average sample loss: 0.015  
Average acc: 1.000  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 1160]:	loss = 0.007  exp loss = 0.007  adjusted loss = 0.007  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 59]:	loss = 0.072  exp loss = 0.064  adjusted loss = 0.064  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 0  [n = 21]:	loss = 0.104  exp loss = 0.102  adjusted loss = 0.102  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 355]:	loss = 0.025  exp loss = 0.023  adjusted loss = 0.023  adv prob = 0.250000   acc = 1.000

Validation:
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_val_epoch_272.csv
logged to wandb
Average incurred loss: 0.461  
Average sample loss: 0.457  
Average acc: 0.803  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.022  exp loss = 0.019  adjusted loss = 0.019  adv prob = 0.250000   acc = 0.996
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.616  exp loss = 0.596  adjusted loss = 0.596  adv prob = 0.250000   acc = 0.695
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.745  exp loss = 1.849  adjusted loss = 1.849  adv prob = 0.250000   acc = 0.361
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.173  exp loss = 0.172  adjusted loss = 0.172  adv prob = 0.250000   acc = 0.947
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_test_epoch_272.csv
logged to wandb
Current lr: 0.000010


Epoch [273]:
Training:
Average incurred loss: 0.017  
Average sample loss: 0.017  
Average acc: 1.000  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2343]:	loss = 0.008  exp loss = 0.007  adjusted loss = 0.007  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 123]:	loss = 0.073  exp loss = 0.065  adjusted loss = 0.065  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 0  [n = 42]:	loss = 0.147  exp loss = 0.137  adjusted loss = 0.137  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 692]:	loss = 0.028  exp loss = 0.029  adjusted loss = 0.029  adv prob = 0.250000   acc = 1.000
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_train_epoch_273.csv
logged to wandb
Average incurred loss: 0.017  
Average sample loss: 0.017  
Average acc: 0.999  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 1155]:	loss = 0.007  exp loss = 0.006  adjusted loss = 0.006  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 61]:	loss = 0.086  exp loss = 0.074  adjusted loss = 0.074  adv prob = 0.250000   acc = 0.984
  waterbird_complete95 = 1, forest2water2 = 0  [n = 14]:	loss = 0.124  exp loss = 0.134  adjusted loss = 0.134  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 365]:	loss = 0.034  exp loss = 0.034  adjusted loss = 0.034  adv prob = 0.250000   acc = 1.000

Validation:
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_val_epoch_273.csv
logged to wandb
Average incurred loss: 0.457  
Average sample loss: 0.453  
Average acc: 0.812  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.018  exp loss = 0.015  adjusted loss = 0.015  adv prob = 0.250000   acc = 0.998
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.550  exp loss = 0.530  adjusted loss = 0.530  adv prob = 0.250000   acc = 0.740
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.926  exp loss = 2.050  adjusted loss = 2.050  adv prob = 0.250000   acc = 0.286
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.202  exp loss = 0.202  adjusted loss = 0.202  adv prob = 0.250000   acc = 0.940
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_test_epoch_273.csv
logged to wandb
Current lr: 0.000010


Epoch [274]:
Training:
Average incurred loss: 0.019  
Average sample loss: 0.019  
Average acc: 1.000  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2328]:	loss = 0.008  exp loss = 0.008  adjusted loss = 0.008  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 118]:	loss = 0.075  exp loss = 0.073  adjusted loss = 0.073  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 0  [n = 42]:	loss = 0.149  exp loss = 0.164  adjusted loss = 0.164  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 712]:	loss = 0.036  exp loss = 0.040  adjusted loss = 0.040  adv prob = 0.250000   acc = 1.000
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_train_epoch_274.csv
logged to wandb
Average incurred loss: 0.017  
Average sample loss: 0.017  
Average acc: 0.999  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 1170]:	loss = 0.008  exp loss = 0.008  adjusted loss = 0.008  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 66]:	loss = 0.096  exp loss = 0.102  adjusted loss = 0.102  adv prob = 0.250000   acc = 0.985
  waterbird_complete95 = 1, forest2water2 = 0  [n = 14]:	loss = 0.087  exp loss = 0.107  adjusted loss = 0.107  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 345]:	loss = 0.028  exp loss = 0.031  adjusted loss = 0.031  adv prob = 0.250000   acc = 1.000

Validation:
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_val_epoch_274.csv
logged to wandb
Average incurred loss: 0.462  
Average sample loss: 0.459  
Average acc: 0.806  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.021  exp loss = 0.019  adjusted loss = 0.019  adv prob = 0.250000   acc = 0.996
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.611  exp loss = 0.590  adjusted loss = 0.590  adv prob = 0.250000   acc = 0.704
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.778  exp loss = 1.885  adjusted loss = 1.885  adv prob = 0.250000   acc = 0.353
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.175  exp loss = 0.174  adjusted loss = 0.174  adv prob = 0.250000   acc = 0.947
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_test_epoch_274.csv
logged to wandb
Current lr: 0.000010


Epoch [275]:
Training:
Average incurred loss: 0.018  
Average sample loss: 0.018  
Average acc: 1.000  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2344]:	loss = 0.009  exp loss = 0.008  adjusted loss = 0.008  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 124]:	loss = 0.088  exp loss = 0.070  adjusted loss = 0.070  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 0  [n = 35]:	loss = 0.107  exp loss = 0.126  adjusted loss = 0.126  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 697]:	loss = 0.032  exp loss = 0.026  adjusted loss = 0.026  adv prob = 0.250000   acc = 1.000
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_train_epoch_275.csv
logged to wandb
Average incurred loss: 0.016  
Average sample loss: 0.016  
Average acc: 1.000  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 1154]:	loss = 0.007  exp loss = 0.007  adjusted loss = 0.007  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 60]:	loss = 0.060  exp loss = 0.063  adjusted loss = 0.063  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 0  [n = 21]:	loss = 0.118  exp loss = 0.105  adjusted loss = 0.105  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 360]:	loss = 0.031  exp loss = 0.025  adjusted loss = 0.025  adv prob = 0.250000   acc = 1.000

Validation:
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_val_epoch_275.csv
logged to wandb
Average incurred loss: 0.466  
Average sample loss: 0.462  
Average acc: 0.802  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.021  exp loss = 0.018  adjusted loss = 0.018  adv prob = 0.250000   acc = 0.996
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.611  exp loss = 0.589  adjusted loss = 0.589  adv prob = 0.250000   acc = 0.700
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.807  exp loss = 1.917  adjusted loss = 1.917  adv prob = 0.250000   acc = 0.338
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.180  exp loss = 0.179  adjusted loss = 0.179  adv prob = 0.250000   acc = 0.947
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_test_epoch_275.csv
logged to wandb
Current lr: 0.000010


Epoch [276]:
Training:
Average incurred loss: 0.017  
Average sample loss: 0.017  
Average acc: 1.000  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2344]:	loss = 0.008  exp loss = 0.008  adjusted loss = 0.008  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 118]:	loss = 0.080  exp loss = 0.074  adjusted loss = 0.074  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 0  [n = 44]:	loss = 0.122  exp loss = 0.127  adjusted loss = 0.127  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 694]:	loss = 0.031  exp loss = 0.025  adjusted loss = 0.025  adv prob = 0.250000   acc = 1.000
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_train_epoch_276.csv
logged to wandb
Average incurred loss: 0.017  
Average sample loss: 0.017  
Average acc: 1.000  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 1154]:	loss = 0.007  exp loss = 0.006  adjusted loss = 0.006  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 66]:	loss = 0.071  exp loss = 0.063  adjusted loss = 0.063  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 0  [n = 12]:	loss = 0.132  exp loss = 0.144  adjusted loss = 0.144  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 363]:	loss = 0.036  exp loss = 0.034  adjusted loss = 0.034  adv prob = 0.250000   acc = 1.000

Validation:
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_val_epoch_276.csv
logged to wandb
Average incurred loss: 0.450  
Average sample loss: 0.446  
Average acc: 0.814  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.019  exp loss = 0.016  adjusted loss = 0.016  adv prob = 0.250000   acc = 0.998
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.554  exp loss = 0.533  adjusted loss = 0.533  adv prob = 0.250000   acc = 0.738
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.857  exp loss = 1.973  adjusted loss = 1.973  adv prob = 0.250000   acc = 0.301
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.195  exp loss = 0.195  adjusted loss = 0.195  adv prob = 0.250000   acc = 0.947
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_test_epoch_276.csv
logged to wandb
Current lr: 0.000010


Epoch [277]:
Training:
Average incurred loss: 0.019  
Average sample loss: 0.019  
Average acc: 1.000  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2330]:	loss = 0.009  exp loss = 0.009  adjusted loss = 0.009  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 116]:	loss = 0.067  exp loss = 0.116  adjusted loss = 0.116  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 0  [n = 39]:	loss = 0.113  exp loss = 0.107  adjusted loss = 0.107  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 715]:	loss = 0.042  exp loss = 0.027  adjusted loss = 0.027  adv prob = 0.250000   acc = 1.000
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_train_epoch_277.csv
logged to wandb
Average incurred loss: 0.017  
Average sample loss: 0.017  
Average acc: 1.000  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 1168]:	loss = 0.008  exp loss = 0.008  adjusted loss = 0.008  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 68]:	loss = 0.085  exp loss = 0.081  adjusted loss = 0.081  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 0  [n = 17]:	loss = 0.113  exp loss = 0.123  adjusted loss = 0.123  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 342]:	loss = 0.030  exp loss = 0.028  adjusted loss = 0.028  adv prob = 0.250000   acc = 1.000

Validation:
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_val_epoch_277.csv
logged to wandb
Average incurred loss: 0.463  
Average sample loss: 0.459  
Average acc: 0.805  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.022  exp loss = 0.019  adjusted loss = 0.019  adv prob = 0.250000   acc = 0.996
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.619  exp loss = 0.595  adjusted loss = 0.595  adv prob = 0.250000   acc = 0.702
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.758  exp loss = 1.865  adjusted loss = 1.865  adv prob = 0.250000   acc = 0.353
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.173  exp loss = 0.172  adjusted loss = 0.172  adv prob = 0.250000   acc = 0.947
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_test_epoch_277.csv
logged to wandb
Current lr: 0.000010


Epoch [278]:
Training:
Average incurred loss: 0.017  
Average sample loss: 0.017  
Average acc: 1.000  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2316]:	loss = 0.007  exp loss = 0.007  adjusted loss = 0.007  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 127]:	loss = 0.073  exp loss = 0.080  adjusted loss = 0.080  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 0  [n = 36]:	loss = 0.100  exp loss = 0.109  adjusted loss = 0.109  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 721]:	loss = 0.033  exp loss = 0.028  adjusted loss = 0.028  adv prob = 0.250000   acc = 0.999
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_train_epoch_278.csv
logged to wandb
Average incurred loss: 0.015  
Average sample loss: 0.015  
Average acc: 1.000  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 1182]:	loss = 0.008  exp loss = 0.008  adjusted loss = 0.008  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 57]:	loss = 0.077  exp loss = 0.072  adjusted loss = 0.072  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 0  [n = 20]:	loss = 0.116  exp loss = 0.110  adjusted loss = 0.110  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 336]:	loss = 0.025  exp loss = 0.021  adjusted loss = 0.021  adv prob = 0.250000   acc = 1.000

Validation:
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_val_epoch_278.csv
logged to wandb
Average incurred loss: 0.473  
Average sample loss: 0.469  
Average acc: 0.797  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.023  exp loss = 0.020  adjusted loss = 0.020  adv prob = 0.250000   acc = 0.996
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.648  exp loss = 0.626  adjusted loss = 0.626  adv prob = 0.250000   acc = 0.678
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.745  exp loss = 1.846  adjusted loss = 1.846  adv prob = 0.250000   acc = 0.361
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.167  exp loss = 0.165  adjusted loss = 0.165  adv prob = 0.250000   acc = 0.955
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_test_epoch_278.csv
logged to wandb
Current lr: 0.000010


Epoch [279]:
Training:
Average incurred loss: 0.018  
Average sample loss: 0.018  
Average acc: 1.000  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2337]:	loss = 0.008  exp loss = 0.007  adjusted loss = 0.007  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 120]:	loss = 0.077  exp loss = 0.065  adjusted loss = 0.065  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 0  [n = 32]:	loss = 0.094  exp loss = 0.093  adjusted loss = 0.093  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 711]:	loss = 0.036  exp loss = 0.032  adjusted loss = 0.032  adv prob = 0.250000   acc = 0.999
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_train_epoch_279.csv
logged to wandb
Average incurred loss: 0.015  
Average sample loss: 0.015  
Average acc: 1.000  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 1161]:	loss = 0.007  exp loss = 0.007  adjusted loss = 0.007  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 64]:	loss = 0.054  exp loss = 0.050  adjusted loss = 0.050  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 0  [n = 24]:	loss = 0.128  exp loss = 0.113  adjusted loss = 0.113  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 346]:	loss = 0.026  exp loss = 0.023  adjusted loss = 0.023  adv prob = 0.250000   acc = 1.000

Validation:
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_val_epoch_279.csv
logged to wandb
Average incurred loss: 0.460  
Average sample loss: 0.457  
Average acc: 0.807  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.021  exp loss = 0.019  adjusted loss = 0.019  adv prob = 0.250000   acc = 0.996
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.609  exp loss = 0.588  adjusted loss = 0.588  adv prob = 0.250000   acc = 0.702
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.766  exp loss = 1.869  adjusted loss = 1.869  adv prob = 0.250000   acc = 0.361
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.175  exp loss = 0.172  adjusted loss = 0.172  adv prob = 0.250000   acc = 0.955
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_test_epoch_279.csv
logged to wandb
Current lr: 0.000010


Epoch [280]:
Training:
Average incurred loss: 0.015  
Average sample loss: 0.015  
Average acc: 1.000  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2346]:	loss = 0.008  exp loss = 0.007  adjusted loss = 0.007  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 126]:	loss = 0.066  exp loss = 0.062  adjusted loss = 0.062  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 0  [n = 29]:	loss = 0.106  exp loss = 0.096  adjusted loss = 0.096  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 699]:	loss = 0.028  exp loss = 0.027  adjusted loss = 0.027  adv prob = 0.250000   acc = 1.000
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_train_epoch_280.csv
logged to wandb
Average incurred loss: 0.016  
Average sample loss: 0.016  
Average acc: 1.000  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 1152]:	loss = 0.007  exp loss = 0.007  adjusted loss = 0.007  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 58]:	loss = 0.068  exp loss = 0.074  adjusted loss = 0.074  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 0  [n = 27]:	loss = 0.111  exp loss = 0.106  adjusted loss = 0.106  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 358]:	loss = 0.030  exp loss = 0.026  adjusted loss = 0.026  adv prob = 0.250000   acc = 1.000

Validation:
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_val_epoch_280.csv
logged to wandb
Average incurred loss: 0.461  
Average sample loss: 0.457  
Average acc: 0.808  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.020  exp loss = 0.018  adjusted loss = 0.018  adv prob = 0.250000   acc = 0.996
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.593  exp loss = 0.571  adjusted loss = 0.571  adv prob = 0.250000   acc = 0.715
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.825  exp loss = 1.937  adjusted loss = 1.937  adv prob = 0.250000   acc = 0.338
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.182  exp loss = 0.181  adjusted loss = 0.181  adv prob = 0.250000   acc = 0.947
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_test_epoch_280.csv
logged to wandb
Current lr: 0.000010


Epoch [281]:
Training:
Average incurred loss: 0.016  
Average sample loss: 0.016  
Average acc: 1.000  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2342]:	loss = 0.008  exp loss = 0.009  adjusted loss = 0.009  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 119]:	loss = 0.068  exp loss = 0.083  adjusted loss = 0.083  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 0  [n = 30]:	loss = 0.108  exp loss = 0.118  adjusted loss = 0.118  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 709]:	loss = 0.031  exp loss = 0.030  adjusted loss = 0.030  adv prob = 0.250000   acc = 1.000
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_train_epoch_281.csv
logged to wandb
Average incurred loss: 0.016  
Average sample loss: 0.016  
Average acc: 1.000  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 1156]:	loss = 0.007  exp loss = 0.007  adjusted loss = 0.007  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 65]:	loss = 0.059  exp loss = 0.065  adjusted loss = 0.065  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 0  [n = 26]:	loss = 0.126  exp loss = 0.124  adjusted loss = 0.124  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 348]:	loss = 0.029  exp loss = 0.027  adjusted loss = 0.027  adv prob = 0.250000   acc = 1.000

Validation:
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_val_epoch_281.csv
logged to wandb
Average incurred loss: 0.463  
Average sample loss: 0.460  
Average acc: 0.805  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.021  exp loss = 0.018  adjusted loss = 0.018  adv prob = 0.250000   acc = 0.996
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.615  exp loss = 0.594  adjusted loss = 0.594  adv prob = 0.250000   acc = 0.697
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.775  exp loss = 1.883  adjusted loss = 1.883  adv prob = 0.250000   acc = 0.361
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.174  exp loss = 0.173  adjusted loss = 0.173  adv prob = 0.250000   acc = 0.955
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_test_epoch_281.csv
logged to wandb
Current lr: 0.000010


Epoch [282]:
Training:
Average incurred loss: 0.020  
Average sample loss: 0.020  
Average acc: 1.000  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2302]:	loss = 0.008  exp loss = 0.007  adjusted loss = 0.007  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 126]:	loss = 0.080  exp loss = 0.090  adjusted loss = 0.090  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 0  [n = 45]:	loss = 0.122  exp loss = 0.111  adjusted loss = 0.111  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 727]:	loss = 0.040  exp loss = 0.031  adjusted loss = 0.031  adv prob = 0.250000   acc = 1.000
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_train_epoch_282.csv
logged to wandb
Average incurred loss: 0.017  
Average sample loss: 0.017  
Average acc: 1.000  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 1196]:	loss = 0.009  exp loss = 0.009  adjusted loss = 0.009  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 58]:	loss = 0.089  exp loss = 0.081  adjusted loss = 0.081  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 0  [n = 11]:	loss = 0.096  exp loss = 0.095  adjusted loss = 0.095  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 330]:	loss = 0.029  exp loss = 0.025  adjusted loss = 0.025  adv prob = 0.250000   acc = 1.000

Validation:
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_val_epoch_282.csv
logged to wandb
Average incurred loss: 0.471  
Average sample loss: 0.468  
Average acc: 0.795  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.024  exp loss = 0.021  adjusted loss = 0.021  adv prob = 0.250000   acc = 0.996
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.670  exp loss = 0.647  adjusted loss = 0.647  adv prob = 0.250000   acc = 0.665
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.662  exp loss = 1.752  adjusted loss = 1.752  adv prob = 0.250000   acc = 0.383
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.157  exp loss = 0.154  adjusted loss = 0.154  adv prob = 0.250000   acc = 0.955
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_test_epoch_282.csv
logged to wandb
Current lr: 0.000010


Epoch [283]:
Training:
Average incurred loss: 0.016  
Average sample loss: 0.016  
Average acc: 1.000  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2325]:	loss = 0.007  exp loss = 0.007  adjusted loss = 0.007  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 120]:	loss = 0.068  exp loss = 0.069  adjusted loss = 0.069  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 0  [n = 33]:	loss = 0.099  exp loss = 0.100  adjusted loss = 0.100  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 722]:	loss = 0.032  exp loss = 0.027  adjusted loss = 0.027  adv prob = 0.250000   acc = 1.000
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_train_epoch_283.csv
logged to wandb
Average incurred loss: 0.015  
Average sample loss: 0.015  
Average acc: 1.000  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 1173]:	loss = 0.008  exp loss = 0.008  adjusted loss = 0.008  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 64]:	loss = 0.069  exp loss = 0.066  adjusted loss = 0.066  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 0  [n = 23]:	loss = 0.107  exp loss = 0.102  adjusted loss = 0.102  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 335]:	loss = 0.024  exp loss = 0.023  adjusted loss = 0.023  adv prob = 0.250000   acc = 1.000

Validation:
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_val_epoch_283.csv
logged to wandb
Average incurred loss: 0.465  
Average sample loss: 0.461  
Average acc: 0.804  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.021  exp loss = 0.019  adjusted loss = 0.019  adv prob = 0.250000   acc = 0.996
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.619  exp loss = 0.597  adjusted loss = 0.597  adv prob = 0.250000   acc = 0.697
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.772  exp loss = 1.875  adjusted loss = 1.875  adv prob = 0.250000   acc = 0.353
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.174  exp loss = 0.173  adjusted loss = 0.173  adv prob = 0.250000   acc = 0.955
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_test_epoch_283.csv
logged to wandb
Current lr: 0.000010


Epoch [284]:
Training:
Average incurred loss: 0.016  
Average sample loss: 0.016  
Average acc: 1.000  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2322]:	loss = 0.007  exp loss = 0.008  adjusted loss = 0.008  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 116]:	loss = 0.065  exp loss = 0.086  adjusted loss = 0.086  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 0  [n = 38]:	loss = 0.103  exp loss = 0.097  adjusted loss = 0.097  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 724]:	loss = 0.031  exp loss = 0.025  adjusted loss = 0.025  adv prob = 0.250000   acc = 1.000
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_train_epoch_284.csv
logged to wandb
Average incurred loss: 0.016  
Average sample loss: 0.016  
Average acc: 1.000  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 1176]:	loss = 0.007  exp loss = 0.007  adjusted loss = 0.007  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 68]:	loss = 0.090  exp loss = 0.086  adjusted loss = 0.086  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 0  [n = 18]:	loss = 0.107  exp loss = 0.097  adjusted loss = 0.097  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 333]:	loss = 0.025  exp loss = 0.021  adjusted loss = 0.021  adv prob = 0.250000   acc = 1.000

Validation:
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_val_epoch_284.csv
logged to wandb
Average incurred loss: 0.471  
Average sample loss: 0.467  
Average acc: 0.797  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.024  exp loss = 0.021  adjusted loss = 0.021  adv prob = 0.250000   acc = 0.996
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.668  exp loss = 0.646  adjusted loss = 0.646  adv prob = 0.250000   acc = 0.670
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.665  exp loss = 1.760  adjusted loss = 1.760  adv prob = 0.250000   acc = 0.391
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.157  exp loss = 0.155  adjusted loss = 0.155  adv prob = 0.250000   acc = 0.955
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_test_epoch_284.csv
logged to wandb
Current lr: 0.000010


Epoch [285]:
Training:
Average incurred loss: 0.015  
Average sample loss: 0.015  
Average acc: 1.000  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2351]:	loss = 0.008  exp loss = 0.008  adjusted loss = 0.008  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 123]:	loss = 0.063  exp loss = 0.067  adjusted loss = 0.067  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 0  [n = 40]:	loss = 0.089  exp loss = 0.098  adjusted loss = 0.098  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 686]:	loss = 0.027  exp loss = 0.021  adjusted loss = 0.021  adv prob = 0.250000   acc = 1.000
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_train_epoch_285.csv
logged to wandb
Average incurred loss: 0.016  
Average sample loss: 0.016  
Average acc: 1.000  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 1147]:	loss = 0.007  exp loss = 0.006  adjusted loss = 0.006  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 61]:	loss = 0.063  exp loss = 0.054  adjusted loss = 0.054  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 0  [n = 16]:	loss = 0.119  exp loss = 0.139  adjusted loss = 0.139  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 371]:	loss = 0.034  exp loss = 0.032  adjusted loss = 0.032  adv prob = 0.250000   acc = 1.000

Validation:
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_val_epoch_285.csv
logged to wandb
Average incurred loss: 0.461  
Average sample loss: 0.457  
Average acc: 0.806  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.019  exp loss = 0.017  adjusted loss = 0.017  adv prob = 0.250000   acc = 0.996
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.590  exp loss = 0.567  adjusted loss = 0.567  adv prob = 0.250000   acc = 0.715
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.841  exp loss = 1.953  adjusted loss = 1.953  adv prob = 0.250000   acc = 0.316
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.183  exp loss = 0.181  adjusted loss = 0.181  adv prob = 0.250000   acc = 0.947
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_test_epoch_285.csv
logged to wandb
Current lr: 0.000010


Epoch [286]:
Training:
Average incurred loss: 0.017  
Average sample loss: 0.017  
Average acc: 1.000  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2324]:	loss = 0.007  exp loss = 0.006  adjusted loss = 0.006  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 126]:	loss = 0.074  exp loss = 0.062  adjusted loss = 0.062  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 0  [n = 39]:	loss = 0.093  exp loss = 0.103  adjusted loss = 0.103  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 711]:	loss = 0.033  exp loss = 0.027  adjusted loss = 0.027  adv prob = 0.250000   acc = 1.000
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_train_epoch_286.csv
logged to wandb
Average incurred loss: 0.017  
Average sample loss: 0.017  
Average acc: 1.000  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 1174]:	loss = 0.008  exp loss = 0.009  adjusted loss = 0.009  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 58]:	loss = 0.075  exp loss = 0.080  adjusted loss = 0.080  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 0  [n = 17]:	loss = 0.088  exp loss = 0.091  adjusted loss = 0.091  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 346]:	loss = 0.033  exp loss = 0.029  adjusted loss = 0.029  adv prob = 0.250000   acc = 1.000

Validation:
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_val_epoch_286.csv
logged to wandb
Average incurred loss: 0.469  
Average sample loss: 0.465  
Average acc: 0.802  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.021  exp loss = 0.018  adjusted loss = 0.018  adv prob = 0.250000   acc = 0.996
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.621  exp loss = 0.598  adjusted loss = 0.598  adv prob = 0.250000   acc = 0.697
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.806  exp loss = 1.921  adjusted loss = 1.921  adv prob = 0.250000   acc = 0.338
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.174  exp loss = 0.173  adjusted loss = 0.173  adv prob = 0.250000   acc = 0.947
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_test_epoch_286.csv
logged to wandb
Current lr: 0.000010


Epoch [287]:
Training:
Average incurred loss: 0.015  
Average sample loss: 0.015  
Average acc: 1.000  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2319]:	loss = 0.007  exp loss = 0.006  adjusted loss = 0.006  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 123]:	loss = 0.056  exp loss = 0.063  adjusted loss = 0.063  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 0  [n = 41]:	loss = 0.129  exp loss = 0.119  adjusted loss = 0.119  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 717]:	loss = 0.027  exp loss = 0.027  adjusted loss = 0.027  adv prob = 0.250000   acc = 1.000
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_train_epoch_287.csv
logged to wandb
Average incurred loss: 0.017  
Average sample loss: 0.017  
Average acc: 0.999  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 1179]:	loss = 0.009  exp loss = 0.008  adjusted loss = 0.008  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 61]:	loss = 0.072  exp loss = 0.069  adjusted loss = 0.069  adv prob = 0.250000   acc = 0.984
  waterbird_complete95 = 1, forest2water2 = 0  [n = 15]:	loss = 0.056  exp loss = 0.074  adjusted loss = 0.074  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 340]:	loss = 0.032  exp loss = 0.032  adjusted loss = 0.032  adv prob = 0.250000   acc = 1.000

Validation:
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_val_epoch_287.csv
logged to wandb
Average incurred loss: 0.470  
Average sample loss: 0.466  
Average acc: 0.799  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.023  exp loss = 0.020  adjusted loss = 0.020  adv prob = 0.250000   acc = 0.996
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.653  exp loss = 0.632  adjusted loss = 0.632  adv prob = 0.250000   acc = 0.676
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.704  exp loss = 1.800  adjusted loss = 1.800  adv prob = 0.250000   acc = 0.383
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.161  exp loss = 0.158  adjusted loss = 0.158  adv prob = 0.250000   acc = 0.955
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_test_epoch_287.csv
logged to wandb
Current lr: 0.000010


Epoch [288]:
Training:
Average incurred loss: 0.016  
Average sample loss: 0.016  
Average acc: 1.000  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2357]:	loss = 0.008  exp loss = 0.008  adjusted loss = 0.008  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 124]:	loss = 0.075  exp loss = 0.101  adjusted loss = 0.101  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 0  [n = 37]:	loss = 0.094  exp loss = 0.090  adjusted loss = 0.090  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 682]:	loss = 0.030  exp loss = 0.023  adjusted loss = 0.023  adv prob = 0.250000   acc = 1.000
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_train_epoch_288.csv
logged to wandb
Average incurred loss: 0.017  
Average sample loss: 0.017  
Average acc: 1.000  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 1141]:	loss = 0.007  exp loss = 0.006  adjusted loss = 0.006  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 60]:	loss = 0.047  exp loss = 0.044  adjusted loss = 0.044  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 0  [n = 19]:	loss = 0.163  exp loss = 0.149  adjusted loss = 0.149  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 375]:	loss = 0.034  exp loss = 0.036  adjusted loss = 0.036  adv prob = 0.250000   acc = 1.000

Validation:
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_val_epoch_288.csv
logged to wandb
Average incurred loss: 0.441  
Average sample loss: 0.437  
Average acc: 0.828  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.015  exp loss = 0.013  adjusted loss = 0.013  adv prob = 0.250000   acc = 0.998
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.484  exp loss = 0.465  adjusted loss = 0.465  adv prob = 0.250000   acc = 0.785
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 2.007  exp loss = 2.154  adjusted loss = 2.154  adv prob = 0.250000   acc = 0.286
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.224  exp loss = 0.225  adjusted loss = 0.225  adv prob = 0.250000   acc = 0.925
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_test_epoch_288.csv
logged to wandb
Current lr: 0.000010


Epoch [289]:
Training:
Average incurred loss: 0.017  
Average sample loss: 0.017  
Average acc: 1.000  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2304]:	loss = 0.007  exp loss = 0.006  adjusted loss = 0.006  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 119]:	loss = 0.059  exp loss = 0.052  adjusted loss = 0.052  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 0  [n = 39]:	loss = 0.126  exp loss = 0.157  adjusted loss = 0.157  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 738]:	loss = 0.036  exp loss = 0.038  adjusted loss = 0.038  adv prob = 0.250000   acc = 1.000
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_train_epoch_289.csv
logged to wandb
Average incurred loss: 0.018  
Average sample loss: 0.018  
Average acc: 0.999  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 1194]:	loss = 0.010  exp loss = 0.011  adjusted loss = 0.011  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 65]:	loss = 0.114  exp loss = 0.148  adjusted loss = 0.148  adv prob = 0.250000   acc = 0.969
  waterbird_complete95 = 1, forest2water2 = 0  [n = 17]:	loss = 0.100  exp loss = 0.092  adjusted loss = 0.092  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 319]:	loss = 0.025  exp loss = 0.021  adjusted loss = 0.021  adv prob = 0.250000   acc = 1.000

Validation:
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_val_epoch_289.csv
logged to wandb
Average incurred loss: 0.494  
Average sample loss: 0.491  
Average acc: 0.784  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.028  exp loss = 0.025  adjusted loss = 0.025  adv prob = 0.250000   acc = 0.994
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.752  exp loss = 0.727  adjusted loss = 0.727  adv prob = 0.250000   acc = 0.633
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.589  exp loss = 1.671  adjusted loss = 1.671  adv prob = 0.250000   acc = 0.391
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.138  exp loss = 0.134  adjusted loss = 0.134  adv prob = 0.250000   acc = 0.970
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_test_epoch_289.csv
logged to wandb
Current lr: 0.000010


Epoch [290]:
Training:
Average incurred loss: 0.015  
Average sample loss: 0.015  
Average acc: 1.000  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2356]:	loss = 0.008  exp loss = 0.008  adjusted loss = 0.008  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 117]:	loss = 0.057  exp loss = 0.053  adjusted loss = 0.053  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 0  [n = 36]:	loss = 0.104  exp loss = 0.120  adjusted loss = 0.120  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 691]:	loss = 0.029  exp loss = 0.030  adjusted loss = 0.030  adv prob = 0.250000   acc = 0.999
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_train_epoch_290.csv
logged to wandb
Average incurred loss: 0.015  
Average sample loss: 0.015  
Average acc: 1.000  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 1142]:	loss = 0.006  exp loss = 0.006  adjusted loss = 0.006  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 67]:	loss = 0.063  exp loss = 0.065  adjusted loss = 0.065  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 0  [n = 20]:	loss = 0.115  exp loss = 0.095  adjusted loss = 0.095  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 366]:	loss = 0.030  exp loss = 0.031  adjusted loss = 0.031  adv prob = 0.250000   acc = 1.000

Validation:
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_val_epoch_290.csv
logged to wandb
Average incurred loss: 0.451  
Average sample loss: 0.447  
Average acc: 0.817  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.016  exp loss = 0.014  adjusted loss = 0.014  adv prob = 0.250000   acc = 0.998
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.529  exp loss = 0.508  adjusted loss = 0.508  adv prob = 0.250000   acc = 0.747
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.953  exp loss = 2.088  adjusted loss = 2.088  adv prob = 0.250000   acc = 0.301
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.206  exp loss = 0.205  adjusted loss = 0.205  adv prob = 0.250000   acc = 0.940
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_test_epoch_290.csv
logged to wandb
Current lr: 0.000010


Epoch [291]:
Training:
Average incurred loss: 0.016  
Average sample loss: 0.016  
Average acc: 1.000  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2344]:	loss = 0.008  exp loss = 0.007  adjusted loss = 0.007  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 123]:	loss = 0.076  exp loss = 0.093  adjusted loss = 0.093  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 0  [n = 36]:	loss = 0.107  exp loss = 0.119  adjusted loss = 0.119  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 697]:	loss = 0.030  exp loss = 0.021  adjusted loss = 0.021  adv prob = 0.250000   acc = 1.000
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_train_epoch_291.csv
logged to wandb
Average incurred loss: 0.017  
Average sample loss: 0.017  
Average acc: 1.000  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 1154]:	loss = 0.007  exp loss = 0.008  adjusted loss = 0.008  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 61]:	loss = 0.069  exp loss = 0.066  adjusted loss = 0.066  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 0  [n = 20]:	loss = 0.137  exp loss = 0.108  adjusted loss = 0.108  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 360]:	loss = 0.033  exp loss = 0.028  adjusted loss = 0.028  adv prob = 0.250000   acc = 1.000

Validation:
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_val_epoch_291.csv
logged to wandb
Average incurred loss: 0.460  
Average sample loss: 0.457  
Average acc: 0.807  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.021  exp loss = 0.018  adjusted loss = 0.018  adv prob = 0.250000   acc = 0.996
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.608  exp loss = 0.585  adjusted loss = 0.585  adv prob = 0.250000   acc = 0.702
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.772  exp loss = 1.883  adjusted loss = 1.883  adv prob = 0.250000   acc = 0.368
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.174  exp loss = 0.172  adjusted loss = 0.172  adv prob = 0.250000   acc = 0.955
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_test_epoch_291.csv
logged to wandb
Current lr: 0.000010


Epoch [292]:
Training:
Average incurred loss: 0.015  
Average sample loss: 0.015  
Average acc: 1.000  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2351]:	loss = 0.007  exp loss = 0.006  adjusted loss = 0.006  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 120]:	loss = 0.073  exp loss = 0.050  adjusted loss = 0.050  adv prob = 0.250000   acc = 0.992
  waterbird_complete95 = 1, forest2water2 = 0  [n = 30]:	loss = 0.112  exp loss = 0.117  adjusted loss = 0.117  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 699]:	loss = 0.027  exp loss = 0.025  adjusted loss = 0.025  adv prob = 0.250000   acc = 1.000
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_train_epoch_292.csv
logged to wandb
Average incurred loss: 0.015  
Average sample loss: 0.015  
Average acc: 1.000  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 1147]:	loss = 0.006  exp loss = 0.006  adjusted loss = 0.006  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 64]:	loss = 0.055  exp loss = 0.046  adjusted loss = 0.046  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 0  [n = 26]:	loss = 0.086  exp loss = 0.089  adjusted loss = 0.089  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 358]:	loss = 0.029  exp loss = 0.029  adjusted loss = 0.029  adv prob = 0.250000   acc = 1.000

Validation:
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_val_epoch_292.csv
logged to wandb
Average incurred loss: 0.452  
Average sample loss: 0.448  
Average acc: 0.815  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.018  exp loss = 0.016  adjusted loss = 0.016  adv prob = 0.250000   acc = 0.996
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.557  exp loss = 0.535  adjusted loss = 0.535  adv prob = 0.250000   acc = 0.738
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.868  exp loss = 1.985  adjusted loss = 1.985  adv prob = 0.250000   acc = 0.316
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.192  exp loss = 0.191  adjusted loss = 0.191  adv prob = 0.250000   acc = 0.947
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_test_epoch_292.csv
logged to wandb
Current lr: 0.000010


Epoch [293]:
Training:
Average incurred loss: 0.017  
Average sample loss: 0.017  
Average acc: 1.000  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2327]:	loss = 0.008  exp loss = 0.007  adjusted loss = 0.007  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 133]:	loss = 0.074  exp loss = 0.072  adjusted loss = 0.072  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 0  [n = 36]:	loss = 0.132  exp loss = 0.130  adjusted loss = 0.130  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 704]:	loss = 0.030  exp loss = 0.025  adjusted loss = 0.025  adv prob = 0.250000   acc = 1.000
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_train_epoch_293.csv
logged to wandb
Average incurred loss: 0.015  
Average sample loss: 0.015  
Average acc: 1.000  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 1171]:	loss = 0.008  exp loss = 0.007  adjusted loss = 0.007  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 51]:	loss = 0.066  exp loss = 0.059  adjusted loss = 0.059  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 0  [n = 20]:	loss = 0.079  exp loss = 0.083  adjusted loss = 0.083  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 353]:	loss = 0.030  exp loss = 0.030  adjusted loss = 0.030  adv prob = 0.250000   acc = 1.000

Validation:
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_val_epoch_293.csv
logged to wandb
Average incurred loss: 0.456  
Average sample loss: 0.452  
Average acc: 0.812  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.018  exp loss = 0.016  adjusted loss = 0.016  adv prob = 0.250000   acc = 0.998
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.567  exp loss = 0.544  adjusted loss = 0.544  adv prob = 0.250000   acc = 0.730
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.874  exp loss = 1.992  adjusted loss = 1.992  adv prob = 0.250000   acc = 0.316
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.189  exp loss = 0.188  adjusted loss = 0.188  adv prob = 0.250000   acc = 0.947
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_test_epoch_293.csv
logged to wandb
Current lr: 0.000010


Epoch [294]:
Training:
Average incurred loss: 0.016  
Average sample loss: 0.016  
Average acc: 1.000  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2348]:	loss = 0.009  exp loss = 0.008  adjusted loss = 0.008  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 124]:	loss = 0.062  exp loss = 0.066  adjusted loss = 0.066  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 0  [n = 41]:	loss = 0.091  exp loss = 0.095  adjusted loss = 0.095  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 687]:	loss = 0.031  exp loss = 0.024  adjusted loss = 0.024  adv prob = 0.250000   acc = 1.000
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_train_epoch_294.csv
logged to wandb
Average incurred loss: 0.015  
Average sample loss: 0.015  
Average acc: 1.000  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 1150]:	loss = 0.006  exp loss = 0.006  adjusted loss = 0.006  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 60]:	loss = 0.059  exp loss = 0.058  adjusted loss = 0.058  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 0  [n = 15]:	loss = 0.114  exp loss = 0.099  adjusted loss = 0.099  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 370]:	loss = 0.032  exp loss = 0.026  adjusted loss = 0.026  adv prob = 0.250000   acc = 1.000

Validation:
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_val_epoch_294.csv
logged to wandb
Average incurred loss: 0.451  
Average sample loss: 0.447  
Average acc: 0.813  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.018  exp loss = 0.016  adjusted loss = 0.016  adv prob = 0.250000   acc = 0.998
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.564  exp loss = 0.543  adjusted loss = 0.543  adv prob = 0.250000   acc = 0.725
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.839  exp loss = 1.957  adjusted loss = 1.957  adv prob = 0.250000   acc = 0.338
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.189  exp loss = 0.188  adjusted loss = 0.188  adv prob = 0.250000   acc = 0.947
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_test_epoch_294.csv
logged to wandb
Current lr: 0.000010


Epoch [295]:
Training:
Average incurred loss: 0.016  
Average sample loss: 0.016  
Average acc: 0.999  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2345]:	loss = 0.008  exp loss = 0.005  adjusted loss = 0.005  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 121]:	loss = 0.071  exp loss = 0.078  adjusted loss = 0.078  adv prob = 0.250000   acc = 0.992
  waterbird_complete95 = 1, forest2water2 = 0  [n = 31]:	loss = 0.112  exp loss = 0.132  adjusted loss = 0.132  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 703]:	loss = 0.029  exp loss = 0.030  adjusted loss = 0.030  adv prob = 0.250000   acc = 1.000
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_train_epoch_295.csv
logged to wandb
Average incurred loss: 0.016  
Average sample loss: 0.016  
Average acc: 1.000  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 1153]:	loss = 0.007  exp loss = 0.006  adjusted loss = 0.006  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 63]:	loss = 0.063  exp loss = 0.051  adjusted loss = 0.051  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 0  [n = 25]:	loss = 0.100  exp loss = 0.130  adjusted loss = 0.130  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 354]:	loss = 0.032  exp loss = 0.034  adjusted loss = 0.034  adv prob = 0.250000   acc = 1.000

Validation:
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_val_epoch_295.csv
logged to wandb
Average incurred loss: 0.447  
Average sample loss: 0.443  
Average acc: 0.823  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.017  exp loss = 0.015  adjusted loss = 0.015  adv prob = 0.250000   acc = 0.998
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.523  exp loss = 0.504  adjusted loss = 0.504  adv prob = 0.250000   acc = 0.762
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.927  exp loss = 2.056  adjusted loss = 2.056  adv prob = 0.250000   acc = 0.308
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.205  exp loss = 0.206  adjusted loss = 0.206  adv prob = 0.250000   acc = 0.940
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_test_epoch_295.csv
logged to wandb
Current lr: 0.000010


Epoch [296]:
Training:
Average incurred loss: 0.016  
Average sample loss: 0.016  
Average acc: 1.000  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2342]:	loss = 0.008  exp loss = 0.010  adjusted loss = 0.010  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 124]:	loss = 0.067  exp loss = 0.064  adjusted loss = 0.064  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 0  [n = 42]:	loss = 0.101  exp loss = 0.093  adjusted loss = 0.093  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 692]:	loss = 0.028  exp loss = 0.021  adjusted loss = 0.021  adv prob = 0.250000   acc = 1.000
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_train_epoch_296.csv
logged to wandb
Average incurred loss: 0.016  
Average sample loss: 0.016  
Average acc: 0.999  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 1156]:	loss = 0.006  exp loss = 0.006  adjusted loss = 0.006  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 60]:	loss = 0.074  exp loss = 0.065  adjusted loss = 0.065  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 0  [n = 14]:	loss = 0.142  exp loss = 0.106  adjusted loss = 0.106  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 365]:	loss = 0.034  exp loss = 0.030  adjusted loss = 0.030  adv prob = 0.250000   acc = 0.997

Validation:
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_val_epoch_296.csv
logged to wandb
Average incurred loss: 0.455  
Average sample loss: 0.451  
Average acc: 0.812  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.019  exp loss = 0.016  adjusted loss = 0.016  adv prob = 0.250000   acc = 0.998
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.570  exp loss = 0.548  adjusted loss = 0.548  adv prob = 0.250000   acc = 0.723
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.850  exp loss = 1.970  adjusted loss = 1.970  adv prob = 0.250000   acc = 0.331
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.186  exp loss = 0.184  adjusted loss = 0.184  adv prob = 0.250000   acc = 0.947
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_test_epoch_296.csv
logged to wandb
Current lr: 0.000010


Epoch [297]:
Training:
Average incurred loss: 0.015  
Average sample loss: 0.015  
Average acc: 1.000  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2338]:	loss = 0.007  exp loss = 0.007  adjusted loss = 0.007  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 122]:	loss = 0.068  exp loss = 0.067  adjusted loss = 0.067  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 0  [n = 38]:	loss = 0.097  exp loss = 0.089  adjusted loss = 0.089  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 702]:	loss = 0.027  exp loss = 0.023  adjusted loss = 0.023  adv prob = 0.250000   acc = 1.000
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_train_epoch_297.csv
logged to wandb
Average incurred loss: 0.017  
Average sample loss: 0.017  
Average acc: 1.000  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 1160]:	loss = 0.008  exp loss = 0.009  adjusted loss = 0.009  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 62]:	loss = 0.061  exp loss = 0.074  adjusted loss = 0.074  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 0  [n = 18]:	loss = 0.119  exp loss = 0.113  adjusted loss = 0.113  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 355]:	loss = 0.030  exp loss = 0.025  adjusted loss = 0.025  adv prob = 0.250000   acc = 1.000

Validation:
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_val_epoch_297.csv
logged to wandb
Average incurred loss: 0.474  
Average sample loss: 0.470  
Average acc: 0.800  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.022  exp loss = 0.020  adjusted loss = 0.020  adv prob = 0.250000   acc = 0.996
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.660  exp loss = 0.634  adjusted loss = 0.634  adv prob = 0.250000   acc = 0.682
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.724  exp loss = 1.820  adjusted loss = 1.820  adv prob = 0.250000   acc = 0.368
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.159  exp loss = 0.157  adjusted loss = 0.157  adv prob = 0.250000   acc = 0.955
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_test_epoch_297.csv
logged to wandb
Current lr: 0.000010


Epoch [298]:
Training:
Average incurred loss: 0.016  
Average sample loss: 0.016  
Average acc: 1.000  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2331]:	loss = 0.007  exp loss = 0.006  adjusted loss = 0.006  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 118]:	loss = 0.072  exp loss = 0.072  adjusted loss = 0.072  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 0  [n = 37]:	loss = 0.109  exp loss = 0.123  adjusted loss = 0.123  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 714]:	loss = 0.031  exp loss = 0.035  adjusted loss = 0.035  adv prob = 0.250000   acc = 1.000
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_train_epoch_298.csv
logged to wandb
Average incurred loss: 0.016  
Average sample loss: 0.016  
Average acc: 1.000  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 1167]:	loss = 0.008  exp loss = 0.008  adjusted loss = 0.008  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 66]:	loss = 0.062  exp loss = 0.079  adjusted loss = 0.079  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 0  [n = 19]:	loss = 0.096  exp loss = 0.095  adjusted loss = 0.095  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 343]:	loss = 0.031  exp loss = 0.024  adjusted loss = 0.024  adv prob = 0.250000   acc = 1.000

Validation:
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_val_epoch_298.csv
logged to wandb
Average incurred loss: 0.467  
Average sample loss: 0.463  
Average acc: 0.802  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.021  exp loss = 0.019  adjusted loss = 0.019  adv prob = 0.250000   acc = 0.996
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.633  exp loss = 0.613  adjusted loss = 0.613  adv prob = 0.250000   acc = 0.689
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.749  exp loss = 1.853  adjusted loss = 1.853  adv prob = 0.250000   acc = 0.368
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.165  exp loss = 0.163  adjusted loss = 0.163  adv prob = 0.250000   acc = 0.955
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_test_epoch_298.csv
logged to wandb
Current lr: 0.000010


Epoch [299]:
Training:
Average incurred loss: 0.015  
Average sample loss: 0.015  
Average acc: 1.000  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2354]:	loss = 0.008  exp loss = 0.007  adjusted loss = 0.007  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 112]:	loss = 0.069  exp loss = 0.064  adjusted loss = 0.064  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 0  [n = 38]:	loss = 0.097  exp loss = 0.117  adjusted loss = 0.117  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 696]:	loss = 0.026  exp loss = 0.022  adjusted loss = 0.022  adv prob = 0.250000   acc = 1.000
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_train_epoch_299.csv
logged to wandb
Average incurred loss: 0.015  
Average sample loss: 0.015  
Average acc: 1.000  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 1144]:	loss = 0.006  exp loss = 0.007  adjusted loss = 0.007  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 72]:	loss = 0.056  exp loss = 0.076  adjusted loss = 0.076  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 0  [n = 18]:	loss = 0.114  exp loss = 0.111  adjusted loss = 0.111  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 361]:	loss = 0.029  exp loss = 0.025  adjusted loss = 0.025  adv prob = 0.250000   acc = 1.000

Validation:
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_val_epoch_299.csv
logged to wandb
Average incurred loss: 0.459  
Average sample loss: 0.456  
Average acc: 0.810  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.019  exp loss = 0.017  adjusted loss = 0.017  adv prob = 0.250000   acc = 0.996
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.592  exp loss = 0.571  adjusted loss = 0.571  adv prob = 0.250000   acc = 0.715
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.819  exp loss = 1.928  adjusted loss = 1.928  adv prob = 0.250000   acc = 0.346
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.180  exp loss = 0.177  adjusted loss = 0.177  adv prob = 0.250000   acc = 0.955
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_test_epoch_299.csv
logged to wandb
Current lr: 0.000010


Epoch [300]:
Training:
Average incurred loss: 0.015  
Average sample loss: 0.015  
Average acc: 1.000  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2338]:	loss = 0.007  exp loss = 0.007  adjusted loss = 0.007  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 126]:	loss = 0.063  exp loss = 0.076  adjusted loss = 0.076  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 0  [n = 37]:	loss = 0.078  exp loss = 0.078  adjusted loss = 0.078  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 699]:	loss = 0.030  exp loss = 0.024  adjusted loss = 0.024  adv prob = 0.250000   acc = 0.999
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_train_epoch_300.csv
logged to wandb
Average incurred loss: 0.014  
Average sample loss: 0.014  
Average acc: 1.000  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 1160]:	loss = 0.006  exp loss = 0.005  adjusted loss = 0.005  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 58]:	loss = 0.060  exp loss = 0.053  adjusted loss = 0.053  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 0  [n = 19]:	loss = 0.104  exp loss = 0.115  adjusted loss = 0.115  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 358]:	loss = 0.026  exp loss = 0.028  adjusted loss = 0.028  adv prob = 0.250000   acc = 1.000

Validation:
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_val_epoch_300.csv
logged to wandb
Average incurred loss: 0.450  
Average sample loss: 0.446  
Average acc: 0.819  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.017  exp loss = 0.015  adjusted loss = 0.015  adv prob = 0.250000   acc = 0.998
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.536  exp loss = 0.515  adjusted loss = 0.515  adv prob = 0.250000   acc = 0.751
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.925  exp loss = 2.053  adjusted loss = 2.053  adv prob = 0.250000   acc = 0.301
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.199  exp loss = 0.197  adjusted loss = 0.197  adv prob = 0.250000   acc = 0.947
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_test_epoch_300.csv
logged to wandb
Current lr: 0.000010


Epoch [301]:
Training:
Average incurred loss: 0.016  
Average sample loss: 0.016  
Average acc: 1.000  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2321]:	loss = 0.007  exp loss = 0.007  adjusted loss = 0.007  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 129]:	loss = 0.070  exp loss = 0.063  adjusted loss = 0.063  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 0  [n = 41]:	loss = 0.095  exp loss = 0.095  adjusted loss = 0.095  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 709]:	loss = 0.030  exp loss = 0.023  adjusted loss = 0.023  adv prob = 0.250000   acc = 1.000
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_train_epoch_301.csv
logged to wandb
Average incurred loss: 0.016  
Average sample loss: 0.016  
Average acc: 0.999  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 1177]:	loss = 0.009  exp loss = 0.008  adjusted loss = 0.008  adv prob = 0.250000   acc = 0.999
  waterbird_complete95 = 0, forest2water2 = 1  [n = 55]:	loss = 0.073  exp loss = 0.074  adjusted loss = 0.074  adv prob = 0.250000   acc = 0.982
  waterbird_complete95 = 1, forest2water2 = 0  [n = 15]:	loss = 0.095  exp loss = 0.113  adjusted loss = 0.113  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 348]:	loss = 0.027  exp loss = 0.027  adjusted loss = 0.027  adv prob = 0.250000   acc = 1.000

Validation:
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_val_epoch_301.csv
logged to wandb
Average incurred loss: 0.455  
Average sample loss: 0.452  
Average acc: 0.812  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.018  exp loss = 0.016  adjusted loss = 0.016  adv prob = 0.250000   acc = 0.998
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.571  exp loss = 0.549  adjusted loss = 0.549  adv prob = 0.250000   acc = 0.727
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.854  exp loss = 1.970  adjusted loss = 1.970  adv prob = 0.250000   acc = 0.323
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.187  exp loss = 0.186  adjusted loss = 0.186  adv prob = 0.250000   acc = 0.947
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_test_epoch_301.csv
logged to wandb
Current lr: 0.000010


Epoch [302]:
Training:
Average incurred loss: 0.015  
Average sample loss: 0.015  
Average acc: 1.000  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2343]:	loss = 0.007  exp loss = 0.007  adjusted loss = 0.007  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 116]:	loss = 0.069  exp loss = 0.073  adjusted loss = 0.073  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 0  [n = 40]:	loss = 0.106  exp loss = 0.101  adjusted loss = 0.101  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 701]:	loss = 0.026  exp loss = 0.021  adjusted loss = 0.021  adv prob = 0.250000   acc = 1.000
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_train_epoch_302.csv
logged to wandb
Average incurred loss: 0.014  
Average sample loss: 0.014  
Average acc: 1.000  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 1155]:	loss = 0.006  exp loss = 0.006  adjusted loss = 0.006  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 68]:	loss = 0.056  exp loss = 0.050  adjusted loss = 0.050  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 0  [n = 16]:	loss = 0.121  exp loss = 0.115  adjusted loss = 0.115  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 356]:	loss = 0.025  exp loss = 0.022  adjusted loss = 0.022  adv prob = 0.250000   acc = 1.000

Validation:
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_val_epoch_302.csv
logged to wandb
Average incurred loss: 0.460  
Average sample loss: 0.456  
Average acc: 0.809  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.019  exp loss = 0.016  adjusted loss = 0.016  adv prob = 0.250000   acc = 0.996
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.588  exp loss = 0.566  adjusted loss = 0.566  adv prob = 0.250000   acc = 0.719
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.834  exp loss = 1.950  adjusted loss = 1.950  adv prob = 0.250000   acc = 0.331
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.182  exp loss = 0.180  adjusted loss = 0.180  adv prob = 0.250000   acc = 0.947
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_test_epoch_302.csv
logged to wandb
Current lr: 0.000010


Epoch [303]:
Training:
Average incurred loss: 0.016  
Average sample loss: 0.016  
Average acc: 1.000  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2329]:	loss = 0.007  exp loss = 0.008  adjusted loss = 0.008  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 129]:	loss = 0.069  exp loss = 0.080  adjusted loss = 0.080  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 0  [n = 38]:	loss = 0.105  exp loss = 0.096  adjusted loss = 0.096  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 704]:	loss = 0.029  exp loss = 0.024  adjusted loss = 0.024  adv prob = 0.250000   acc = 1.000
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_train_epoch_303.csv
logged to wandb
Average incurred loss: 0.017  
Average sample loss: 0.017  
Average acc: 1.000  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 1169]:	loss = 0.008  exp loss = 0.006  adjusted loss = 0.006  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 55]:	loss = 0.081  exp loss = 0.085  adjusted loss = 0.085  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 0  [n = 18]:	loss = 0.110  exp loss = 0.123  adjusted loss = 0.123  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 353]:	loss = 0.032  exp loss = 0.029  adjusted loss = 0.029  adv prob = 0.250000   acc = 1.000

Validation:
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_val_epoch_303.csv
logged to wandb
Average incurred loss: 0.465  
Average sample loss: 0.461  
Average acc: 0.805  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.019  exp loss = 0.016  adjusted loss = 0.016  adv prob = 0.250000   acc = 0.996
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.591  exp loss = 0.568  adjusted loss = 0.568  adv prob = 0.250000   acc = 0.712
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.870  exp loss = 1.992  adjusted loss = 1.992  adv prob = 0.250000   acc = 0.316
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.184  exp loss = 0.182  adjusted loss = 0.182  adv prob = 0.250000   acc = 0.947
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_test_epoch_303.csv
logged to wandb
Current lr: 0.000010


Epoch [304]:
Training:
Average incurred loss: 0.016  
Average sample loss: 0.016  
Average acc: 1.000  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2334]:	loss = 0.008  exp loss = 0.008  adjusted loss = 0.008  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 128]:	loss = 0.070  exp loss = 0.085  adjusted loss = 0.085  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 0  [n = 36]:	loss = 0.092  exp loss = 0.094  adjusted loss = 0.094  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 702]:	loss = 0.031  exp loss = 0.024  adjusted loss = 0.024  adv prob = 0.250000   acc = 1.000
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_train_epoch_304.csv
logged to wandb
Average incurred loss: 0.015  
Average sample loss: 0.015  
Average acc: 1.000  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 1164]:	loss = 0.008  exp loss = 0.008  adjusted loss = 0.008  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 56]:	loss = 0.048  exp loss = 0.059  adjusted loss = 0.059  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 0  [n = 20]:	loss = 0.095  exp loss = 0.099  adjusted loss = 0.099  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 355]:	loss = 0.027  exp loss = 0.023  adjusted loss = 0.023  adv prob = 0.250000   acc = 1.000

Validation:
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_val_epoch_304.csv
logged to wandb
Average incurred loss: 0.469  
Average sample loss: 0.465  
Average acc: 0.804  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.021  exp loss = 0.019  adjusted loss = 0.019  adv prob = 0.250000   acc = 0.996
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.638  exp loss = 0.616  adjusted loss = 0.616  adv prob = 0.250000   acc = 0.689
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.750  exp loss = 1.851  adjusted loss = 1.851  adv prob = 0.250000   acc = 0.383
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.166  exp loss = 0.163  adjusted loss = 0.163  adv prob = 0.250000   acc = 0.955
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_test_epoch_304.csv
logged to wandb
Current lr: 0.000010


Epoch [305]:
Training:
Average incurred loss: 0.016  
Average sample loss: 0.016  
Average acc: 1.000  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 2344]:	loss = 0.008  exp loss = 0.007  adjusted loss = 0.007  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 119]:	loss = 0.066  exp loss = 0.097  adjusted loss = 0.097  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 0  [n = 37]:	loss = 0.117  exp loss = 0.114  adjusted loss = 0.114  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 700]:	loss = 0.030  exp loss = 0.025  adjusted loss = 0.025  adv prob = 0.250000   acc = 1.000
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_train_epoch_305.csv
logged to wandb
Average incurred loss: 0.013  
Average sample loss: 0.013  
Average acc: 1.000  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 1154]:	loss = 0.006  exp loss = 0.006  adjusted loss = 0.006  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 65]:	loss = 0.051  exp loss = 0.060  adjusted loss = 0.060  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 0  [n = 19]:	loss = 0.079  exp loss = 0.090  adjusted loss = 0.090  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 357]:	loss = 0.026  exp loss = 0.020  adjusted loss = 0.020  adv prob = 0.250000   acc = 1.000

Validation:
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_val_epoch_305.csv
logged to wandb
Average incurred loss: 0.469  
Average sample loss: 0.466  
Average acc: 0.802  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.021  exp loss = 0.019  adjusted loss = 0.019  adv prob = 0.250000   acc = 0.996
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.641  exp loss = 0.620  adjusted loss = 0.620  adv prob = 0.250000   acc = 0.689
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 1.746  exp loss = 1.841  adjusted loss = 1.841  adv prob = 0.250000   acc = 0.368
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.165  exp loss = 0.162  adjusted loss = 0.162  adv prob = 0.250000   acc = 0.947
Saved results/CUB/CUB_sample_exp/ERM_upweight_0_epochs_306_lr_1e-05_weight_decay_0.0/model_outputs/output_test_epoch_305.csv
logged to wandb
Current lr: 0.000010

wandb: Waiting for W&B process to finish, PID 224110
wandb: Program ended successfully.
wandb: - 0.02MB of 0.02MB uploaded (0.00MB deduped)wandb: \ 1.05MB of 1.05MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Find user logs for this run at: wandb/run-20220710_204033-e3nkrqsx/logs/debug.log
wandb: Find internal logs for this run at: wandb/run-20220710_204033-e3nkrqsx/logs/debug-internal.log
wandb: Run summary:
wandb:                   train/avg_loss_group:0 0.00604
wandb:               train/exp_avg_loss_group:0 0.006
wandb:                    train/avg_acc_group:0 1.0
wandb:       train/processed_data_count_group:0 1154.0
wandb:          train/update_data_count_group:0 1154.0
wandb:         train/update_batch_count_group:0 25.0
wandb:                   train/avg_loss_group:1 0.05083
wandb:               train/exp_avg_loss_group:1 0.05967
wandb:                    train/avg_acc_group:1 1.0
wandb:       train/processed_data_count_group:1 65.0
wandb:          train/update_data_count_group:1 65.0
wandb:         train/update_batch_count_group:1 25.0
wandb:                   train/avg_loss_group:2 0.07892
wandb:               train/exp_avg_loss_group:2 0.08962
wandb:                    train/avg_acc_group:2 1.0
wandb:       train/processed_data_count_group:2 19.0
wandb:          train/update_data_count_group:2 19.0
wandb:         train/update_batch_count_group:2 13.0
wandb:                   train/avg_loss_group:3 0.02556
wandb:               train/exp_avg_loss_group:3 0.01996
wandb:                    train/avg_acc_group:3 1.0
wandb:       train/processed_data_count_group:3 357.0
wandb:          train/update_data_count_group:3 357.0
wandb:         train/update_batch_count_group:3 25.0
wandb:                    train/avg_actual_loss 0.01309
wandb:                train/avg_per_sample_loss 0.0131
wandb:                            train/avg_acc 1.0
wandb:                      train/model_norm_sq 8432.45898
wandb:                           train/reg_loss 0.0
wandb:                              train/epoch 305
wandb:                              train/batch 49
wandb:                                    epoch 305
wandb:                                batch_idx 90
wandb:                                    _step 1223
wandb:                                 _runtime 23568
wandb:                               _timestamp 1657523601
wandb:                     val/avg_loss_group:0 0.02131
wandb:                 val/exp_avg_loss_group:0 0.01881
wandb:                      val/avg_acc_group:0 0.99572
wandb:         val/processed_data_count_group:0 467.0
wandb:            val/update_data_count_group:0 467.0
wandb:           val/update_batch_count_group:0 19.0
wandb:                     val/avg_loss_group:1 0.64122
wandb:                 val/exp_avg_loss_group:1 0.61973
wandb:                      val/avg_acc_group:1 0.68884
wandb:         val/processed_data_count_group:1 466.0
wandb:            val/update_data_count_group:1 466.0
wandb:           val/update_batch_count_group:1 19.0
wandb:                     val/avg_loss_group:2 1.74605
wandb:                 val/exp_avg_loss_group:2 1.84082
wandb:                      val/avg_acc_group:2 0.36842
wandb:         val/processed_data_count_group:2 133.0
wandb:            val/update_data_count_group:2 133.0
wandb:           val/update_batch_count_group:2 12.0
wandb:                     val/avg_loss_group:3 0.16464
wandb:                 val/exp_avg_loss_group:3 0.16157
wandb:                      val/avg_acc_group:3 0.94737
wandb:         val/processed_data_count_group:3 133.0
wandb:            val/update_data_count_group:3 133.0
wandb:           val/update_batch_count_group:3 12.0
wandb:                      val/avg_actual_loss 0.46592
wandb:                  val/avg_per_sample_loss 0.46946
wandb:                              val/avg_acc 0.8015
wandb:                        val/model_norm_sq 8432.45898
wandb:                             val/reg_loss 0.0
wandb:                    test/avg_loss_group:0 0.01921
wandb:                test/exp_avg_loss_group:0 0.01762
wandb:                     test/avg_acc_group:0 0.99734
wandb:        test/processed_data_count_group:0 2255.0
wandb:           test/update_data_count_group:0 2255.0
wandb:          test/update_batch_count_group:0 79.0
wandb:                    test/avg_loss_group:1 0.62487
wandb:                test/exp_avg_loss_group:1 0.66192
wandb:                     test/avg_acc_group:1 0.69933
wandb:        test/processed_data_count_group:1 2255.0
wandb:           test/update_data_count_group:1 2255.0
wandb:          test/update_batch_count_group:1 79.0
wandb:                    test/avg_loss_group:2 1.47581
wandb:                test/exp_avg_loss_group:2 1.56635
wandb:                     test/avg_acc_group:2 0.38629
wandb:        test/processed_data_count_group:2 642.0
wandb:           test/update_data_count_group:2 642.0
wandb:          test/update_batch_count_group:2 32.0
wandb:                    test/avg_loss_group:3 0.19777
wandb:                test/exp_avg_loss_group:3 0.19916
wandb:                     test/avg_acc_group:3 0.92523
wandb:        test/processed_data_count_group:3 642.0
wandb:           test/update_data_count_group:3 642.0
wandb:          test/update_batch_count_group:3 30.0
wandb:                     test/avg_actual_loss 0.43518
wandb:                 test/avg_per_sample_loss 0.43611
wandb:                             test/avg_acc 0.80566
wandb:                       test/model_norm_sq 8432.45898
wandb:                            test/reg_loss 0.0
wandb: Run history:
wandb:               train/avg_loss_group:0 ‚ñà‚ñá‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:           train/exp_avg_loss_group:0 ‚ñà‚ñá‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                train/avg_acc_group:0 ‚ñà‚ñà‚ñÅ‚ñà‚ñÅ‚ñÅ‚ñà‚ñÅ‚ñà‚ñà‚ñÅ‚ñÅ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñÅ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:   train/processed_data_count_group:0 ‚ñÑ‚ñÑ‚ñÇ‚ñÖ‚ñá‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñÉ‚ñÜ‚ñÖ‚ñÅ‚ñá‚ñÖ‚ñÜ‚ñà‚ñà‚ñÖ‚ñÑ‚ñÉ‚ñá‚ñÑ‚ñÉ‚ñÑ‚ñÖ‚ñà‚ñÑ‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÜ‚ñÇ‚ñà‚ñÖ‚ñá‚ñÑ‚ñÜ
wandb:      train/update_data_count_group:0 ‚ñÑ‚ñÑ‚ñÇ‚ñÖ‚ñá‚ñÖ‚ñÖ‚ñÜ‚ñá‚ñá‚ñÉ‚ñÜ‚ñÖ‚ñÅ‚ñá‚ñÖ‚ñÜ‚ñà‚ñà‚ñÖ‚ñÑ‚ñÉ‚ñá‚ñÑ‚ñÉ‚ñÑ‚ñÖ‚ñà‚ñÑ‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÜ‚ñÇ‚ñà‚ñÖ‚ñá‚ñÑ‚ñÜ
wandb:     train/update_batch_count_group:0 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:               train/avg_loss_group:1 ‚ñÖ‚ñÜ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÑ‚ñÜ‚ñÖ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:           train/exp_avg_loss_group:1 ‚ñÖ‚ñÖ‚ñá‚ñÜ‚ñà‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÜ‚ñÖ‚ñÉ‚ñÖ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ
wandb:                train/avg_acc_group:1 ‚ñà‚ñá‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÖ‚ñÜ‚ñÖ‚ñÜ‚ñá‚ñá‚ñÜ‚ñá‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñà‚ñà
wandb:   train/processed_data_count_group:1 ‚ñÉ‚ñÑ‚ñÜ‚ñÜ‚ñÉ‚ñÉ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÅ‚ñÉ‚ñÉ‚ñÖ‚ñÅ‚ñÉ‚ñÑ‚ñÇ‚ñÖ‚ñá‚ñÜ‚ñÑ‚ñÑ‚ñÖ‚ñÉ‚ñà‚ñÖ‚ñÑ‚ñÖ‚ñÜ‚ñÖ‚ñÑ‚ñÖ‚ñÉ
wandb:      train/update_data_count_group:1 ‚ñÉ‚ñÑ‚ñÜ‚ñÜ‚ñÉ‚ñÉ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÅ‚ñÉ‚ñÉ‚ñÖ‚ñÅ‚ñÉ‚ñÑ‚ñÇ‚ñÖ‚ñá‚ñÜ‚ñÑ‚ñÑ‚ñÖ‚ñÉ‚ñà‚ñÖ‚ñÑ‚ñÖ‚ñÜ‚ñÖ‚ñÑ‚ñÖ‚ñÉ
wandb:     train/update_batch_count_group:1 ‚ñà‚ñÉ‚ñÜ‚ñÜ‚ñÉ‚ñà‚ñÖ‚ñÜ‚ñÅ‚ñÉ‚ñÖ‚ñÅ‚ñà‚ñÜ‚ñà‚ñÖ‚ñÜ‚ñÅ‚ñÉ‚ñÖ‚ñÜ‚ñÜ‚ñÅ‚ñÉ‚ñÉ‚ñÖ‚ñÖ‚ñÉ‚ñÉ‚ñÖ‚ñÖ‚ñà‚ñÜ‚ñÅ‚ñÉ‚ñÉ‚ñÖ‚ñÉ‚ñÜ‚ñÖ
wandb:               train/avg_loss_group:2 ‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:           train/exp_avg_loss_group:2 ‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                train/avg_acc_group:2 ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÉ‚ñÉ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñÜ‚ñÜ‚ñá‚ñà‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:   train/processed_data_count_group:2 ‚ñÇ‚ñá‚ñÉ‚ñÅ‚ñÇ‚ñÇ‚ñÖ‚ñÜ‚ñÉ‚ñÇ‚ñÖ‚ñá‚ñÅ‚ñÖ‚ñÅ‚ñÉ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÇ‚ñÉ‚ñà‚ñÖ‚ñÖ‚ñÉ‚ñÜ‚ñÇ‚ñÇ‚ñÑ‚ñÖ‚ñÅ‚ñÖ‚ñÉ‚ñÜ‚ñÇ‚ñÜ‚ñÉ
wandb:      train/update_data_count_group:2 ‚ñÇ‚ñá‚ñÉ‚ñÅ‚ñÇ‚ñÇ‚ñÖ‚ñÜ‚ñÉ‚ñÇ‚ñÖ‚ñá‚ñÅ‚ñÖ‚ñÅ‚ñÉ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÇ‚ñÉ‚ñà‚ñÖ‚ñÖ‚ñÉ‚ñÜ‚ñÇ‚ñÇ‚ñÑ‚ñÖ‚ñÅ‚ñÖ‚ñÉ‚ñÜ‚ñÇ‚ñÜ‚ñÉ
wandb:     train/update_batch_count_group:2 ‚ñÑ‚ñÖ‚ñÜ‚ñÑ‚ñÇ‚ñÑ‚ñá‚ñá‚ñÑ‚ñÉ‚ñá‚ñá‚ñÇ‚ñá‚ñÅ‚ñÇ‚ñÖ‚ñÇ‚ñÖ‚ñÉ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñà‚ñÜ‚ñÖ‚ñÑ‚ñÖ‚ñÑ‚ñÑ‚ñá‚ñÑ‚ñÇ‚ñÜ‚ñÖ‚ñá‚ñÑ‚ñà‚ñÖ
wandb:               train/avg_loss_group:3 ‚ñà‚ñÜ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:           train/exp_avg_loss_group:3 ‚ñà‚ñÜ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                train/avg_acc_group:3 ‚ñÅ‚ñÉ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:   train/processed_data_count_group:3 ‚ñá‚ñÖ‚ñá‚ñÑ‚ñÉ‚ñÜ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñá‚ñÉ‚ñÖ‚ñà‚ñÉ‚ñÑ‚ñÜ‚ñÉ‚ñÉ‚ñÖ‚ñá‚ñá‚ñÑ‚ñá‚ñÖ‚ñÑ‚ñÉ‚ñÇ‚ñÖ‚ñÑ‚ñÜ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÅ‚ñÑ‚ñÉ‚ñÖ‚ñÖ
wandb:      train/update_data_count_group:3 ‚ñá‚ñÖ‚ñá‚ñÑ‚ñÉ‚ñÜ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñá‚ñÉ‚ñÖ‚ñà‚ñÉ‚ñÑ‚ñÜ‚ñÉ‚ñÉ‚ñÖ‚ñá‚ñá‚ñÑ‚ñá‚ñÖ‚ñÑ‚ñÉ‚ñÇ‚ñÖ‚ñÑ‚ñÜ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÅ‚ñÑ‚ñÉ‚ñÖ‚ñÖ
wandb:     train/update_batch_count_group:3 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                train/avg_actual_loss ‚ñà‚ñÜ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:            train/avg_per_sample_loss ‚ñà‚ñÜ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                        train/avg_acc ‚ñÅ‚ñÉ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:                  train/model_norm_sq ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:                       train/reg_loss ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                          train/epoch ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà
wandb:                          train/batch ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                                epoch ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà
wandb:                            batch_idx ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                                _step ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà
wandb:                             _runtime ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà
wandb:                           _timestamp ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà
wandb:                 val/avg_loss_group:0 ‚ñà‚ñÜ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:             val/exp_avg_loss_group:0 ‚ñà‚ñÜ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                  val/avg_acc_group:0 ‚ñà‚ñà‚ñà‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÅ‚ñÉ‚ñÉ‚ñÜ‚ñÉ‚ñÅ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÅ‚ñÉ‚ñÉ‚ñÜ‚ñÉ
wandb:     val/processed_data_count_group:0 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:        val/update_data_count_group:0 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       val/update_batch_count_group:0 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                 val/avg_loss_group:1 ‚ñÅ‚ñÇ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÖ‚ñá‚ñá‚ñÜ‚ñá‚ñÜ‚ñÜ‚ñá‚ñÜ‚ñÜ‚ñÑ‚ñÜ‚ñá‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÜ‚ñÖ‚ñÜ‚ñÜ‚ñà‚ñÜ‚ñá‚ñÑ‚ñÜ
wandb:             val/exp_avg_loss_group:1 ‚ñÅ‚ñÇ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñÜ‚ñá‚ñÖ‚ñá‚ñá‚ñÜ‚ñá‚ñÜ‚ñÜ‚ñá‚ñÜ‚ñÜ‚ñÑ‚ñÜ‚ñá‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÜ‚ñÖ‚ñÜ‚ñÜ‚ñà‚ñÜ‚ñá‚ñÑ‚ñÜ
wandb:                  val/avg_acc_group:1 ‚ñà‚ñà‚ñÖ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÅ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÇ‚ñÉ‚ñÇ‚ñÉ‚ñÅ‚ñÉ‚ñÇ‚ñÑ‚ñÉ
wandb:     val/processed_data_count_group:1 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:        val/update_data_count_group:1 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       val/update_batch_count_group:1 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                 val/avg_loss_group:2 ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÖ‚ñÑ‚ñÖ‚ñÑ‚ñÖ‚ñÖ‚ñÑ‚ñÖ‚ñÖ‚ñá‚ñÜ‚ñÑ‚ñá‚ñÖ‚ñÜ‚ñÜ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñÜ‚ñá‚ñÜ‚ñÜ‚ñÑ‚ñÜ‚ñÖ‚ñà‚ñá
wandb:             val/exp_avg_loss_group:2 ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÖ‚ñÑ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÖ‚ñÖ‚ñá‚ñÜ‚ñÑ‚ñá‚ñÖ‚ñÜ‚ñÜ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñÜ‚ñá‚ñÜ‚ñÜ‚ñÑ‚ñÜ‚ñÖ‚ñà‚ñá
wandb:                  val/avg_acc_group:2 ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÑ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñÜ‚ñá‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñá‚ñÜ‚ñá‚ñá‚ñà‚ñá‚ñà‚ñá‚ñá
wandb:     val/processed_data_count_group:2 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:        val/update_data_count_group:2 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       val/update_batch_count_group:2 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                 val/avg_loss_group:3 ‚ñà‚ñÜ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:             val/exp_avg_loss_group:3 ‚ñà‚ñÜ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                  val/avg_acc_group:3 ‚ñÅ‚ñÉ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:     val/processed_data_count_group:3 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:        val/update_data_count_group:3 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       val/update_batch_count_group:3 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                  val/avg_actual_loss ‚ñá‚ñÑ‚ñÑ‚ñÖ‚ñà‚ñà‚ñà‚ñà‚ñÜ‚ñá‚ñÑ‚ñÜ‚ñÜ‚ñÖ‚ñÜ‚ñÑ‚ñÖ‚ñÜ‚ñÑ‚ñÑ‚ñÅ‚ñÉ‚ñÜ‚ñÇ‚ñÉ‚ñÑ‚ñÉ‚ñÑ‚ñÉ‚ñÑ‚ñÇ‚ñÑ‚ñÉ‚ñÑ‚ñÉ‚ñá‚ñÉ‚ñÑ‚ñÅ‚ñÑ
wandb:              val/avg_per_sample_loss ‚ñá‚ñÑ‚ñÑ‚ñÖ‚ñà‚ñà‚ñà‚ñà‚ñÜ‚ñá‚ñÑ‚ñÜ‚ñÜ‚ñÖ‚ñÜ‚ñÑ‚ñÖ‚ñÜ‚ñÑ‚ñÑ‚ñÅ‚ñÉ‚ñÜ‚ñÇ‚ñÉ‚ñÑ‚ñÉ‚ñÑ‚ñÉ‚ñÑ‚ñÇ‚ñÑ‚ñÉ‚ñÑ‚ñÉ‚ñá‚ñÉ‚ñÑ‚ñÅ‚ñÑ
wandb:                          val/avg_acc ‚ñÑ‚ñÜ‚ñÖ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÑ‚ñÖ‚ñÖ‚ñá‚ñÜ‚ñÑ‚ñÜ‚ñÖ‚ñÖ‚ñÜ‚ñÖ‚ñÜ‚ñÖ‚ñá‚ñÜ‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñá‚ñÜ‚ñà‚ñá
wandb:                    val/model_norm_sq ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:                         val/reg_loss ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                test/avg_loss_group:0 ‚ñà‚ñá‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:            test/exp_avg_loss_group:0 ‚ñà‚ñÜ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                 test/avg_acc_group:0 ‚ñà‚ñá‚ñÖ‚ñÉ‚ñÅ‚ñÉ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÉ‚ñÇ‚ñÑ‚ñÅ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÜ‚ñÑ‚ñÉ‚ñÖ‚ñÉ‚ñÉ‚ñÑ‚ñÉ‚ñÑ‚ñÉ‚ñÖ‚ñÉ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ
wandb:    test/processed_data_count_group:0 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test/update_data_count_group:0 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:      test/update_batch_count_group:0 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                test/avg_loss_group:1 ‚ñÅ‚ñÇ‚ñÑ‚ñÖ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÖ‚ñá‚ñá‚ñÜ‚ñá‚ñÜ‚ñÜ‚ñà‚ñÜ‚ñá‚ñÑ‚ñÜ‚ñá‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÜ‚ñÖ‚ñÜ‚ñÜ‚ñà‚ñÜ‚ñá‚ñÑ‚ñÖ
wandb:            test/exp_avg_loss_group:1 ‚ñÅ‚ñÇ‚ñÑ‚ñÖ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñá‚ñá‚ñÜ‚ñá‚ñÜ‚ñá‚ñà‚ñá‚ñá‚ñÑ‚ñÜ‚ñá‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÜ‚ñÖ‚ñÜ‚ñÜ‚ñà‚ñÜ‚ñá‚ñÑ‚ñÜ
wandb:                 test/avg_acc_group:1 ‚ñà‚ñà‚ñÖ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÑ‚ñÉ‚ñÇ‚ñÉ‚ñÇ‚ñÉ‚ñÉ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÉ‚ñÇ‚ñÑ‚ñÉ
wandb:    test/processed_data_count_group:1 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test/update_data_count_group:1 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:      test/update_batch_count_group:1 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                test/avg_loss_group:2 ‚ñÅ‚ñÅ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñá‚ñÑ‚ñÉ‚ñÖ‚ñÑ‚ñÖ‚ñÖ‚ñÉ‚ñÑ‚ñÑ‚ñà‚ñÜ‚ñÉ‚ñá‚ñÑ‚ñÖ‚ñÖ‚ñÑ‚ñÖ‚ñÖ‚ñá‚ñÖ‚ñá‚ñÖ‚ñÜ‚ñÉ‚ñÖ‚ñÑ‚ñà‚ñá
wandb:            test/exp_avg_loss_group:2 ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñá‚ñÑ‚ñÉ‚ñÖ‚ñÑ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÖ‚ñà‚ñÜ‚ñÑ‚ñá‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñá‚ñÖ‚ñá‚ñÖ‚ñÜ‚ñÉ‚ñÜ‚ñÖ‚ñà‚ñá
wandb:                 test/avg_acc_group:2 ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÑ‚ñÖ‚ñÜ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÜ‚ñá‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñá‚ñà‚ñÜ‚ñá
wandb:    test/processed_data_count_group:2 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test/update_data_count_group:2 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:      test/update_batch_count_group:2 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                test/avg_loss_group:3 ‚ñà‚ñÜ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ
wandb:            test/exp_avg_loss_group:3 ‚ñà‚ñÜ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                 test/avg_acc_group:3 ‚ñÅ‚ñÉ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:    test/processed_data_count_group:3 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test/update_data_count_group:3 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:      test/update_batch_count_group:3 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                 test/avg_actual_loss ‚ñà‚ñÜ‚ñÖ‚ñÜ‚ñà‚ñà‚ñà‚ñá‚ñÜ‚ñá‚ñÖ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÖ‚ñÜ‚ñÑ‚ñÑ‚ñÇ‚ñÉ‚ñÖ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÉ‚ñÇ‚ñÉ‚ñÇ‚ñÖ‚ñÇ‚ñÉ‚ñÅ‚ñÉ
wandb:             test/avg_per_sample_loss ‚ñà‚ñÜ‚ñÖ‚ñÜ‚ñà‚ñà‚ñà‚ñá‚ñÜ‚ñá‚ñÖ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÖ‚ñÜ‚ñÑ‚ñÑ‚ñÇ‚ñÉ‚ñÖ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÉ‚ñÇ‚ñÉ‚ñÇ‚ñÖ‚ñÇ‚ñÉ‚ñÅ‚ñÉ
wandb:                         test/avg_acc ‚ñÑ‚ñÜ‚ñÖ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÑ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñá‚ñÜ‚ñÑ‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñÜ‚ñá‚ñÜ‚ñá‚ñÖ‚ñá‚ñÜ‚ñà‚ñá
wandb:                   test/model_norm_sq ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:                        test/reg_loss ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: 
wandb: Synced 5 W&B file(s), 1 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: 
wandb: Synced glamorous-sea-34: https://wandb.ai/gaotang/spurious_CUB/runs/e3nkrqsx

Done
