wandb: Currently logged in as: gaotang (use `wandb login --relogin` to force relogin)
wandb: wandb version 0.12.21 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.10.8
wandb: Syncing run graceful-butterfly-57
wandb: ‚≠êÔ∏è View project at https://wandb.ai/gaotang/spurious_CUB
wandb: üöÄ View run at https://wandb.ai/gaotang/spurious_CUB/runs/3u7z0meo
wandb: Run data is saved locally in wandb/run-20220715_135613-3u7z0meo
wandb: Run `wandb off` to turn off syncing.
Dataset: CUB
Shift type: confounder
Wandb: True
Project name: spurious
Target name: waterbird_complete95
Confounder names: ['forest2water2']
Up weight: 50
Resume: False
Minority fraction: None
Imbalance ratio: None
Fraction: 1.0
Root dir: ./cub
Reweight groups: False
Augment data: False
Val fraction: 0.1
Loss type: erm
Alpha: 0.2
Generalization adjustment: 0.0
Automatic adjustment: False
Robust step size: 0.01
Joint dro alpha: 1
Use normalized loss: False
Btl: False
Hinge: False
Model: resnet50
Train from scratch: False
N epochs: 80
Batch size: 64
Lr: 1e-05
Scheduler: False
Weight decay: 1.0
Gamma: 0.1
Minimum variational weight: 0
Seed: 0
Show progress: False
Log dir: results/CUB/CUB_sample_exp/train_downstream_ERM_upweight_0_epochs_80_lr_1e-05_weight_decay_0.0/final_epoch31/JTT_upweight_50_epochs_80_lr_1e-05_weight_decay_1.0/model_outputs
Log every: 50
Save step: 10
Save best: False
Save last: False
Use bert params: 1
Num folds per sweep: 5
Num sweeps: 4
Q: 0.7
Metadata csv name: metadata.csv
Fold: None
Metadata path: results/CUB/CUB_sample_exp/train_downstream_ERM_upweight_0_epochs_80_lr_1e-05_weight_decay_0.0/final_epoch31/metadata_aug.csv
Aug col: wrong_1_times

Reading './cub/data/waterbird_complete95_forest2water2/metadata.csv'
length of train_data:  4795
length of test_data:  5794
length of val_data:  1199
args fold:  None
len 4795 195
Up-weight factor: 50
Training Data...
    waterbird_complete95 = 0, forest2water2 = 0: n = 3798
    waterbird_complete95 = 0, forest2water2 = 1: n = 2934
    waterbird_complete95 = 1, forest2water2 = 0: n = 2306
    waterbird_complete95 = 1, forest2water2 = 1: n = 5507
Validation Data...
    waterbird_complete95 = 0, forest2water2 = 0: n = 467
    waterbird_complete95 = 0, forest2water2 = 1: n = 466
    waterbird_complete95 = 1, forest2water2 = 0: n = 133
    waterbird_complete95 = 1, forest2water2 = 1: n = 133
Test Data...
    waterbird_complete95 = 0, forest2water2 = 0: n = 2255
    waterbird_complete95 = 0, forest2water2 = 1: n = 2255
    waterbird_complete95 = 1, forest2water2 = 0: n = 642
    waterbird_complete95 = 1, forest2water2 = 1: n = 642

Epoch [0]:
Training:
/home/gaotang/jtt/venv/lib/python3.6/site-packages/torch/nn/modules/module.py:795: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.
  warnings.warn("Using a non-full backward hook when the forward contains multiple autograd Nodes "
Average incurred loss: 0.724  
Average sample loss: 0.724  
Average acc: 0.446  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 835]:	loss = 0.658  exp loss = 0.712  adjusted loss = 0.712  adv prob = 0.250000   acc = 0.624
  waterbird_complete95 = 0, forest2water2 = 1  [n = 627]:	loss = 0.593  exp loss = 0.640  adjusted loss = 0.640  adv prob = 0.250000   acc = 0.815
  waterbird_complete95 = 1, forest2water2 = 0  [n = 516]:	loss = 0.739  exp loss = 0.676  adjusted loss = 0.676  adv prob = 0.250000   acc = 0.347
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1222]:	loss = 0.829  exp loss = 0.765  adjusted loss = 0.765  adv prob = 0.250000   acc = 0.176
Average incurred loss: 0.696  
Average sample loss: 0.696  
Average acc: 0.513  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 846]:	loss = 0.776  exp loss = 0.793  adjusted loss = 0.793  adv prob = 0.250000   acc = 0.272
  waterbird_complete95 = 0, forest2water2 = 1  [n = 618]:	loss = 0.708  exp loss = 0.721  adjusted loss = 0.721  adv prob = 0.250000   acc = 0.469
  waterbird_complete95 = 1, forest2water2 = 0  [n = 524]:	loss = 0.597  exp loss = 0.588  adjusted loss = 0.588  adv prob = 0.250000   acc = 0.805
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1212]:	loss = 0.676  exp loss = 0.653  adjusted loss = 0.653  adv prob = 0.250000   acc = 0.577
Average incurred loss: 0.687  
Average sample loss: 0.687  
Average acc: 0.549  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 850]:	loss = 0.794  exp loss = 0.788  adjusted loss = 0.788  adv prob = 0.250000   acc = 0.229
  waterbird_complete95 = 0, forest2water2 = 1  [n = 657]:	loss = 0.721  exp loss = 0.717  adjusted loss = 0.717  adv prob = 0.250000   acc = 0.451
  waterbird_complete95 = 1, forest2water2 = 0  [n = 483]:	loss = 0.565  exp loss = 0.551  adjusted loss = 0.551  adv prob = 0.250000   acc = 0.917
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1210]:	loss = 0.642  exp loss = 0.635  adjusted loss = 0.635  adv prob = 0.250000   acc = 0.680
Average incurred loss: 0.678  
Average sample loss: 0.678  
Average acc: 0.570  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 856]:	loss = 0.794  exp loss = 0.784  adjusted loss = 0.784  adv prob = 0.250000   acc = 0.218
  waterbird_complete95 = 0, forest2water2 = 1  [n = 642]:	loss = 0.711  exp loss = 0.715  adjusted loss = 0.715  adv prob = 0.250000   acc = 0.472
  waterbird_complete95 = 1, forest2water2 = 0  [n = 482]:	loss = 0.554  exp loss = 0.546  adjusted loss = 0.546  adv prob = 0.250000   acc = 0.946
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1220]:	loss = 0.629  exp loss = 0.635  adjusted loss = 0.635  adv prob = 0.250000   acc = 0.720
Saved results/CUB/CUB_sample_exp/train_downstream_ERM_upweight_0_epochs_80_lr_1e-05_weight_decay_0.0/final_epoch31/JTT_upweight_50_epochs_80_lr_1e-05_weight_decay_1.0/model_outputs/output_train_epoch_0.csv
logged to wandb
Average incurred loss: 0.672  
Average sample loss: 0.672  
Average acc: 0.572  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 411]:	loss = 0.792  exp loss = 0.792  adjusted loss = 0.792  adv prob = 0.250000   acc = 0.224
  waterbird_complete95 = 0, forest2water2 = 1  [n = 390]:	loss = 0.709  exp loss = 0.705  adjusted loss = 0.705  adv prob = 0.250000   acc = 0.446
  waterbird_complete95 = 1, forest2water2 = 0  [n = 301]:	loss = 0.550  exp loss = 0.551  adjusted loss = 0.551  adv prob = 0.250000   acc = 0.957
  waterbird_complete95 = 1, forest2water2 = 1  [n = 643]:	loss = 0.631  exp loss = 0.625  adjusted loss = 0.625  adv prob = 0.250000   acc = 0.691

Validation:
Saved results/CUB/CUB_sample_exp/train_downstream_ERM_upweight_0_epochs_80_lr_1e-05_weight_decay_0.0/final_epoch31/JTT_upweight_50_epochs_80_lr_1e-05_weight_decay_1.0/model_outputs/output_val_epoch_0.csv
logged to wandb
Average incurred loss: 0.709  
Average sample loss: 0.709  
Average acc: 0.481  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.797  exp loss = 0.792  adjusted loss = 0.792  adv prob = 0.250000   acc = 0.246
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.707  exp loss = 0.709  adjusted loss = 0.709  adv prob = 0.250000   acc = 0.500
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 0.536  exp loss = 0.558  adjusted loss = 0.558  adv prob = 0.250000   acc = 0.902
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.586  exp loss = 0.579  adjusted loss = 0.579  adv prob = 0.250000   acc = 0.820
Spurious Score = 0.760
Saved results/CUB/CUB_sample_exp/train_downstream_ERM_upweight_0_epochs_80_lr_1e-05_weight_decay_0.0/final_epoch31/JTT_upweight_50_epochs_80_lr_1e-05_weight_decay_1.0/model_outputs/output_test_epoch_0.csv
logged to wandb
Current lr: 0.000010


Epoch [1]:
Training:
Average incurred loss: 0.665  
Average sample loss: 0.665  
Average acc: 0.600  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 811]:	loss = 0.796  exp loss = 0.795  adjusted loss = 0.795  adv prob = 0.250000   acc = 0.233
  waterbird_complete95 = 0, forest2water2 = 1  [n = 663]:	loss = 0.708  exp loss = 0.699  adjusted loss = 0.699  adv prob = 0.250000   acc = 0.496
  waterbird_complete95 = 1, forest2water2 = 0  [n = 501]:	loss = 0.523  exp loss = 0.509  adjusted loss = 0.509  adv prob = 0.250000   acc = 0.982
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1225]:	loss = 0.615  exp loss = 0.608  adjusted loss = 0.608  adv prob = 0.250000   acc = 0.744
Average incurred loss: 0.656  
Average sample loss: 0.656  
Average acc: 0.618  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 847]:	loss = 0.783  exp loss = 0.779  adjusted loss = 0.779  adv prob = 0.250000   acc = 0.249
  waterbird_complete95 = 0, forest2water2 = 1  [n = 646]:	loss = 0.694  exp loss = 0.688  adjusted loss = 0.688  adv prob = 0.250000   acc = 0.508
  waterbird_complete95 = 1, forest2water2 = 0  [n = 513]:	loss = 0.522  exp loss = 0.522  adjusted loss = 0.522  adv prob = 0.250000   acc = 0.977
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1194]:	loss = 0.602  exp loss = 0.609  adjusted loss = 0.609  adv prob = 0.250000   acc = 0.785
Average incurred loss: 0.650  
Average sample loss: 0.650  
Average acc: 0.629  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 843]:	loss = 0.770  exp loss = 0.766  adjusted loss = 0.766  adv prob = 0.250000   acc = 0.298
  waterbird_complete95 = 0, forest2water2 = 1  [n = 635]:	loss = 0.682  exp loss = 0.684  adjusted loss = 0.684  adv prob = 0.250000   acc = 0.532
  waterbird_complete95 = 1, forest2water2 = 0  [n = 483]:	loss = 0.523  exp loss = 0.525  adjusted loss = 0.525  adv prob = 0.250000   acc = 0.969
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1239]:	loss = 0.602  exp loss = 0.592  adjusted loss = 0.592  adv prob = 0.250000   acc = 0.772
Average incurred loss: 0.643  
Average sample loss: 0.643  
Average acc: 0.644  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 813]:	loss = 0.780  exp loss = 0.784  adjusted loss = 0.784  adv prob = 0.250000   acc = 0.296
  waterbird_complete95 = 0, forest2water2 = 1  [n = 622]:	loss = 0.684  exp loss = 0.677  adjusted loss = 0.677  adv prob = 0.250000   acc = 0.532
  waterbird_complete95 = 1, forest2water2 = 0  [n = 540]:	loss = 0.507  exp loss = 0.492  adjusted loss = 0.492  adv prob = 0.250000   acc = 0.952
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1225]:	loss = 0.590  exp loss = 0.587  adjusted loss = 0.587  adv prob = 0.250000   acc = 0.797
Saved results/CUB/CUB_sample_exp/train_downstream_ERM_upweight_0_epochs_80_lr_1e-05_weight_decay_0.0/final_epoch31/JTT_upweight_50_epochs_80_lr_1e-05_weight_decay_1.0/model_outputs/output_train_epoch_1.csv
logged to wandb
Average incurred loss: 0.644  
Average sample loss: 0.642  
Average acc: 0.631  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 484]:	loss = 0.771  exp loss = 0.762  adjusted loss = 0.762  adv prob = 0.250000   acc = 0.308
  waterbird_complete95 = 0, forest2water2 = 1  [n = 368]:	loss = 0.687  exp loss = 0.671  adjusted loss = 0.671  adv prob = 0.250000   acc = 0.519
  waterbird_complete95 = 1, forest2water2 = 0  [n = 269]:	loss = 0.502  exp loss = 0.516  adjusted loss = 0.516  adv prob = 0.250000   acc = 0.963
  waterbird_complete95 = 1, forest2water2 = 1  [n = 624]:	loss = 0.580  exp loss = 0.579  adjusted loss = 0.579  adv prob = 0.250000   acc = 0.804

Validation:
Saved results/CUB/CUB_sample_exp/train_downstream_ERM_upweight_0_epochs_80_lr_1e-05_weight_decay_0.0/final_epoch31/JTT_upweight_50_epochs_80_lr_1e-05_weight_decay_1.0/model_outputs/output_val_epoch_1.csv
logged to wandb
Average incurred loss: 0.685  
Average sample loss: 0.685  
Average acc: 0.542  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.776  exp loss = 0.775  adjusted loss = 0.775  adv prob = 0.250000   acc = 0.306
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.679  exp loss = 0.685  adjusted loss = 0.685  adv prob = 0.250000   acc = 0.575
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 0.507  exp loss = 0.529  adjusted loss = 0.529  adv prob = 0.250000   acc = 0.932
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.566  exp loss = 0.558  adjusted loss = 0.558  adv prob = 0.250000   acc = 0.865
Spurious Score = 0.777
Saved results/CUB/CUB_sample_exp/train_downstream_ERM_upweight_0_epochs_80_lr_1e-05_weight_decay_0.0/final_epoch31/JTT_upweight_50_epochs_80_lr_1e-05_weight_decay_1.0/model_outputs/output_test_epoch_1.csv
logged to wandb
Current lr: 0.000010


Epoch [2]:
Training:
Average incurred loss: 0.636  
Average sample loss: 0.636  
Average acc: 0.670  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 861]:	loss = 0.745  exp loss = 0.743  adjusted loss = 0.743  adv prob = 0.250000   acc = 0.381
  waterbird_complete95 = 0, forest2water2 = 1  [n = 669]:	loss = 0.647  exp loss = 0.630  adjusted loss = 0.630  adv prob = 0.250000   acc = 0.680
  waterbird_complete95 = 1, forest2water2 = 0  [n = 458]:	loss = 0.516  exp loss = 0.506  adjusted loss = 0.506  adv prob = 0.250000   acc = 0.945
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1212]:	loss = 0.599  exp loss = 0.599  adjusted loss = 0.599  adv prob = 0.250000   acc = 0.765
Average incurred loss: 0.627  
Average sample loss: 0.627  
Average acc: 0.696  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 848]:	loss = 0.729  exp loss = 0.734  adjusted loss = 0.734  adv prob = 0.250000   acc = 0.439
  waterbird_complete95 = 0, forest2water2 = 1  [n = 632]:	loss = 0.640  exp loss = 0.637  adjusted loss = 0.637  adv prob = 0.250000   acc = 0.691
  waterbird_complete95 = 1, forest2water2 = 0  [n = 510]:	loss = 0.508  exp loss = 0.507  adjusted loss = 0.507  adv prob = 0.250000   acc = 0.963
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1210]:	loss = 0.599  exp loss = 0.591  adjusted loss = 0.591  adv prob = 0.250000   acc = 0.766
Average incurred loss: 0.619  
Average sample loss: 0.619  
Average acc: 0.692  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 799]:	loss = 0.743  exp loss = 0.739  adjusted loss = 0.739  adv prob = 0.250000   acc = 0.393
  waterbird_complete95 = 0, forest2water2 = 1  [n = 662]:	loss = 0.649  exp loss = 0.641  adjusted loss = 0.641  adv prob = 0.250000   acc = 0.650
  waterbird_complete95 = 1, forest2water2 = 0  [n = 519]:	loss = 0.485  exp loss = 0.483  adjusted loss = 0.483  adv prob = 0.250000   acc = 0.971
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1220]:	loss = 0.579  exp loss = 0.571  adjusted loss = 0.571  adv prob = 0.250000   acc = 0.792
Average incurred loss: 0.616  
Average sample loss: 0.616  
Average acc: 0.693  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 854]:	loss = 0.748  exp loss = 0.735  adjusted loss = 0.735  adv prob = 0.250000   acc = 0.383
  waterbird_complete95 = 0, forest2water2 = 1  [n = 627]:	loss = 0.644  exp loss = 0.626  adjusted loss = 0.626  adv prob = 0.250000   acc = 0.686
  waterbird_complete95 = 1, forest2water2 = 0  [n = 509]:	loss = 0.479  exp loss = 0.479  adjusted loss = 0.479  adv prob = 0.250000   acc = 0.957
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1210]:	loss = 0.567  exp loss = 0.558  adjusted loss = 0.558  adv prob = 0.250000   acc = 0.806
Saved results/CUB/CUB_sample_exp/train_downstream_ERM_upweight_0_epochs_80_lr_1e-05_weight_decay_0.0/final_epoch31/JTT_upweight_50_epochs_80_lr_1e-05_weight_decay_1.0/model_outputs/output_train_epoch_2.csv
logged to wandb
Average incurred loss: 0.604  
Average sample loss: 0.606  
Average acc: 0.719  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 436]:	loss = 0.722  exp loss = 0.727  adjusted loss = 0.727  adv prob = 0.250000   acc = 0.454
  waterbird_complete95 = 0, forest2water2 = 1  [n = 344]:	loss = 0.636  exp loss = 0.637  adjusted loss = 0.637  adv prob = 0.250000   acc = 0.701
  waterbird_complete95 = 1, forest2water2 = 0  [n = 310]:	loss = 0.472  exp loss = 0.486  adjusted loss = 0.486  adv prob = 0.250000   acc = 0.971
  waterbird_complete95 = 1, forest2water2 = 1  [n = 655]:	loss = 0.572  exp loss = 0.569  adjusted loss = 0.569  adv prob = 0.250000   acc = 0.786

Validation:
Saved results/CUB/CUB_sample_exp/train_downstream_ERM_upweight_0_epochs_80_lr_1e-05_weight_decay_0.0/final_epoch31/JTT_upweight_50_epochs_80_lr_1e-05_weight_decay_1.0/model_outputs/output_val_epoch_2.csv
logged to wandb
Average incurred loss: 0.660  
Average sample loss: 0.660  
Average acc: 0.600  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.751  exp loss = 0.755  adjusted loss = 0.755  adv prob = 0.250000   acc = 0.366
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.649  exp loss = 0.660  adjusted loss = 0.660  adv prob = 0.250000   acc = 0.659
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 0.486  exp loss = 0.506  adjusted loss = 0.506  adv prob = 0.250000   acc = 0.947
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.553  exp loss = 0.542  adjusted loss = 0.542  adv prob = 0.250000   acc = 0.865
Spurious Score = 0.766
Saved results/CUB/CUB_sample_exp/train_downstream_ERM_upweight_0_epochs_80_lr_1e-05_weight_decay_0.0/final_epoch31/JTT_upweight_50_epochs_80_lr_1e-05_weight_decay_1.0/model_outputs/output_test_epoch_2.csv
logged to wandb
Current lr: 0.000010


Epoch [3]:
Training:
Average incurred loss: 0.607  
Average sample loss: 0.607  
Average acc: 0.716  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 835]:	loss = 0.733  exp loss = 0.717  adjusted loss = 0.717  adv prob = 0.250000   acc = 0.437
  waterbird_complete95 = 0, forest2water2 = 1  [n = 669]:	loss = 0.648  exp loss = 0.637  adjusted loss = 0.637  adv prob = 0.250000   acc = 0.697
  waterbird_complete95 = 1, forest2water2 = 0  [n = 468]:	loss = 0.462  exp loss = 0.454  adjusted loss = 0.454  adv prob = 0.250000   acc = 0.979
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1228]:	loss = 0.555  exp loss = 0.553  adjusted loss = 0.553  adv prob = 0.250000   acc = 0.817
Average incurred loss: 0.597  
Average sample loss: 0.597  
Average acc: 0.739  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 822]:	loss = 0.712  exp loss = 0.691  adjusted loss = 0.691  adv prob = 0.250000   acc = 0.490
  waterbird_complete95 = 0, forest2water2 = 1  [n = 626]:	loss = 0.610  exp loss = 0.591  adjusted loss = 0.591  adv prob = 0.250000   acc = 0.762
  waterbird_complete95 = 1, forest2water2 = 0  [n = 550]:	loss = 0.473  exp loss = 0.479  adjusted loss = 0.479  adv prob = 0.250000   acc = 0.956
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1202]:	loss = 0.569  exp loss = 0.566  adjusted loss = 0.566  adv prob = 0.250000   acc = 0.799
Average incurred loss: 0.598  
Average sample loss: 0.598  
Average acc: 0.719  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 857]:	loss = 0.735  exp loss = 0.724  adjusted loss = 0.724  adv prob = 0.250000   acc = 0.417
  waterbird_complete95 = 0, forest2water2 = 1  [n = 625]:	loss = 0.615  exp loss = 0.610  adjusted loss = 0.610  adv prob = 0.250000   acc = 0.738
  waterbird_complete95 = 1, forest2water2 = 0  [n = 485]:	loss = 0.453  exp loss = 0.445  adjusted loss = 0.445  adv prob = 0.250000   acc = 0.955
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1233]:	loss = 0.550  exp loss = 0.549  adjusted loss = 0.549  adv prob = 0.250000   acc = 0.826
Average incurred loss: 0.590  
Average sample loss: 0.590  
Average acc: 0.749  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 833]:	loss = 0.714  exp loss = 0.715  adjusted loss = 0.715  adv prob = 0.250000   acc = 0.486
  waterbird_complete95 = 0, forest2water2 = 1  [n = 657]:	loss = 0.614  exp loss = 0.607  adjusted loss = 0.607  adv prob = 0.250000   acc = 0.756
  waterbird_complete95 = 1, forest2water2 = 0  [n = 517]:	loss = 0.456  exp loss = 0.455  adjusted loss = 0.455  adv prob = 0.250000   acc = 0.967
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1193]:	loss = 0.549  exp loss = 0.556  adjusted loss = 0.556  adv prob = 0.250000   acc = 0.834
Saved results/CUB/CUB_sample_exp/train_downstream_ERM_upweight_0_epochs_80_lr_1e-05_weight_decay_0.0/final_epoch31/JTT_upweight_50_epochs_80_lr_1e-05_weight_decay_1.0/model_outputs/output_train_epoch_3.csv
logged to wandb
Average incurred loss: 0.582  
Average sample loss: 0.583  
Average acc: 0.757  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 451]:	loss = 0.707  exp loss = 0.705  adjusted loss = 0.705  adv prob = 0.250000   acc = 0.501
  waterbird_complete95 = 0, forest2water2 = 1  [n = 357]:	loss = 0.596  exp loss = 0.596  adjusted loss = 0.596  adv prob = 0.250000   acc = 0.798
  waterbird_complete95 = 1, forest2water2 = 0  [n = 286]:	loss = 0.450  exp loss = 0.454  adjusted loss = 0.454  adv prob = 0.250000   acc = 0.962
  waterbird_complete95 = 1, forest2water2 = 1  [n = 651]:	loss = 0.546  exp loss = 0.555  adjusted loss = 0.555  adv prob = 0.250000   acc = 0.822

Validation:
Saved results/CUB/CUB_sample_exp/train_downstream_ERM_upweight_0_epochs_80_lr_1e-05_weight_decay_0.0/final_epoch31/JTT_upweight_50_epochs_80_lr_1e-05_weight_decay_1.0/model_outputs/output_val_epoch_3.csv
logged to wandb
Average incurred loss: 0.634  
Average sample loss: 0.634  
Average acc: 0.657  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.721  exp loss = 0.727  adjusted loss = 0.727  adv prob = 0.250000   acc = 0.458
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.620  exp loss = 0.633  adjusted loss = 0.633  adv prob = 0.250000   acc = 0.719
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 0.474  exp loss = 0.494  adjusted loss = 0.494  adv prob = 0.250000   acc = 0.940
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.544  exp loss = 0.533  adjusted loss = 0.533  adv prob = 0.250000   acc = 0.857
Spurious Score = 0.793
Saved results/CUB/CUB_sample_exp/train_downstream_ERM_upweight_0_epochs_80_lr_1e-05_weight_decay_0.0/final_epoch31/JTT_upweight_50_epochs_80_lr_1e-05_weight_decay_1.0/model_outputs/output_test_epoch_3.csv
logged to wandb
Current lr: 0.000010


Epoch [4]:
Training:
Average incurred loss: 0.582  
Average sample loss: 0.582  
Average acc: 0.756  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 810]:	loss = 0.713  exp loss = 0.713  adjusted loss = 0.713  adv prob = 0.250000   acc = 0.499
  waterbird_complete95 = 0, forest2water2 = 1  [n = 667]:	loss = 0.600  exp loss = 0.587  adjusted loss = 0.587  adv prob = 0.250000   acc = 0.772
  waterbird_complete95 = 1, forest2water2 = 0  [n = 515]:	loss = 0.440  exp loss = 0.448  adjusted loss = 0.448  adv prob = 0.250000   acc = 0.973
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1208]:	loss = 0.545  exp loss = 0.541  adjusted loss = 0.541  adv prob = 0.250000   acc = 0.828
Average incurred loss: 0.575  
Average sample loss: 0.575  
Average acc: 0.781  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 847]:	loss = 0.692  exp loss = 0.696  adjusted loss = 0.696  adv prob = 0.250000   acc = 0.579
  waterbird_complete95 = 0, forest2water2 = 1  [n = 617]:	loss = 0.591  exp loss = 0.592  adjusted loss = 0.592  adv prob = 0.250000   acc = 0.796
  waterbird_complete95 = 1, forest2water2 = 0  [n = 506]:	loss = 0.448  exp loss = 0.443  adjusted loss = 0.443  adv prob = 0.250000   acc = 0.951
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1230]:	loss = 0.538  exp loss = 0.530  adjusted loss = 0.530  adv prob = 0.250000   acc = 0.844
Average incurred loss: 0.572  
Average sample loss: 0.572  
Average acc: 0.775  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 865]:	loss = 0.688  exp loss = 0.668  adjusted loss = 0.668  adv prob = 0.250000   acc = 0.566
  waterbird_complete95 = 0, forest2water2 = 1  [n = 659]:	loss = 0.579  exp loss = 0.572  adjusted loss = 0.572  adv prob = 0.250000   acc = 0.822
  waterbird_complete95 = 1, forest2water2 = 0  [n = 492]:	loss = 0.441  exp loss = 0.437  adjusted loss = 0.437  adv prob = 0.250000   acc = 0.955
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1184]:	loss = 0.537  exp loss = 0.552  adjusted loss = 0.552  adv prob = 0.250000   acc = 0.826
Average incurred loss: 0.570  
Average sample loss: 0.570  
Average acc: 0.777  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 836]:	loss = 0.686  exp loss = 0.678  adjusted loss = 0.678  adv prob = 0.250000   acc = 0.581
  waterbird_complete95 = 0, forest2water2 = 1  [n = 631]:	loss = 0.575  exp loss = 0.579  adjusted loss = 0.579  adv prob = 0.250000   acc = 0.830
  waterbird_complete95 = 1, forest2water2 = 0  [n = 517]:	loss = 0.432  exp loss = 0.435  adjusted loss = 0.435  adv prob = 0.250000   acc = 0.952
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1216]:	loss = 0.547  exp loss = 0.546  adjusted loss = 0.546  adv prob = 0.250000   acc = 0.810
Saved results/CUB/CUB_sample_exp/train_downstream_ERM_upweight_0_epochs_80_lr_1e-05_weight_decay_0.0/final_epoch31/JTT_upweight_50_epochs_80_lr_1e-05_weight_decay_1.0/model_outputs/output_train_epoch_4.csv
logged to wandb
Average incurred loss: 0.565  
Average sample loss: 0.565  
Average acc: 0.781  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 440]:	loss = 0.684  exp loss = 0.684  adjusted loss = 0.684  adv prob = 0.250000   acc = 0.586
  waterbird_complete95 = 0, forest2water2 = 1  [n = 360]:	loss = 0.587  exp loss = 0.584  adjusted loss = 0.584  adv prob = 0.250000   acc = 0.792
  waterbird_complete95 = 1, forest2water2 = 0  [n = 276]:	loss = 0.432  exp loss = 0.419  adjusted loss = 0.419  adv prob = 0.250000   acc = 0.942
  waterbird_complete95 = 1, forest2water2 = 1  [n = 669]:	loss = 0.531  exp loss = 0.526  adjusted loss = 0.526  adv prob = 0.250000   acc = 0.836

Validation:
Saved results/CUB/CUB_sample_exp/train_downstream_ERM_upweight_0_epochs_80_lr_1e-05_weight_decay_0.0/final_epoch31/JTT_upweight_50_epochs_80_lr_1e-05_weight_decay_1.0/model_outputs/output_val_epoch_4.csv
logged to wandb
Average incurred loss: 0.620  
Average sample loss: 0.620  
Average acc: 0.685  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.702  exp loss = 0.710  adjusted loss = 0.710  adv prob = 0.250000   acc = 0.499
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.614  exp loss = 0.631  adjusted loss = 0.631  adv prob = 0.250000   acc = 0.740
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 0.457  exp loss = 0.477  adjusted loss = 0.477  adv prob = 0.250000   acc = 0.940
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.515  exp loss = 0.504  adjusted loss = 0.504  adv prob = 0.250000   acc = 0.887
Spurious Score = 0.825
Saved results/CUB/CUB_sample_exp/train_downstream_ERM_upweight_0_epochs_80_lr_1e-05_weight_decay_0.0/final_epoch31/JTT_upweight_50_epochs_80_lr_1e-05_weight_decay_1.0/model_outputs/output_test_epoch_4.csv
logged to wandb
Current lr: 0.000010


Epoch [5]:
Training:
Average incurred loss: 0.557  
Average sample loss: 0.557  
Average acc: 0.794  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 828]:	loss = 0.672  exp loss = 0.678  adjusted loss = 0.678  adv prob = 0.250000   acc = 0.615
  waterbird_complete95 = 0, forest2water2 = 1  [n = 639]:	loss = 0.579  exp loss = 0.575  adjusted loss = 0.575  adv prob = 0.250000   acc = 0.801
  waterbird_complete95 = 1, forest2water2 = 0  [n = 531]:	loss = 0.425  exp loss = 0.429  adjusted loss = 0.429  adv prob = 0.250000   acc = 0.960
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1202]:	loss = 0.524  exp loss = 0.524  adjusted loss = 0.524  adv prob = 0.250000   acc = 0.840
Average incurred loss: 0.555  
Average sample loss: 0.555  
Average acc: 0.786  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 813]:	loss = 0.679  exp loss = 0.668  adjusted loss = 0.668  adv prob = 0.250000   acc = 0.581
  waterbird_complete95 = 0, forest2water2 = 1  [n = 622]:	loss = 0.568  exp loss = 0.571  adjusted loss = 0.571  adv prob = 0.250000   acc = 0.814
  waterbird_complete95 = 1, forest2water2 = 0  [n = 510]:	loss = 0.421  exp loss = 0.421  adjusted loss = 0.421  adv prob = 0.250000   acc = 0.959
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1255]:	loss = 0.523  exp loss = 0.514  adjusted loss = 0.514  adv prob = 0.250000   acc = 0.836
Average incurred loss: 0.548  
Average sample loss: 0.548  
Average acc: 0.799  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 833]:	loss = 0.674  exp loss = 0.654  adjusted loss = 0.654  adv prob = 0.250000   acc = 0.593
  waterbird_complete95 = 0, forest2water2 = 1  [n = 666]:	loss = 0.570  exp loss = 0.572  adjusted loss = 0.572  adv prob = 0.250000   acc = 0.841
  waterbird_complete95 = 1, forest2water2 = 0  [n = 486]:	loss = 0.403  exp loss = 0.395  adjusted loss = 0.395  adv prob = 0.250000   acc = 0.951
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1215]:	loss = 0.508  exp loss = 0.526  adjusted loss = 0.526  adv prob = 0.250000   acc = 0.857
Average incurred loss: 0.547  
Average sample loss: 0.547  
Average acc: 0.807  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 860]:	loss = 0.664  exp loss = 0.662  adjusted loss = 0.662  adv prob = 0.250000   acc = 0.620
  waterbird_complete95 = 0, forest2water2 = 1  [n = 632]:	loss = 0.546  exp loss = 0.538  adjusted loss = 0.538  adv prob = 0.250000   acc = 0.859
  waterbird_complete95 = 1, forest2water2 = 0  [n = 506]:	loss = 0.414  exp loss = 0.402  adjusted loss = 0.402  adv prob = 0.250000   acc = 0.955
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1202]:	loss = 0.519  exp loss = 0.522  adjusted loss = 0.522  adv prob = 0.250000   acc = 0.851
Saved results/CUB/CUB_sample_exp/train_downstream_ERM_upweight_0_epochs_80_lr_1e-05_weight_decay_0.0/final_epoch31/JTT_upweight_50_epochs_80_lr_1e-05_weight_decay_1.0/model_outputs/output_train_epoch_5.csv
logged to wandb
Average incurred loss: 0.548  
Average sample loss: 0.548  
Average acc: 0.797  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 464]:	loss = 0.667  exp loss = 0.660  adjusted loss = 0.660  adv prob = 0.250000   acc = 0.603
  waterbird_complete95 = 0, forest2water2 = 1  [n = 375]:	loss = 0.554  exp loss = 0.552  adjusted loss = 0.552  adv prob = 0.250000   acc = 0.848
  waterbird_complete95 = 1, forest2water2 = 0  [n = 273]:	loss = 0.407  exp loss = 0.406  adjusted loss = 0.406  adv prob = 0.250000   acc = 0.956
  waterbird_complete95 = 1, forest2water2 = 1  [n = 633]:	loss = 0.517  exp loss = 0.513  adjusted loss = 0.513  adv prob = 0.250000   acc = 0.840

Validation:
Saved results/CUB/CUB_sample_exp/train_downstream_ERM_upweight_0_epochs_80_lr_1e-05_weight_decay_0.0/final_epoch31/JTT_upweight_50_epochs_80_lr_1e-05_weight_decay_1.0/model_outputs/output_val_epoch_5.csv
logged to wandb
Average incurred loss: 0.590  
Average sample loss: 0.589  
Average acc: 0.752  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.662  exp loss = 0.671  adjusted loss = 0.671  adv prob = 0.250000   acc = 0.634
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.574  exp loss = 0.593  adjusted loss = 0.593  adv prob = 0.250000   acc = 0.792
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 0.458  exp loss = 0.479  adjusted loss = 0.479  adv prob = 0.250000   acc = 0.932
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.522  exp loss = 0.510  adjusted loss = 0.510  adv prob = 0.250000   acc = 0.850
Spurious Score = 0.860
Saved results/CUB/CUB_sample_exp/train_downstream_ERM_upweight_0_epochs_80_lr_1e-05_weight_decay_0.0/final_epoch31/JTT_upweight_50_epochs_80_lr_1e-05_weight_decay_1.0/model_outputs/output_test_epoch_5.csv
logged to wandb
Current lr: 0.000010


Epoch [6]:
Training:
Average incurred loss: 0.539  
Average sample loss: 0.539  
Average acc: 0.817  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 845]:	loss = 0.655  exp loss = 0.648  adjusted loss = 0.648  adv prob = 0.250000   acc = 0.652
  waterbird_complete95 = 0, forest2water2 = 1  [n = 644]:	loss = 0.531  exp loss = 0.527  adjusted loss = 0.527  adv prob = 0.250000   acc = 0.899
  waterbird_complete95 = 1, forest2water2 = 0  [n = 495]:	loss = 0.413  exp loss = 0.396  adjusted loss = 0.396  adv prob = 0.250000   acc = 0.933
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1216]:	loss = 0.515  exp loss = 0.504  adjusted loss = 0.504  adv prob = 0.250000   acc = 0.840
Average incurred loss: 0.538  
Average sample loss: 0.538  
Average acc: 0.818  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 858]:	loss = 0.645  exp loss = 0.659  adjusted loss = 0.659  adv prob = 0.250000   acc = 0.663
  waterbird_complete95 = 0, forest2water2 = 1  [n = 673]:	loss = 0.541  exp loss = 0.543  adjusted loss = 0.543  adv prob = 0.250000   acc = 0.859
  waterbird_complete95 = 1, forest2water2 = 0  [n = 489]:	loss = 0.409  exp loss = 0.416  adjusted loss = 0.416  adv prob = 0.250000   acc = 0.957
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1180]:	loss = 0.512  exp loss = 0.506  adjusted loss = 0.506  adv prob = 0.250000   acc = 0.851
Average incurred loss: 0.527  
Average sample loss: 0.527  
Average acc: 0.833  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 859]:	loss = 0.616  exp loss = 0.610  adjusted loss = 0.610  adv prob = 0.250000   acc = 0.721
  waterbird_complete95 = 0, forest2water2 = 1  [n = 643]:	loss = 0.517  exp loss = 0.517  adjusted loss = 0.517  adv prob = 0.250000   acc = 0.897
  waterbird_complete95 = 1, forest2water2 = 0  [n = 510]:	loss = 0.420  exp loss = 0.426  adjusted loss = 0.426  adv prob = 0.250000   acc = 0.937
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1188]:	loss = 0.515  exp loss = 0.503  adjusted loss = 0.503  adv prob = 0.250000   acc = 0.835
Average incurred loss: 0.525  
Average sample loss: 0.525  
Average acc: 0.818  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 799]:	loss = 0.632  exp loss = 0.646  adjusted loss = 0.646  adv prob = 0.250000   acc = 0.662
  waterbird_complete95 = 0, forest2water2 = 1  [n = 653]:	loss = 0.514  exp loss = 0.523  adjusted loss = 0.523  adv prob = 0.250000   acc = 0.897
  waterbird_complete95 = 1, forest2water2 = 0  [n = 512]:	loss = 0.400  exp loss = 0.375  adjusted loss = 0.375  adv prob = 0.250000   acc = 0.957
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1236]:	loss = 0.512  exp loss = 0.506  adjusted loss = 0.506  adv prob = 0.250000   acc = 0.820
Saved results/CUB/CUB_sample_exp/train_downstream_ERM_upweight_0_epochs_80_lr_1e-05_weight_decay_0.0/final_epoch31/JTT_upweight_50_epochs_80_lr_1e-05_weight_decay_1.0/model_outputs/output_train_epoch_6.csv
logged to wandb
Average incurred loss: 0.521  
Average sample loss: 0.523  
Average acc: 0.836  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 437]:	loss = 0.621  exp loss = 0.631  adjusted loss = 0.631  adv prob = 0.250000   acc = 0.696
  waterbird_complete95 = 0, forest2water2 = 1  [n = 321]:	loss = 0.529  exp loss = 0.522  adjusted loss = 0.522  adv prob = 0.250000   acc = 0.894
  waterbird_complete95 = 1, forest2water2 = 0  [n = 300]:	loss = 0.379  exp loss = 0.380  adjusted loss = 0.380  adv prob = 0.250000   acc = 0.980
  waterbird_complete95 = 1, forest2water2 = 1  [n = 687]:	loss = 0.517  exp loss = 0.513  adjusted loss = 0.513  adv prob = 0.250000   acc = 0.834

Validation:
Saved results/CUB/CUB_sample_exp/train_downstream_ERM_upweight_0_epochs_80_lr_1e-05_weight_decay_0.0/final_epoch31/JTT_upweight_50_epochs_80_lr_1e-05_weight_decay_1.0/model_outputs/output_val_epoch_6.csv
logged to wandb
Average incurred loss: 0.578  
Average sample loss: 0.578  
Average acc: 0.760  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.648  exp loss = 0.659  adjusted loss = 0.659  adv prob = 0.250000   acc = 0.649
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.568  exp loss = 0.588  adjusted loss = 0.588  adv prob = 0.250000   acc = 0.800
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 0.444  exp loss = 0.464  adjusted loss = 0.464  adv prob = 0.250000   acc = 0.925
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.506  exp loss = 0.491  adjusted loss = 0.491  adv prob = 0.250000   acc = 0.842
Spurious Score = 0.864
Saved results/CUB/CUB_sample_exp/train_downstream_ERM_upweight_0_epochs_80_lr_1e-05_weight_decay_0.0/final_epoch31/JTT_upweight_50_epochs_80_lr_1e-05_weight_decay_1.0/model_outputs/output_test_epoch_6.csv
logged to wandb
Current lr: 0.000010


Epoch [7]:
Training:
Average incurred loss: 0.515  
Average sample loss: 0.515  
Average acc: 0.837  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 870]:	loss = 0.636  exp loss = 0.630  adjusted loss = 0.630  adv prob = 0.250000   acc = 0.687
  waterbird_complete95 = 0, forest2water2 = 1  [n = 608]:	loss = 0.527  exp loss = 0.528  adjusted loss = 0.528  adv prob = 0.250000   acc = 0.900
  waterbird_complete95 = 1, forest2water2 = 0  [n = 539]:	loss = 0.377  exp loss = 0.371  adjusted loss = 0.371  adv prob = 0.250000   acc = 0.952
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1183]:	loss = 0.484  exp loss = 0.483  adjusted loss = 0.483  adv prob = 0.250000   acc = 0.862
Average incurred loss: 0.516  
Average sample loss: 0.516  
Average acc: 0.826  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 846]:	loss = 0.641  exp loss = 0.637  adjusted loss = 0.637  adv prob = 0.250000   acc = 0.647
  waterbird_complete95 = 0, forest2water2 = 1  [n = 624]:	loss = 0.522  exp loss = 0.514  adjusted loss = 0.514  adv prob = 0.250000   acc = 0.889
  waterbird_complete95 = 1, forest2water2 = 0  [n = 511]:	loss = 0.377  exp loss = 0.376  adjusted loss = 0.376  adv prob = 0.250000   acc = 0.961
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1219]:	loss = 0.485  exp loss = 0.479  adjusted loss = 0.479  adv prob = 0.250000   acc = 0.862
Average incurred loss: 0.505  
Average sample loss: 0.505  
Average acc: 0.843  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 825]:	loss = 0.609  exp loss = 0.601  adjusted loss = 0.601  adv prob = 0.250000   acc = 0.714
  waterbird_complete95 = 0, forest2water2 = 1  [n = 653]:	loss = 0.515  exp loss = 0.519  adjusted loss = 0.519  adv prob = 0.250000   acc = 0.884
  waterbird_complete95 = 1, forest2water2 = 0  [n = 508]:	loss = 0.379  exp loss = 0.366  adjusted loss = 0.366  adv prob = 0.250000   acc = 0.959
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1214]:	loss = 0.482  exp loss = 0.488  adjusted loss = 0.488  adv prob = 0.250000   acc = 0.859
Average incurred loss: 0.504  
Average sample loss: 0.504  
Average acc: 0.849  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 802]:	loss = 0.620  exp loss = 0.611  adjusted loss = 0.611  adv prob = 0.250000   acc = 0.702
  waterbird_complete95 = 0, forest2water2 = 1  [n = 719]:	loss = 0.509  exp loss = 0.484  adjusted loss = 0.484  adv prob = 0.250000   acc = 0.898
  waterbird_complete95 = 1, forest2water2 = 0  [n = 460]:	loss = 0.378  exp loss = 0.387  adjusted loss = 0.387  adv prob = 0.250000   acc = 0.952
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1219]:	loss = 0.473  exp loss = 0.472  adjusted loss = 0.472  adv prob = 0.250000   acc = 0.877
Saved results/CUB/CUB_sample_exp/train_downstream_ERM_upweight_0_epochs_80_lr_1e-05_weight_decay_0.0/final_epoch31/JTT_upweight_50_epochs_80_lr_1e-05_weight_decay_1.0/model_outputs/output_train_epoch_7.csv
logged to wandb
Average incurred loss: 0.510  
Average sample loss: 0.511  
Average acc: 0.840  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 455]:	loss = 0.610  exp loss = 0.626  adjusted loss = 0.626  adv prob = 0.250000   acc = 0.721
  waterbird_complete95 = 0, forest2water2 = 1  [n = 330]:	loss = 0.497  exp loss = 0.490  adjusted loss = 0.490  adv prob = 0.250000   acc = 0.903
  waterbird_complete95 = 1, forest2water2 = 0  [n = 288]:	loss = 0.373  exp loss = 0.372  adjusted loss = 0.372  adv prob = 0.250000   acc = 0.962
  waterbird_complete95 = 1, forest2water2 = 1  [n = 672]:	loss = 0.508  exp loss = 0.515  adjusted loss = 0.515  adv prob = 0.250000   acc = 0.838

Validation:
Saved results/CUB/CUB_sample_exp/train_downstream_ERM_upweight_0_epochs_80_lr_1e-05_weight_decay_0.0/final_epoch31/JTT_upweight_50_epochs_80_lr_1e-05_weight_decay_1.0/model_outputs/output_val_epoch_7.csv
logged to wandb
Average incurred loss: 0.552  
Average sample loss: 0.551  
Average acc: 0.802  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.609  exp loss = 0.622  adjusted loss = 0.622  adv prob = 0.250000   acc = 0.741
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.538  exp loss = 0.562  adjusted loss = 0.562  adv prob = 0.250000   acc = 0.818
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 0.448  exp loss = 0.469  adjusted loss = 0.469  adv prob = 0.250000   acc = 0.917
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.504  exp loss = 0.489  adjusted loss = 0.489  adv prob = 0.250000   acc = 0.842
Spurious Score = 0.912
Saved results/CUB/CUB_sample_exp/train_downstream_ERM_upweight_0_epochs_80_lr_1e-05_weight_decay_0.0/final_epoch31/JTT_upweight_50_epochs_80_lr_1e-05_weight_decay_1.0/model_outputs/output_test_epoch_7.csv
logged to wandb
Current lr: 0.000010


Epoch [8]:
Training:
Average incurred loss: 0.496  
Average sample loss: 0.496  
Average acc: 0.849  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 807]:	loss = 0.611  exp loss = 0.627  adjusted loss = 0.627  adv prob = 0.250000   acc = 0.719
  waterbird_complete95 = 0, forest2water2 = 1  [n = 636]:	loss = 0.500  exp loss = 0.495  adjusted loss = 0.495  adv prob = 0.250000   acc = 0.893
  waterbird_complete95 = 1, forest2water2 = 0  [n = 518]:	loss = 0.375  exp loss = 0.354  adjusted loss = 0.354  adv prob = 0.250000   acc = 0.942
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1239]:	loss = 0.470  exp loss = 0.458  adjusted loss = 0.458  adv prob = 0.250000   acc = 0.873
Average incurred loss: 0.502  
Average sample loss: 0.502  
Average acc: 0.837  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 878]:	loss = 0.619  exp loss = 0.589  adjusted loss = 0.589  adv prob = 0.250000   acc = 0.691
  waterbird_complete95 = 0, forest2water2 = 1  [n = 658]:	loss = 0.501  exp loss = 0.465  adjusted loss = 0.465  adv prob = 0.250000   acc = 0.892
  waterbird_complete95 = 1, forest2water2 = 0  [n = 485]:	loss = 0.361  exp loss = 0.364  adjusted loss = 0.364  adv prob = 0.250000   acc = 0.965
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1179]:	loss = 0.474  exp loss = 0.474  adjusted loss = 0.474  adv prob = 0.250000   acc = 0.863
Average incurred loss: 0.493  
Average sample loss: 0.493  
Average acc: 0.853  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 814]:	loss = 0.592  exp loss = 0.606  adjusted loss = 0.606  adv prob = 0.250000   acc = 0.733
  waterbird_complete95 = 0, forest2water2 = 1  [n = 630]:	loss = 0.484  exp loss = 0.481  adjusted loss = 0.481  adv prob = 0.250000   acc = 0.937
  waterbird_complete95 = 1, forest2water2 = 0  [n = 526]:	loss = 0.362  exp loss = 0.361  adjusted loss = 0.361  adv prob = 0.250000   acc = 0.966
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1230]:	loss = 0.487  exp loss = 0.488  adjusted loss = 0.488  adv prob = 0.250000   acc = 0.841
Average incurred loss: 0.489  
Average sample loss: 0.489  
Average acc: 0.849  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 842]:	loss = 0.599  exp loss = 0.594  adjusted loss = 0.594  adv prob = 0.250000   acc = 0.723
  waterbird_complete95 = 0, forest2water2 = 1  [n = 652]:	loss = 0.494  exp loss = 0.481  adjusted loss = 0.481  adv prob = 0.250000   acc = 0.890
  waterbird_complete95 = 1, forest2water2 = 0  [n = 492]:	loss = 0.357  exp loss = 0.348  adjusted loss = 0.348  adv prob = 0.250000   acc = 0.943
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1214]:	loss = 0.463  exp loss = 0.465  adjusted loss = 0.465  adv prob = 0.250000   acc = 0.877
Saved results/CUB/CUB_sample_exp/train_downstream_ERM_upweight_0_epochs_80_lr_1e-05_weight_decay_0.0/final_epoch31/JTT_upweight_50_epochs_80_lr_1e-05_weight_decay_1.0/model_outputs/output_train_epoch_8.csv
logged to wandb
Average incurred loss: 0.479  
Average sample loss: 0.479  
Average acc: 0.868  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 457]:	loss = 0.588  exp loss = 0.583  adjusted loss = 0.583  adv prob = 0.250000   acc = 0.751
  waterbird_complete95 = 0, forest2water2 = 1  [n = 358]:	loss = 0.479  exp loss = 0.471  adjusted loss = 0.471  adv prob = 0.250000   acc = 0.913
  waterbird_complete95 = 1, forest2water2 = 0  [n = 285]:	loss = 0.361  exp loss = 0.347  adjusted loss = 0.347  adv prob = 0.250000   acc = 0.968
  waterbird_complete95 = 1, forest2water2 = 1  [n = 645]:	loss = 0.455  exp loss = 0.455  adjusted loss = 0.455  adv prob = 0.250000   acc = 0.881

Validation:
Saved results/CUB/CUB_sample_exp/train_downstream_ERM_upweight_0_epochs_80_lr_1e-05_weight_decay_0.0/final_epoch31/JTT_upweight_50_epochs_80_lr_1e-05_weight_decay_1.0/model_outputs/output_val_epoch_8.csv
logged to wandb
Average incurred loss: 0.541  
Average sample loss: 0.541  
Average acc: 0.802  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.598  exp loss = 0.612  adjusted loss = 0.612  adv prob = 0.250000   acc = 0.749
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.531  exp loss = 0.556  adjusted loss = 0.556  adv prob = 0.250000   acc = 0.813
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 0.432  exp loss = 0.452  adjusted loss = 0.452  adv prob = 0.250000   acc = 0.910
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.486  exp loss = 0.471  adjusted loss = 0.471  adv prob = 0.250000   acc = 0.842
Spurious Score = 0.924
Saved results/CUB/CUB_sample_exp/train_downstream_ERM_upweight_0_epochs_80_lr_1e-05_weight_decay_0.0/final_epoch31/JTT_upweight_50_epochs_80_lr_1e-05_weight_decay_1.0/model_outputs/output_test_epoch_8.csv
logged to wandb
Current lr: 0.000010


Epoch [9]:
Training:
Average incurred loss: 0.481  
Average sample loss: 0.481  
Average acc: 0.863  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 829]:	loss = 0.586  exp loss = 0.575  adjusted loss = 0.575  adv prob = 0.250000   acc = 0.744
  waterbird_complete95 = 0, forest2water2 = 1  [n = 664]:	loss = 0.474  exp loss = 0.482  adjusted loss = 0.482  adv prob = 0.250000   acc = 0.914
  waterbird_complete95 = 1, forest2water2 = 0  [n = 514]:	loss = 0.361  exp loss = 0.343  adjusted loss = 0.343  adv prob = 0.250000   acc = 0.963
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1193]:	loss = 0.463  exp loss = 0.464  adjusted loss = 0.464  adv prob = 0.250000   acc = 0.873
Average incurred loss: 0.483  
Average sample loss: 0.483  
Average acc: 0.850  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 862]:	loss = 0.584  exp loss = 0.585  adjusted loss = 0.585  adv prob = 0.250000   acc = 0.741
  waterbird_complete95 = 0, forest2water2 = 1  [n = 620]:	loss = 0.477  exp loss = 0.481  adjusted loss = 0.481  adv prob = 0.250000   acc = 0.900
  waterbird_complete95 = 1, forest2water2 = 0  [n = 508]:	loss = 0.346  exp loss = 0.335  adjusted loss = 0.335  adv prob = 0.250000   acc = 0.955
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1210]:	loss = 0.472  exp loss = 0.465  adjusted loss = 0.465  adv prob = 0.250000   acc = 0.858
Average incurred loss: 0.472  
Average sample loss: 0.472  
Average acc: 0.866  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 848]:	loss = 0.579  exp loss = 0.572  adjusted loss = 0.572  adv prob = 0.250000   acc = 0.755
  waterbird_complete95 = 0, forest2water2 = 1  [n = 665]:	loss = 0.463  exp loss = 0.456  adjusted loss = 0.456  adv prob = 0.250000   acc = 0.923
  waterbird_complete95 = 1, forest2water2 = 0  [n = 506]:	loss = 0.352  exp loss = 0.353  adjusted loss = 0.353  adv prob = 0.250000   acc = 0.953
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1181]:	loss = 0.450  exp loss = 0.455  adjusted loss = 0.455  adv prob = 0.250000   acc = 0.876
Average incurred loss: 0.468  
Average sample loss: 0.468  
Average acc: 0.874  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 804]:	loss = 0.561  exp loss = 0.542  adjusted loss = 0.542  adv prob = 0.250000   acc = 0.782
  waterbird_complete95 = 0, forest2water2 = 1  [n = 632]:	loss = 0.448  exp loss = 0.450  adjusted loss = 0.450  adv prob = 0.250000   acc = 0.945
  waterbird_complete95 = 1, forest2water2 = 0  [n = 489]:	loss = 0.354  exp loss = 0.356  adjusted loss = 0.356  adv prob = 0.250000   acc = 0.951
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1275]:	loss = 0.461  exp loss = 0.454  adjusted loss = 0.454  adv prob = 0.250000   acc = 0.867
Saved results/CUB/CUB_sample_exp/train_downstream_ERM_upweight_0_epochs_80_lr_1e-05_weight_decay_0.0/final_epoch31/JTT_upweight_50_epochs_80_lr_1e-05_weight_decay_1.0/model_outputs/output_train_epoch_9.csv
logged to wandb
Average incurred loss: 0.452  
Average sample loss: 0.453  
Average acc: 0.892  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 455]:	loss = 0.560  exp loss = 0.560  adjusted loss = 0.560  adv prob = 0.250000   acc = 0.774
  waterbird_complete95 = 0, forest2water2 = 1  [n = 353]:	loss = 0.442  exp loss = 0.449  adjusted loss = 0.449  adv prob = 0.250000   acc = 0.966
  waterbird_complete95 = 1, forest2water2 = 0  [n = 289]:	loss = 0.322  exp loss = 0.311  adjusted loss = 0.311  adv prob = 0.250000   acc = 0.976
  waterbird_complete95 = 1, forest2water2 = 1  [n = 648]:	loss = 0.439  exp loss = 0.444  adjusted loss = 0.444  adv prob = 0.250000   acc = 0.897

Validation:
Saved results/CUB/CUB_sample_exp/train_downstream_ERM_upweight_0_epochs_80_lr_1e-05_weight_decay_0.0/final_epoch31/JTT_upweight_50_epochs_80_lr_1e-05_weight_decay_1.0/model_outputs/output_val_epoch_9.csv
logged to wandb
Average incurred loss: 0.526  
Average sample loss: 0.526  
Average acc: 0.812  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.577  exp loss = 0.593  adjusted loss = 0.593  adv prob = 0.250000   acc = 0.760
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.516  exp loss = 0.543  adjusted loss = 0.543  adv prob = 0.250000   acc = 0.828
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 0.429  exp loss = 0.449  adjusted loss = 0.449  adv prob = 0.250000   acc = 0.902
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.483  exp loss = 0.467  adjusted loss = 0.467  adv prob = 0.250000   acc = 0.842
Spurious Score = 0.926
Saved results/CUB/CUB_sample_exp/train_downstream_ERM_upweight_0_epochs_80_lr_1e-05_weight_decay_0.0/final_epoch31/JTT_upweight_50_epochs_80_lr_1e-05_weight_decay_1.0/model_outputs/output_test_epoch_9.csv
logged to wandb
Current lr: 0.000010


Epoch [10]:
Training:
Average incurred loss: 0.456  
Average sample loss: 0.456  
Average acc: 0.879  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 794]:	loss = 0.557  exp loss = 0.556  adjusted loss = 0.556  adv prob = 0.250000   acc = 0.777
  waterbird_complete95 = 0, forest2water2 = 1  [n = 643]:	loss = 0.451  exp loss = 0.453  adjusted loss = 0.453  adv prob = 0.250000   acc = 0.942
  waterbird_complete95 = 1, forest2water2 = 0  [n = 522]:	loss = 0.337  exp loss = 0.332  adjusted loss = 0.332  adv prob = 0.250000   acc = 0.954
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1241]:	loss = 0.443  exp loss = 0.442  adjusted loss = 0.442  adv prob = 0.250000   acc = 0.881
Average incurred loss: 0.455  
Average sample loss: 0.455  
Average acc: 0.873  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 864]:	loss = 0.571  exp loss = 0.561  adjusted loss = 0.561  adv prob = 0.250000   acc = 0.753
  waterbird_complete95 = 0, forest2water2 = 1  [n = 641]:	loss = 0.454  exp loss = 0.456  adjusted loss = 0.456  adv prob = 0.250000   acc = 0.919
  waterbird_complete95 = 1, forest2water2 = 0  [n = 502]:	loss = 0.318  exp loss = 0.320  adjusted loss = 0.320  adv prob = 0.250000   acc = 0.974
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1193]:	loss = 0.430  exp loss = 0.426  adjusted loss = 0.426  adv prob = 0.250000   acc = 0.893
Average incurred loss: 0.454  
Average sample loss: 0.454  
Average acc: 0.881  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 842]:	loss = 0.557  exp loss = 0.540  adjusted loss = 0.540  adv prob = 0.250000   acc = 0.783
  waterbird_complete95 = 0, forest2water2 = 1  [n = 662]:	loss = 0.448  exp loss = 0.440  adjusted loss = 0.440  adv prob = 0.250000   acc = 0.947
  waterbird_complete95 = 1, forest2water2 = 0  [n = 502]:	loss = 0.331  exp loss = 0.303  adjusted loss = 0.303  adv prob = 0.250000   acc = 0.948
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1194]:	loss = 0.437  exp loss = 0.429  adjusted loss = 0.429  adv prob = 0.250000   acc = 0.884
Average incurred loss: 0.455  
Average sample loss: 0.455  
Average acc: 0.874  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 861]:	loss = 0.553  exp loss = 0.537  adjusted loss = 0.537  adv prob = 0.250000   acc = 0.777
  waterbird_complete95 = 0, forest2water2 = 1  [n = 619]:	loss = 0.422  exp loss = 0.413  adjusted loss = 0.413  adv prob = 0.250000   acc = 0.953
  waterbird_complete95 = 1, forest2water2 = 0  [n = 491]:	loss = 0.333  exp loss = 0.335  adjusted loss = 0.335  adv prob = 0.250000   acc = 0.951
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1229]:	loss = 0.451  exp loss = 0.442  adjusted loss = 0.442  adv prob = 0.250000   acc = 0.872
Saved results/CUB/CUB_sample_exp/train_downstream_ERM_upweight_0_epochs_80_lr_1e-05_weight_decay_0.0/final_epoch31/JTT_upweight_50_epochs_80_lr_1e-05_weight_decay_1.0/model_outputs/output_train_epoch_10.csv
logged to wandb
Average incurred loss: 0.446  
Average sample loss: 0.448  
Average acc: 0.879  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 437]:	loss = 0.546  exp loss = 0.541  adjusted loss = 0.541  adv prob = 0.250000   acc = 0.769
  waterbird_complete95 = 0, forest2water2 = 1  [n = 369]:	loss = 0.438  exp loss = 0.447  adjusted loss = 0.447  adv prob = 0.250000   acc = 0.930
  waterbird_complete95 = 1, forest2water2 = 0  [n = 289]:	loss = 0.332  exp loss = 0.324  adjusted loss = 0.324  adv prob = 0.250000   acc = 0.945
  waterbird_complete95 = 1, forest2water2 = 1  [n = 650]:	loss = 0.435  exp loss = 0.439  adjusted loss = 0.439  adv prob = 0.250000   acc = 0.894

Validation:
Saved results/CUB/CUB_sample_exp/train_downstream_ERM_upweight_0_epochs_80_lr_1e-05_weight_decay_0.0/final_epoch31/JTT_upweight_50_epochs_80_lr_1e-05_weight_decay_1.0/model_outputs/output_val_epoch_10.csv
logged to wandb
Average incurred loss: 0.513  
Average sample loss: 0.512  
Average acc: 0.817  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.562  exp loss = 0.579  adjusted loss = 0.579  adv prob = 0.250000   acc = 0.771
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.504  exp loss = 0.533  adjusted loss = 0.533  adv prob = 0.250000   acc = 0.830
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 0.418  exp loss = 0.437  adjusted loss = 0.437  adv prob = 0.250000   acc = 0.902
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.469  exp loss = 0.453  adjusted loss = 0.453  adv prob = 0.250000   acc = 0.842
Spurious Score = 0.931
Saved results/CUB/CUB_sample_exp/train_downstream_ERM_upweight_0_epochs_80_lr_1e-05_weight_decay_0.0/final_epoch31/JTT_upweight_50_epochs_80_lr_1e-05_weight_decay_1.0/model_outputs/output_test_epoch_10.csv
logged to wandb
Current lr: 0.000010


Epoch [11]:
Training:
Average incurred loss: 0.448  
Average sample loss: 0.448  
Average acc: 0.881  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 855]:	loss = 0.548  exp loss = 0.542  adjusted loss = 0.542  adv prob = 0.250000   acc = 0.778
  waterbird_complete95 = 0, forest2water2 = 1  [n = 667]:	loss = 0.431  exp loss = 0.418  adjusted loss = 0.418  adv prob = 0.250000   acc = 0.958
  waterbird_complete95 = 1, forest2water2 = 0  [n = 466]:	loss = 0.323  exp loss = 0.315  adjusted loss = 0.315  adv prob = 0.250000   acc = 0.948
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1212]:	loss = 0.436  exp loss = 0.445  adjusted loss = 0.445  adv prob = 0.250000   acc = 0.886
Average incurred loss: 0.438  
Average sample loss: 0.438  
Average acc: 0.894  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 796]:	loss = 0.529  exp loss = 0.530  adjusted loss = 0.530  adv prob = 0.250000   acc = 0.805
  waterbird_complete95 = 0, forest2water2 = 1  [n = 654]:	loss = 0.423  exp loss = 0.414  adjusted loss = 0.414  adv prob = 0.250000   acc = 0.953
  waterbird_complete95 = 1, forest2water2 = 0  [n = 516]:	loss = 0.328  exp loss = 0.316  adjusted loss = 0.316  adv prob = 0.250000   acc = 0.957
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1234]:	loss = 0.433  exp loss = 0.419  adjusted loss = 0.419  adv prob = 0.250000   acc = 0.893
Average incurred loss: 0.434  
Average sample loss: 0.434  
Average acc: 0.888  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 826]:	loss = 0.532  exp loss = 0.533  adjusted loss = 0.533  adv prob = 0.250000   acc = 0.793
  waterbird_complete95 = 0, forest2water2 = 1  [n = 646]:	loss = 0.422  exp loss = 0.409  adjusted loss = 0.409  adv prob = 0.250000   acc = 0.943
  waterbird_complete95 = 1, forest2water2 = 0  [n = 499]:	loss = 0.313  exp loss = 0.305  adjusted loss = 0.305  adv prob = 0.250000   acc = 0.960
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1229]:	loss = 0.423  exp loss = 0.419  adjusted loss = 0.419  adv prob = 0.250000   acc = 0.894
Average incurred loss: 0.430  
Average sample loss: 0.430  
Average acc: 0.891  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 840]:	loss = 0.533  exp loss = 0.520  adjusted loss = 0.520  adv prob = 0.250000   acc = 0.800
  waterbird_complete95 = 0, forest2water2 = 1  [n = 623]:	loss = 0.416  exp loss = 0.421  adjusted loss = 0.421  adv prob = 0.250000   acc = 0.942
  waterbird_complete95 = 1, forest2water2 = 0  [n = 538]:	loss = 0.308  exp loss = 0.306  adjusted loss = 0.306  adv prob = 0.250000   acc = 0.968
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1199]:	loss = 0.420  exp loss = 0.401  adjusted loss = 0.401  adv prob = 0.250000   acc = 0.894
Saved results/CUB/CUB_sample_exp/train_downstream_ERM_upweight_0_epochs_80_lr_1e-05_weight_decay_0.0/final_epoch31/JTT_upweight_50_epochs_80_lr_1e-05_weight_decay_1.0/model_outputs/output_train_epoch_11.csv
logged to wandb
Average incurred loss: 0.423  
Average sample loss: 0.424  
Average acc: 0.896  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 481]:	loss = 0.525  exp loss = 0.515  adjusted loss = 0.515  adv prob = 0.250000   acc = 0.790
  waterbird_complete95 = 0, forest2water2 = 1  [n = 344]:	loss = 0.416  exp loss = 0.417  adjusted loss = 0.417  adv prob = 0.250000   acc = 0.968
  waterbird_complete95 = 1, forest2water2 = 0  [n = 287]:	loss = 0.298  exp loss = 0.303  adjusted loss = 0.303  adv prob = 0.250000   acc = 0.948
  waterbird_complete95 = 1, forest2water2 = 1  [n = 633]:	loss = 0.406  exp loss = 0.403  adjusted loss = 0.403  adv prob = 0.250000   acc = 0.913

Validation:
Saved results/CUB/CUB_sample_exp/train_downstream_ERM_upweight_0_epochs_80_lr_1e-05_weight_decay_0.0/final_epoch31/JTT_upweight_50_epochs_80_lr_1e-05_weight_decay_1.0/model_outputs/output_val_epoch_11.csv
logged to wandb
Average incurred loss: 0.504  
Average sample loss: 0.504  
Average acc: 0.820  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.551  exp loss = 0.569  adjusted loss = 0.569  adv prob = 0.250000   acc = 0.779
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.500  exp loss = 0.531  adjusted loss = 0.531  adv prob = 0.250000   acc = 0.826
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 0.407  exp loss = 0.425  adjusted loss = 0.425  adv prob = 0.250000   acc = 0.902
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.452  exp loss = 0.436  adjusted loss = 0.436  adv prob = 0.250000   acc = 0.857
Spurious Score = 0.947
Saved results/CUB/CUB_sample_exp/train_downstream_ERM_upweight_0_epochs_80_lr_1e-05_weight_decay_0.0/final_epoch31/JTT_upweight_50_epochs_80_lr_1e-05_weight_decay_1.0/model_outputs/output_test_epoch_11.csv
logged to wandb
Current lr: 0.000010


Epoch [12]:
Training:
Average incurred loss: 0.420  
Average sample loss: 0.420  
Average acc: 0.903  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 807]:	loss = 0.513  exp loss = 0.528  adjusted loss = 0.528  adv prob = 0.250000   acc = 0.820
  waterbird_complete95 = 0, forest2water2 = 1  [n = 642]:	loss = 0.411  exp loss = 0.414  adjusted loss = 0.414  adv prob = 0.250000   acc = 0.955
  waterbird_complete95 = 1, forest2water2 = 0  [n = 510]:	loss = 0.302  exp loss = 0.296  adjusted loss = 0.296  adv prob = 0.250000   acc = 0.969
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1241]:	loss = 0.413  exp loss = 0.418  adjusted loss = 0.418  adv prob = 0.250000   acc = 0.902
Average incurred loss: 0.423  
Average sample loss: 0.423  
Average acc: 0.895  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 840]:	loss = 0.529  exp loss = 0.532  adjusted loss = 0.532  adv prob = 0.250000   acc = 0.793
  waterbird_complete95 = 0, forest2water2 = 1  [n = 628]:	loss = 0.406  exp loss = 0.419  adjusted loss = 0.419  adv prob = 0.250000   acc = 0.965
  waterbird_complete95 = 1, forest2water2 = 0  [n = 526]:	loss = 0.305  exp loss = 0.297  adjusted loss = 0.297  adv prob = 0.250000   acc = 0.954
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1206]:	loss = 0.410  exp loss = 0.391  adjusted loss = 0.391  adv prob = 0.250000   acc = 0.904
Average incurred loss: 0.418  
Average sample loss: 0.418  
Average acc: 0.898  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 865]:	loss = 0.519  exp loss = 0.517  adjusted loss = 0.517  adv prob = 0.250000   acc = 0.806
  waterbird_complete95 = 0, forest2water2 = 1  [n = 666]:	loss = 0.412  exp loss = 0.401  adjusted loss = 0.401  adv prob = 0.250000   acc = 0.938
  waterbird_complete95 = 1, forest2water2 = 0  [n = 489]:	loss = 0.284  exp loss = 0.288  adjusted loss = 0.288  adv prob = 0.250000   acc = 0.984
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1180]:	loss = 0.404  exp loss = 0.408  adjusted loss = 0.408  adv prob = 0.250000   acc = 0.908
Average incurred loss: 0.415  
Average sample loss: 0.415  
Average acc: 0.899  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 844]:	loss = 0.510  exp loss = 0.500  adjusted loss = 0.500  adv prob = 0.250000   acc = 0.816
  waterbird_complete95 = 0, forest2water2 = 1  [n = 645]:	loss = 0.386  exp loss = 0.362  adjusted loss = 0.362  adv prob = 0.250000   acc = 0.957
  waterbird_complete95 = 1, forest2water2 = 0  [n = 497]:	loss = 0.307  exp loss = 0.301  adjusted loss = 0.301  adv prob = 0.250000   acc = 0.956
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1214]:	loss = 0.408  exp loss = 0.406  adjusted loss = 0.406  adv prob = 0.250000   acc = 0.903
Saved results/CUB/CUB_sample_exp/train_downstream_ERM_upweight_0_epochs_80_lr_1e-05_weight_decay_0.0/final_epoch31/JTT_upweight_50_epochs_80_lr_1e-05_weight_decay_1.0/model_outputs/output_train_epoch_12.csv
logged to wandb
Average incurred loss: 0.402  
Average sample loss: 0.403  
Average acc: 0.907  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 442]:	loss = 0.483  exp loss = 0.481  adjusted loss = 0.481  adv prob = 0.250000   acc = 0.839
  waterbird_complete95 = 0, forest2water2 = 1  [n = 353]:	loss = 0.391  exp loss = 0.388  adjusted loss = 0.388  adv prob = 0.250000   acc = 0.941
  waterbird_complete95 = 1, forest2water2 = 0  [n = 284]:	loss = 0.296  exp loss = 0.290  adjusted loss = 0.290  adv prob = 0.250000   acc = 0.958
  waterbird_complete95 = 1, forest2water2 = 1  [n = 666]:	loss = 0.400  exp loss = 0.396  adjusted loss = 0.396  adv prob = 0.250000   acc = 0.913

Validation:
Saved results/CUB/CUB_sample_exp/train_downstream_ERM_upweight_0_epochs_80_lr_1e-05_weight_decay_0.0/final_epoch31/JTT_upweight_50_epochs_80_lr_1e-05_weight_decay_1.0/model_outputs/output_val_epoch_12.csv
logged to wandb
Average incurred loss: 0.487  
Average sample loss: 0.486  
Average acc: 0.834  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.525  exp loss = 0.544  adjusted loss = 0.544  adv prob = 0.250000   acc = 0.809
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.484  exp loss = 0.516  adjusted loss = 0.516  adv prob = 0.250000   acc = 0.830
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 0.404  exp loss = 0.422  adjusted loss = 0.422  adv prob = 0.250000   acc = 0.902
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.443  exp loss = 0.427  adjusted loss = 0.427  adv prob = 0.250000   acc = 0.865
Spurious Score = 0.966
Saved results/CUB/CUB_sample_exp/train_downstream_ERM_upweight_0_epochs_80_lr_1e-05_weight_decay_0.0/final_epoch31/JTT_upweight_50_epochs_80_lr_1e-05_weight_decay_1.0/model_outputs/output_test_epoch_12.csv
logged to wandb
Current lr: 0.000010


Epoch [13]:
Training:
Average incurred loss: 0.406  
Average sample loss: 0.406  
Average acc: 0.905  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 845]:	loss = 0.495  exp loss = 0.491  adjusted loss = 0.491  adv prob = 0.250000   acc = 0.830
  waterbird_complete95 = 0, forest2water2 = 1  [n = 641]:	loss = 0.391  exp loss = 0.379  adjusted loss = 0.379  adv prob = 0.250000   acc = 0.964
  waterbird_complete95 = 1, forest2water2 = 0  [n = 524]:	loss = 0.290  exp loss = 0.290  adjusted loss = 0.290  adv prob = 0.250000   acc = 0.958
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1190]:	loss = 0.403  exp loss = 0.401  adjusted loss = 0.401  adv prob = 0.250000   acc = 0.903
Average incurred loss: 0.400  
Average sample loss: 0.400  
Average acc: 0.914  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 842]:	loss = 0.492  exp loss = 0.487  adjusted loss = 0.487  adv prob = 0.250000   acc = 0.821
  waterbird_complete95 = 0, forest2water2 = 1  [n = 637]:	loss = 0.373  exp loss = 0.360  adjusted loss = 0.360  adv prob = 0.250000   acc = 0.973
  waterbird_complete95 = 1, forest2water2 = 0  [n = 507]:	loss = 0.295  exp loss = 0.298  adjusted loss = 0.298  adv prob = 0.250000   acc = 0.963
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1214]:	loss = 0.394  exp loss = 0.403  adjusted loss = 0.403  adv prob = 0.250000   acc = 0.928
Average incurred loss: 0.396  
Average sample loss: 0.396  
Average acc: 0.913  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 811]:	loss = 0.483  exp loss = 0.489  adjusted loss = 0.489  adv prob = 0.250000   acc = 0.840
  waterbird_complete95 = 0, forest2water2 = 1  [n = 660]:	loss = 0.381  exp loss = 0.368  adjusted loss = 0.368  adv prob = 0.250000   acc = 0.962
  waterbird_complete95 = 1, forest2water2 = 0  [n = 521]:	loss = 0.280  exp loss = 0.297  adjusted loss = 0.297  adv prob = 0.250000   acc = 0.967
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1208]:	loss = 0.396  exp loss = 0.388  adjusted loss = 0.388  adv prob = 0.250000   acc = 0.912
Average incurred loss: 0.398  
Average sample loss: 0.398  
Average acc: 0.907  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 853]:	loss = 0.497  exp loss = 0.490  adjusted loss = 0.490  adv prob = 0.250000   acc = 0.821
  waterbird_complete95 = 0, forest2water2 = 1  [n = 641]:	loss = 0.380  exp loss = 0.374  adjusted loss = 0.374  adv prob = 0.250000   acc = 0.963
  waterbird_complete95 = 1, forest2water2 = 0  [n = 491]:	loss = 0.279  exp loss = 0.278  adjusted loss = 0.278  adv prob = 0.250000   acc = 0.963
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1215]:	loss = 0.387  exp loss = 0.382  adjusted loss = 0.382  adv prob = 0.250000   acc = 0.914
Saved results/CUB/CUB_sample_exp/train_downstream_ERM_upweight_0_epochs_80_lr_1e-05_weight_decay_0.0/final_epoch31/JTT_upweight_50_epochs_80_lr_1e-05_weight_decay_1.0/model_outputs/output_train_epoch_13.csv
logged to wandb
Average incurred loss: 0.388  
Average sample loss: 0.388  
Average acc: 0.913  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 447]:	loss = 0.481  exp loss = 0.479  adjusted loss = 0.479  adv prob = 0.250000   acc = 0.850
  waterbird_complete95 = 0, forest2water2 = 1  [n = 355]:	loss = 0.363  exp loss = 0.358  adjusted loss = 0.358  adv prob = 0.250000   acc = 0.963
  waterbird_complete95 = 1, forest2water2 = 0  [n = 263]:	loss = 0.287  exp loss = 0.275  adjusted loss = 0.275  adv prob = 0.250000   acc = 0.958
  waterbird_complete95 = 1, forest2water2 = 1  [n = 680]:	loss = 0.380  exp loss = 0.381  adjusted loss = 0.381  adv prob = 0.250000   acc = 0.910

Validation:
Saved results/CUB/CUB_sample_exp/train_downstream_ERM_upweight_0_epochs_80_lr_1e-05_weight_decay_0.0/final_epoch31/JTT_upweight_50_epochs_80_lr_1e-05_weight_decay_1.0/model_outputs/output_val_epoch_13.csv
logged to wandb
Average incurred loss: 0.469  
Average sample loss: 0.469  
Average acc: 0.849  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.498  exp loss = 0.517  adjusted loss = 0.517  adv prob = 0.250000   acc = 0.835
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.470  exp loss = 0.502  adjusted loss = 0.502  adv prob = 0.250000   acc = 0.843
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 0.406  exp loss = 0.424  adjusted loss = 0.424  adv prob = 0.250000   acc = 0.902
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.431  exp loss = 0.415  adjusted loss = 0.415  adv prob = 0.250000   acc = 0.865
Spurious Score = 0.974
Saved results/CUB/CUB_sample_exp/train_downstream_ERM_upweight_0_epochs_80_lr_1e-05_weight_decay_0.0/final_epoch31/JTT_upweight_50_epochs_80_lr_1e-05_weight_decay_1.0/model_outputs/output_test_epoch_13.csv
logged to wandb
Current lr: 0.000010


Epoch [14]:
Training:
Average incurred loss: 0.389  
Average sample loss: 0.389  
Average acc: 0.919  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 856]:	loss = 0.474  exp loss = 0.460  adjusted loss = 0.460  adv prob = 0.250000   acc = 0.838
  waterbird_complete95 = 0, forest2water2 = 1  [n = 645]:	loss = 0.376  exp loss = 0.369  adjusted loss = 0.369  adv prob = 0.250000   acc = 0.978
  waterbird_complete95 = 1, forest2water2 = 0  [n = 521]:	loss = 0.270  exp loss = 0.263  adjusted loss = 0.263  adv prob = 0.250000   acc = 0.975
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1178]:	loss = 0.386  exp loss = 0.381  adjusted loss = 0.381  adv prob = 0.250000   acc = 0.921
Average incurred loss: 0.383  
Average sample loss: 0.383  
Average acc: 0.925  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 810]:	loss = 0.468  exp loss = 0.448  adjusted loss = 0.448  adv prob = 0.250000   acc = 0.844
  waterbird_complete95 = 0, forest2water2 = 1  [n = 636]:	loss = 0.359  exp loss = 0.330  adjusted loss = 0.330  adv prob = 0.250000   acc = 0.983
  waterbird_complete95 = 1, forest2water2 = 0  [n = 529]:	loss = 0.283  exp loss = 0.272  adjusted loss = 0.272  adv prob = 0.250000   acc = 0.964
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1225]:	loss = 0.381  exp loss = 0.376  adjusted loss = 0.376  adv prob = 0.250000   acc = 0.931
Average incurred loss: 0.385  
Average sample loss: 0.385  
Average acc: 0.915  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 839]:	loss = 0.487  exp loss = 0.476  adjusted loss = 0.476  adv prob = 0.250000   acc = 0.821
  waterbird_complete95 = 0, forest2water2 = 1  [n = 626]:	loss = 0.360  exp loss = 0.376  adjusted loss = 0.376  adv prob = 0.250000   acc = 0.970
  waterbird_complete95 = 1, forest2water2 = 0  [n = 520]:	loss = 0.268  exp loss = 0.262  adjusted loss = 0.262  adv prob = 0.250000   acc = 0.971
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1215]:	loss = 0.378  exp loss = 0.370  adjusted loss = 0.370  adv prob = 0.250000   acc = 0.927
Average incurred loss: 0.381  
Average sample loss: 0.381  
Average acc: 0.919  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 849]:	loss = 0.478  exp loss = 0.474  adjusted loss = 0.474  adv prob = 0.250000   acc = 0.837
  waterbird_complete95 = 0, forest2water2 = 1  [n = 660]:	loss = 0.368  exp loss = 0.360  adjusted loss = 0.360  adv prob = 0.250000   acc = 0.967
  waterbird_complete95 = 1, forest2water2 = 0  [n = 462]:	loss = 0.266  exp loss = 0.254  adjusted loss = 0.254  adv prob = 0.250000   acc = 0.965
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1229]:	loss = 0.365  exp loss = 0.366  adjusted loss = 0.366  adv prob = 0.250000   acc = 0.933
Saved results/CUB/CUB_sample_exp/train_downstream_ERM_upweight_0_epochs_80_lr_1e-05_weight_decay_0.0/final_epoch31/JTT_upweight_50_epochs_80_lr_1e-05_weight_decay_1.0/model_outputs/output_train_epoch_14.csv
logged to wandb
Average incurred loss: 0.366  
Average sample loss: 0.367  
Average acc: 0.934  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 444]:	loss = 0.456  exp loss = 0.442  adjusted loss = 0.442  adv prob = 0.250000   acc = 0.863
  waterbird_complete95 = 0, forest2water2 = 1  [n = 367]:	loss = 0.349  exp loss = 0.364  adjusted loss = 0.364  adv prob = 0.250000   acc = 0.986
  waterbird_complete95 = 1, forest2water2 = 0  [n = 274]:	loss = 0.265  exp loss = 0.261  adjusted loss = 0.261  adv prob = 0.250000   acc = 0.974
  waterbird_complete95 = 1, forest2water2 = 1  [n = 660]:	loss = 0.358  exp loss = 0.362  adjusted loss = 0.362  adv prob = 0.250000   acc = 0.936

Validation:
Saved results/CUB/CUB_sample_exp/train_downstream_ERM_upweight_0_epochs_80_lr_1e-05_weight_decay_0.0/final_epoch31/JTT_upweight_50_epochs_80_lr_1e-05_weight_decay_1.0/model_outputs/output_val_epoch_14.csv
logged to wandb
Average incurred loss: 0.455  
Average sample loss: 0.454  
Average acc: 0.851  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.477  exp loss = 0.497  adjusted loss = 0.497  adv prob = 0.250000   acc = 0.844
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.458  exp loss = 0.491  adjusted loss = 0.491  adv prob = 0.250000   acc = 0.841
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 0.402  exp loss = 0.419  adjusted loss = 0.419  adv prob = 0.250000   acc = 0.895
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.421  exp loss = 0.405  adjusted loss = 0.405  adv prob = 0.250000   acc = 0.865
Spurious Score = 0.984
Saved results/CUB/CUB_sample_exp/train_downstream_ERM_upweight_0_epochs_80_lr_1e-05_weight_decay_0.0/final_epoch31/JTT_upweight_50_epochs_80_lr_1e-05_weight_decay_1.0/model_outputs/output_test_epoch_14.csv
logged to wandb
Current lr: 0.000010


Epoch [15]:
Training:
Average incurred loss: 0.366  
Average sample loss: 0.366  
Average acc: 0.930  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 854]:	loss = 0.448  exp loss = 0.434  adjusted loss = 0.434  adv prob = 0.250000   acc = 0.858
  waterbird_complete95 = 0, forest2water2 = 1  [n = 613]:	loss = 0.340  exp loss = 0.327  adjusted loss = 0.327  adv prob = 0.250000   acc = 0.987
  waterbird_complete95 = 1, forest2water2 = 0  [n = 511]:	loss = 0.266  exp loss = 0.262  adjusted loss = 0.262  adv prob = 0.250000   acc = 0.965
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1222]:	loss = 0.363  exp loss = 0.357  adjusted loss = 0.357  adv prob = 0.250000   acc = 0.937
Average incurred loss: 0.364  
Average sample loss: 0.364  
Average acc: 0.934  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 840]:	loss = 0.454  exp loss = 0.458  adjusted loss = 0.458  adv prob = 0.250000   acc = 0.860
  waterbird_complete95 = 0, forest2water2 = 1  [n = 652]:	loss = 0.344  exp loss = 0.338  adjusted loss = 0.338  adv prob = 0.250000   acc = 0.980
  waterbird_complete95 = 1, forest2water2 = 0  [n = 499]:	loss = 0.258  exp loss = 0.264  adjusted loss = 0.264  adv prob = 0.250000   acc = 0.976
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1209]:	loss = 0.357  exp loss = 0.348  adjusted loss = 0.348  adv prob = 0.250000   acc = 0.945
Average incurred loss: 0.362  
Average sample loss: 0.362  
Average acc: 0.927  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 844]:	loss = 0.457  exp loss = 0.447  adjusted loss = 0.447  adv prob = 0.250000   acc = 0.844
  waterbird_complete95 = 0, forest2water2 = 1  [n = 649]:	loss = 0.337  exp loss = 0.331  adjusted loss = 0.331  adv prob = 0.250000   acc = 0.975
  waterbird_complete95 = 1, forest2water2 = 0  [n = 557]:	loss = 0.255  exp loss = 0.253  adjusted loss = 0.253  adv prob = 0.250000   acc = 0.971
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1150]:	loss = 0.357  exp loss = 0.359  adjusted loss = 0.359  adv prob = 0.250000   acc = 0.938
Average incurred loss: 0.363  
Average sample loss: 0.363  
Average acc: 0.923  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 800]:	loss = 0.452  exp loss = 0.477  adjusted loss = 0.477  adv prob = 0.250000   acc = 0.840
  waterbird_complete95 = 0, forest2water2 = 1  [n = 688]:	loss = 0.342  exp loss = 0.353  adjusted loss = 0.353  adv prob = 0.250000   acc = 0.974
  waterbird_complete95 = 1, forest2water2 = 0  [n = 457]:	loss = 0.252  exp loss = 0.256  adjusted loss = 0.256  adv prob = 0.250000   acc = 0.969
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1255]:	loss = 0.357  exp loss = 0.326  adjusted loss = 0.326  adv prob = 0.250000   acc = 0.931
Saved results/CUB/CUB_sample_exp/train_downstream_ERM_upweight_0_epochs_80_lr_1e-05_weight_decay_0.0/final_epoch31/JTT_upweight_50_epochs_80_lr_1e-05_weight_decay_1.0/model_outputs/output_train_epoch_15.csv
logged to wandb
Average incurred loss: 0.363  
Average sample loss: 0.362  
Average acc: 0.920  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 460]:	loss = 0.443  exp loss = 0.437  adjusted loss = 0.437  adv prob = 0.250000   acc = 0.839
  waterbird_complete95 = 0, forest2water2 = 1  [n = 332]:	loss = 0.333  exp loss = 0.333  adjusted loss = 0.333  adv prob = 0.250000   acc = 0.988
  waterbird_complete95 = 1, forest2water2 = 0  [n = 282]:	loss = 0.253  exp loss = 0.228  adjusted loss = 0.228  adv prob = 0.250000   acc = 0.979
  waterbird_complete95 = 1, forest2water2 = 1  [n = 671]:	loss = 0.369  exp loss = 0.349  adjusted loss = 0.349  adv prob = 0.250000   acc = 0.917

Validation:
Saved results/CUB/CUB_sample_exp/train_downstream_ERM_upweight_0_epochs_80_lr_1e-05_weight_decay_0.0/final_epoch31/JTT_upweight_50_epochs_80_lr_1e-05_weight_decay_1.0/model_outputs/output_val_epoch_15.csv
logged to wandb
Average incurred loss: 0.451  
Average sample loss: 0.451  
Average acc: 0.848  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.474  exp loss = 0.496  adjusted loss = 0.496  adv prob = 0.250000   acc = 0.842
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.460  exp loss = 0.496  adjusted loss = 0.496  adv prob = 0.250000   acc = 0.833
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 0.389  exp loss = 0.405  adjusted loss = 0.405  adv prob = 0.250000   acc = 0.902
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.404  exp loss = 0.389  adjusted loss = 0.389  adv prob = 0.250000   acc = 0.872
Spurious Score = 0.988
Saved results/CUB/CUB_sample_exp/train_downstream_ERM_upweight_0_epochs_80_lr_1e-05_weight_decay_0.0/final_epoch31/JTT_upweight_50_epochs_80_lr_1e-05_weight_decay_1.0/model_outputs/output_test_epoch_15.csv
logged to wandb
Current lr: 0.000010


Epoch [16]:
Training:
Average incurred loss: 0.357  
Average sample loss: 0.357  
Average acc: 0.932  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 846]:	loss = 0.444  exp loss = 0.431  adjusted loss = 0.431  adv prob = 0.250000   acc = 0.859
  waterbird_complete95 = 0, forest2water2 = 1  [n = 638]:	loss = 0.337  exp loss = 0.327  adjusted loss = 0.327  adv prob = 0.250000   acc = 0.973
  waterbird_complete95 = 1, forest2water2 = 0  [n = 471]:	loss = 0.253  exp loss = 0.240  adjusted loss = 0.240  adv prob = 0.250000   acc = 0.975
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1245]:	loss = 0.348  exp loss = 0.344  adjusted loss = 0.344  adv prob = 0.250000   acc = 0.943
Average incurred loss: 0.347  
Average sample loss: 0.347  
Average acc: 0.939  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 813]:	loss = 0.425  exp loss = 0.419  adjusted loss = 0.419  adv prob = 0.250000   acc = 0.873
  waterbird_complete95 = 0, forest2water2 = 1  [n = 662]:	loss = 0.330  exp loss = 0.343  adjusted loss = 0.343  adv prob = 0.250000   acc = 0.983
  waterbird_complete95 = 1, forest2water2 = 0  [n = 537]:	loss = 0.250  exp loss = 0.251  adjusted loss = 0.251  adv prob = 0.250000   acc = 0.978
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1188]:	loss = 0.346  exp loss = 0.339  adjusted loss = 0.339  adv prob = 0.250000   acc = 0.941
Average incurred loss: 0.344  
Average sample loss: 0.344  
Average acc: 0.936  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 853]:	loss = 0.428  exp loss = 0.405  adjusted loss = 0.405  adv prob = 0.250000   acc = 0.864
  waterbird_complete95 = 0, forest2water2 = 1  [n = 628]:	loss = 0.320  exp loss = 0.308  adjusted loss = 0.308  adv prob = 0.250000   acc = 0.987
  waterbird_complete95 = 1, forest2water2 = 0  [n = 529]:	loss = 0.243  exp loss = 0.236  adjusted loss = 0.236  adv prob = 0.250000   acc = 0.975
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1190]:	loss = 0.343  exp loss = 0.322  adjusted loss = 0.322  adv prob = 0.250000   acc = 0.942
Average incurred loss: 0.340  
Average sample loss: 0.340  
Average acc: 0.939  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 817]:	loss = 0.424  exp loss = 0.416  adjusted loss = 0.416  adv prob = 0.250000   acc = 0.867
  waterbird_complete95 = 0, forest2water2 = 1  [n = 650]:	loss = 0.316  exp loss = 0.303  adjusted loss = 0.303  adv prob = 0.250000   acc = 0.989
  waterbird_complete95 = 1, forest2water2 = 0  [n = 507]:	loss = 0.236  exp loss = 0.233  adjusted loss = 0.233  adv prob = 0.250000   acc = 0.982
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1226]:	loss = 0.341  exp loss = 0.355  adjusted loss = 0.355  adv prob = 0.250000   acc = 0.944
Saved results/CUB/CUB_sample_exp/train_downstream_ERM_upweight_0_epochs_80_lr_1e-05_weight_decay_0.0/final_epoch31/JTT_upweight_50_epochs_80_lr_1e-05_weight_decay_1.0/model_outputs/output_train_epoch_16.csv
logged to wandb
Average incurred loss: 0.343  
Average sample loss: 0.345  
Average acc: 0.931  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 469]:	loss = 0.445  exp loss = 0.462  adjusted loss = 0.462  adv prob = 0.250000   acc = 0.838
  waterbird_complete95 = 0, forest2water2 = 1  [n = 356]:	loss = 0.313  exp loss = 0.319  adjusted loss = 0.319  adv prob = 0.250000   acc = 0.997
  waterbird_complete95 = 1, forest2water2 = 0  [n = 262]:	loss = 0.236  exp loss = 0.215  adjusted loss = 0.215  adv prob = 0.250000   acc = 0.966
  waterbird_complete95 = 1, forest2water2 = 1  [n = 658]:	loss = 0.329  exp loss = 0.328  adjusted loss = 0.328  adv prob = 0.250000   acc = 0.947

Validation:
Saved results/CUB/CUB_sample_exp/train_downstream_ERM_upweight_0_epochs_80_lr_1e-05_weight_decay_0.0/final_epoch31/JTT_upweight_50_epochs_80_lr_1e-05_weight_decay_1.0/model_outputs/output_val_epoch_16.csv
logged to wandb
Average incurred loss: 0.441  
Average sample loss: 0.441  
Average acc: 0.851  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.459  exp loss = 0.481  adjusted loss = 0.481  adv prob = 0.250000   acc = 0.846
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.457  exp loss = 0.493  adjusted loss = 0.493  adv prob = 0.250000   acc = 0.830
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 0.380  exp loss = 0.396  adjusted loss = 0.396  adv prob = 0.250000   acc = 0.902
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.386  exp loss = 0.369  adjusted loss = 0.369  adv prob = 0.250000   acc = 0.887
Spurious Score = 1.000
Saved results/CUB/CUB_sample_exp/train_downstream_ERM_upweight_0_epochs_80_lr_1e-05_weight_decay_0.0/final_epoch31/JTT_upweight_50_epochs_80_lr_1e-05_weight_decay_1.0/model_outputs/output_test_epoch_16.csv
logged to wandb
Current lr: 0.000010


Epoch [17]:
Training:
Average incurred loss: 0.340  
Average sample loss: 0.340  
Average acc: 0.941  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 855]:	loss = 0.421  exp loss = 0.422  adjusted loss = 0.422  adv prob = 0.250000   acc = 0.875
  waterbird_complete95 = 0, forest2water2 = 1  [n = 619]:	loss = 0.317  exp loss = 0.318  adjusted loss = 0.318  adv prob = 0.250000   acc = 0.989
  waterbird_complete95 = 1, forest2water2 = 0  [n = 507]:	loss = 0.232  exp loss = 0.228  adjusted loss = 0.228  adv prob = 0.250000   acc = 0.982
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1219]:	loss = 0.341  exp loss = 0.340  adjusted loss = 0.340  adv prob = 0.250000   acc = 0.947
Average incurred loss: 0.331  
Average sample loss: 0.331  
Average acc: 0.944  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 842]:	loss = 0.411  exp loss = 0.412  adjusted loss = 0.412  adv prob = 0.250000   acc = 0.878
  waterbird_complete95 = 0, forest2water2 = 1  [n = 637]:	loss = 0.310  exp loss = 0.315  adjusted loss = 0.315  adv prob = 0.250000   acc = 0.983
  waterbird_complete95 = 1, forest2water2 = 0  [n = 502]:	loss = 0.235  exp loss = 0.219  adjusted loss = 0.219  adv prob = 0.250000   acc = 0.982
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1219]:	loss = 0.325  exp loss = 0.311  adjusted loss = 0.311  adv prob = 0.250000   acc = 0.955
Average incurred loss: 0.329  
Average sample loss: 0.329  
Average acc: 0.947  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 851]:	loss = 0.410  exp loss = 0.389  adjusted loss = 0.389  adv prob = 0.250000   acc = 0.875
  waterbird_complete95 = 0, forest2water2 = 1  [n = 639]:	loss = 0.305  exp loss = 0.298  adjusted loss = 0.298  adv prob = 0.250000   acc = 0.984
  waterbird_complete95 = 1, forest2water2 = 0  [n = 465]:	loss = 0.236  exp loss = 0.228  adjusted loss = 0.228  adv prob = 0.250000   acc = 0.994
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1245]:	loss = 0.320  exp loss = 0.305  adjusted loss = 0.305  adv prob = 0.250000   acc = 0.958
Average incurred loss: 0.327  
Average sample loss: 0.327  
Average acc: 0.942  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 795]:	loss = 0.410  exp loss = 0.401  adjusted loss = 0.401  adv prob = 0.250000   acc = 0.868
  waterbird_complete95 = 0, forest2water2 = 1  [n = 686]:	loss = 0.300  exp loss = 0.287  adjusted loss = 0.287  adv prob = 0.250000   acc = 0.988
  waterbird_complete95 = 1, forest2water2 = 0  [n = 531]:	loss = 0.238  exp loss = 0.228  adjusted loss = 0.228  adv prob = 0.250000   acc = 0.976
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1188]:	loss = 0.327  exp loss = 0.335  adjusted loss = 0.335  adv prob = 0.250000   acc = 0.949
Saved results/CUB/CUB_sample_exp/train_downstream_ERM_upweight_0_epochs_80_lr_1e-05_weight_decay_0.0/final_epoch31/JTT_upweight_50_epochs_80_lr_1e-05_weight_decay_1.0/model_outputs/output_train_epoch_17.csv
logged to wandb
Average incurred loss: 0.321  
Average sample loss: 0.322  
Average acc: 0.942  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 455]:	loss = 0.398  exp loss = 0.378  adjusted loss = 0.378  adv prob = 0.250000   acc = 0.870
  waterbird_complete95 = 0, forest2water2 = 1  [n = 353]:	loss = 0.296  exp loss = 0.276  adjusted loss = 0.276  adv prob = 0.250000   acc = 0.992
  waterbird_complete95 = 1, forest2water2 = 0  [n = 301]:	loss = 0.215  exp loss = 0.208  adjusted loss = 0.208  adv prob = 0.250000   acc = 0.990
  waterbird_complete95 = 1, forest2water2 = 1  [n = 636]:	loss = 0.330  exp loss = 0.344  adjusted loss = 0.344  adv prob = 0.250000   acc = 0.943

Validation:
Saved results/CUB/CUB_sample_exp/train_downstream_ERM_upweight_0_epochs_80_lr_1e-05_weight_decay_0.0/final_epoch31/JTT_upweight_50_epochs_80_lr_1e-05_weight_decay_1.0/model_outputs/output_val_epoch_17.csv
logged to wandb
Average incurred loss: 0.416  
Average sample loss: 0.415  
Average acc: 0.871  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.420  exp loss = 0.442  adjusted loss = 0.442  adv prob = 0.250000   acc = 0.876
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.423  exp loss = 0.459  adjusted loss = 0.459  adv prob = 0.250000   acc = 0.865
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 0.395  exp loss = 0.411  adjusted loss = 0.411  adv prob = 0.250000   acc = 0.887
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.396  exp loss = 0.379  adjusted loss = 0.379  adv prob = 0.250000   acc = 0.857
Spurious Score = 0.989
Saved results/CUB/CUB_sample_exp/train_downstream_ERM_upweight_0_epochs_80_lr_1e-05_weight_decay_0.0/final_epoch31/JTT_upweight_50_epochs_80_lr_1e-05_weight_decay_1.0/model_outputs/output_test_epoch_17.csv
logged to wandb
Current lr: 0.000010


Epoch [18]:
Training:
Average incurred loss: 0.322  
Average sample loss: 0.322  
Average acc: 0.943  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 822]:	loss = 0.397  exp loss = 0.396  adjusted loss = 0.396  adv prob = 0.250000   acc = 0.873
  waterbird_complete95 = 0, forest2water2 = 1  [n = 659]:	loss = 0.303  exp loss = 0.294  adjusted loss = 0.294  adv prob = 0.250000   acc = 0.986
  waterbird_complete95 = 1, forest2water2 = 0  [n = 526]:	loss = 0.231  exp loss = 0.220  adjusted loss = 0.220  adv prob = 0.250000   acc = 0.987
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1193]:	loss = 0.321  exp loss = 0.316  adjusted loss = 0.316  adv prob = 0.250000   acc = 0.949
Average incurred loss: 0.313  
Average sample loss: 0.313  
Average acc: 0.953  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 846]:	loss = 0.384  exp loss = 0.404  adjusted loss = 0.404  adv prob = 0.250000   acc = 0.891
  waterbird_complete95 = 0, forest2water2 = 1  [n = 613]:	loss = 0.291  exp loss = 0.281  adjusted loss = 0.281  adv prob = 0.250000   acc = 0.992
  waterbird_complete95 = 1, forest2water2 = 0  [n = 526]:	loss = 0.216  exp loss = 0.211  adjusted loss = 0.211  adv prob = 0.250000   acc = 0.987
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1215]:	loss = 0.317  exp loss = 0.308  adjusted loss = 0.308  adv prob = 0.250000   acc = 0.960
Average incurred loss: 0.316  
Average sample loss: 0.316  
Average acc: 0.944  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 855]:	loss = 0.409  exp loss = 0.409  adjusted loss = 0.409  adv prob = 0.250000   acc = 0.857
  waterbird_complete95 = 0, forest2water2 = 1  [n = 631]:	loss = 0.284  exp loss = 0.275  adjusted loss = 0.275  adv prob = 0.250000   acc = 0.994
  waterbird_complete95 = 1, forest2water2 = 0  [n = 502]:	loss = 0.222  exp loss = 0.209  adjusted loss = 0.209  adv prob = 0.250000   acc = 0.982
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1212]:	loss = 0.306  exp loss = 0.311  adjusted loss = 0.311  adv prob = 0.250000   acc = 0.963
Average incurred loss: 0.306  
Average sample loss: 0.306  
Average acc: 0.953  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 792]:	loss = 0.381  exp loss = 0.382  adjusted loss = 0.382  adv prob = 0.250000   acc = 0.896
  waterbird_complete95 = 0, forest2water2 = 1  [n = 667]:	loss = 0.282  exp loss = 0.265  adjusted loss = 0.265  adv prob = 0.250000   acc = 0.993
  waterbird_complete95 = 1, forest2water2 = 0  [n = 477]:	loss = 0.220  exp loss = 0.223  adjusted loss = 0.223  adv prob = 0.250000   acc = 0.979
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1264]:	loss = 0.303  exp loss = 0.297  adjusted loss = 0.297  adv prob = 0.250000   acc = 0.959
Saved results/CUB/CUB_sample_exp/train_downstream_ERM_upweight_0_epochs_80_lr_1e-05_weight_decay_0.0/final_epoch31/JTT_upweight_50_epochs_80_lr_1e-05_weight_decay_1.0/model_outputs/output_train_epoch_18.csv
logged to wandb
Average incurred loss: 0.313  
Average sample loss: 0.313  
Average acc: 0.950  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 483]:	loss = 0.412  exp loss = 0.404  adjusted loss = 0.404  adv prob = 0.250000   acc = 0.874
  waterbird_complete95 = 0, forest2water2 = 1  [n = 364]:	loss = 0.296  exp loss = 0.308  adjusted loss = 0.308  adv prob = 0.250000   acc = 0.981
  waterbird_complete95 = 1, forest2water2 = 0  [n = 275]:	loss = 0.199  exp loss = 0.190  adjusted loss = 0.190  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 623]:	loss = 0.296  exp loss = 0.285  adjusted loss = 0.285  adv prob = 0.250000   acc = 0.970

Validation:
Saved results/CUB/CUB_sample_exp/train_downstream_ERM_upweight_0_epochs_80_lr_1e-05_weight_decay_0.0/final_epoch31/JTT_upweight_50_epochs_80_lr_1e-05_weight_decay_1.0/model_outputs/output_val_epoch_18.csv
logged to wandb
Average incurred loss: 0.420  
Average sample loss: 0.419  
Average acc: 0.854  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.426  exp loss = 0.449  adjusted loss = 0.449  adv prob = 0.250000   acc = 0.861
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.444  exp loss = 0.482  adjusted loss = 0.482  adv prob = 0.250000   acc = 0.830
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 0.374  exp loss = 0.387  adjusted loss = 0.387  adv prob = 0.250000   acc = 0.887
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.361  exp loss = 0.345  adjusted loss = 0.345  adv prob = 0.250000   acc = 0.880
Spurious Score = 1.013
Saved results/CUB/CUB_sample_exp/train_downstream_ERM_upweight_0_epochs_80_lr_1e-05_weight_decay_0.0/final_epoch31/JTT_upweight_50_epochs_80_lr_1e-05_weight_decay_1.0/model_outputs/output_test_epoch_18.csv
logged to wandb
Current lr: 0.000010


Epoch [19]:
Training:
Average incurred loss: 0.307  
Average sample loss: 0.307  
Average acc: 0.953  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 846]:	loss = 0.375  exp loss = 0.374  adjusted loss = 0.374  adv prob = 0.250000   acc = 0.894
  waterbird_complete95 = 0, forest2water2 = 1  [n = 636]:	loss = 0.286  exp loss = 0.288  adjusted loss = 0.288  adv prob = 0.250000   acc = 0.994
  waterbird_complete95 = 1, forest2water2 = 0  [n = 481]:	loss = 0.218  exp loss = 0.204  adjusted loss = 0.204  adv prob = 0.250000   acc = 0.979
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1237]:	loss = 0.305  exp loss = 0.303  adjusted loss = 0.303  adv prob = 0.250000   acc = 0.963
Average incurred loss: 0.304  
Average sample loss: 0.304  
Average acc: 0.951  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 863]:	loss = 0.386  exp loss = 0.384  adjusted loss = 0.384  adv prob = 0.250000   acc = 0.886
  waterbird_complete95 = 0, forest2water2 = 1  [n = 650]:	loss = 0.274  exp loss = 0.263  adjusted loss = 0.263  adv prob = 0.250000   acc = 0.997
  waterbird_complete95 = 1, forest2water2 = 0  [n = 502]:	loss = 0.212  exp loss = 0.208  adjusted loss = 0.208  adv prob = 0.250000   acc = 0.986
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1185]:	loss = 0.300  exp loss = 0.301  adjusted loss = 0.301  adv prob = 0.250000   acc = 0.959
Average incurred loss: 0.297  
Average sample loss: 0.297  
Average acc: 0.954  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 808]:	loss = 0.376  exp loss = 0.348  adjusted loss = 0.348  adv prob = 0.250000   acc = 0.886
  waterbird_complete95 = 0, forest2water2 = 1  [n = 680]:	loss = 0.270  exp loss = 0.264  adjusted loss = 0.264  adv prob = 0.250000   acc = 0.990
  waterbird_complete95 = 1, forest2water2 = 0  [n = 517]:	loss = 0.211  exp loss = 0.206  adjusted loss = 0.206  adv prob = 0.250000   acc = 0.994
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1195]:	loss = 0.297  exp loss = 0.295  adjusted loss = 0.295  adv prob = 0.250000   acc = 0.962
Average incurred loss: 0.297  
Average sample loss: 0.297  
Average acc: 0.953  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 832]:	loss = 0.371  exp loss = 0.362  adjusted loss = 0.362  adv prob = 0.250000   acc = 0.894
  waterbird_complete95 = 0, forest2water2 = 1  [n = 639]:	loss = 0.265  exp loss = 0.263  adjusted loss = 0.263  adv prob = 0.250000   acc = 0.991
  waterbird_complete95 = 1, forest2water2 = 0  [n = 534]:	loss = 0.207  exp loss = 0.205  adjusted loss = 0.205  adv prob = 0.250000   acc = 0.991
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1195]:	loss = 0.303  exp loss = 0.294  adjusted loss = 0.294  adv prob = 0.250000   acc = 0.957
Saved results/CUB/CUB_sample_exp/train_downstream_ERM_upweight_0_epochs_80_lr_1e-05_weight_decay_0.0/final_epoch31/JTT_upweight_50_epochs_80_lr_1e-05_weight_decay_1.0/model_outputs/output_train_epoch_19.csv
logged to wandb
Average incurred loss: 0.296  
Average sample loss: 0.299  
Average acc: 0.952  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 449]:	loss = 0.360  exp loss = 0.368  adjusted loss = 0.368  adv prob = 0.250000   acc = 0.906
  waterbird_complete95 = 0, forest2water2 = 1  [n = 329]:	loss = 0.258  exp loss = 0.256  adjusted loss = 0.256  adv prob = 0.250000   acc = 0.994
  waterbird_complete95 = 1, forest2water2 = 0  [n = 272]:	loss = 0.217  exp loss = 0.224  adjusted loss = 0.224  adv prob = 0.250000   acc = 0.974
  waterbird_complete95 = 1, forest2water2 = 1  [n = 695]:	loss = 0.304  exp loss = 0.304  adjusted loss = 0.304  adv prob = 0.250000   acc = 0.953

Validation:
Saved results/CUB/CUB_sample_exp/train_downstream_ERM_upweight_0_epochs_80_lr_1e-05_weight_decay_0.0/final_epoch31/JTT_upweight_50_epochs_80_lr_1e-05_weight_decay_1.0/model_outputs/output_val_epoch_19.csv
logged to wandb
Average incurred loss: 0.390  
Average sample loss: 0.389  
Average acc: 0.885  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.378  exp loss = 0.401  adjusted loss = 0.401  adv prob = 0.250000   acc = 0.910
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.397  exp loss = 0.434  adjusted loss = 0.434  adv prob = 0.250000   acc = 0.867
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 0.406  exp loss = 0.421  adjusted loss = 0.421  adv prob = 0.250000   acc = 0.887
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.392  exp loss = 0.374  adjusted loss = 0.374  adv prob = 0.250000   acc = 0.857
Spurious Score = 1.007
Saved results/CUB/CUB_sample_exp/train_downstream_ERM_upweight_0_epochs_80_lr_1e-05_weight_decay_0.0/final_epoch31/JTT_upweight_50_epochs_80_lr_1e-05_weight_decay_1.0/model_outputs/output_test_epoch_19.csv
logged to wandb
Current lr: 0.000010


Epoch [20]:
Training:
Average incurred loss: 0.291  
Average sample loss: 0.291  
Average acc: 0.956  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 819]:	loss = 0.374  exp loss = 0.372  adjusted loss = 0.372  adv prob = 0.250000   acc = 0.883
  waterbird_complete95 = 0, forest2water2 = 1  [n = 663]:	loss = 0.263  exp loss = 0.258  adjusted loss = 0.258  adv prob = 0.250000   acc = 0.995
  waterbird_complete95 = 1, forest2water2 = 0  [n = 508]:	loss = 0.205  exp loss = 0.209  adjusted loss = 0.209  adv prob = 0.250000   acc = 0.994
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1210]:	loss = 0.287  exp loss = 0.282  adjusted loss = 0.282  adv prob = 0.250000   acc = 0.969
Average incurred loss: 0.286  
Average sample loss: 0.286  
Average acc: 0.962  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 825]:	loss = 0.359  exp loss = 0.362  adjusted loss = 0.362  adv prob = 0.250000   acc = 0.915
  waterbird_complete95 = 0, forest2water2 = 1  [n = 664]:	loss = 0.270  exp loss = 0.271  adjusted loss = 0.271  adv prob = 0.250000   acc = 0.992
  waterbird_complete95 = 1, forest2water2 = 0  [n = 502]:	loss = 0.201  exp loss = 0.206  adjusted loss = 0.206  adv prob = 0.250000   acc = 0.998
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1209]:	loss = 0.282  exp loss = 0.274  adjusted loss = 0.274  adv prob = 0.250000   acc = 0.962
Average incurred loss: 0.284  
Average sample loss: 0.284  
Average acc: 0.958  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 828]:	loss = 0.354  exp loss = 0.337  adjusted loss = 0.337  adv prob = 0.250000   acc = 0.900
  waterbird_complete95 = 0, forest2water2 = 1  [n = 639]:	loss = 0.256  exp loss = 0.248  adjusted loss = 0.248  adv prob = 0.250000   acc = 0.997
  waterbird_complete95 = 1, forest2water2 = 0  [n = 504]:	loss = 0.206  exp loss = 0.213  adjusted loss = 0.213  adv prob = 0.250000   acc = 0.992
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1229]:	loss = 0.284  exp loss = 0.278  adjusted loss = 0.278  adv prob = 0.250000   acc = 0.963
Average incurred loss: 0.284  
Average sample loss: 0.284  
Average acc: 0.956  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 870]:	loss = 0.368  exp loss = 0.352  adjusted loss = 0.352  adv prob = 0.250000   acc = 0.889
  waterbird_complete95 = 0, forest2water2 = 1  [n = 632]:	loss = 0.257  exp loss = 0.263  adjusted loss = 0.263  adv prob = 0.250000   acc = 0.991
  waterbird_complete95 = 1, forest2water2 = 0  [n = 510]:	loss = 0.182  exp loss = 0.166  adjusted loss = 0.166  adv prob = 0.250000   acc = 0.996
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1188]:	loss = 0.281  exp loss = 0.276  adjusted loss = 0.276  adv prob = 0.250000   acc = 0.969
Saved results/CUB/CUB_sample_exp/train_downstream_ERM_upweight_0_epochs_80_lr_1e-05_weight_decay_0.0/final_epoch31/JTT_upweight_50_epochs_80_lr_1e-05_weight_decay_1.0/model_outputs/output_train_epoch_20.csv
logged to wandb
Average incurred loss: 0.281  
Average sample loss: 0.281  
Average acc: 0.960  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 456]:	loss = 0.352  exp loss = 0.334  adjusted loss = 0.334  adv prob = 0.250000   acc = 0.897
  waterbird_complete95 = 0, forest2water2 = 1  [n = 336]:	loss = 0.247  exp loss = 0.233  adjusted loss = 0.233  adv prob = 0.250000   acc = 0.994
  waterbird_complete95 = 1, forest2water2 = 0  [n = 282]:	loss = 0.210  exp loss = 0.204  adjusted loss = 0.204  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 671]:	loss = 0.281  exp loss = 0.275  adjusted loss = 0.275  adv prob = 0.250000   acc = 0.970

Validation:
Saved results/CUB/CUB_sample_exp/train_downstream_ERM_upweight_0_epochs_80_lr_1e-05_weight_decay_0.0/final_epoch31/JTT_upweight_50_epochs_80_lr_1e-05_weight_decay_1.0/model_outputs/output_val_epoch_20.csv
logged to wandb
Average incurred loss: 0.383  
Average sample loss: 0.382  
Average acc: 0.891  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.364  exp loss = 0.385  adjusted loss = 0.385  adv prob = 0.250000   acc = 0.919
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.397  exp loss = 0.434  adjusted loss = 0.434  adv prob = 0.250000   acc = 0.871
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 0.409  exp loss = 0.423  adjusted loss = 0.423  adv prob = 0.250000   acc = 0.880
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.374  exp loss = 0.357  adjusted loss = 0.357  adv prob = 0.250000   acc = 0.872
Spurious Score = 1.023
Saved results/CUB/CUB_sample_exp/train_downstream_ERM_upweight_0_epochs_80_lr_1e-05_weight_decay_0.0/final_epoch31/JTT_upweight_50_epochs_80_lr_1e-05_weight_decay_1.0/model_outputs/output_test_epoch_20.csv
logged to wandb
Current lr: 0.000010


Epoch [21]:
Training:
Average incurred loss: 0.277  
Average sample loss: 0.277  
Average acc: 0.960  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 853]:	loss = 0.346  exp loss = 0.342  adjusted loss = 0.342  adv prob = 0.250000   acc = 0.899
  waterbird_complete95 = 0, forest2water2 = 1  [n = 609]:	loss = 0.248  exp loss = 0.241  adjusted loss = 0.241  adv prob = 0.250000   acc = 0.995
  waterbird_complete95 = 1, forest2water2 = 0  [n = 516]:	loss = 0.188  exp loss = 0.185  adjusted loss = 0.185  adv prob = 0.250000   acc = 0.998
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1222]:	loss = 0.281  exp loss = 0.277  adjusted loss = 0.277  adv prob = 0.250000   acc = 0.969
Average incurred loss: 0.277  
Average sample loss: 0.277  
Average acc: 0.963  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 861]:	loss = 0.351  exp loss = 0.352  adjusted loss = 0.352  adv prob = 0.250000   acc = 0.898
  waterbird_complete95 = 0, forest2water2 = 1  [n = 642]:	loss = 0.262  exp loss = 0.271  adjusted loss = 0.271  adv prob = 0.250000   acc = 0.995
  waterbird_complete95 = 1, forest2water2 = 0  [n = 499]:	loss = 0.190  exp loss = 0.181  adjusted loss = 0.181  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1198]:	loss = 0.269  exp loss = 0.264  adjusted loss = 0.264  adv prob = 0.250000   acc = 0.978
Average incurred loss: 0.272  
Average sample loss: 0.272  
Average acc: 0.960  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 814]:	loss = 0.337  exp loss = 0.335  adjusted loss = 0.335  adv prob = 0.250000   acc = 0.902
  waterbird_complete95 = 0, forest2water2 = 1  [n = 629]:	loss = 0.249  exp loss = 0.244  adjusted loss = 0.244  adv prob = 0.250000   acc = 0.989
  waterbird_complete95 = 1, forest2water2 = 0  [n = 528]:	loss = 0.197  exp loss = 0.188  adjusted loss = 0.188  adv prob = 0.250000   acc = 0.998
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1229]:	loss = 0.274  exp loss = 0.260  adjusted loss = 0.260  adv prob = 0.250000   acc = 0.968
Average incurred loss: 0.270  
Average sample loss: 0.270  
Average acc: 0.963  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 831]:	loss = 0.352  exp loss = 0.344  adjusted loss = 0.344  adv prob = 0.250000   acc = 0.904
  waterbird_complete95 = 0, forest2water2 = 1  [n = 687]:	loss = 0.252  exp loss = 0.262  adjusted loss = 0.262  adv prob = 0.250000   acc = 0.997
  waterbird_complete95 = 1, forest2water2 = 0  [n = 501]:	loss = 0.189  exp loss = 0.185  adjusted loss = 0.185  adv prob = 0.250000   acc = 0.998
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1181]:	loss = 0.257  exp loss = 0.251  adjusted loss = 0.251  adv prob = 0.250000   acc = 0.970
Saved results/CUB/CUB_sample_exp/train_downstream_ERM_upweight_0_epochs_80_lr_1e-05_weight_decay_0.0/final_epoch31/JTT_upweight_50_epochs_80_lr_1e-05_weight_decay_1.0/model_outputs/output_train_epoch_21.csv
logged to wandb
Average incurred loss: 0.269  
Average sample loss: 0.268  
Average acc: 0.972  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 439]:	loss = 0.328  exp loss = 0.307  adjusted loss = 0.307  adv prob = 0.250000   acc = 0.932
  waterbird_complete95 = 0, forest2water2 = 1  [n = 367]:	loss = 0.255  exp loss = 0.249  adjusted loss = 0.249  adv prob = 0.250000   acc = 0.989
  waterbird_complete95 = 1, forest2water2 = 0  [n = 262]:	loss = 0.190  exp loss = 0.197  adjusted loss = 0.197  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 677]:	loss = 0.268  exp loss = 0.254  adjusted loss = 0.254  adv prob = 0.250000   acc = 0.978

Validation:
Saved results/CUB/CUB_sample_exp/train_downstream_ERM_upweight_0_epochs_80_lr_1e-05_weight_decay_0.0/final_epoch31/JTT_upweight_50_epochs_80_lr_1e-05_weight_decay_1.0/model_outputs/output_val_epoch_21.csv
logged to wandb
Average incurred loss: 0.370  
Average sample loss: 0.369  
Average acc: 0.892  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.342  exp loss = 0.365  adjusted loss = 0.365  adv prob = 0.250000   acc = 0.927
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.387  exp loss = 0.424  adjusted loss = 0.424  adv prob = 0.250000   acc = 0.867
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 0.412  exp loss = 0.427  adjusted loss = 0.427  adv prob = 0.250000   acc = 0.865
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.365  exp loss = 0.346  adjusted loss = 0.346  adv prob = 0.250000   acc = 0.880
Spurious Score = 1.043
Saved results/CUB/CUB_sample_exp/train_downstream_ERM_upweight_0_epochs_80_lr_1e-05_weight_decay_0.0/final_epoch31/JTT_upweight_50_epochs_80_lr_1e-05_weight_decay_1.0/model_outputs/output_test_epoch_21.csv
logged to wandb
Current lr: 0.000010


Epoch [22]:
Training:
Average incurred loss: 0.270  
Average sample loss: 0.270  
Average acc: 0.957  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 875]:	loss = 0.353  exp loss = 0.342  adjusted loss = 0.342  adv prob = 0.250000   acc = 0.887
  waterbird_complete95 = 0, forest2water2 = 1  [n = 681]:	loss = 0.253  exp loss = 0.256  adjusted loss = 0.256  adv prob = 0.250000   acc = 0.991
  waterbird_complete95 = 1, forest2water2 = 0  [n = 465]:	loss = 0.175  exp loss = 0.166  adjusted loss = 0.166  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1179]:	loss = 0.256  exp loss = 0.244  adjusted loss = 0.244  adv prob = 0.250000   acc = 0.972
Average incurred loss: 0.265  
Average sample loss: 0.265  
Average acc: 0.964  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 835]:	loss = 0.329  exp loss = 0.322  adjusted loss = 0.322  adv prob = 0.250000   acc = 0.905
  waterbird_complete95 = 0, forest2water2 = 1  [n = 634]:	loss = 0.232  exp loss = 0.221  adjusted loss = 0.221  adv prob = 0.250000   acc = 0.995
  waterbird_complete95 = 1, forest2water2 = 0  [n = 493]:	loss = 0.184  exp loss = 0.180  adjusted loss = 0.180  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1238]:	loss = 0.271  exp loss = 0.270  adjusted loss = 0.270  adv prob = 0.250000   acc = 0.973
Average incurred loss: 0.259  
Average sample loss: 0.259  
Average acc: 0.967  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 820]:	loss = 0.318  exp loss = 0.331  adjusted loss = 0.331  adv prob = 0.250000   acc = 0.922
  waterbird_complete95 = 0, forest2water2 = 1  [n = 637]:	loss = 0.228  exp loss = 0.227  adjusted loss = 0.227  adv prob = 0.250000   acc = 0.994
  waterbird_complete95 = 1, forest2water2 = 0  [n = 540]:	loss = 0.191  exp loss = 0.179  adjusted loss = 0.179  adv prob = 0.250000   acc = 0.994
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1203]:	loss = 0.265  exp loss = 0.241  adjusted loss = 0.241  adv prob = 0.250000   acc = 0.970
Average incurred loss: 0.251  
Average sample loss: 0.251  
Average acc: 0.975  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 822]:	loss = 0.300  exp loss = 0.304  adjusted loss = 0.304  adv prob = 0.250000   acc = 0.942
  waterbird_complete95 = 0, forest2water2 = 1  [n = 636]:	loss = 0.233  exp loss = 0.229  adjusted loss = 0.229  adv prob = 0.250000   acc = 0.997
  waterbird_complete95 = 1, forest2water2 = 0  [n = 532]:	loss = 0.188  exp loss = 0.183  adjusted loss = 0.183  adv prob = 0.250000   acc = 0.994
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1210]:	loss = 0.253  exp loss = 0.248  adjusted loss = 0.248  adv prob = 0.250000   acc = 0.978
Saved results/CUB/CUB_sample_exp/train_downstream_ERM_upweight_0_epochs_80_lr_1e-05_weight_decay_0.0/final_epoch31/JTT_upweight_50_epochs_80_lr_1e-05_weight_decay_1.0/model_outputs/output_train_epoch_22.csv
logged to wandb
Average incurred loss: 0.257  
Average sample loss: 0.258  
Average acc: 0.966  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 446]:	loss = 0.324  exp loss = 0.303  adjusted loss = 0.303  adv prob = 0.250000   acc = 0.910
  waterbird_complete95 = 0, forest2water2 = 1  [n = 346]:	loss = 0.223  exp loss = 0.224  adjusted loss = 0.224  adv prob = 0.250000   acc = 0.997
  waterbird_complete95 = 1, forest2water2 = 0  [n = 276]:	loss = 0.187  exp loss = 0.186  adjusted loss = 0.186  adv prob = 0.250000   acc = 0.993
  waterbird_complete95 = 1, forest2water2 = 1  [n = 677]:	loss = 0.260  exp loss = 0.255  adjusted loss = 0.255  adv prob = 0.250000   acc = 0.975

Validation:
Saved results/CUB/CUB_sample_exp/train_downstream_ERM_upweight_0_epochs_80_lr_1e-05_weight_decay_0.0/final_epoch31/JTT_upweight_50_epochs_80_lr_1e-05_weight_decay_1.0/model_outputs/output_val_epoch_22.csv
logged to wandb
Average incurred loss: 0.360  
Average sample loss: 0.359  
Average acc: 0.896  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.325  exp loss = 0.348  adjusted loss = 0.348  adv prob = 0.250000   acc = 0.931
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.376  exp loss = 0.411  adjusted loss = 0.411  adv prob = 0.250000   acc = 0.871
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 0.421  exp loss = 0.436  adjusted loss = 0.436  adv prob = 0.250000   acc = 0.872
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.365  exp loss = 0.346  adjusted loss = 0.346  adv prob = 0.250000   acc = 0.880
Spurious Score = 1.039
Saved results/CUB/CUB_sample_exp/train_downstream_ERM_upweight_0_epochs_80_lr_1e-05_weight_decay_0.0/final_epoch31/JTT_upweight_50_epochs_80_lr_1e-05_weight_decay_1.0/model_outputs/output_test_epoch_22.csv
logged to wandb
Current lr: 0.000010


Epoch [23]:
Training:
Average incurred loss: 0.255  
Average sample loss: 0.255  
Average acc: 0.964  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 861]:	loss = 0.332  exp loss = 0.312  adjusted loss = 0.312  adv prob = 0.250000   acc = 0.911
  waterbird_complete95 = 0, forest2water2 = 1  [n = 634]:	loss = 0.225  exp loss = 0.220  adjusted loss = 0.220  adv prob = 0.250000   acc = 0.995
  waterbird_complete95 = 1, forest2water2 = 0  [n = 485]:	loss = 0.169  exp loss = 0.166  adjusted loss = 0.166  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1220]:	loss = 0.252  exp loss = 0.247  adjusted loss = 0.247  adv prob = 0.250000   acc = 0.972
Average incurred loss: 0.251  
Average sample loss: 0.251  
Average acc: 0.971  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 811]:	loss = 0.314  exp loss = 0.306  adjusted loss = 0.306  adv prob = 0.250000   acc = 0.922
  waterbird_complete95 = 0, forest2water2 = 1  [n = 649]:	loss = 0.227  exp loss = 0.214  adjusted loss = 0.214  adv prob = 0.250000   acc = 0.995
  waterbird_complete95 = 1, forest2water2 = 0  [n = 523]:	loss = 0.189  exp loss = 0.193  adjusted loss = 0.193  adv prob = 0.250000   acc = 0.994
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1217]:	loss = 0.250  exp loss = 0.256  adjusted loss = 0.256  adv prob = 0.250000   acc = 0.981
Average incurred loss: 0.248  
Average sample loss: 0.248  
Average acc: 0.968  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 857]:	loss = 0.320  exp loss = 0.317  adjusted loss = 0.317  adv prob = 0.250000   acc = 0.907
  waterbird_complete95 = 0, forest2water2 = 1  [n = 644]:	loss = 0.226  exp loss = 0.231  adjusted loss = 0.231  adv prob = 0.250000   acc = 0.998
  waterbird_complete95 = 1, forest2water2 = 0  [n = 505]:	loss = 0.172  exp loss = 0.162  adjusted loss = 0.162  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1194]:	loss = 0.240  exp loss = 0.233  adjusted loss = 0.233  adv prob = 0.250000   acc = 0.981
Average incurred loss: 0.249  
Average sample loss: 0.249  
Average acc: 0.966  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 820]:	loss = 0.309  exp loss = 0.294  adjusted loss = 0.294  adv prob = 0.250000   acc = 0.913
  waterbird_complete95 = 0, forest2water2 = 1  [n = 648]:	loss = 0.229  exp loss = 0.221  adjusted loss = 0.221  adv prob = 0.250000   acc = 0.995
  waterbird_complete95 = 1, forest2water2 = 0  [n = 505]:	loss = 0.177  exp loss = 0.176  adjusted loss = 0.176  adv prob = 0.250000   acc = 0.994
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1227]:	loss = 0.249  exp loss = 0.250  adjusted loss = 0.250  adv prob = 0.250000   acc = 0.975
Saved results/CUB/CUB_sample_exp/train_downstream_ERM_upweight_0_epochs_80_lr_1e-05_weight_decay_0.0/final_epoch31/JTT_upweight_50_epochs_80_lr_1e-05_weight_decay_1.0/model_outputs/output_train_epoch_23.csv
logged to wandb
Average incurred loss: 0.246  
Average sample loss: 0.247  
Average acc: 0.974  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 449]:	loss = 0.307  exp loss = 0.299  adjusted loss = 0.299  adv prob = 0.250000   acc = 0.931
  waterbird_complete95 = 0, forest2water2 = 1  [n = 359]:	loss = 0.231  exp loss = 0.221  adjusted loss = 0.221  adv prob = 0.250000   acc = 0.989
  waterbird_complete95 = 1, forest2water2 = 0  [n = 288]:	loss = 0.173  exp loss = 0.171  adjusted loss = 0.171  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 649]:	loss = 0.243  exp loss = 0.252  adjusted loss = 0.252  adv prob = 0.250000   acc = 0.985

Validation:
Saved results/CUB/CUB_sample_exp/train_downstream_ERM_upweight_0_epochs_80_lr_1e-05_weight_decay_0.0/final_epoch31/JTT_upweight_50_epochs_80_lr_1e-05_weight_decay_1.0/model_outputs/output_val_epoch_23.csv
logged to wandb
Average incurred loss: 0.346  
Average sample loss: 0.345  
Average acc: 0.897  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.304  exp loss = 0.327  adjusted loss = 0.327  adv prob = 0.250000   acc = 0.936
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.359  exp loss = 0.397  adjusted loss = 0.397  adv prob = 0.250000   acc = 0.878
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 0.430  exp loss = 0.444  adjusted loss = 0.444  adv prob = 0.250000   acc = 0.857
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.364  exp loss = 0.345  adjusted loss = 0.345  adv prob = 0.250000   acc = 0.872
Spurious Score = 1.042
Saved results/CUB/CUB_sample_exp/train_downstream_ERM_upweight_0_epochs_80_lr_1e-05_weight_decay_0.0/final_epoch31/JTT_upweight_50_epochs_80_lr_1e-05_weight_decay_1.0/model_outputs/output_test_epoch_23.csv
logged to wandb
Current lr: 0.000010


Epoch [24]:
Training:
Average incurred loss: 0.243  
Average sample loss: 0.243  
Average acc: 0.970  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 840]:	loss = 0.306  exp loss = 0.324  adjusted loss = 0.324  adv prob = 0.250000   acc = 0.921
  waterbird_complete95 = 0, forest2water2 = 1  [n = 615]:	loss = 0.214  exp loss = 0.229  adjusted loss = 0.229  adv prob = 0.250000   acc = 0.995
  waterbird_complete95 = 1, forest2water2 = 0  [n = 513]:	loss = 0.174  exp loss = 0.166  adjusted loss = 0.166  adv prob = 0.250000   acc = 0.996
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1232]:	loss = 0.243  exp loss = 0.230  adjusted loss = 0.230  adv prob = 0.250000   acc = 0.980
Average incurred loss: 0.237  
Average sample loss: 0.237  
Average acc: 0.976  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 834]:	loss = 0.299  exp loss = 0.306  adjusted loss = 0.306  adv prob = 0.250000   acc = 0.932
  waterbird_complete95 = 0, forest2water2 = 1  [n = 645]:	loss = 0.219  exp loss = 0.203  adjusted loss = 0.203  adv prob = 0.250000   acc = 0.997
  waterbird_complete95 = 1, forest2water2 = 0  [n = 503]:	loss = 0.170  exp loss = 0.170  adjusted loss = 0.170  adv prob = 0.250000   acc = 0.996
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1218]:	loss = 0.232  exp loss = 0.236  adjusted loss = 0.236  adv prob = 0.250000   acc = 0.987
Average incurred loss: 0.238  
Average sample loss: 0.238  
Average acc: 0.975  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 830]:	loss = 0.300  exp loss = 0.298  adjusted loss = 0.298  adv prob = 0.250000   acc = 0.935
  waterbird_complete95 = 0, forest2water2 = 1  [n = 680]:	loss = 0.231  exp loss = 0.220  adjusted loss = 0.220  adv prob = 0.250000   acc = 0.991
  waterbird_complete95 = 1, forest2water2 = 0  [n = 505]:	loss = 0.167  exp loss = 0.171  adjusted loss = 0.171  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1185]:	loss = 0.229  exp loss = 0.224  adjusted loss = 0.224  adv prob = 0.250000   acc = 0.982
Average incurred loss: 0.238  
Average sample loss: 0.238  
Average acc: 0.971  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 839]:	loss = 0.302  exp loss = 0.304  adjusted loss = 0.304  adv prob = 0.250000   acc = 0.923
  waterbird_complete95 = 0, forest2water2 = 1  [n = 644]:	loss = 0.215  exp loss = 0.213  adjusted loss = 0.213  adv prob = 0.250000   acc = 0.994
  waterbird_complete95 = 1, forest2water2 = 0  [n = 501]:	loss = 0.169  exp loss = 0.151  adjusted loss = 0.151  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1216]:	loss = 0.235  exp loss = 0.224  adjusted loss = 0.224  adv prob = 0.250000   acc = 0.980
Saved results/CUB/CUB_sample_exp/train_downstream_ERM_upweight_0_epochs_80_lr_1e-05_weight_decay_0.0/final_epoch31/JTT_upweight_50_epochs_80_lr_1e-05_weight_decay_1.0/model_outputs/output_train_epoch_24.csv
logged to wandb
Average incurred loss: 0.233  
Average sample loss: 0.238  
Average acc: 0.973  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 455]:	loss = 0.294  exp loss = 0.315  adjusted loss = 0.315  adv prob = 0.250000   acc = 0.932
  waterbird_complete95 = 0, forest2water2 = 1  [n = 350]:	loss = 0.208  exp loss = 0.211  adjusted loss = 0.211  adv prob = 0.250000   acc = 0.997
  waterbird_complete95 = 1, forest2water2 = 0  [n = 284]:	loss = 0.161  exp loss = 0.150  adjusted loss = 0.150  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 656]:	loss = 0.234  exp loss = 0.221  adjusted loss = 0.221  adv prob = 0.250000   acc = 0.977

Validation:
Saved results/CUB/CUB_sample_exp/train_downstream_ERM_upweight_0_epochs_80_lr_1e-05_weight_decay_0.0/final_epoch31/JTT_upweight_50_epochs_80_lr_1e-05_weight_decay_1.0/model_outputs/output_val_epoch_24.csv
logged to wandb
Average incurred loss: 0.361  
Average sample loss: 0.359  
Average acc: 0.892  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.329  exp loss = 0.352  adjusted loss = 0.352  adv prob = 0.250000   acc = 0.923
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.388  exp loss = 0.426  adjusted loss = 0.426  adv prob = 0.250000   acc = 0.865
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 0.398  exp loss = 0.408  adjusted loss = 0.408  adv prob = 0.250000   acc = 0.887
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.337  exp loss = 0.317  adjusted loss = 0.317  adv prob = 0.250000   acc = 0.887
Spurious Score = 1.033
Saved results/CUB/CUB_sample_exp/train_downstream_ERM_upweight_0_epochs_80_lr_1e-05_weight_decay_0.0/final_epoch31/JTT_upweight_50_epochs_80_lr_1e-05_weight_decay_1.0/model_outputs/output_test_epoch_24.csv
logged to wandb
Current lr: 0.000010


Epoch [25]:
Training:
Average incurred loss: 0.231  
Average sample loss: 0.231  
Average acc: 0.977  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 806]:	loss = 0.287  exp loss = 0.270  adjusted loss = 0.270  adv prob = 0.250000   acc = 0.934
  waterbird_complete95 = 0, forest2water2 = 1  [n = 664]:	loss = 0.208  exp loss = 0.201  adjusted loss = 0.201  adv prob = 0.250000   acc = 0.995
  waterbird_complete95 = 1, forest2water2 = 0  [n = 506]:	loss = 0.166  exp loss = 0.163  adjusted loss = 0.163  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1224]:	loss = 0.234  exp loss = 0.233  adjusted loss = 0.233  adv prob = 0.250000   acc = 0.985
Average incurred loss: 0.229  
Average sample loss: 0.229  
Average acc: 0.976  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 845]:	loss = 0.284  exp loss = 0.285  adjusted loss = 0.285  adv prob = 0.250000   acc = 0.934
  waterbird_complete95 = 0, forest2water2 = 1  [n = 623]:	loss = 0.206  exp loss = 0.197  adjusted loss = 0.197  adv prob = 0.250000   acc = 0.998
  waterbird_complete95 = 1, forest2water2 = 0  [n = 524]:	loss = 0.169  exp loss = 0.167  adjusted loss = 0.167  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1208]:	loss = 0.229  exp loss = 0.232  adjusted loss = 0.232  adv prob = 0.250000   acc = 0.984
Average incurred loss: 0.231  
Average sample loss: 0.231  
Average acc: 0.967  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 833]:	loss = 0.289  exp loss = 0.253  adjusted loss = 0.253  adv prob = 0.250000   acc = 0.912
  waterbird_complete95 = 0, forest2water2 = 1  [n = 647]:	loss = 0.213  exp loss = 0.189  adjusted loss = 0.189  adv prob = 0.250000   acc = 0.992
  waterbird_complete95 = 1, forest2water2 = 0  [n = 503]:	loss = 0.162  exp loss = 0.169  adjusted loss = 0.169  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1217]:	loss = 0.228  exp loss = 0.239  adjusted loss = 0.239  adv prob = 0.250000   acc = 0.976
Average incurred loss: 0.224  
Average sample loss: 0.224  
Average acc: 0.977  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 854]:	loss = 0.287  exp loss = 0.302  adjusted loss = 0.302  adv prob = 0.250000   acc = 0.925
  waterbird_complete95 = 0, forest2water2 = 1  [n = 655]:	loss = 0.211  exp loss = 0.209  adjusted loss = 0.209  adv prob = 0.250000   acc = 0.997
  waterbird_complete95 = 1, forest2water2 = 0  [n = 499]:	loss = 0.156  exp loss = 0.153  adjusted loss = 0.153  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1192]:	loss = 0.214  exp loss = 0.207  adjusted loss = 0.207  adv prob = 0.250000   acc = 0.993
Saved results/CUB/CUB_sample_exp/train_downstream_ERM_upweight_0_epochs_80_lr_1e-05_weight_decay_0.0/final_epoch31/JTT_upweight_50_epochs_80_lr_1e-05_weight_decay_1.0/model_outputs/output_train_epoch_25.csv
logged to wandb
Average incurred loss: 0.227  
Average sample loss: 0.227  
Average acc: 0.973  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 460]:	loss = 0.292  exp loss = 0.270  adjusted loss = 0.270  adv prob = 0.250000   acc = 0.920
  waterbird_complete95 = 0, forest2water2 = 1  [n = 345]:	loss = 0.197  exp loss = 0.181  adjusted loss = 0.181  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 0  [n = 274]:	loss = 0.157  exp loss = 0.166  adjusted loss = 0.166  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 666]:	loss = 0.226  exp loss = 0.225  adjusted loss = 0.225  adv prob = 0.250000   acc = 0.985

Validation:
Saved results/CUB/CUB_sample_exp/train_downstream_ERM_upweight_0_epochs_80_lr_1e-05_weight_decay_0.0/final_epoch31/JTT_upweight_50_epochs_80_lr_1e-05_weight_decay_1.0/model_outputs/output_val_epoch_25.csv
logged to wandb
Average incurred loss: 0.335  
Average sample loss: 0.334  
Average acc: 0.902  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.283  exp loss = 0.304  adjusted loss = 0.304  adv prob = 0.250000   acc = 0.942
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.346  exp loss = 0.382  adjusted loss = 0.382  adv prob = 0.250000   acc = 0.884
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 0.448  exp loss = 0.463  adjusted loss = 0.463  adv prob = 0.250000   acc = 0.842
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.366  exp loss = 0.346  adjusted loss = 0.346  adv prob = 0.250000   acc = 0.880
Spurious Score = 1.055
Saved results/CUB/CUB_sample_exp/train_downstream_ERM_upweight_0_epochs_80_lr_1e-05_weight_decay_0.0/final_epoch31/JTT_upweight_50_epochs_80_lr_1e-05_weight_decay_1.0/model_outputs/output_test_epoch_25.csv
logged to wandb
Current lr: 0.000010


Epoch [26]:
Training:
Average incurred loss: 0.221  
Average sample loss: 0.221  
Average acc: 0.978  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 878]:	loss = 0.271  exp loss = 0.258  adjusted loss = 0.258  adv prob = 0.250000   acc = 0.944
  waterbird_complete95 = 0, forest2water2 = 1  [n = 626]:	loss = 0.213  exp loss = 0.204  adjusted loss = 0.204  adv prob = 0.250000   acc = 0.994
  waterbird_complete95 = 1, forest2water2 = 0  [n = 507]:	loss = 0.156  exp loss = 0.151  adjusted loss = 0.151  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1189]:	loss = 0.215  exp loss = 0.211  adjusted loss = 0.211  adv prob = 0.250000   acc = 0.986
Average incurred loss: 0.224  
Average sample loss: 0.224  
Average acc: 0.971  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 823]:	loss = 0.300  exp loss = 0.288  adjusted loss = 0.288  adv prob = 0.250000   acc = 0.910
  waterbird_complete95 = 0, forest2water2 = 1  [n = 673]:	loss = 0.195  exp loss = 0.187  adjusted loss = 0.187  adv prob = 0.250000   acc = 0.999
  waterbird_complete95 = 1, forest2water2 = 0  [n = 479]:	loss = 0.158  exp loss = 0.146  adjusted loss = 0.146  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1225]:	loss = 0.215  exp loss = 0.207  adjusted loss = 0.207  adv prob = 0.250000   acc = 0.984
Average incurred loss: 0.223  
Average sample loss: 0.223  
Average acc: 0.980  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 838]:	loss = 0.280  exp loss = 0.263  adjusted loss = 0.263  adv prob = 0.250000   acc = 0.946
  waterbird_complete95 = 0, forest2water2 = 1  [n = 623]:	loss = 0.192  exp loss = 0.189  adjusted loss = 0.189  adv prob = 0.250000   acc = 0.997
  waterbird_complete95 = 1, forest2water2 = 0  [n = 543]:	loss = 0.165  exp loss = 0.162  adjusted loss = 0.162  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1196]:	loss = 0.225  exp loss = 0.213  adjusted loss = 0.213  adv prob = 0.250000   acc = 0.985
Average incurred loss: 0.213  
Average sample loss: 0.213  
Average acc: 0.984  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 790]:	loss = 0.255  exp loss = 0.241  adjusted loss = 0.241  adv prob = 0.250000   acc = 0.959
  waterbird_complete95 = 0, forest2water2 = 1  [n = 668]:	loss = 0.193  exp loss = 0.195  adjusted loss = 0.195  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 0  [n = 507]:	loss = 0.159  exp loss = 0.150  adjusted loss = 0.150  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1235]:	loss = 0.219  exp loss = 0.208  adjusted loss = 0.208  adv prob = 0.250000   acc = 0.985
Saved results/CUB/CUB_sample_exp/train_downstream_ERM_upweight_0_epochs_80_lr_1e-05_weight_decay_0.0/final_epoch31/JTT_upweight_50_epochs_80_lr_1e-05_weight_decay_1.0/model_outputs/output_train_epoch_26.csv
logged to wandb
Average incurred loss: 0.219  
Average sample loss: 0.219  
Average acc: 0.977  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 469]:	loss = 0.273  exp loss = 0.263  adjusted loss = 0.263  adv prob = 0.250000   acc = 0.938
  waterbird_complete95 = 0, forest2water2 = 1  [n = 344]:	loss = 0.203  exp loss = 0.210  adjusted loss = 0.210  adv prob = 0.250000   acc = 0.997
  waterbird_complete95 = 1, forest2water2 = 0  [n = 270]:	loss = 0.154  exp loss = 0.135  adjusted loss = 0.135  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 662]:	loss = 0.217  exp loss = 0.197  adjusted loss = 0.197  adv prob = 0.250000   acc = 0.985

Validation:
Saved results/CUB/CUB_sample_exp/train_downstream_ERM_upweight_0_epochs_80_lr_1e-05_weight_decay_0.0/final_epoch31/JTT_upweight_50_epochs_80_lr_1e-05_weight_decay_1.0/model_outputs/output_val_epoch_26.csv
logged to wandb
Average incurred loss: 0.343  
Average sample loss: 0.342  
Average acc: 0.897  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.301  exp loss = 0.324  adjusted loss = 0.324  adv prob = 0.250000   acc = 0.936
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.379  exp loss = 0.417  adjusted loss = 0.417  adv prob = 0.250000   acc = 0.861
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 0.402  exp loss = 0.412  adjusted loss = 0.412  adv prob = 0.250000   acc = 0.872
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.313  exp loss = 0.294  adjusted loss = 0.294  adv prob = 0.250000   acc = 0.910
Spurious Score = 1.065
Saved results/CUB/CUB_sample_exp/train_downstream_ERM_upweight_0_epochs_80_lr_1e-05_weight_decay_0.0/final_epoch31/JTT_upweight_50_epochs_80_lr_1e-05_weight_decay_1.0/model_outputs/output_test_epoch_26.csv
logged to wandb
Current lr: 0.000010


Epoch [27]:
Training:
Average incurred loss: 0.212  
Average sample loss: 0.212  
Average acc: 0.981  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 831]:	loss = 0.274  exp loss = 0.255  adjusted loss = 0.255  adv prob = 0.250000   acc = 0.948
  waterbird_complete95 = 0, forest2water2 = 1  [n = 676]:	loss = 0.192  exp loss = 0.176  adjusted loss = 0.176  adv prob = 0.250000   acc = 0.994
  waterbird_complete95 = 1, forest2water2 = 0  [n = 490]:	loss = 0.148  exp loss = 0.150  adjusted loss = 0.150  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1203]:	loss = 0.206  exp loss = 0.210  adjusted loss = 0.210  adv prob = 0.250000   acc = 0.989
Average incurred loss: 0.214  
Average sample loss: 0.214  
Average acc: 0.977  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 815]:	loss = 0.271  exp loss = 0.257  adjusted loss = 0.257  adv prob = 0.250000   acc = 0.933
  waterbird_complete95 = 0, forest2water2 = 1  [n = 644]:	loss = 0.187  exp loss = 0.179  adjusted loss = 0.179  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 0  [n = 529]:	loss = 0.162  exp loss = 0.167  adjusted loss = 0.167  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1212]:	loss = 0.214  exp loss = 0.214  adjusted loss = 0.214  adv prob = 0.250000   acc = 0.985
Average incurred loss: 0.211  
Average sample loss: 0.211  
Average acc: 0.977  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 863]:	loss = 0.263  exp loss = 0.235  adjusted loss = 0.235  adv prob = 0.250000   acc = 0.937
  waterbird_complete95 = 0, forest2water2 = 1  [n = 628]:	loss = 0.192  exp loss = 0.177  adjusted loss = 0.177  adv prob = 0.250000   acc = 0.997
  waterbird_complete95 = 1, forest2water2 = 0  [n = 489]:	loss = 0.155  exp loss = 0.153  adjusted loss = 0.153  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1220]:	loss = 0.206  exp loss = 0.208  adjusted loss = 0.208  adv prob = 0.250000   acc = 0.985
Average incurred loss: 0.209  
Average sample loss: 0.209  
Average acc: 0.981  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 830]:	loss = 0.257  exp loss = 0.262  adjusted loss = 0.262  adv prob = 0.250000   acc = 0.949
  waterbird_complete95 = 0, forest2water2 = 1  [n = 639]:	loss = 0.192  exp loss = 0.189  adjusted loss = 0.189  adv prob = 0.250000   acc = 0.998
  waterbird_complete95 = 1, forest2water2 = 0  [n = 522]:	loss = 0.152  exp loss = 0.140  adjusted loss = 0.140  adv prob = 0.250000   acc = 0.998
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1209]:	loss = 0.210  exp loss = 0.208  adjusted loss = 0.208  adv prob = 0.250000   acc = 0.987
Saved results/CUB/CUB_sample_exp/train_downstream_ERM_upweight_0_epochs_80_lr_1e-05_weight_decay_0.0/final_epoch31/JTT_upweight_50_epochs_80_lr_1e-05_weight_decay_1.0/model_outputs/output_train_epoch_27.csv
logged to wandb
Average incurred loss: 0.211  
Average sample loss: 0.213  
Average acc: 0.974  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 459]:	loss = 0.272  exp loss = 0.278  adjusted loss = 0.278  adv prob = 0.250000   acc = 0.928
  waterbird_complete95 = 0, forest2water2 = 1  [n = 347]:	loss = 0.185  exp loss = 0.181  adjusted loss = 0.181  adv prob = 0.250000   acc = 0.994
  waterbird_complete95 = 1, forest2water2 = 0  [n = 276]:	loss = 0.151  exp loss = 0.157  adjusted loss = 0.157  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 663]:	loss = 0.207  exp loss = 0.210  adjusted loss = 0.210  adv prob = 0.250000   acc = 0.985

Validation:
Saved results/CUB/CUB_sample_exp/train_downstream_ERM_upweight_0_epochs_80_lr_1e-05_weight_decay_0.0/final_epoch31/JTT_upweight_50_epochs_80_lr_1e-05_weight_decay_1.0/model_outputs/output_val_epoch_27.csv
logged to wandb
Average incurred loss: 0.327  
Average sample loss: 0.326  
Average acc: 0.902  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.273  exp loss = 0.295  adjusted loss = 0.295  adv prob = 0.250000   acc = 0.942
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.352  exp loss = 0.389  adjusted loss = 0.389  adv prob = 0.250000   acc = 0.871
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 0.427  exp loss = 0.439  adjusted loss = 0.439  adv prob = 0.250000   acc = 0.857
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.327  exp loss = 0.307  adjusted loss = 0.307  adv prob = 0.250000   acc = 0.910
Spurious Score = 1.071
Saved results/CUB/CUB_sample_exp/train_downstream_ERM_upweight_0_epochs_80_lr_1e-05_weight_decay_0.0/final_epoch31/JTT_upweight_50_epochs_80_lr_1e-05_weight_decay_1.0/model_outputs/output_test_epoch_27.csv
logged to wandb
Current lr: 0.000010


Epoch [28]:
Training:
Average incurred loss: 0.209  
Average sample loss: 0.209  
Average acc: 0.976  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 847]:	loss = 0.268  exp loss = 0.260  adjusted loss = 0.260  adv prob = 0.250000   acc = 0.933
  waterbird_complete95 = 0, forest2water2 = 1  [n = 643]:	loss = 0.189  exp loss = 0.191  adjusted loss = 0.191  adv prob = 0.250000   acc = 0.992
  waterbird_complete95 = 1, forest2water2 = 0  [n = 498]:	loss = 0.151  exp loss = 0.145  adjusted loss = 0.145  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1212]:	loss = 0.203  exp loss = 0.201  adjusted loss = 0.201  adv prob = 0.250000   acc = 0.987
Average incurred loss: 0.202  
Average sample loss: 0.202  
Average acc: 0.984  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 819]:	loss = 0.242  exp loss = 0.232  adjusted loss = 0.232  adv prob = 0.250000   acc = 0.956
  waterbird_complete95 = 0, forest2water2 = 1  [n = 657]:	loss = 0.189  exp loss = 0.177  adjusted loss = 0.177  adv prob = 0.250000   acc = 0.997
  waterbird_complete95 = 1, forest2water2 = 0  [n = 512]:	loss = 0.152  exp loss = 0.162  adjusted loss = 0.162  adv prob = 0.250000   acc = 0.998
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1212]:	loss = 0.202  exp loss = 0.209  adjusted loss = 0.209  adv prob = 0.250000   acc = 0.990
Average incurred loss: 0.205  
Average sample loss: 0.205  
Average acc: 0.980  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 858]:	loss = 0.262  exp loss = 0.250  adjusted loss = 0.250  adv prob = 0.250000   acc = 0.945
  waterbird_complete95 = 0, forest2water2 = 1  [n = 657]:	loss = 0.192  exp loss = 0.182  adjusted loss = 0.182  adv prob = 0.250000   acc = 0.998
  waterbird_complete95 = 1, forest2water2 = 0  [n = 490]:	loss = 0.140  exp loss = 0.140  adjusted loss = 0.140  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1195]:	loss = 0.197  exp loss = 0.187  adjusted loss = 0.187  adv prob = 0.250000   acc = 0.987
Average incurred loss: 0.204  
Average sample loss: 0.204  
Average acc: 0.981  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 789]:	loss = 0.256  exp loss = 0.257  adjusted loss = 0.257  adv prob = 0.250000   acc = 0.947
  waterbird_complete95 = 0, forest2water2 = 1  [n = 644]:	loss = 0.171  exp loss = 0.166  adjusted loss = 0.166  adv prob = 0.250000   acc = 0.997
  waterbird_complete95 = 1, forest2water2 = 0  [n = 542]:	loss = 0.153  exp loss = 0.138  adjusted loss = 0.138  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1225]:	loss = 0.209  exp loss = 0.196  adjusted loss = 0.196  adv prob = 0.250000   acc = 0.986
Saved results/CUB/CUB_sample_exp/train_downstream_ERM_upweight_0_epochs_80_lr_1e-05_weight_decay_0.0/final_epoch31/JTT_upweight_50_epochs_80_lr_1e-05_weight_decay_1.0/model_outputs/output_train_epoch_28.csv
logged to wandb
Average incurred loss: 0.202  
Average sample loss: 0.201  
Average acc: 0.978  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 485]:	loss = 0.259  exp loss = 0.246  adjusted loss = 0.246  adv prob = 0.250000   acc = 0.938
  waterbird_complete95 = 0, forest2water2 = 1  [n = 333]:	loss = 0.185  exp loss = 0.174  adjusted loss = 0.174  adv prob = 0.250000   acc = 0.997
  waterbird_complete95 = 1, forest2water2 = 0  [n = 264]:	loss = 0.141  exp loss = 0.133  adjusted loss = 0.133  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 663]:	loss = 0.192  exp loss = 0.190  adjusted loss = 0.190  adv prob = 0.250000   acc = 0.988

Validation:
Saved results/CUB/CUB_sample_exp/train_downstream_ERM_upweight_0_epochs_80_lr_1e-05_weight_decay_0.0/final_epoch31/JTT_upweight_50_epochs_80_lr_1e-05_weight_decay_1.0/model_outputs/output_val_epoch_28.csv
logged to wandb
Average incurred loss: 0.333  
Average sample loss: 0.331  
Average acc: 0.902  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.280  exp loss = 0.302  adjusted loss = 0.302  adv prob = 0.250000   acc = 0.942
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.363  exp loss = 0.399  adjusted loss = 0.399  adv prob = 0.250000   acc = 0.876
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 0.422  exp loss = 0.436  adjusted loss = 0.436  adv prob = 0.250000   acc = 0.850
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.321  exp loss = 0.301  adjusted loss = 0.301  adv prob = 0.250000   acc = 0.910
Spurious Score = 1.073
Saved results/CUB/CUB_sample_exp/train_downstream_ERM_upweight_0_epochs_80_lr_1e-05_weight_decay_0.0/final_epoch31/JTT_upweight_50_epochs_80_lr_1e-05_weight_decay_1.0/model_outputs/output_test_epoch_28.csv
logged to wandb
Current lr: 0.000010


Epoch [29]:
Training:
Average incurred loss: 0.201  
Average sample loss: 0.201  
Average acc: 0.980  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 834]:	loss = 0.250  exp loss = 0.237  adjusted loss = 0.237  adv prob = 0.250000   acc = 0.947
  waterbird_complete95 = 0, forest2water2 = 1  [n = 635]:	loss = 0.177  exp loss = 0.171  adjusted loss = 0.171  adv prob = 0.250000   acc = 0.997
  waterbird_complete95 = 1, forest2water2 = 0  [n = 521]:	loss = 0.148  exp loss = 0.146  adjusted loss = 0.146  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1210]:	loss = 0.201  exp loss = 0.209  adjusted loss = 0.209  adv prob = 0.250000   acc = 0.985
Average incurred loss: 0.197  
Average sample loss: 0.197  
Average acc: 0.984  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 831]:	loss = 0.246  exp loss = 0.252  adjusted loss = 0.252  adv prob = 0.250000   acc = 0.963
  waterbird_complete95 = 0, forest2water2 = 1  [n = 652]:	loss = 0.180  exp loss = 0.174  adjusted loss = 0.174  adv prob = 0.250000   acc = 0.997
  waterbird_complete95 = 1, forest2water2 = 0  [n = 494]:	loss = 0.147  exp loss = 0.142  adjusted loss = 0.142  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1223]:	loss = 0.192  exp loss = 0.199  adjusted loss = 0.199  adv prob = 0.250000   acc = 0.986
Average incurred loss: 0.195  
Average sample loss: 0.195  
Average acc: 0.981  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 816]:	loss = 0.238  exp loss = 0.243  adjusted loss = 0.243  adv prob = 0.250000   acc = 0.946
  waterbird_complete95 = 0, forest2water2 = 1  [n = 638]:	loss = 0.177  exp loss = 0.163  adjusted loss = 0.163  adv prob = 0.250000   acc = 0.997
  waterbird_complete95 = 1, forest2water2 = 0  [n = 528]:	loss = 0.149  exp loss = 0.140  adjusted loss = 0.140  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1218]:	loss = 0.195  exp loss = 0.192  adjusted loss = 0.192  adv prob = 0.250000   acc = 0.988
Average incurred loss: 0.198  
Average sample loss: 0.198  
Average acc: 0.982  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 849]:	loss = 0.256  exp loss = 0.255  adjusted loss = 0.255  adv prob = 0.250000   acc = 0.945
  waterbird_complete95 = 0, forest2water2 = 1  [n = 654]:	loss = 0.184  exp loss = 0.200  adjusted loss = 0.200  adv prob = 0.250000   acc = 0.994
  waterbird_complete95 = 1, forest2water2 = 0  [n = 501]:	loss = 0.140  exp loss = 0.132  adjusted loss = 0.132  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1196]:	loss = 0.189  exp loss = 0.166  adjusted loss = 0.166  adv prob = 0.250000   acc = 0.995
Saved results/CUB/CUB_sample_exp/train_downstream_ERM_upweight_0_epochs_80_lr_1e-05_weight_decay_0.0/final_epoch31/JTT_upweight_50_epochs_80_lr_1e-05_weight_decay_1.0/model_outputs/output_train_epoch_29.csv
logged to wandb
Average incurred loss: 0.197  
Average sample loss: 0.197  
Average acc: 0.981  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 468]:	loss = 0.256  exp loss = 0.253  adjusted loss = 0.253  adv prob = 0.250000   acc = 0.940
  waterbird_complete95 = 0, forest2water2 = 1  [n = 355]:	loss = 0.184  exp loss = 0.186  adjusted loss = 0.186  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 0  [n = 262]:	loss = 0.140  exp loss = 0.136  adjusted loss = 0.136  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 660]:	loss = 0.184  exp loss = 0.165  adjusted loss = 0.165  adv prob = 0.250000   acc = 0.992

Validation:
Saved results/CUB/CUB_sample_exp/train_downstream_ERM_upweight_0_epochs_80_lr_1e-05_weight_decay_0.0/final_epoch31/JTT_upweight_50_epochs_80_lr_1e-05_weight_decay_1.0/model_outputs/output_val_epoch_29.csv
logged to wandb
Average incurred loss: 0.335  
Average sample loss: 0.334  
Average acc: 0.895  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.283  exp loss = 0.306  adjusted loss = 0.306  adv prob = 0.250000   acc = 0.936
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.379  exp loss = 0.416  adjusted loss = 0.416  adv prob = 0.250000   acc = 0.856
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 0.408  exp loss = 0.418  adjusted loss = 0.418  adv prob = 0.250000   acc = 0.872
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.294  exp loss = 0.275  adjusted loss = 0.275  adv prob = 0.250000   acc = 0.910
Spurious Score = 1.068
Saved results/CUB/CUB_sample_exp/train_downstream_ERM_upweight_0_epochs_80_lr_1e-05_weight_decay_0.0/final_epoch31/JTT_upweight_50_epochs_80_lr_1e-05_weight_decay_1.0/model_outputs/output_test_epoch_29.csv
logged to wandb
Current lr: 0.000010


Epoch [30]:
Training:
Average incurred loss: 0.198  
Average sample loss: 0.198  
Average acc: 0.982  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 849]:	loss = 0.241  exp loss = 0.235  adjusted loss = 0.235  adv prob = 0.250000   acc = 0.953
  waterbird_complete95 = 0, forest2water2 = 1  [n = 605]:	loss = 0.173  exp loss = 0.159  adjusted loss = 0.159  adv prob = 0.250000   acc = 0.997
  waterbird_complete95 = 1, forest2water2 = 0  [n = 527]:	loss = 0.153  exp loss = 0.145  adjusted loss = 0.145  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1219]:	loss = 0.201  exp loss = 0.192  adjusted loss = 0.192  adv prob = 0.250000   acc = 0.986
Average incurred loss: 0.189  
Average sample loss: 0.189  
Average acc: 0.985  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 826]:	loss = 0.240  exp loss = 0.232  adjusted loss = 0.232  adv prob = 0.250000   acc = 0.959
  waterbird_complete95 = 0, forest2water2 = 1  [n = 669]:	loss = 0.176  exp loss = 0.179  adjusted loss = 0.179  adv prob = 0.250000   acc = 0.997
  waterbird_complete95 = 1, forest2water2 = 0  [n = 511]:	loss = 0.142  exp loss = 0.131  adjusted loss = 0.131  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1194]:	loss = 0.182  exp loss = 0.177  adjusted loss = 0.177  adv prob = 0.250000   acc = 0.991
Average incurred loss: 0.192  
Average sample loss: 0.192  
Average acc: 0.982  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 810]:	loss = 0.238  exp loss = 0.237  adjusted loss = 0.237  adv prob = 0.250000   acc = 0.953
  waterbird_complete95 = 0, forest2water2 = 1  [n = 639]:	loss = 0.170  exp loss = 0.166  adjusted loss = 0.166  adv prob = 0.250000   acc = 0.997
  waterbird_complete95 = 1, forest2water2 = 0  [n = 526]:	loss = 0.147  exp loss = 0.145  adjusted loss = 0.145  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1225]:	loss = 0.193  exp loss = 0.196  adjusted loss = 0.196  adv prob = 0.250000   acc = 0.985
Average incurred loss: 0.190  
Average sample loss: 0.190  
Average acc: 0.979  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 836]:	loss = 0.238  exp loss = 0.219  adjusted loss = 0.219  adv prob = 0.250000   acc = 0.946
  waterbird_complete95 = 0, forest2water2 = 1  [n = 658]:	loss = 0.177  exp loss = 0.168  adjusted loss = 0.168  adv prob = 0.250000   acc = 0.997
  waterbird_complete95 = 1, forest2water2 = 0  [n = 488]:	loss = 0.132  exp loss = 0.129  adjusted loss = 0.129  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1218]:	loss = 0.187  exp loss = 0.188  adjusted loss = 0.188  adv prob = 0.250000   acc = 0.984
Saved results/CUB/CUB_sample_exp/train_downstream_ERM_upweight_0_epochs_80_lr_1e-05_weight_decay_0.0/final_epoch31/JTT_upweight_50_epochs_80_lr_1e-05_weight_decay_1.0/model_outputs/output_train_epoch_30.csv
logged to wandb
Average incurred loss: 0.192  
Average sample loss: 0.191  
Average acc: 0.983  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 477]:	loss = 0.251  exp loss = 0.239  adjusted loss = 0.239  adv prob = 0.250000   acc = 0.950
  waterbird_complete95 = 0, forest2water2 = 1  [n = 363]:	loss = 0.184  exp loss = 0.184  adjusted loss = 0.184  adv prob = 0.250000   acc = 0.994
  waterbird_complete95 = 1, forest2water2 = 0  [n = 254]:	loss = 0.139  exp loss = 0.129  adjusted loss = 0.129  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 651]:	loss = 0.173  exp loss = 0.164  adjusted loss = 0.164  adv prob = 0.250000   acc = 0.994

Validation:
Saved results/CUB/CUB_sample_exp/train_downstream_ERM_upweight_0_epochs_80_lr_1e-05_weight_decay_0.0/final_epoch31/JTT_upweight_50_epochs_80_lr_1e-05_weight_decay_1.0/model_outputs/output_val_epoch_30.csv
logged to wandb
Average incurred loss: 0.337  
Average sample loss: 0.336  
Average acc: 0.892  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.284  exp loss = 0.307  adjusted loss = 0.307  adv prob = 0.250000   acc = 0.931
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.389  exp loss = 0.426  adjusted loss = 0.426  adv prob = 0.250000   acc = 0.848
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 0.400  exp loss = 0.409  adjusted loss = 0.409  adv prob = 0.250000   acc = 0.865
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.281  exp loss = 0.264  adjusted loss = 0.264  adv prob = 0.250000   acc = 0.932
Spurious Score = 1.088
Saved results/CUB/CUB_sample_exp/train_downstream_ERM_upweight_0_epochs_80_lr_1e-05_weight_decay_0.0/final_epoch31/JTT_upweight_50_epochs_80_lr_1e-05_weight_decay_1.0/model_outputs/output_test_epoch_30.csv
logged to wandb
Current lr: 0.000010


Epoch [31]:
Training:
Average incurred loss: 0.189  
Average sample loss: 0.189  
Average acc: 0.983  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 832]:	loss = 0.241  exp loss = 0.240  adjusted loss = 0.240  adv prob = 0.250000   acc = 0.950
  waterbird_complete95 = 0, forest2water2 = 1  [n = 652]:	loss = 0.166  exp loss = 0.162  adjusted loss = 0.162  adv prob = 0.250000   acc = 0.998
  waterbird_complete95 = 1, forest2water2 = 0  [n = 497]:	loss = 0.138  exp loss = 0.134  adjusted loss = 0.134  adv prob = 0.250000   acc = 0.998
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1219]:	loss = 0.187  exp loss = 0.185  adjusted loss = 0.185  adv prob = 0.250000   acc = 0.991
Average incurred loss: 0.187  
Average sample loss: 0.187  
Average acc: 0.982  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 843]:	loss = 0.234  exp loss = 0.221  adjusted loss = 0.221  adv prob = 0.250000   acc = 0.951
  waterbird_complete95 = 0, forest2water2 = 1  [n = 653]:	loss = 0.172  exp loss = 0.169  adjusted loss = 0.169  adv prob = 0.250000   acc = 0.995
  waterbird_complete95 = 1, forest2water2 = 0  [n = 511]:	loss = 0.139  exp loss = 0.132  adjusted loss = 0.132  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1193]:	loss = 0.182  exp loss = 0.181  adjusted loss = 0.181  adv prob = 0.250000   acc = 0.987
Average incurred loss: 0.182  
Average sample loss: 0.182  
Average acc: 0.987  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 848]:	loss = 0.225  exp loss = 0.225  adjusted loss = 0.225  adv prob = 0.250000   acc = 0.967
  waterbird_complete95 = 0, forest2water2 = 1  [n = 638]:	loss = 0.165  exp loss = 0.168  adjusted loss = 0.168  adv prob = 0.250000   acc = 0.997
  waterbird_complete95 = 1, forest2water2 = 0  [n = 500]:	loss = 0.140  exp loss = 0.132  adjusted loss = 0.132  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1214]:	loss = 0.179  exp loss = 0.171  adjusted loss = 0.171  adv prob = 0.250000   acc = 0.989
Average incurred loss: 0.183  
Average sample loss: 0.183  
Average acc: 0.985  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 811]:	loss = 0.222  exp loss = 0.203  adjusted loss = 0.203  adv prob = 0.250000   acc = 0.958
  waterbird_complete95 = 0, forest2water2 = 1  [n = 645]:	loss = 0.165  exp loss = 0.152  adjusted loss = 0.152  adv prob = 0.250000   acc = 0.995
  waterbird_complete95 = 1, forest2water2 = 0  [n = 494]:	loss = 0.145  exp loss = 0.147  adjusted loss = 0.147  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1250]:	loss = 0.182  exp loss = 0.190  adjusted loss = 0.190  adv prob = 0.250000   acc = 0.992
Saved results/CUB/CUB_sample_exp/train_downstream_ERM_upweight_0_epochs_80_lr_1e-05_weight_decay_0.0/final_epoch31/JTT_upweight_50_epochs_80_lr_1e-05_weight_decay_1.0/model_outputs/output_train_epoch_31.csv
logged to wandb
Average incurred loss: 0.192  
Average sample loss: 0.193  
Average acc: 0.977  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 464]:	loss = 0.244  exp loss = 0.246  adjusted loss = 0.246  adv prob = 0.250000   acc = 0.944
  waterbird_complete95 = 0, forest2water2 = 1  [n = 346]:	loss = 0.166  exp loss = 0.173  adjusted loss = 0.173  adv prob = 0.250000   acc = 0.994
  waterbird_complete95 = 1, forest2water2 = 0  [n = 304]:	loss = 0.144  exp loss = 0.125  adjusted loss = 0.125  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 631]:	loss = 0.190  exp loss = 0.177  adjusted loss = 0.177  adv prob = 0.250000   acc = 0.981

Validation:
Saved results/CUB/CUB_sample_exp/train_downstream_ERM_upweight_0_epochs_80_lr_1e-05_weight_decay_0.0/final_epoch31/JTT_upweight_50_epochs_80_lr_1e-05_weight_decay_1.0/model_outputs/output_val_epoch_31.csv
logged to wandb
Average incurred loss: 0.321  
Average sample loss: 0.319  
Average acc: 0.902  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.258  exp loss = 0.280  adjusted loss = 0.280  adv prob = 0.250000   acc = 0.946
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.362  exp loss = 0.396  adjusted loss = 0.396  adv prob = 0.250000   acc = 0.869
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 0.423  exp loss = 0.435  adjusted loss = 0.435  adv prob = 0.250000   acc = 0.850
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.291  exp loss = 0.272  adjusted loss = 0.272  adv prob = 0.250000   acc = 0.910
Spurious Score = 1.080
Saved results/CUB/CUB_sample_exp/train_downstream_ERM_upweight_0_epochs_80_lr_1e-05_weight_decay_0.0/final_epoch31/JTT_upweight_50_epochs_80_lr_1e-05_weight_decay_1.0/model_outputs/output_test_epoch_31.csv
logged to wandb
Current lr: 0.000010


Epoch [32]:
Training:
Average incurred loss: 0.183  
Average sample loss: 0.183  
Average acc: 0.986  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 859]:	loss = 0.227  exp loss = 0.224  adjusted loss = 0.224  adv prob = 0.250000   acc = 0.966
  waterbird_complete95 = 0, forest2water2 = 1  [n = 636]:	loss = 0.167  exp loss = 0.167  adjusted loss = 0.167  adv prob = 0.250000   acc = 0.998
  waterbird_complete95 = 1, forest2water2 = 0  [n = 509]:	loss = 0.136  exp loss = 0.133  adjusted loss = 0.133  adv prob = 0.250000   acc = 0.998
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1196]:	loss = 0.181  exp loss = 0.167  adjusted loss = 0.167  adv prob = 0.250000   acc = 0.989
Average incurred loss: 0.181  
Average sample loss: 0.181  
Average acc: 0.987  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 807]:	loss = 0.223  exp loss = 0.223  adjusted loss = 0.223  adv prob = 0.250000   acc = 0.968
  waterbird_complete95 = 0, forest2water2 = 1  [n = 656]:	loss = 0.158  exp loss = 0.154  adjusted loss = 0.154  adv prob = 0.250000   acc = 0.998
  waterbird_complete95 = 1, forest2water2 = 0  [n = 478]:	loss = 0.137  exp loss = 0.131  adjusted loss = 0.131  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1259]:	loss = 0.184  exp loss = 0.185  adjusted loss = 0.185  adv prob = 0.250000   acc = 0.987
Average incurred loss: 0.180  
Average sample loss: 0.180  
Average acc: 0.985  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 834]:	loss = 0.212  exp loss = 0.206  adjusted loss = 0.206  adv prob = 0.250000   acc = 0.965
  waterbird_complete95 = 0, forest2water2 = 1  [n = 613]:	loss = 0.162  exp loss = 0.148  adjusted loss = 0.148  adv prob = 0.250000   acc = 0.995
  waterbird_complete95 = 1, forest2water2 = 0  [n = 510]:	loss = 0.146  exp loss = 0.141  adjusted loss = 0.141  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1243]:	loss = 0.181  exp loss = 0.183  adjusted loss = 0.183  adv prob = 0.250000   acc = 0.988
Average incurred loss: 0.182  
Average sample loss: 0.182  
Average acc: 0.982  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 848]:	loss = 0.241  exp loss = 0.214  adjusted loss = 0.214  adv prob = 0.250000   acc = 0.942
  waterbird_complete95 = 0, forest2water2 = 1  [n = 668]:	loss = 0.169  exp loss = 0.157  adjusted loss = 0.157  adv prob = 0.250000   acc = 0.997
  waterbird_complete95 = 1, forest2water2 = 0  [n = 513]:	loss = 0.134  exp loss = 0.139  adjusted loss = 0.139  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1171]:	loss = 0.169  exp loss = 0.180  adjusted loss = 0.180  adv prob = 0.250000   acc = 0.993
Saved results/CUB/CUB_sample_exp/train_downstream_ERM_upweight_0_epochs_80_lr_1e-05_weight_decay_0.0/final_epoch31/JTT_upweight_50_epochs_80_lr_1e-05_weight_decay_1.0/model_outputs/output_train_epoch_32.csv
logged to wandb
Average incurred loss: 0.178  
Average sample loss: 0.177  
Average acc: 0.983  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 450]:	loss = 0.224  exp loss = 0.214  adjusted loss = 0.214  adv prob = 0.250000   acc = 0.951
  waterbird_complete95 = 0, forest2water2 = 1  [n = 361]:	loss = 0.167  exp loss = 0.163  adjusted loss = 0.163  adv prob = 0.250000   acc = 0.992
  waterbird_complete95 = 1, forest2water2 = 0  [n = 296]:	loss = 0.136  exp loss = 0.133  adjusted loss = 0.133  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 638]:	loss = 0.172  exp loss = 0.168  adjusted loss = 0.168  adv prob = 0.250000   acc = 0.994

Validation:
Saved results/CUB/CUB_sample_exp/train_downstream_ERM_upweight_0_epochs_80_lr_1e-05_weight_decay_0.0/final_epoch31/JTT_upweight_50_epochs_80_lr_1e-05_weight_decay_1.0/model_outputs/output_val_epoch_32.csv
logged to wandb
Average incurred loss: 0.316  
Average sample loss: 0.315  
Average acc: 0.907  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.249  exp loss = 0.269  adjusted loss = 0.269  adv prob = 0.250000   acc = 0.949
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.351  exp loss = 0.384  adjusted loss = 0.384  adv prob = 0.250000   acc = 0.884
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 0.441  exp loss = 0.454  adjusted loss = 0.454  adv prob = 0.250000   acc = 0.835
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.304  exp loss = 0.284  adjusted loss = 0.284  adv prob = 0.250000   acc = 0.910
Spurious Score = 1.081
Saved results/CUB/CUB_sample_exp/train_downstream_ERM_upweight_0_epochs_80_lr_1e-05_weight_decay_0.0/final_epoch31/JTT_upweight_50_epochs_80_lr_1e-05_weight_decay_1.0/model_outputs/output_test_epoch_32.csv
logged to wandb
Current lr: 0.000010


Epoch [33]:
Training:
Average incurred loss: 0.179  
Average sample loss: 0.179  
Average acc: 0.986  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 816]:	loss = 0.214  exp loss = 0.210  adjusted loss = 0.210  adv prob = 0.250000   acc = 0.964
  waterbird_complete95 = 0, forest2water2 = 1  [n = 621]:	loss = 0.152  exp loss = 0.150  adjusted loss = 0.150  adv prob = 0.250000   acc = 0.998
  waterbird_complete95 = 1, forest2water2 = 0  [n = 477]:	loss = 0.140  exp loss = 0.140  adjusted loss = 0.140  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1286]:	loss = 0.183  exp loss = 0.190  adjusted loss = 0.190  adv prob = 0.250000   acc = 0.989
Average incurred loss: 0.183  
Average sample loss: 0.183  
Average acc: 0.981  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 892]:	loss = 0.240  exp loss = 0.233  adjusted loss = 0.233  adv prob = 0.250000   acc = 0.951
  waterbird_complete95 = 0, forest2water2 = 1  [n = 646]:	loss = 0.171  exp loss = 0.175  adjusted loss = 0.175  adv prob = 0.250000   acc = 0.995
  waterbird_complete95 = 1, forest2water2 = 0  [n = 499]:	loss = 0.130  exp loss = 0.122  adjusted loss = 0.122  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1163]:	loss = 0.169  exp loss = 0.166  adjusted loss = 0.166  adv prob = 0.250000   acc = 0.989
Average incurred loss: 0.174  
Average sample loss: 0.174  
Average acc: 0.989  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 847]:	loss = 0.217  exp loss = 0.217  adjusted loss = 0.217  adv prob = 0.250000   acc = 0.966
  waterbird_complete95 = 0, forest2water2 = 1  [n = 647]:	loss = 0.159  exp loss = 0.165  adjusted loss = 0.165  adv prob = 0.250000   acc = 0.998
  waterbird_complete95 = 1, forest2water2 = 0  [n = 512]:	loss = 0.136  exp loss = 0.126  adjusted loss = 0.126  adv prob = 0.250000   acc = 0.998
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1194]:	loss = 0.167  exp loss = 0.159  adjusted loss = 0.159  adv prob = 0.250000   acc = 0.997
Average incurred loss: 0.175  
Average sample loss: 0.175  
Average acc: 0.988  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 797]:	loss = 0.208  exp loss = 0.200  adjusted loss = 0.200  adv prob = 0.250000   acc = 0.975
  waterbird_complete95 = 0, forest2water2 = 1  [n = 669]:	loss = 0.159  exp loss = 0.145  adjusted loss = 0.145  adv prob = 0.250000   acc = 0.997
  waterbird_complete95 = 1, forest2water2 = 0  [n = 560]:	loss = 0.139  exp loss = 0.141  adjusted loss = 0.141  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1174]:	loss = 0.179  exp loss = 0.185  adjusted loss = 0.185  adv prob = 0.250000   acc = 0.986
Saved results/CUB/CUB_sample_exp/train_downstream_ERM_upweight_0_epochs_80_lr_1e-05_weight_decay_0.0/final_epoch31/JTT_upweight_50_epochs_80_lr_1e-05_weight_decay_1.0/model_outputs/output_train_epoch_33.csv
logged to wandb
Average incurred loss: 0.175  
Average sample loss: 0.175  
Average acc: 0.989  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 446]:	loss = 0.210  exp loss = 0.195  adjusted loss = 0.195  adv prob = 0.250000   acc = 0.969
  waterbird_complete95 = 0, forest2water2 = 1  [n = 351]:	loss = 0.162  exp loss = 0.181  adjusted loss = 0.181  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 0  [n = 258]:	loss = 0.137  exp loss = 0.127  adjusted loss = 0.127  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 690]:	loss = 0.174  exp loss = 0.164  adjusted loss = 0.164  adv prob = 0.250000   acc = 0.991

Validation:
Saved results/CUB/CUB_sample_exp/train_downstream_ERM_upweight_0_epochs_80_lr_1e-05_weight_decay_0.0/final_epoch31/JTT_upweight_50_epochs_80_lr_1e-05_weight_decay_1.0/model_outputs/output_val_epoch_33.csv
logged to wandb
Average incurred loss: 0.315  
Average sample loss: 0.314  
Average acc: 0.906  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.248  exp loss = 0.268  adjusted loss = 0.268  adv prob = 0.250000   acc = 0.951
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.358  exp loss = 0.391  adjusted loss = 0.391  adv prob = 0.250000   acc = 0.876
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 0.433  exp loss = 0.446  adjusted loss = 0.446  adv prob = 0.250000   acc = 0.835
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.286  exp loss = 0.267  adjusted loss = 0.267  adv prob = 0.250000   acc = 0.925
Spurious Score = 1.097
Saved results/CUB/CUB_sample_exp/train_downstream_ERM_upweight_0_epochs_80_lr_1e-05_weight_decay_0.0/final_epoch31/JTT_upweight_50_epochs_80_lr_1e-05_weight_decay_1.0/model_outputs/output_test_epoch_33.csv
logged to wandb
Current lr: 0.000010


Epoch [34]:
Training:
Average incurred loss: 0.173  
Average sample loss: 0.173  
Average acc: 0.988  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 823]:	loss = 0.206  exp loss = 0.222  adjusted loss = 0.222  adv prob = 0.250000   acc = 0.973
  waterbird_complete95 = 0, forest2water2 = 1  [n = 627]:	loss = 0.157  exp loss = 0.157  adjusted loss = 0.157  adv prob = 0.250000   acc = 0.997
  waterbird_complete95 = 1, forest2water2 = 0  [n = 538]:	loss = 0.139  exp loss = 0.129  adjusted loss = 0.129  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1212]:	loss = 0.175  exp loss = 0.159  adjusted loss = 0.159  adv prob = 0.250000   acc = 0.989
Average incurred loss: 0.176  
Average sample loss: 0.176  
Average acc: 0.986  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 806]:	loss = 0.213  exp loss = 0.218  adjusted loss = 0.218  adv prob = 0.250000   acc = 0.967
  waterbird_complete95 = 0, forest2water2 = 1  [n = 663]:	loss = 0.161  exp loss = 0.155  adjusted loss = 0.155  adv prob = 0.250000   acc = 0.994
  waterbird_complete95 = 1, forest2water2 = 0  [n = 489]:	loss = 0.138  exp loss = 0.132  adjusted loss = 0.132  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1242]:	loss = 0.176  exp loss = 0.175  adjusted loss = 0.175  adv prob = 0.250000   acc = 0.988
Average incurred loss: 0.174  
Average sample loss: 0.174  
Average acc: 0.986  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 860]:	loss = 0.231  exp loss = 0.197  adjusted loss = 0.197  adv prob = 0.250000   acc = 0.958
  waterbird_complete95 = 0, forest2water2 = 1  [n = 679]:	loss = 0.164  exp loss = 0.162  adjusted loss = 0.162  adv prob = 0.250000   acc = 0.996
  waterbird_complete95 = 1, forest2water2 = 0  [n = 495]:	loss = 0.133  exp loss = 0.132  adjusted loss = 0.132  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1166]:	loss = 0.155  exp loss = 0.147  adjusted loss = 0.147  adv prob = 0.250000   acc = 0.995
Average incurred loss: 0.170  
Average sample loss: 0.170  
Average acc: 0.988  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 820]:	loss = 0.200  exp loss = 0.215  adjusted loss = 0.215  adv prob = 0.250000   acc = 0.973
  waterbird_complete95 = 0, forest2water2 = 1  [n = 643]:	loss = 0.154  exp loss = 0.157  adjusted loss = 0.157  adv prob = 0.250000   acc = 0.998
  waterbird_complete95 = 1, forest2water2 = 0  [n = 495]:	loss = 0.132  exp loss = 0.119  adjusted loss = 0.119  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1242]:	loss = 0.173  exp loss = 0.159  adjusted loss = 0.159  adv prob = 0.250000   acc = 0.988
Saved results/CUB/CUB_sample_exp/train_downstream_ERM_upweight_0_epochs_80_lr_1e-05_weight_decay_0.0/final_epoch31/JTT_upweight_50_epochs_80_lr_1e-05_weight_decay_1.0/model_outputs/output_train_epoch_34.csv
logged to wandb
Average incurred loss: 0.177  
Average sample loss: 0.177  
Average acc: 0.983  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 489]:	loss = 0.223  exp loss = 0.238  adjusted loss = 0.238  adv prob = 0.250000   acc = 0.951
  waterbird_complete95 = 0, forest2water2 = 1  [n = 322]:	loss = 0.158  exp loss = 0.166  adjusted loss = 0.166  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 0  [n = 289]:	loss = 0.136  exp loss = 0.122  adjusted loss = 0.122  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 645]:	loss = 0.168  exp loss = 0.157  adjusted loss = 0.157  adv prob = 0.250000   acc = 0.992

Validation:
Saved results/CUB/CUB_sample_exp/train_downstream_ERM_upweight_0_epochs_80_lr_1e-05_weight_decay_0.0/final_epoch31/JTT_upweight_50_epochs_80_lr_1e-05_weight_decay_1.0/model_outputs/output_val_epoch_34.csv
logged to wandb
Average incurred loss: 0.316  
Average sample loss: 0.315  
Average acc: 0.901  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.249  exp loss = 0.269  adjusted loss = 0.269  adv prob = 0.250000   acc = 0.944
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.365  exp loss = 0.398  adjusted loss = 0.398  adv prob = 0.250000   acc = 0.869
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 0.424  exp loss = 0.433  adjusted loss = 0.433  adv prob = 0.250000   acc = 0.827
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.276  exp loss = 0.257  adjusted loss = 0.257  adv prob = 0.250000   acc = 0.932
Spurious Score = 1.106
Saved results/CUB/CUB_sample_exp/train_downstream_ERM_upweight_0_epochs_80_lr_1e-05_weight_decay_0.0/final_epoch31/JTT_upweight_50_epochs_80_lr_1e-05_weight_decay_1.0/model_outputs/output_test_epoch_34.csv
logged to wandb
Current lr: 0.000010


Epoch [35]:
Training:
Average incurred loss: 0.173  
Average sample loss: 0.173  
Average acc: 0.983  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 808]:	loss = 0.213  exp loss = 0.218  adjusted loss = 0.218  adv prob = 0.250000   acc = 0.962
  waterbird_complete95 = 0, forest2water2 = 1  [n = 675]:	loss = 0.158  exp loss = 0.171  adjusted loss = 0.171  adv prob = 0.250000   acc = 0.996
  waterbird_complete95 = 1, forest2water2 = 0  [n = 509]:	loss = 0.131  exp loss = 0.118  adjusted loss = 0.118  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1208]:	loss = 0.173  exp loss = 0.150  adjusted loss = 0.150  adv prob = 0.250000   acc = 0.984
Average incurred loss: 0.170  
Average sample loss: 0.170  
Average acc: 0.990  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 845]:	loss = 0.208  exp loss = 0.211  adjusted loss = 0.211  adv prob = 0.250000   acc = 0.972
  waterbird_complete95 = 0, forest2water2 = 1  [n = 630]:	loss = 0.155  exp loss = 0.157  adjusted loss = 0.157  adv prob = 0.250000   acc = 0.998
  waterbird_complete95 = 1, forest2water2 = 0  [n = 513]:	loss = 0.140  exp loss = 0.138  adjusted loss = 0.138  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1212]:	loss = 0.163  exp loss = 0.151  adjusted loss = 0.151  adv prob = 0.250000   acc = 0.994
Average incurred loss: 0.172  
Average sample loss: 0.172  
Average acc: 0.986  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 858]:	loss = 0.220  exp loss = 0.230  adjusted loss = 0.230  adv prob = 0.250000   acc = 0.959
  waterbird_complete95 = 0, forest2water2 = 1  [n = 664]:	loss = 0.161  exp loss = 0.146  adjusted loss = 0.146  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 0  [n = 481]:	loss = 0.129  exp loss = 0.130  adjusted loss = 0.130  adv prob = 0.250000   acc = 0.998
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1197]:	loss = 0.160  exp loss = 0.160  adjusted loss = 0.160  adv prob = 0.250000   acc = 0.992
Average incurred loss: 0.170  
Average sample loss: 0.170  
Average acc: 0.987  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 823]:	loss = 0.194  exp loss = 0.183  adjusted loss = 0.183  adv prob = 0.250000   acc = 0.974
  waterbird_complete95 = 0, forest2water2 = 1  [n = 627]:	loss = 0.152  exp loss = 0.153  adjusted loss = 0.153  adv prob = 0.250000   acc = 0.998
  waterbird_complete95 = 1, forest2water2 = 0  [n = 524]:	loss = 0.137  exp loss = 0.129  adjusted loss = 0.129  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1226]:	loss = 0.177  exp loss = 0.165  adjusted loss = 0.165  adv prob = 0.250000   acc = 0.985
Saved results/CUB/CUB_sample_exp/train_downstream_ERM_upweight_0_epochs_80_lr_1e-05_weight_decay_0.0/final_epoch31/JTT_upweight_50_epochs_80_lr_1e-05_weight_decay_1.0/model_outputs/output_train_epoch_35.csv
logged to wandb
Average incurred loss: 0.169  
Average sample loss: 0.170  
Average acc: 0.990  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 464]:	loss = 0.211  exp loss = 0.208  adjusted loss = 0.208  adv prob = 0.250000   acc = 0.970
  waterbird_complete95 = 0, forest2water2 = 1  [n = 338]:	loss = 0.150  exp loss = 0.142  adjusted loss = 0.142  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 0  [n = 279]:	loss = 0.134  exp loss = 0.134  adjusted loss = 0.134  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 664]:	loss = 0.165  exp loss = 0.162  adjusted loss = 0.162  adv prob = 0.250000   acc = 0.995

Validation:
Saved results/CUB/CUB_sample_exp/train_downstream_ERM_upweight_0_epochs_80_lr_1e-05_weight_decay_0.0/final_epoch31/JTT_upweight_50_epochs_80_lr_1e-05_weight_decay_1.0/model_outputs/output_val_epoch_35.csv
logged to wandb
Average incurred loss: 0.298  
Average sample loss: 0.296  
Average acc: 0.912  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.218  exp loss = 0.236  adjusted loss = 0.236  adv prob = 0.250000   acc = 0.961
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.324  exp loss = 0.353  adjusted loss = 0.353  adv prob = 0.250000   acc = 0.895
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 0.477  exp loss = 0.492  adjusted loss = 0.492  adv prob = 0.250000   acc = 0.797
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.310  exp loss = 0.289  adjusted loss = 0.289  adv prob = 0.250000   acc = 0.910
Spurious Score = 1.106
Saved results/CUB/CUB_sample_exp/train_downstream_ERM_upweight_0_epochs_80_lr_1e-05_weight_decay_0.0/final_epoch31/JTT_upweight_50_epochs_80_lr_1e-05_weight_decay_1.0/model_outputs/output_test_epoch_35.csv
logged to wandb
Current lr: 0.000010


Epoch [36]:
Training:
Average incurred loss: 0.168  
Average sample loss: 0.168  
Average acc: 0.989  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 858]:	loss = 0.204  exp loss = 0.189  adjusted loss = 0.189  adv prob = 0.250000   acc = 0.977
  waterbird_complete95 = 0, forest2water2 = 1  [n = 636]:	loss = 0.157  exp loss = 0.138  adjusted loss = 0.138  adv prob = 0.250000   acc = 0.997
  waterbird_complete95 = 1, forest2water2 = 0  [n = 508]:	loss = 0.134  exp loss = 0.139  adjusted loss = 0.139  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1198]:	loss = 0.163  exp loss = 0.170  adjusted loss = 0.170  adv prob = 0.250000   acc = 0.990
Average incurred loss: 0.172  
Average sample loss: 0.172  
Average acc: 0.986  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 885]:	loss = 0.212  exp loss = 0.230  adjusted loss = 0.230  adv prob = 0.250000   acc = 0.965
  waterbird_complete95 = 0, forest2water2 = 1  [n = 625]:	loss = 0.163  exp loss = 0.174  adjusted loss = 0.174  adv prob = 0.250000   acc = 0.998
  waterbird_complete95 = 1, forest2water2 = 0  [n = 472]:	loss = 0.132  exp loss = 0.118  adjusted loss = 0.118  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1218]:	loss = 0.163  exp loss = 0.144  adjusted loss = 0.144  adv prob = 0.250000   acc = 0.989
Average incurred loss: 0.166  
Average sample loss: 0.166  
Average acc: 0.989  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 805]:	loss = 0.194  exp loss = 0.185  adjusted loss = 0.185  adv prob = 0.250000   acc = 0.973
  waterbird_complete95 = 0, forest2water2 = 1  [n = 634]:	loss = 0.147  exp loss = 0.132  adjusted loss = 0.132  adv prob = 0.250000   acc = 0.997
  waterbird_complete95 = 1, forest2water2 = 0  [n = 580]:	loss = 0.141  exp loss = 0.141  adjusted loss = 0.141  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1181]:	loss = 0.171  exp loss = 0.180  adjusted loss = 0.180  adv prob = 0.250000   acc = 0.992
Average incurred loss: 0.167  
Average sample loss: 0.167  
Average acc: 0.990  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 802]:	loss = 0.201  exp loss = 0.203  adjusted loss = 0.203  adv prob = 0.250000   acc = 0.976
  waterbird_complete95 = 0, forest2water2 = 1  [n = 659]:	loss = 0.149  exp loss = 0.160  adjusted loss = 0.160  adv prob = 0.250000   acc = 0.998
  waterbird_complete95 = 1, forest2water2 = 0  [n = 517]:	loss = 0.142  exp loss = 0.133  adjusted loss = 0.133  adv prob = 0.250000   acc = 0.998
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1222]:	loss = 0.164  exp loss = 0.142  adjusted loss = 0.142  adv prob = 0.250000   acc = 0.991
Saved results/CUB/CUB_sample_exp/train_downstream_ERM_upweight_0_epochs_80_lr_1e-05_weight_decay_0.0/final_epoch31/JTT_upweight_50_epochs_80_lr_1e-05_weight_decay_1.0/model_outputs/output_train_epoch_36.csv
logged to wandb
Average incurred loss: 0.169  
Average sample loss: 0.172  
Average acc: 0.986  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 448]:	loss = 0.216  exp loss = 0.218  adjusted loss = 0.218  adv prob = 0.250000   acc = 0.958
  waterbird_complete95 = 0, forest2water2 = 1  [n = 380]:	loss = 0.156  exp loss = 0.170  adjusted loss = 0.170  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 0  [n = 229]:	loss = 0.128  exp loss = 0.114  adjusted loss = 0.114  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 688]:	loss = 0.159  exp loss = 0.145  adjusted loss = 0.145  adv prob = 0.250000   acc = 0.991

Validation:
Saved results/CUB/CUB_sample_exp/train_downstream_ERM_upweight_0_epochs_80_lr_1e-05_weight_decay_0.0/final_epoch31/JTT_upweight_50_epochs_80_lr_1e-05_weight_decay_1.0/model_outputs/output_val_epoch_36.csv
logged to wandb
Average incurred loss: 0.313  
Average sample loss: 0.312  
Average acc: 0.902  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.243  exp loss = 0.263  adjusted loss = 0.263  adv prob = 0.250000   acc = 0.949
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.367  exp loss = 0.400  adjusted loss = 0.400  adv prob = 0.250000   acc = 0.865
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 0.420  exp loss = 0.431  adjusted loss = 0.431  adv prob = 0.250000   acc = 0.835
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.262  exp loss = 0.243  adjusted loss = 0.243  adv prob = 0.250000   acc = 0.932
Spurious Score = 1.107
Saved results/CUB/CUB_sample_exp/train_downstream_ERM_upweight_0_epochs_80_lr_1e-05_weight_decay_0.0/final_epoch31/JTT_upweight_50_epochs_80_lr_1e-05_weight_decay_1.0/model_outputs/output_test_epoch_36.csv
logged to wandb
Current lr: 0.000010


Epoch [37]:
Training:
Average incurred loss: 0.163  
Average sample loss: 0.163  
Average acc: 0.989  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 834]:	loss = 0.201  exp loss = 0.185  adjusted loss = 0.185  adv prob = 0.250000   acc = 0.969
  waterbird_complete95 = 0, forest2water2 = 1  [n = 670]:	loss = 0.156  exp loss = 0.133  adjusted loss = 0.133  adv prob = 0.250000   acc = 0.996
  waterbird_complete95 = 1, forest2water2 = 0  [n = 541]:	loss = 0.134  exp loss = 0.147  adjusted loss = 0.147  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1155]:	loss = 0.152  exp loss = 0.158  adjusted loss = 0.158  adv prob = 0.250000   acc = 0.995
Average incurred loss: 0.165  
Average sample loss: 0.165  
Average acc: 0.991  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 861]:	loss = 0.195  exp loss = 0.191  adjusted loss = 0.191  adv prob = 0.250000   acc = 0.983
  waterbird_complete95 = 0, forest2water2 = 1  [n = 605]:	loss = 0.145  exp loss = 0.141  adjusted loss = 0.141  adv prob = 0.250000   acc = 0.998
  waterbird_complete95 = 1, forest2water2 = 0  [n = 527]:	loss = 0.132  exp loss = 0.132  adjusted loss = 0.132  adv prob = 0.250000   acc = 0.998
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1207]:	loss = 0.169  exp loss = 0.166  adjusted loss = 0.166  adv prob = 0.250000   acc = 0.991
Average incurred loss: 0.168  
Average sample loss: 0.168  
Average acc: 0.988  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 817]:	loss = 0.207  exp loss = 0.184  adjusted loss = 0.184  adv prob = 0.250000   acc = 0.969
  waterbird_complete95 = 0, forest2water2 = 1  [n = 668]:	loss = 0.152  exp loss = 0.137  adjusted loss = 0.137  adv prob = 0.250000   acc = 0.997
  waterbird_complete95 = 1, forest2water2 = 0  [n = 485]:	loss = 0.131  exp loss = 0.137  adjusted loss = 0.137  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1230]:	loss = 0.164  exp loss = 0.168  adjusted loss = 0.168  adv prob = 0.250000   acc = 0.990
Average incurred loss: 0.165  
Average sample loss: 0.165  
Average acc: 0.988  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 819]:	loss = 0.195  exp loss = 0.208  adjusted loss = 0.208  adv prob = 0.250000   acc = 0.979
  waterbird_complete95 = 0, forest2water2 = 1  [n = 639]:	loss = 0.147  exp loss = 0.162  adjusted loss = 0.162  adv prob = 0.250000   acc = 0.994
  waterbird_complete95 = 1, forest2water2 = 0  [n = 485]:	loss = 0.135  exp loss = 0.116  adjusted loss = 0.116  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1257]:	loss = 0.167  exp loss = 0.151  adjusted loss = 0.151  adv prob = 0.250000   acc = 0.987
Saved results/CUB/CUB_sample_exp/train_downstream_ERM_upweight_0_epochs_80_lr_1e-05_weight_decay_0.0/final_epoch31/JTT_upweight_50_epochs_80_lr_1e-05_weight_decay_1.0/model_outputs/output_train_epoch_37.csv
logged to wandb
Average incurred loss: 0.165  
Average sample loss: 0.168  
Average acc: 0.992  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.201  exp loss = 0.185  adjusted loss = 0.185  adv prob = 0.250000   acc = 0.981
  waterbird_complete95 = 0, forest2water2 = 1  [n = 352]:	loss = 0.152  exp loss = 0.143  adjusted loss = 0.143  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 0  [n = 268]:	loss = 0.127  exp loss = 0.141  adjusted loss = 0.141  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 658]:	loss = 0.162  exp loss = 0.171  adjusted loss = 0.171  adv prob = 0.250000   acc = 0.992

Validation:
Saved results/CUB/CUB_sample_exp/train_downstream_ERM_upweight_0_epochs_80_lr_1e-05_weight_decay_0.0/final_epoch31/JTT_upweight_50_epochs_80_lr_1e-05_weight_decay_1.0/model_outputs/output_val_epoch_37.csv
logged to wandb
Average incurred loss: 0.293  
Average sample loss: 0.291  
Average acc: 0.912  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.212  exp loss = 0.229  adjusted loss = 0.229  adv prob = 0.250000   acc = 0.966
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.317  exp loss = 0.346  adjusted loss = 0.346  adv prob = 0.250000   acc = 0.893
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 0.480  exp loss = 0.496  adjusted loss = 0.496  adv prob = 0.250000   acc = 0.789
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.304  exp loss = 0.284  adjusted loss = 0.284  adv prob = 0.250000   acc = 0.917
Spurious Score = 1.119
Saved results/CUB/CUB_sample_exp/train_downstream_ERM_upweight_0_epochs_80_lr_1e-05_weight_decay_0.0/final_epoch31/JTT_upweight_50_epochs_80_lr_1e-05_weight_decay_1.0/model_outputs/output_test_epoch_37.csv
logged to wandb
Current lr: 0.000010


Epoch [38]:
Training:
Average incurred loss: 0.168  
Average sample loss: 0.168  
Average acc: 0.984  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 877]:	loss = 0.211  exp loss = 0.207  adjusted loss = 0.207  adv prob = 0.250000   acc = 0.964
  waterbird_complete95 = 0, forest2water2 = 1  [n = 656]:	loss = 0.161  exp loss = 0.163  adjusted loss = 0.163  adv prob = 0.250000   acc = 0.995
  waterbird_complete95 = 1, forest2water2 = 0  [n = 499]:	loss = 0.127  exp loss = 0.120  adjusted loss = 0.120  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1168]:	loss = 0.158  exp loss = 0.138  adjusted loss = 0.138  adv prob = 0.250000   acc = 0.987
Average incurred loss: 0.162  
Average sample loss: 0.162  
Average acc: 0.991  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 857]:	loss = 0.199  exp loss = 0.190  adjusted loss = 0.190  adv prob = 0.250000   acc = 0.974
  waterbird_complete95 = 0, forest2water2 = 1  [n = 664]:	loss = 0.154  exp loss = 0.152  adjusted loss = 0.152  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 0  [n = 499]:	loss = 0.128  exp loss = 0.119  adjusted loss = 0.119  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1180]:	loss = 0.154  exp loss = 0.154  adjusted loss = 0.154  adv prob = 0.250000   acc = 0.993
Average incurred loss: 0.163  
Average sample loss: 0.163  
Average acc: 0.990  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 793]:	loss = 0.188  exp loss = 0.196  adjusted loss = 0.196  adv prob = 0.250000   acc = 0.976
  waterbird_complete95 = 0, forest2water2 = 1  [n = 646]:	loss = 0.144  exp loss = 0.144  adjusted loss = 0.144  adv prob = 0.250000   acc = 0.995
  waterbird_complete95 = 1, forest2water2 = 0  [n = 520]:	loss = 0.141  exp loss = 0.135  adjusted loss = 0.135  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1241]:	loss = 0.167  exp loss = 0.172  adjusted loss = 0.172  adv prob = 0.250000   acc = 0.993
Average incurred loss: 0.161  
Average sample loss: 0.161  
Average acc: 0.993  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 803]:	loss = 0.182  exp loss = 0.182  adjusted loss = 0.182  adv prob = 0.250000   acc = 0.989
  waterbird_complete95 = 0, forest2water2 = 1  [n = 627]:	loss = 0.140  exp loss = 0.136  adjusted loss = 0.136  adv prob = 0.250000   acc = 0.998
  waterbird_complete95 = 1, forest2water2 = 0  [n = 517]:	loss = 0.137  exp loss = 0.128  adjusted loss = 0.128  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1253]:	loss = 0.168  exp loss = 0.173  adjusted loss = 0.173  adv prob = 0.250000   acc = 0.990
Saved results/CUB/CUB_sample_exp/train_downstream_ERM_upweight_0_epochs_80_lr_1e-05_weight_decay_0.0/final_epoch31/JTT_upweight_50_epochs_80_lr_1e-05_weight_decay_1.0/model_outputs/output_train_epoch_38.csv
logged to wandb
Average incurred loss: 0.163  
Average sample loss: 0.163  
Average acc: 0.990  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 468]:	loss = 0.198  exp loss = 0.188  adjusted loss = 0.188  adv prob = 0.250000   acc = 0.970
  waterbird_complete95 = 0, forest2water2 = 1  [n = 341]:	loss = 0.152  exp loss = 0.162  adjusted loss = 0.162  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 0  [n = 271]:	loss = 0.139  exp loss = 0.126  adjusted loss = 0.126  adv prob = 0.250000   acc = 0.996
  waterbird_complete95 = 1, forest2water2 = 1  [n = 665]:	loss = 0.154  exp loss = 0.149  adjusted loss = 0.149  adv prob = 0.250000   acc = 0.995

Validation:
Saved results/CUB/CUB_sample_exp/train_downstream_ERM_upweight_0_epochs_80_lr_1e-05_weight_decay_0.0/final_epoch31/JTT_upweight_50_epochs_80_lr_1e-05_weight_decay_1.0/model_outputs/output_val_epoch_38.csv
logged to wandb
Average incurred loss: 0.305  
Average sample loss: 0.304  
Average acc: 0.908  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.229  exp loss = 0.246  adjusted loss = 0.246  adv prob = 0.250000   acc = 0.959
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.348  exp loss = 0.376  adjusted loss = 0.376  adv prob = 0.250000   acc = 0.878
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 0.447  exp loss = 0.458  adjusted loss = 0.458  adv prob = 0.250000   acc = 0.812
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.278  exp loss = 0.260  adjusted loss = 0.260  adv prob = 0.250000   acc = 0.932
Spurious Score = 1.120
Saved results/CUB/CUB_sample_exp/train_downstream_ERM_upweight_0_epochs_80_lr_1e-05_weight_decay_0.0/final_epoch31/JTT_upweight_50_epochs_80_lr_1e-05_weight_decay_1.0/model_outputs/output_test_epoch_38.csv
logged to wandb
Current lr: 0.000010


Epoch [39]:
Training:
Average incurred loss: 0.164  
Average sample loss: 0.164  
Average acc: 0.990  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 832]:	loss = 0.207  exp loss = 0.192  adjusted loss = 0.192  adv prob = 0.250000   acc = 0.975
  waterbird_complete95 = 0, forest2water2 = 1  [n = 698]:	loss = 0.158  exp loss = 0.153  adjusted loss = 0.153  adv prob = 0.250000   acc = 0.997
  waterbird_complete95 = 1, forest2water2 = 0  [n = 480]:	loss = 0.127  exp loss = 0.124  adjusted loss = 0.124  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1190]:	loss = 0.153  exp loss = 0.151  adjusted loss = 0.151  adv prob = 0.250000   acc = 0.993
Average incurred loss: 0.164  
Average sample loss: 0.164  
Average acc: 0.989  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 837]:	loss = 0.194  exp loss = 0.176  adjusted loss = 0.176  adv prob = 0.250000   acc = 0.974
  waterbird_complete95 = 0, forest2water2 = 1  [n = 602]:	loss = 0.138  exp loss = 0.131  adjusted loss = 0.131  adv prob = 0.250000   acc = 0.998
  waterbird_complete95 = 1, forest2water2 = 0  [n = 533]:	loss = 0.141  exp loss = 0.142  adjusted loss = 0.142  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1228]:	loss = 0.167  exp loss = 0.167  adjusted loss = 0.167  adv prob = 0.250000   acc = 0.991
Average incurred loss: 0.161  
Average sample loss: 0.161  
Average acc: 0.990  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 841]:	loss = 0.196  exp loss = 0.179  adjusted loss = 0.179  adv prob = 0.250000   acc = 0.975
  waterbird_complete95 = 0, forest2water2 = 1  [n = 634]:	loss = 0.145  exp loss = 0.138  adjusted loss = 0.138  adv prob = 0.250000   acc = 0.997
  waterbird_complete95 = 1, forest2water2 = 0  [n = 523]:	loss = 0.135  exp loss = 0.140  adjusted loss = 0.140  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1202]:	loss = 0.157  exp loss = 0.159  adjusted loss = 0.159  adv prob = 0.250000   acc = 0.992
Average incurred loss: 0.163  
Average sample loss: 0.163  
Average acc: 0.991  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 802]:	loss = 0.184  exp loss = 0.175  adjusted loss = 0.175  adv prob = 0.250000   acc = 0.983
  waterbird_complete95 = 0, forest2water2 = 1  [n = 642]:	loss = 0.149  exp loss = 0.142  adjusted loss = 0.142  adv prob = 0.250000   acc = 0.998
  waterbird_complete95 = 1, forest2water2 = 0  [n = 516]:	loss = 0.135  exp loss = 0.133  adjusted loss = 0.133  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1240]:	loss = 0.169  exp loss = 0.172  adjusted loss = 0.172  adv prob = 0.250000   acc = 0.989
Saved results/CUB/CUB_sample_exp/train_downstream_ERM_upweight_0_epochs_80_lr_1e-05_weight_decay_0.0/final_epoch31/JTT_upweight_50_epochs_80_lr_1e-05_weight_decay_1.0/model_outputs/output_train_epoch_39.csv
logged to wandb
Average incurred loss: 0.165  
Average sample loss: 0.166  
Average acc: 0.993  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 486]:	loss = 0.203  exp loss = 0.209  adjusted loss = 0.209  adv prob = 0.250000   acc = 0.981
  waterbird_complete95 = 0, forest2water2 = 1  [n = 358]:	loss = 0.171  exp loss = 0.179  adjusted loss = 0.179  adv prob = 0.250000   acc = 0.994
  waterbird_complete95 = 1, forest2water2 = 0  [n = 254]:	loss = 0.125  exp loss = 0.123  adjusted loss = 0.123  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 647]:	loss = 0.148  exp loss = 0.141  adjusted loss = 0.141  adv prob = 0.250000   acc = 0.997

Validation:
Saved results/CUB/CUB_sample_exp/train_downstream_ERM_upweight_0_epochs_80_lr_1e-05_weight_decay_0.0/final_epoch31/JTT_upweight_50_epochs_80_lr_1e-05_weight_decay_1.0/model_outputs/output_val_epoch_39.csv
logged to wandb
Average incurred loss: 0.315  
Average sample loss: 0.314  
Average acc: 0.902  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.244  exp loss = 0.264  adjusted loss = 0.264  adv prob = 0.250000   acc = 0.951
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.375  exp loss = 0.406  adjusted loss = 0.406  adv prob = 0.250000   acc = 0.865
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 0.417  exp loss = 0.422  adjusted loss = 0.422  adv prob = 0.250000   acc = 0.835
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.252  exp loss = 0.235  adjusted loss = 0.235  adv prob = 0.250000   acc = 0.932
Spurious Score = 1.108
Saved results/CUB/CUB_sample_exp/train_downstream_ERM_upweight_0_epochs_80_lr_1e-05_weight_decay_0.0/final_epoch31/JTT_upweight_50_epochs_80_lr_1e-05_weight_decay_1.0/model_outputs/output_test_epoch_39.csv
logged to wandb
Current lr: 0.000010


Epoch [40]:
Training:
Average incurred loss: 0.163  
Average sample loss: 0.163  
Average acc: 0.990  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 858]:	loss = 0.203  exp loss = 0.210  adjusted loss = 0.210  adv prob = 0.250000   acc = 0.974
  waterbird_complete95 = 0, forest2water2 = 1  [n = 697]:	loss = 0.162  exp loss = 0.154  adjusted loss = 0.154  adv prob = 0.250000   acc = 0.999
  waterbird_complete95 = 1, forest2water2 = 0  [n = 501]:	loss = 0.129  exp loss = 0.124  adjusted loss = 0.124  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1144]:	loss = 0.148  exp loss = 0.143  adjusted loss = 0.143  adv prob = 0.250000   acc = 0.992
Average incurred loss: 0.165  
Average sample loss: 0.165  
Average acc: 0.989  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 848]:	loss = 0.196  exp loss = 0.191  adjusted loss = 0.191  adv prob = 0.250000   acc = 0.971
  waterbird_complete95 = 0, forest2water2 = 1  [n = 605]:	loss = 0.140  exp loss = 0.137  adjusted loss = 0.137  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 0  [n = 489]:	loss = 0.140  exp loss = 0.136  adjusted loss = 0.136  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1258]:	loss = 0.165  exp loss = 0.164  adjusted loss = 0.164  adv prob = 0.250000   acc = 0.991
Average incurred loss: 0.163  
Average sample loss: 0.163  
Average acc: 0.989  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 793]:	loss = 0.191  exp loss = 0.186  adjusted loss = 0.186  adv prob = 0.250000   acc = 0.979
  waterbird_complete95 = 0, forest2water2 = 1  [n = 657]:	loss = 0.144  exp loss = 0.147  adjusted loss = 0.147  adv prob = 0.250000   acc = 0.997
  waterbird_complete95 = 1, forest2water2 = 0  [n = 525]:	loss = 0.141  exp loss = 0.130  adjusted loss = 0.130  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1225]:	loss = 0.164  exp loss = 0.153  adjusted loss = 0.153  adv prob = 0.250000   acc = 0.988
Average incurred loss: 0.160  
Average sample loss: 0.160  
Average acc: 0.989  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 844]:	loss = 0.186  exp loss = 0.177  adjusted loss = 0.177  adv prob = 0.250000   acc = 0.977
  waterbird_complete95 = 0, forest2water2 = 1  [n = 638]:	loss = 0.151  exp loss = 0.147  adjusted loss = 0.147  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 0  [n = 499]:	loss = 0.132  exp loss = 0.124  adjusted loss = 0.124  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1219]:	loss = 0.159  exp loss = 0.154  adjusted loss = 0.154  adv prob = 0.250000   acc = 0.988
Saved results/CUB/CUB_sample_exp/train_downstream_ERM_upweight_0_epochs_80_lr_1e-05_weight_decay_0.0/final_epoch31/JTT_upweight_50_epochs_80_lr_1e-05_weight_decay_1.0/model_outputs/output_train_epoch_40.csv
logged to wandb
Average incurred loss: 0.162  
Average sample loss: 0.162  
Average acc: 0.992  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 455]:	loss = 0.185  exp loss = 0.168  adjusted loss = 0.168  adv prob = 0.250000   acc = 0.982
  waterbird_complete95 = 0, forest2water2 = 1  [n = 337]:	loss = 0.148  exp loss = 0.145  adjusted loss = 0.145  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 0  [n = 292]:	loss = 0.138  exp loss = 0.136  adjusted loss = 0.136  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 661]:	loss = 0.163  exp loss = 0.168  adjusted loss = 0.168  adv prob = 0.250000   acc = 0.991

Validation:
Saved results/CUB/CUB_sample_exp/train_downstream_ERM_upweight_0_epochs_80_lr_1e-05_weight_decay_0.0/final_epoch31/JTT_upweight_50_epochs_80_lr_1e-05_weight_decay_1.0/model_outputs/output_val_epoch_40.csv
logged to wandb
Average incurred loss: 0.288  
Average sample loss: 0.287  
Average acc: 0.920  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.203  exp loss = 0.219  adjusted loss = 0.219  adv prob = 0.250000   acc = 0.970
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.302  exp loss = 0.328  adjusted loss = 0.328  adv prob = 0.250000   acc = 0.914
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 0.505  exp loss = 0.519  adjusted loss = 0.519  adv prob = 0.250000   acc = 0.789
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.321  exp loss = 0.303  adjusted loss = 0.303  adv prob = 0.250000   acc = 0.895
Spurious Score = 1.095
Saved results/CUB/CUB_sample_exp/train_downstream_ERM_upweight_0_epochs_80_lr_1e-05_weight_decay_0.0/final_epoch31/JTT_upweight_50_epochs_80_lr_1e-05_weight_decay_1.0/model_outputs/output_test_epoch_40.csv
logged to wandb
Current lr: 0.000010


Epoch [41]:
Training:
Average incurred loss: 0.161  
Average sample loss: 0.161  
Average acc: 0.989  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 830]:	loss = 0.195  exp loss = 0.197  adjusted loss = 0.197  adv prob = 0.250000   acc = 0.972
  waterbird_complete95 = 0, forest2water2 = 1  [n = 653]:	loss = 0.145  exp loss = 0.145  adjusted loss = 0.145  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 0  [n = 484]:	loss = 0.133  exp loss = 0.122  adjusted loss = 0.122  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1233]:	loss = 0.159  exp loss = 0.149  adjusted loss = 0.149  adv prob = 0.250000   acc = 0.990
Average incurred loss: 0.164  
Average sample loss: 0.164  
Average acc: 0.991  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 847]:	loss = 0.195  exp loss = 0.189  adjusted loss = 0.189  adv prob = 0.250000   acc = 0.981
  waterbird_complete95 = 0, forest2water2 = 1  [n = 626]:	loss = 0.147  exp loss = 0.141  adjusted loss = 0.141  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 0  [n = 517]:	loss = 0.134  exp loss = 0.130  adjusted loss = 0.130  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1210]:	loss = 0.163  exp loss = 0.165  adjusted loss = 0.165  adv prob = 0.250000   acc = 0.988
Average incurred loss: 0.161  
Average sample loss: 0.161  
Average acc: 0.992  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 843]:	loss = 0.189  exp loss = 0.194  adjusted loss = 0.194  adv prob = 0.250000   acc = 0.982
  waterbird_complete95 = 0, forest2water2 = 1  [n = 640]:	loss = 0.152  exp loss = 0.147  adjusted loss = 0.147  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 0  [n = 490]:	loss = 0.133  exp loss = 0.128  adjusted loss = 0.128  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1227]:	loss = 0.158  exp loss = 0.154  adjusted loss = 0.154  adv prob = 0.250000   acc = 0.991
Average incurred loss: 0.160  
Average sample loss: 0.160  
Average acc: 0.993  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 831]:	loss = 0.187  exp loss = 0.180  adjusted loss = 0.180  adv prob = 0.250000   acc = 0.986
  waterbird_complete95 = 0, forest2water2 = 1  [n = 640]:	loss = 0.149  exp loss = 0.145  adjusted loss = 0.145  adv prob = 0.250000   acc = 0.998
  waterbird_complete95 = 1, forest2water2 = 0  [n = 522]:	loss = 0.138  exp loss = 0.133  adjusted loss = 0.133  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1207]:	loss = 0.158  exp loss = 0.154  adjusted loss = 0.154  adv prob = 0.250000   acc = 0.993
Saved results/CUB/CUB_sample_exp/train_downstream_ERM_upweight_0_epochs_80_lr_1e-05_weight_decay_0.0/final_epoch31/JTT_upweight_50_epochs_80_lr_1e-05_weight_decay_1.0/model_outputs/output_train_epoch_41.csv
logged to wandb
Average incurred loss: 0.160  
Average sample loss: 0.160  
Average acc: 0.995  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 447]:	loss = 0.189  exp loss = 0.182  adjusted loss = 0.182  adv prob = 0.250000   acc = 0.989
  waterbird_complete95 = 0, forest2water2 = 1  [n = 375]:	loss = 0.158  exp loss = 0.154  adjusted loss = 0.154  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 0  [n = 293]:	loss = 0.142  exp loss = 0.133  adjusted loss = 0.133  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 630]:	loss = 0.148  exp loss = 0.146  adjusted loss = 0.146  adv prob = 0.250000   acc = 0.995

Validation:
Saved results/CUB/CUB_sample_exp/train_downstream_ERM_upweight_0_epochs_80_lr_1e-05_weight_decay_0.0/final_epoch31/JTT_upweight_50_epochs_80_lr_1e-05_weight_decay_1.0/model_outputs/output_val_epoch_41.csv
logged to wandb
Average incurred loss: 0.299  
Average sample loss: 0.298  
Average acc: 0.914  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.217  exp loss = 0.233  adjusted loss = 0.233  adv prob = 0.250000   acc = 0.968
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.335  exp loss = 0.361  adjusted loss = 0.361  adv prob = 0.250000   acc = 0.886
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 0.476  exp loss = 0.487  adjusted loss = 0.487  adv prob = 0.250000   acc = 0.805
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.288  exp loss = 0.269  adjusted loss = 0.269  adv prob = 0.250000   acc = 0.932
Spurious Score = 1.124
Saved results/CUB/CUB_sample_exp/train_downstream_ERM_upweight_0_epochs_80_lr_1e-05_weight_decay_0.0/final_epoch31/JTT_upweight_50_epochs_80_lr_1e-05_weight_decay_1.0/model_outputs/output_test_epoch_41.csv
logged to wandb
Current lr: 0.000010


Epoch [42]:
Training:
Average incurred loss: 0.160  
Average sample loss: 0.160  
Average acc: 0.992  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 825]:	loss = 0.194  exp loss = 0.184  adjusted loss = 0.184  adv prob = 0.250000   acc = 0.977
  waterbird_complete95 = 0, forest2water2 = 1  [n = 664]:	loss = 0.147  exp loss = 0.139  adjusted loss = 0.139  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 0  [n = 502]:	loss = 0.136  exp loss = 0.138  adjusted loss = 0.138  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1209]:	loss = 0.153  exp loss = 0.149  adjusted loss = 0.149  adv prob = 0.250000   acc = 0.993
Average incurred loss: 0.163  
Average sample loss: 0.163  
Average acc: 0.991  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 820]:	loss = 0.187  exp loss = 0.196  adjusted loss = 0.196  adv prob = 0.250000   acc = 0.985
  waterbird_complete95 = 0, forest2water2 = 1  [n = 636]:	loss = 0.149  exp loss = 0.147  adjusted loss = 0.147  adv prob = 0.250000   acc = 0.994
  waterbird_complete95 = 1, forest2water2 = 0  [n = 496]:	loss = 0.137  exp loss = 0.129  adjusted loss = 0.129  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1248]:	loss = 0.165  exp loss = 0.148  adjusted loss = 0.148  adv prob = 0.250000   acc = 0.990
Average incurred loss: 0.159  
Average sample loss: 0.159  
Average acc: 0.993  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 840]:	loss = 0.183  exp loss = 0.173  adjusted loss = 0.173  adv prob = 0.250000   acc = 0.985
  waterbird_complete95 = 0, forest2water2 = 1  [n = 628]:	loss = 0.149  exp loss = 0.135  adjusted loss = 0.135  adv prob = 0.250000   acc = 0.995
  waterbird_complete95 = 1, forest2water2 = 0  [n = 512]:	loss = 0.140  exp loss = 0.144  adjusted loss = 0.144  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1220]:	loss = 0.156  exp loss = 0.161  adjusted loss = 0.161  adv prob = 0.250000   acc = 0.995
Average incurred loss: 0.165  
Average sample loss: 0.165  
Average acc: 0.987  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 837]:	loss = 0.195  exp loss = 0.177  adjusted loss = 0.177  adv prob = 0.250000   acc = 0.969
  waterbird_complete95 = 0, forest2water2 = 1  [n = 640]:	loss = 0.146  exp loss = 0.139  adjusted loss = 0.139  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 0  [n = 523]:	loss = 0.139  exp loss = 0.141  adjusted loss = 0.141  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1200]:	loss = 0.165  exp loss = 0.175  adjusted loss = 0.175  adv prob = 0.250000   acc = 0.987
Saved results/CUB/CUB_sample_exp/train_downstream_ERM_upweight_0_epochs_80_lr_1e-05_weight_decay_0.0/final_epoch31/JTT_upweight_50_epochs_80_lr_1e-05_weight_decay_1.0/model_outputs/output_train_epoch_42.csv
logged to wandb
Average incurred loss: 0.163  
Average sample loss: 0.164  
Average acc: 0.991  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 476]:	loss = 0.203  exp loss = 0.201  adjusted loss = 0.201  adv prob = 0.250000   acc = 0.981
  waterbird_complete95 = 0, forest2water2 = 1  [n = 366]:	loss = 0.158  exp loss = 0.154  adjusted loss = 0.154  adv prob = 0.250000   acc = 0.995
  waterbird_complete95 = 1, forest2water2 = 0  [n = 273]:	loss = 0.128  exp loss = 0.132  adjusted loss = 0.132  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 630]:	loss = 0.150  exp loss = 0.159  adjusted loss = 0.159  adv prob = 0.250000   acc = 0.992

Validation:
Saved results/CUB/CUB_sample_exp/train_downstream_ERM_upweight_0_epochs_80_lr_1e-05_weight_decay_0.0/final_epoch31/JTT_upweight_50_epochs_80_lr_1e-05_weight_decay_1.0/model_outputs/output_val_epoch_42.csv
logged to wandb
Average incurred loss: 0.294  
Average sample loss: 0.293  
Average acc: 0.917  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.211  exp loss = 0.226  adjusted loss = 0.226  adv prob = 0.250000   acc = 0.970
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.328  exp loss = 0.354  adjusted loss = 0.354  adv prob = 0.250000   acc = 0.899
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 0.479  exp loss = 0.489  adjusted loss = 0.489  adv prob = 0.250000   acc = 0.789
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.285  exp loss = 0.266  adjusted loss = 0.266  adv prob = 0.250000   acc = 0.925
Spurious Score = 1.122
Saved results/CUB/CUB_sample_exp/train_downstream_ERM_upweight_0_epochs_80_lr_1e-05_weight_decay_0.0/final_epoch31/JTT_upweight_50_epochs_80_lr_1e-05_weight_decay_1.0/model_outputs/output_test_epoch_42.csv
logged to wandb
Current lr: 0.000010


Epoch [43]:
Training:
Average incurred loss: 0.163  
Average sample loss: 0.163  
Average acc: 0.992  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 817]:	loss = 0.190  exp loss = 0.181  adjusted loss = 0.181  adv prob = 0.250000   acc = 0.979
  waterbird_complete95 = 0, forest2water2 = 1  [n = 636]:	loss = 0.145  exp loss = 0.137  adjusted loss = 0.137  adv prob = 0.250000   acc = 0.998
  waterbird_complete95 = 1, forest2water2 = 0  [n = 527]:	loss = 0.145  exp loss = 0.142  adjusted loss = 0.142  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1220]:	loss = 0.161  exp loss = 0.158  adjusted loss = 0.158  adv prob = 0.250000   acc = 0.993
Average incurred loss: 0.159  
Average sample loss: 0.159  
Average acc: 0.993  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 818]:	loss = 0.181  exp loss = 0.174  adjusted loss = 0.174  adv prob = 0.250000   acc = 0.985
  waterbird_complete95 = 0, forest2water2 = 1  [n = 652]:	loss = 0.147  exp loss = 0.138  adjusted loss = 0.138  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 0  [n = 513]:	loss = 0.136  exp loss = 0.139  adjusted loss = 0.139  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1217]:	loss = 0.159  exp loss = 0.164  adjusted loss = 0.164  adv prob = 0.250000   acc = 0.993
Average incurred loss: 0.161  
Average sample loss: 0.161  
Average acc: 0.993  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 847]:	loss = 0.198  exp loss = 0.192  adjusted loss = 0.192  adv prob = 0.250000   acc = 0.979
  waterbird_complete95 = 0, forest2water2 = 1  [n = 675]:	loss = 0.154  exp loss = 0.159  adjusted loss = 0.159  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 0  [n = 474]:	loss = 0.130  exp loss = 0.125  adjusted loss = 0.125  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1204]:	loss = 0.150  exp loss = 0.140  adjusted loss = 0.140  adv prob = 0.250000   acc = 0.995
Average incurred loss: 0.161  
Average sample loss: 0.161  
Average acc: 0.990  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 853]:	loss = 0.187  exp loss = 0.187  adjusted loss = 0.187  adv prob = 0.250000   acc = 0.980
  waterbird_complete95 = 0, forest2water2 = 1  [n = 618]:	loss = 0.146  exp loss = 0.141  adjusted loss = 0.141  adv prob = 0.250000   acc = 0.995
  waterbird_complete95 = 1, forest2water2 = 0  [n = 517]:	loss = 0.137  exp loss = 0.134  adjusted loss = 0.134  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1212]:	loss = 0.162  exp loss = 0.162  adjusted loss = 0.162  adv prob = 0.250000   acc = 0.989
Saved results/CUB/CUB_sample_exp/train_downstream_ERM_upweight_0_epochs_80_lr_1e-05_weight_decay_0.0/final_epoch31/JTT_upweight_50_epochs_80_lr_1e-05_weight_decay_1.0/model_outputs/output_train_epoch_43.csv
logged to wandb
Average incurred loss: 0.163  
Average sample loss: 0.164  
Average acc: 0.994  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 463]:	loss = 0.187  exp loss = 0.173  adjusted loss = 0.173  adv prob = 0.250000   acc = 0.991
  waterbird_complete95 = 0, forest2water2 = 1  [n = 353]:	loss = 0.156  exp loss = 0.145  adjusted loss = 0.145  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 0  [n = 275]:	loss = 0.140  exp loss = 0.139  adjusted loss = 0.139  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 654]:	loss = 0.159  exp loss = 0.161  adjusted loss = 0.161  adv prob = 0.250000   acc = 0.989

Validation:
Saved results/CUB/CUB_sample_exp/train_downstream_ERM_upweight_0_epochs_80_lr_1e-05_weight_decay_0.0/final_epoch31/JTT_upweight_50_epochs_80_lr_1e-05_weight_decay_1.0/model_outputs/output_val_epoch_43.csv
logged to wandb
Average incurred loss: 0.292  
Average sample loss: 0.291  
Average acc: 0.918  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.206  exp loss = 0.221  adjusted loss = 0.221  adv prob = 0.250000   acc = 0.970
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.320  exp loss = 0.343  adjusted loss = 0.343  adv prob = 0.250000   acc = 0.903
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 0.498  exp loss = 0.511  adjusted loss = 0.511  adv prob = 0.250000   acc = 0.782
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.295  exp loss = 0.277  adjusted loss = 0.277  adv prob = 0.250000   acc = 0.925
Spurious Score = 1.124
Saved results/CUB/CUB_sample_exp/train_downstream_ERM_upweight_0_epochs_80_lr_1e-05_weight_decay_0.0/final_epoch31/JTT_upweight_50_epochs_80_lr_1e-05_weight_decay_1.0/model_outputs/output_test_epoch_43.csv
logged to wandb
Current lr: 0.000010


Epoch [44]:
Training:
Average incurred loss: 0.156  
Average sample loss: 0.156  
Average acc: 0.996  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 810]:	loss = 0.178  exp loss = 0.182  adjusted loss = 0.182  adv prob = 0.250000   acc = 0.988
  waterbird_complete95 = 0, forest2water2 = 1  [n = 655]:	loss = 0.145  exp loss = 0.154  adjusted loss = 0.154  adv prob = 0.250000   acc = 0.998
  waterbird_complete95 = 1, forest2water2 = 0  [n = 521]:	loss = 0.142  exp loss = 0.133  adjusted loss = 0.133  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1214]:	loss = 0.155  exp loss = 0.147  adjusted loss = 0.147  adv prob = 0.250000   acc = 0.998
Average incurred loss: 0.163  
Average sample loss: 0.163  
Average acc: 0.992  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 845]:	loss = 0.188  exp loss = 0.184  adjusted loss = 0.184  adv prob = 0.250000   acc = 0.981
  waterbird_complete95 = 0, forest2water2 = 1  [n = 628]:	loss = 0.151  exp loss = 0.157  adjusted loss = 0.157  adv prob = 0.250000   acc = 0.997
  waterbird_complete95 = 1, forest2water2 = 0  [n = 517]:	loss = 0.142  exp loss = 0.135  adjusted loss = 0.135  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1210]:	loss = 0.160  exp loss = 0.149  adjusted loss = 0.149  adv prob = 0.250000   acc = 0.993
Average incurred loss: 0.167  
Average sample loss: 0.167  
Average acc: 0.992  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 823]:	loss = 0.196  exp loss = 0.195  adjusted loss = 0.195  adv prob = 0.250000   acc = 0.984
  waterbird_complete95 = 0, forest2water2 = 1  [n = 669]:	loss = 0.155  exp loss = 0.150  adjusted loss = 0.150  adv prob = 0.250000   acc = 0.999
  waterbird_complete95 = 1, forest2water2 = 0  [n = 487]:	loss = 0.137  exp loss = 0.131  adjusted loss = 0.131  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1221]:	loss = 0.165  exp loss = 0.160  adjusted loss = 0.160  adv prob = 0.250000   acc = 0.989
Average incurred loss: 0.164  
Average sample loss: 0.164  
Average acc: 0.992  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 874]:	loss = 0.190  exp loss = 0.182  adjusted loss = 0.182  adv prob = 0.250000   acc = 0.982
  waterbird_complete95 = 0, forest2water2 = 1  [n = 611]:	loss = 0.153  exp loss = 0.150  adjusted loss = 0.150  adv prob = 0.250000   acc = 0.998
  waterbird_complete95 = 1, forest2water2 = 0  [n = 517]:	loss = 0.138  exp loss = 0.138  adjusted loss = 0.138  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1198]:	loss = 0.161  exp loss = 0.157  adjusted loss = 0.157  adv prob = 0.250000   acc = 0.992
Saved results/CUB/CUB_sample_exp/train_downstream_ERM_upweight_0_epochs_80_lr_1e-05_weight_decay_0.0/final_epoch31/JTT_upweight_50_epochs_80_lr_1e-05_weight_decay_1.0/model_outputs/output_train_epoch_44.csv
logged to wandb
Average incurred loss: 0.164  
Average sample loss: 0.164  
Average acc: 0.993  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 446]:	loss = 0.195  exp loss = 0.192  adjusted loss = 0.192  adv prob = 0.250000   acc = 0.987
  waterbird_complete95 = 0, forest2water2 = 1  [n = 371]:	loss = 0.153  exp loss = 0.154  adjusted loss = 0.154  adv prob = 0.250000   acc = 0.997
  waterbird_complete95 = 1, forest2water2 = 0  [n = 264]:	loss = 0.140  exp loss = 0.132  adjusted loss = 0.132  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 664]:	loss = 0.159  exp loss = 0.158  adjusted loss = 0.158  adv prob = 0.250000   acc = 0.992

Validation:
Saved results/CUB/CUB_sample_exp/train_downstream_ERM_upweight_0_epochs_80_lr_1e-05_weight_decay_0.0/final_epoch31/JTT_upweight_50_epochs_80_lr_1e-05_weight_decay_1.0/model_outputs/output_val_epoch_44.csv
logged to wandb
Average incurred loss: 0.299  
Average sample loss: 0.298  
Average acc: 0.914  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.218  exp loss = 0.234  adjusted loss = 0.234  adv prob = 0.250000   acc = 0.970
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.338  exp loss = 0.362  adjusted loss = 0.362  adv prob = 0.250000   acc = 0.888
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 0.470  exp loss = 0.478  adjusted loss = 0.478  adv prob = 0.250000   acc = 0.789
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.279  exp loss = 0.262  adjusted loss = 0.262  adv prob = 0.250000   acc = 0.932
Spurious Score = 1.134
Saved results/CUB/CUB_sample_exp/train_downstream_ERM_upweight_0_epochs_80_lr_1e-05_weight_decay_0.0/final_epoch31/JTT_upweight_50_epochs_80_lr_1e-05_weight_decay_1.0/model_outputs/output_test_epoch_44.csv
logged to wandb
Current lr: 0.000010


Epoch [45]:
Training:
Average incurred loss: 0.166  
Average sample loss: 0.166  
Average acc: 0.993  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 820]:	loss = 0.192  exp loss = 0.184  adjusted loss = 0.184  adv prob = 0.250000   acc = 0.984
  waterbird_complete95 = 0, forest2water2 = 1  [n = 639]:	loss = 0.149  exp loss = 0.140  adjusted loss = 0.140  adv prob = 0.250000   acc = 0.997
  waterbird_complete95 = 1, forest2water2 = 0  [n = 532]:	loss = 0.150  exp loss = 0.146  adjusted loss = 0.146  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1209]:	loss = 0.164  exp loss = 0.158  adjusted loss = 0.158  adv prob = 0.250000   acc = 0.993
Average incurred loss: 0.165  
Average sample loss: 0.165  
Average acc: 0.991  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 871]:	loss = 0.195  exp loss = 0.195  adjusted loss = 0.195  adv prob = 0.250000   acc = 0.985
  waterbird_complete95 = 0, forest2water2 = 1  [n = 631]:	loss = 0.154  exp loss = 0.157  adjusted loss = 0.157  adv prob = 0.250000   acc = 0.995
  waterbird_complete95 = 1, forest2water2 = 0  [n = 485]:	loss = 0.142  exp loss = 0.130  adjusted loss = 0.130  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1213]:	loss = 0.159  exp loss = 0.149  adjusted loss = 0.149  adv prob = 0.250000   acc = 0.989
Average incurred loss: 0.165  
Average sample loss: 0.165  
Average acc: 0.993  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 808]:	loss = 0.192  exp loss = 0.190  adjusted loss = 0.190  adv prob = 0.250000   acc = 0.983
  waterbird_complete95 = 0, forest2water2 = 1  [n = 663]:	loss = 0.150  exp loss = 0.150  adjusted loss = 0.150  adv prob = 0.250000   acc = 0.998
  waterbird_complete95 = 1, forest2water2 = 0  [n = 506]:	loss = 0.145  exp loss = 0.140  adjusted loss = 0.140  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1223]:	loss = 0.164  exp loss = 0.159  adjusted loss = 0.159  adv prob = 0.250000   acc = 0.993
Average incurred loss: 0.163  
Average sample loss: 0.163  
Average acc: 0.992  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 842]:	loss = 0.186  exp loss = 0.190  adjusted loss = 0.190  adv prob = 0.250000   acc = 0.986
  waterbird_complete95 = 0, forest2water2 = 1  [n = 640]:	loss = 0.154  exp loss = 0.152  adjusted loss = 0.152  adv prob = 0.250000   acc = 0.997
  waterbird_complete95 = 1, forest2water2 = 0  [n = 529]:	loss = 0.142  exp loss = 0.137  adjusted loss = 0.137  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1189]:	loss = 0.161  exp loss = 0.155  adjusted loss = 0.155  adv prob = 0.250000   acc = 0.992
Saved results/CUB/CUB_sample_exp/train_downstream_ERM_upweight_0_epochs_80_lr_1e-05_weight_decay_0.0/final_epoch31/JTT_upweight_50_epochs_80_lr_1e-05_weight_decay_1.0/model_outputs/output_train_epoch_45.csv
logged to wandb
Average incurred loss: 0.166  
Average sample loss: 0.167  
Average acc: 0.995  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 457]:	loss = 0.199  exp loss = 0.187  adjusted loss = 0.187  adv prob = 0.250000   acc = 0.987
  waterbird_complete95 = 0, forest2water2 = 1  [n = 361]:	loss = 0.153  exp loss = 0.152  adjusted loss = 0.152  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 0  [n = 254]:	loss = 0.147  exp loss = 0.139  adjusted loss = 0.139  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 673]:	loss = 0.157  exp loss = 0.161  adjusted loss = 0.161  adv prob = 0.250000   acc = 0.996

Validation:
Saved results/CUB/CUB_sample_exp/train_downstream_ERM_upweight_0_epochs_80_lr_1e-05_weight_decay_0.0/final_epoch31/JTT_upweight_50_epochs_80_lr_1e-05_weight_decay_1.0/model_outputs/output_val_epoch_45.csv
logged to wandb
Average incurred loss: 0.293  
Average sample loss: 0.292  
Average acc: 0.917  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.208  exp loss = 0.223  adjusted loss = 0.223  adv prob = 0.250000   acc = 0.972
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.323  exp loss = 0.346  adjusted loss = 0.346  adv prob = 0.250000   acc = 0.901
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 0.492  exp loss = 0.504  adjusted loss = 0.504  adv prob = 0.250000   acc = 0.774
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.288  exp loss = 0.271  adjusted loss = 0.271  adv prob = 0.250000   acc = 0.925
Spurious Score = 1.132
Saved results/CUB/CUB_sample_exp/train_downstream_ERM_upweight_0_epochs_80_lr_1e-05_weight_decay_0.0/final_epoch31/JTT_upweight_50_epochs_80_lr_1e-05_weight_decay_1.0/model_outputs/output_test_epoch_45.csv
logged to wandb
Current lr: 0.000010


Epoch [46]:
Training:
Average incurred loss: 0.162  
Average sample loss: 0.162  
Average acc: 0.994  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 825]:	loss = 0.183  exp loss = 0.182  adjusted loss = 0.182  adv prob = 0.250000   acc = 0.989
  waterbird_complete95 = 0, forest2water2 = 1  [n = 672]:	loss = 0.158  exp loss = 0.156  adjusted loss = 0.156  adv prob = 0.250000   acc = 0.997
  waterbird_complete95 = 1, forest2water2 = 0  [n = 491]:	loss = 0.138  exp loss = 0.136  adjusted loss = 0.136  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1212]:	loss = 0.158  exp loss = 0.155  adjusted loss = 0.155  adv prob = 0.250000   acc = 0.994
Average incurred loss: 0.167  
Average sample loss: 0.167  
Average acc: 0.992  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 830]:	loss = 0.192  exp loss = 0.203  adjusted loss = 0.203  adv prob = 0.250000   acc = 0.981
  waterbird_complete95 = 0, forest2water2 = 1  [n = 655]:	loss = 0.158  exp loss = 0.159  adjusted loss = 0.159  adv prob = 0.250000   acc = 0.998
  waterbird_complete95 = 1, forest2water2 = 0  [n = 522]:	loss = 0.147  exp loss = 0.137  adjusted loss = 0.137  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1193]:	loss = 0.163  exp loss = 0.147  adjusted loss = 0.147  adv prob = 0.250000   acc = 0.994
Average incurred loss: 0.166  
Average sample loss: 0.166  
Average acc: 0.992  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 842]:	loss = 0.188  exp loss = 0.178  adjusted loss = 0.178  adv prob = 0.250000   acc = 0.986
  waterbird_complete95 = 0, forest2water2 = 1  [n = 617]:	loss = 0.152  exp loss = 0.146  adjusted loss = 0.146  adv prob = 0.250000   acc = 0.997
  waterbird_complete95 = 1, forest2water2 = 0  [n = 512]:	loss = 0.148  exp loss = 0.145  adjusted loss = 0.145  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1229]:	loss = 0.166  exp loss = 0.165  adjusted loss = 0.165  adv prob = 0.250000   acc = 0.991
Average incurred loss: 0.169  
Average sample loss: 0.169  
Average acc: 0.992  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 819]:	loss = 0.189  exp loss = 0.186  adjusted loss = 0.186  adv prob = 0.250000   acc = 0.987
  waterbird_complete95 = 0, forest2water2 = 1  [n = 616]:	loss = 0.145  exp loss = 0.145  adjusted loss = 0.145  adv prob = 0.250000   acc = 0.997
  waterbird_complete95 = 1, forest2water2 = 0  [n = 512]:	loss = 0.155  exp loss = 0.153  adjusted loss = 0.153  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1253]:	loss = 0.173  exp loss = 0.176  adjusted loss = 0.176  adv prob = 0.250000   acc = 0.989
Saved results/CUB/CUB_sample_exp/train_downstream_ERM_upweight_0_epochs_80_lr_1e-05_weight_decay_0.0/final_epoch31/JTT_upweight_50_epochs_80_lr_1e-05_weight_decay_1.0/model_outputs/output_train_epoch_46.csv
logged to wandb
Average incurred loss: 0.165  
Average sample loss: 0.165  
Average acc: 0.994  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 482]:	loss = 0.203  exp loss = 0.199  adjusted loss = 0.199  adv prob = 0.250000   acc = 0.988
  waterbird_complete95 = 0, forest2water2 = 1  [n = 374]:	loss = 0.165  exp loss = 0.158  adjusted loss = 0.158  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 0  [n = 269]:	loss = 0.133  exp loss = 0.131  adjusted loss = 0.131  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 620]:	loss = 0.150  exp loss = 0.154  adjusted loss = 0.154  adv prob = 0.250000   acc = 0.994

Validation:
Saved results/CUB/CUB_sample_exp/train_downstream_ERM_upweight_0_epochs_80_lr_1e-05_weight_decay_0.0/final_epoch31/JTT_upweight_50_epochs_80_lr_1e-05_weight_decay_1.0/model_outputs/output_val_epoch_46.csv
logged to wandb
Average incurred loss: 0.306  
Average sample loss: 0.305  
Average acc: 0.912  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.226  exp loss = 0.243  adjusted loss = 0.243  adv prob = 0.250000   acc = 0.966
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.349  exp loss = 0.374  adjusted loss = 0.374  adv prob = 0.250000   acc = 0.886
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 0.467  exp loss = 0.473  adjusted loss = 0.473  adv prob = 0.250000   acc = 0.789
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.276  exp loss = 0.261  adjusted loss = 0.261  adv prob = 0.250000   acc = 0.932
Spurious Score = 1.133
Saved results/CUB/CUB_sample_exp/train_downstream_ERM_upweight_0_epochs_80_lr_1e-05_weight_decay_0.0/final_epoch31/JTT_upweight_50_epochs_80_lr_1e-05_weight_decay_1.0/model_outputs/output_test_epoch_46.csv
logged to wandb
Current lr: 0.000010


Epoch [47]:
Training:
Average incurred loss: 0.166  
Average sample loss: 0.166  
Average acc: 0.993  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 816]:	loss = 0.184  exp loss = 0.173  adjusted loss = 0.173  adv prob = 0.250000   acc = 0.987
  waterbird_complete95 = 0, forest2water2 = 1  [n = 647]:	loss = 0.153  exp loss = 0.145  adjusted loss = 0.145  adv prob = 0.250000   acc = 0.998
  waterbird_complete95 = 1, forest2water2 = 0  [n = 563]:	loss = 0.150  exp loss = 0.150  adjusted loss = 0.150  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1174]:	loss = 0.167  exp loss = 0.168  adjusted loss = 0.168  adv prob = 0.250000   acc = 0.990
Average incurred loss: 0.167  
Average sample loss: 0.167  
Average acc: 0.992  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 831]:	loss = 0.197  exp loss = 0.199  adjusted loss = 0.199  adv prob = 0.250000   acc = 0.982
  waterbird_complete95 = 0, forest2water2 = 1  [n = 656]:	loss = 0.155  exp loss = 0.149  adjusted loss = 0.149  adv prob = 0.250000   acc = 0.997
  waterbird_complete95 = 1, forest2water2 = 0  [n = 496]:	loss = 0.146  exp loss = 0.147  adjusted loss = 0.147  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1217]:	loss = 0.163  exp loss = 0.162  adjusted loss = 0.162  adv prob = 0.250000   acc = 0.993
Average incurred loss: 0.168  
Average sample loss: 0.168  
Average acc: 0.992  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 840]:	loss = 0.199  exp loss = 0.181  adjusted loss = 0.181  adv prob = 0.250000   acc = 0.982
  waterbird_complete95 = 0, forest2water2 = 1  [n = 663]:	loss = 0.157  exp loss = 0.150  adjusted loss = 0.150  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 0  [n = 486]:	loss = 0.145  exp loss = 0.147  adjusted loss = 0.147  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1211]:	loss = 0.162  exp loss = 0.164  adjusted loss = 0.164  adv prob = 0.250000   acc = 0.992
Average incurred loss: 0.167  
Average sample loss: 0.167  
Average acc: 0.995  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 836]:	loss = 0.184  exp loss = 0.179  adjusted loss = 0.179  adv prob = 0.250000   acc = 0.993
  waterbird_complete95 = 0, forest2water2 = 1  [n = 622]:	loss = 0.152  exp loss = 0.148  adjusted loss = 0.148  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 0  [n = 502]:	loss = 0.151  exp loss = 0.149  adjusted loss = 0.149  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1240]:	loss = 0.168  exp loss = 0.164  adjusted loss = 0.164  adv prob = 0.250000   acc = 0.991
Saved results/CUB/CUB_sample_exp/train_downstream_ERM_upweight_0_epochs_80_lr_1e-05_weight_decay_0.0/final_epoch31/JTT_upweight_50_epochs_80_lr_1e-05_weight_decay_1.0/model_outputs/output_train_epoch_47.csv
logged to wandb
Average incurred loss: 0.168  
Average sample loss: 0.168  
Average acc: 0.995  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 475]:	loss = 0.198  exp loss = 0.192  adjusted loss = 0.192  adv prob = 0.250000   acc = 0.985
  waterbird_complete95 = 0, forest2water2 = 1  [n = 346]:	loss = 0.158  exp loss = 0.150  adjusted loss = 0.150  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 0  [n = 259]:	loss = 0.151  exp loss = 0.147  adjusted loss = 0.147  adv prob = 0.250000   acc = 0.996
  waterbird_complete95 = 1, forest2water2 = 1  [n = 665]:	loss = 0.158  exp loss = 0.157  adjusted loss = 0.157  adv prob = 0.250000   acc = 0.998

Validation:
Saved results/CUB/CUB_sample_exp/train_downstream_ERM_upweight_0_epochs_80_lr_1e-05_weight_decay_0.0/final_epoch31/JTT_upweight_50_epochs_80_lr_1e-05_weight_decay_1.0/model_outputs/output_val_epoch_47.csv
logged to wandb
Average incurred loss: 0.301  
Average sample loss: 0.299  
Average acc: 0.915  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.216  exp loss = 0.231  adjusted loss = 0.231  adv prob = 0.250000   acc = 0.970
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.334  exp loss = 0.356  adjusted loss = 0.356  adv prob = 0.250000   acc = 0.891
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 0.492  exp loss = 0.500  adjusted loss = 0.500  adv prob = 0.250000   acc = 0.789
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.289  exp loss = 0.274  adjusted loss = 0.274  adv prob = 0.250000   acc = 0.932
Spurious Score = 1.132
Saved results/CUB/CUB_sample_exp/train_downstream_ERM_upweight_0_epochs_80_lr_1e-05_weight_decay_0.0/final_epoch31/JTT_upweight_50_epochs_80_lr_1e-05_weight_decay_1.0/model_outputs/output_test_epoch_47.csv
logged to wandb
Current lr: 0.000010


Epoch [48]:
Training:
Average incurred loss: 0.167  
Average sample loss: 0.167  
Average acc: 0.994  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 837]:	loss = 0.191  exp loss = 0.172  adjusted loss = 0.172  adv prob = 0.250000   acc = 0.986
  waterbird_complete95 = 0, forest2water2 = 1  [n = 654]:	loss = 0.158  exp loss = 0.156  adjusted loss = 0.156  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 0  [n = 490]:	loss = 0.148  exp loss = 0.147  adjusted loss = 0.147  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1219]:	loss = 0.164  exp loss = 0.167  adjusted loss = 0.167  adv prob = 0.250000   acc = 0.994
Average incurred loss: 0.168  
Average sample loss: 0.168  
Average acc: 0.995  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 813]:	loss = 0.188  exp loss = 0.186  adjusted loss = 0.186  adv prob = 0.250000   acc = 0.994
  waterbird_complete95 = 0, forest2water2 = 1  [n = 672]:	loss = 0.159  exp loss = 0.156  adjusted loss = 0.156  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 0  [n = 505]:	loss = 0.151  exp loss = 0.142  adjusted loss = 0.142  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1210]:	loss = 0.167  exp loss = 0.158  adjusted loss = 0.158  adv prob = 0.250000   acc = 0.991
Average incurred loss: 0.169  
Average sample loss: 0.169  
Average acc: 0.993  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 834]:	loss = 0.191  exp loss = 0.179  adjusted loss = 0.179  adv prob = 0.250000   acc = 0.989
  waterbird_complete95 = 0, forest2water2 = 1  [n = 648]:	loss = 0.161  exp loss = 0.151  adjusted loss = 0.151  adv prob = 0.250000   acc = 0.994
  waterbird_complete95 = 1, forest2water2 = 0  [n = 498]:	loss = 0.152  exp loss = 0.154  adjusted loss = 0.154  adv prob = 0.250000   acc = 0.998
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1220]:	loss = 0.165  exp loss = 0.162  adjusted loss = 0.162  adv prob = 0.250000   acc = 0.993
Average incurred loss: 0.171  
Average sample loss: 0.171  
Average acc: 0.991  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 833]:	loss = 0.194  exp loss = 0.173  adjusted loss = 0.173  adv prob = 0.250000   acc = 0.977
  waterbird_complete95 = 0, forest2water2 = 1  [n = 624]:	loss = 0.154  exp loss = 0.147  adjusted loss = 0.147  adv prob = 0.250000   acc = 0.998
  waterbird_complete95 = 1, forest2water2 = 0  [n = 540]:	loss = 0.156  exp loss = 0.156  adjusted loss = 0.156  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1203]:	loss = 0.171  exp loss = 0.174  adjusted loss = 0.174  adv prob = 0.250000   acc = 0.993
Saved results/CUB/CUB_sample_exp/train_downstream_ERM_upweight_0_epochs_80_lr_1e-05_weight_decay_0.0/final_epoch31/JTT_upweight_50_epochs_80_lr_1e-05_weight_decay_1.0/model_outputs/output_train_epoch_48.csv
logged to wandb
Average incurred loss: 0.172  
Average sample loss: 0.172  
Average acc: 0.994  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 481]:	loss = 0.201  exp loss = 0.196  adjusted loss = 0.196  adv prob = 0.250000   acc = 0.985
  waterbird_complete95 = 0, forest2water2 = 1  [n = 336]:	loss = 0.158  exp loss = 0.158  adjusted loss = 0.158  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 0  [n = 273]:	loss = 0.152  exp loss = 0.153  adjusted loss = 0.153  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 655]:	loss = 0.166  exp loss = 0.159  adjusted loss = 0.159  adv prob = 0.250000   acc = 0.994

Validation:
Saved results/CUB/CUB_sample_exp/train_downstream_ERM_upweight_0_epochs_80_lr_1e-05_weight_decay_0.0/final_epoch31/JTT_upweight_50_epochs_80_lr_1e-05_weight_decay_1.0/model_outputs/output_val_epoch_48.csv
logged to wandb
Average incurred loss: 0.304  
Average sample loss: 0.303  
Average acc: 0.917  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.220  exp loss = 0.234  adjusted loss = 0.234  adv prob = 0.250000   acc = 0.970
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.339  exp loss = 0.360  adjusted loss = 0.360  adv prob = 0.250000   acc = 0.895
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 0.490  exp loss = 0.495  adjusted loss = 0.495  adv prob = 0.250000   acc = 0.789
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.290  exp loss = 0.276  adjusted loss = 0.276  adv prob = 0.250000   acc = 0.932
Spurious Score = 1.129
Saved results/CUB/CUB_sample_exp/train_downstream_ERM_upweight_0_epochs_80_lr_1e-05_weight_decay_0.0/final_epoch31/JTT_upweight_50_epochs_80_lr_1e-05_weight_decay_1.0/model_outputs/output_test_epoch_48.csv
logged to wandb
Current lr: 0.000010


Epoch [49]:
Training:
Average incurred loss: 0.172  
Average sample loss: 0.172  
Average acc: 0.993  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 800]:	loss = 0.194  exp loss = 0.188  adjusted loss = 0.188  adv prob = 0.250000   acc = 0.989
  waterbird_complete95 = 0, forest2water2 = 1  [n = 678]:	loss = 0.159  exp loss = 0.154  adjusted loss = 0.154  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 0  [n = 507]:	loss = 0.155  exp loss = 0.156  adjusted loss = 0.156  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1215]:	loss = 0.171  exp loss = 0.167  adjusted loss = 0.167  adv prob = 0.250000   acc = 0.990
Average incurred loss: 0.173  
Average sample loss: 0.173  
Average acc: 0.993  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 861]:	loss = 0.205  exp loss = 0.196  adjusted loss = 0.196  adv prob = 0.250000   acc = 0.978
  waterbird_complete95 = 0, forest2water2 = 1  [n = 645]:	loss = 0.161  exp loss = 0.155  adjusted loss = 0.155  adv prob = 0.250000   acc = 0.998
  waterbird_complete95 = 1, forest2water2 = 0  [n = 503]:	loss = 0.151  exp loss = 0.147  adjusted loss = 0.147  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1191]:	loss = 0.165  exp loss = 0.162  adjusted loss = 0.162  adv prob = 0.250000   acc = 0.997
Average incurred loss: 0.171  
Average sample loss: 0.171  
Average acc: 0.993  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 836]:	loss = 0.190  exp loss = 0.183  adjusted loss = 0.183  adv prob = 0.250000   acc = 0.992
  waterbird_complete95 = 0, forest2water2 = 1  [n = 651]:	loss = 0.164  exp loss = 0.164  adjusted loss = 0.164  adv prob = 0.250000   acc = 0.995
  waterbird_complete95 = 1, forest2water2 = 0  [n = 471]:	loss = 0.155  exp loss = 0.148  adjusted loss = 0.148  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1242]:	loss = 0.168  exp loss = 0.164  adjusted loss = 0.164  adv prob = 0.250000   acc = 0.991
Average incurred loss: 0.172  
Average sample loss: 0.172  
Average acc: 0.996  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 836]:	loss = 0.196  exp loss = 0.187  adjusted loss = 0.187  adv prob = 0.250000   acc = 0.989
  waterbird_complete95 = 0, forest2water2 = 1  [n = 644]:	loss = 0.155  exp loss = 0.139  adjusted loss = 0.139  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 0  [n = 541]:	loss = 0.157  exp loss = 0.166  adjusted loss = 0.166  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1179]:	loss = 0.170  exp loss = 0.181  adjusted loss = 0.181  adv prob = 0.250000   acc = 0.996
Saved results/CUB/CUB_sample_exp/train_downstream_ERM_upweight_0_epochs_80_lr_1e-05_weight_decay_0.0/final_epoch31/JTT_upweight_50_epochs_80_lr_1e-05_weight_decay_1.0/model_outputs/output_train_epoch_49.csv
logged to wandb
Average incurred loss: 0.175  
Average sample loss: 0.174  
Average acc: 0.995  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 465]:	loss = 0.186  exp loss = 0.182  adjusted loss = 0.182  adv prob = 0.250000   acc = 0.996
  waterbird_complete95 = 0, forest2water2 = 1  [n = 316]:	loss = 0.153  exp loss = 0.150  adjusted loss = 0.150  adv prob = 0.250000   acc = 0.997
  waterbird_complete95 = 1, forest2water2 = 0  [n = 284]:	loss = 0.165  exp loss = 0.161  adjusted loss = 0.161  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 680]:	loss = 0.181  exp loss = 0.172  adjusted loss = 0.172  adv prob = 0.250000   acc = 0.991

Validation:
Saved results/CUB/CUB_sample_exp/train_downstream_ERM_upweight_0_epochs_80_lr_1e-05_weight_decay_0.0/final_epoch31/JTT_upweight_50_epochs_80_lr_1e-05_weight_decay_1.0/model_outputs/output_val_epoch_49.csv
logged to wandb
Average incurred loss: 0.297  
Average sample loss: 0.295  
Average acc: 0.920  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.208  exp loss = 0.222  adjusted loss = 0.222  adv prob = 0.250000   acc = 0.972
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.319  exp loss = 0.339  adjusted loss = 0.339  adv prob = 0.250000   acc = 0.908
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 0.518  exp loss = 0.526  adjusted loss = 0.526  adv prob = 0.250000   acc = 0.774
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.308  exp loss = 0.293  adjusted loss = 0.293  adv prob = 0.250000   acc = 0.925
Spurious Score = 1.128
Saved results/CUB/CUB_sample_exp/train_downstream_ERM_upweight_0_epochs_80_lr_1e-05_weight_decay_0.0/final_epoch31/JTT_upweight_50_epochs_80_lr_1e-05_weight_decay_1.0/model_outputs/output_test_epoch_49.csv
logged to wandb
Current lr: 0.000010


Epoch [50]:
Training:
Average incurred loss: 0.173  
Average sample loss: 0.173  
Average acc: 0.993  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 836]:	loss = 0.197  exp loss = 0.199  adjusted loss = 0.199  adv prob = 0.250000   acc = 0.986
  waterbird_complete95 = 0, forest2water2 = 1  [n = 679]:	loss = 0.168  exp loss = 0.160  adjusted loss = 0.160  adv prob = 0.250000   acc = 0.999
  waterbird_complete95 = 1, forest2water2 = 0  [n = 496]:	loss = 0.152  exp loss = 0.149  adjusted loss = 0.149  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1189]:	loss = 0.167  exp loss = 0.167  adjusted loss = 0.167  adv prob = 0.250000   acc = 0.993
Average incurred loss: 0.175  
Average sample loss: 0.175  
Average acc: 0.993  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 816]:	loss = 0.200  exp loss = 0.206  adjusted loss = 0.206  adv prob = 0.250000   acc = 0.984
  waterbird_complete95 = 0, forest2water2 = 1  [n = 670]:	loss = 0.162  exp loss = 0.160  adjusted loss = 0.160  adv prob = 0.250000   acc = 0.999
  waterbird_complete95 = 1, forest2water2 = 0  [n = 488]:	loss = 0.159  exp loss = 0.154  adjusted loss = 0.154  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1226]:	loss = 0.171  exp loss = 0.163  adjusted loss = 0.163  adv prob = 0.250000   acc = 0.993
Average incurred loss: 0.177  
Average sample loss: 0.177  
Average acc: 0.993  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 859]:	loss = 0.194  exp loss = 0.202  adjusted loss = 0.202  adv prob = 0.250000   acc = 0.991
  waterbird_complete95 = 0, forest2water2 = 1  [n = 611]:	loss = 0.162  exp loss = 0.162  adjusted loss = 0.162  adv prob = 0.250000   acc = 0.998
  waterbird_complete95 = 1, forest2water2 = 0  [n = 494]:	loss = 0.161  exp loss = 0.151  adjusted loss = 0.151  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1236]:	loss = 0.178  exp loss = 0.174  adjusted loss = 0.174  adv prob = 0.250000   acc = 0.990
Average incurred loss: 0.176  
Average sample loss: 0.176  
Average acc: 0.996  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 817]:	loss = 0.187  exp loss = 0.189  adjusted loss = 0.189  adv prob = 0.250000   acc = 0.993
  waterbird_complete95 = 0, forest2water2 = 1  [n = 612]:	loss = 0.159  exp loss = 0.156  adjusted loss = 0.156  adv prob = 0.250000   acc = 0.998
  waterbird_complete95 = 1, forest2water2 = 0  [n = 540]:	loss = 0.168  exp loss = 0.164  adjusted loss = 0.164  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1231]:	loss = 0.180  exp loss = 0.175  adjusted loss = 0.175  adv prob = 0.250000   acc = 0.994
Saved results/CUB/CUB_sample_exp/train_downstream_ERM_upweight_0_epochs_80_lr_1e-05_weight_decay_0.0/final_epoch31/JTT_upweight_50_epochs_80_lr_1e-05_weight_decay_1.0/model_outputs/output_train_epoch_50.csv
logged to wandb
Average incurred loss: 0.179  
Average sample loss: 0.180  
Average acc: 0.994  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 470]:	loss = 0.206  exp loss = 0.204  adjusted loss = 0.204  adv prob = 0.250000   acc = 0.994
  waterbird_complete95 = 0, forest2water2 = 1  [n = 362]:	loss = 0.176  exp loss = 0.175  adjusted loss = 0.175  adv prob = 0.250000   acc = 0.997
  waterbird_complete95 = 1, forest2water2 = 0  [n = 288]:	loss = 0.158  exp loss = 0.152  adjusted loss = 0.152  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 625]:	loss = 0.171  exp loss = 0.162  adjusted loss = 0.162  adv prob = 0.250000   acc = 0.990

Validation:
Saved results/CUB/CUB_sample_exp/train_downstream_ERM_upweight_0_epochs_80_lr_1e-05_weight_decay_0.0/final_epoch31/JTT_upweight_50_epochs_80_lr_1e-05_weight_decay_1.0/model_outputs/output_val_epoch_50.csv
logged to wandb
Average incurred loss: 0.312  
Average sample loss: 0.311  
Average acc: 0.912  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.231  exp loss = 0.246  adjusted loss = 0.246  adv prob = 0.250000   acc = 0.968
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.354  exp loss = 0.377  adjusted loss = 0.377  adv prob = 0.250000   acc = 0.886
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 0.477  exp loss = 0.480  adjusted loss = 0.480  adv prob = 0.250000   acc = 0.789
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.280  exp loss = 0.267  adjusted loss = 0.267  adv prob = 0.250000   acc = 0.932
Spurious Score = 1.134
Saved results/CUB/CUB_sample_exp/train_downstream_ERM_upweight_0_epochs_80_lr_1e-05_weight_decay_0.0/final_epoch31/JTT_upweight_50_epochs_80_lr_1e-05_weight_decay_1.0/model_outputs/output_test_epoch_50.csv
logged to wandb
Current lr: 0.000010


Epoch [51]:
Training:
Average incurred loss: 0.174  
Average sample loss: 0.174  
Average acc: 0.995  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 861]:	loss = 0.196  exp loss = 0.183  adjusted loss = 0.183  adv prob = 0.250000   acc = 0.988
  waterbird_complete95 = 0, forest2water2 = 1  [n = 626]:	loss = 0.164  exp loss = 0.158  adjusted loss = 0.158  adv prob = 0.250000   acc = 0.998
  waterbird_complete95 = 1, forest2water2 = 0  [n = 491]:	loss = 0.160  exp loss = 0.164  adjusted loss = 0.164  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1222]:	loss = 0.171  exp loss = 0.171  adjusted loss = 0.171  adv prob = 0.250000   acc = 0.997
Average incurred loss: 0.180  
Average sample loss: 0.180  
Average acc: 0.993  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 839]:	loss = 0.207  exp loss = 0.209  adjusted loss = 0.209  adv prob = 0.250000   acc = 0.986
  waterbird_complete95 = 0, forest2water2 = 1  [n = 666]:	loss = 0.171  exp loss = 0.173  adjusted loss = 0.173  adv prob = 0.250000   acc = 0.998
  waterbird_complete95 = 1, forest2water2 = 0  [n = 504]:	loss = 0.160  exp loss = 0.152  adjusted loss = 0.152  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1191]:	loss = 0.175  exp loss = 0.159  adjusted loss = 0.159  adv prob = 0.250000   acc = 0.992
Average incurred loss: 0.181  
Average sample loss: 0.181  
Average acc: 0.993  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 779]:	loss = 0.192  exp loss = 0.211  adjusted loss = 0.211  adv prob = 0.250000   acc = 0.988
  waterbird_complete95 = 0, forest2water2 = 1  [n = 645]:	loss = 0.159  exp loss = 0.161  adjusted loss = 0.161  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 0  [n = 554]:	loss = 0.174  exp loss = 0.162  adjusted loss = 0.162  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1222]:	loss = 0.188  exp loss = 0.174  adjusted loss = 0.174  adv prob = 0.250000   acc = 0.990
Average incurred loss: 0.181  
Average sample loss: 0.181  
Average acc: 0.994  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 867]:	loss = 0.210  exp loss = 0.203  adjusted loss = 0.203  adv prob = 0.250000   acc = 0.985
  waterbird_complete95 = 0, forest2water2 = 1  [n = 657]:	loss = 0.175  exp loss = 0.178  adjusted loss = 0.178  adv prob = 0.250000   acc = 0.998
  waterbird_complete95 = 1, forest2water2 = 0  [n = 487]:	loss = 0.160  exp loss = 0.155  adjusted loss = 0.155  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1189]:	loss = 0.173  exp loss = 0.166  adjusted loss = 0.166  adv prob = 0.250000   acc = 0.997
Saved results/CUB/CUB_sample_exp/train_downstream_ERM_upweight_0_epochs_80_lr_1e-05_weight_decay_0.0/final_epoch31/JTT_upweight_50_epochs_80_lr_1e-05_weight_decay_1.0/model_outputs/output_train_epoch_51.csv
logged to wandb
Average incurred loss: 0.179  
Average sample loss: 0.181  
Average acc: 0.995  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 452]:	loss = 0.189  exp loss = 0.176  adjusted loss = 0.176  adv prob = 0.250000   acc = 0.996
  waterbird_complete95 = 0, forest2water2 = 1  [n = 340]:	loss = 0.168  exp loss = 0.151  adjusted loss = 0.151  adv prob = 0.250000   acc = 0.994
  waterbird_complete95 = 1, forest2water2 = 0  [n = 270]:	loss = 0.170  exp loss = 0.186  adjusted loss = 0.186  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 683]:	loss = 0.182  exp loss = 0.195  adjusted loss = 0.195  adv prob = 0.250000   acc = 0.993

Validation:
Saved results/CUB/CUB_sample_exp/train_downstream_ERM_upweight_0_epochs_80_lr_1e-05_weight_decay_0.0/final_epoch31/JTT_upweight_50_epochs_80_lr_1e-05_weight_decay_1.0/model_outputs/output_val_epoch_51.csv
logged to wandb
Average incurred loss: 0.296  
Average sample loss: 0.295  
Average acc: 0.917  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.203  exp loss = 0.215  adjusted loss = 0.215  adv prob = 0.250000   acc = 0.972
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.305  exp loss = 0.323  adjusted loss = 0.323  adv prob = 0.250000   acc = 0.925
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 0.557  exp loss = 0.568  adjusted loss = 0.568  adv prob = 0.250000   acc = 0.729
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.333  exp loss = 0.320  adjusted loss = 0.320  adv prob = 0.250000   acc = 0.887
Spurious Score = 1.124
Saved results/CUB/CUB_sample_exp/train_downstream_ERM_upweight_0_epochs_80_lr_1e-05_weight_decay_0.0/final_epoch31/JTT_upweight_50_epochs_80_lr_1e-05_weight_decay_1.0/model_outputs/output_test_epoch_51.csv
logged to wandb
Current lr: 0.000010


Epoch [52]:
Training:
Average incurred loss: 0.178  
Average sample loss: 0.178  
Average acc: 0.996  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 818]:	loss = 0.197  exp loss = 0.188  adjusted loss = 0.188  adv prob = 0.250000   acc = 0.990
  waterbird_complete95 = 0, forest2water2 = 1  [n = 647]:	loss = 0.165  exp loss = 0.160  adjusted loss = 0.160  adv prob = 0.250000   acc = 0.998
  waterbird_complete95 = 1, forest2water2 = 0  [n = 521]:	loss = 0.169  exp loss = 0.171  adjusted loss = 0.171  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1214]:	loss = 0.176  exp loss = 0.177  adjusted loss = 0.177  adv prob = 0.250000   acc = 0.998
Average incurred loss: 0.183  
Average sample loss: 0.183  
Average acc: 0.993  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 804]:	loss = 0.198  exp loss = 0.202  adjusted loss = 0.202  adv prob = 0.250000   acc = 0.990
  waterbird_complete95 = 0, forest2water2 = 1  [n = 657]:	loss = 0.167  exp loss = 0.161  adjusted loss = 0.161  adv prob = 0.250000   acc = 0.998
  waterbird_complete95 = 1, forest2water2 = 0  [n = 531]:	loss = 0.171  exp loss = 0.166  adjusted loss = 0.166  adv prob = 0.250000   acc = 0.998
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1208]:	loss = 0.187  exp loss = 0.176  adjusted loss = 0.176  adv prob = 0.250000   acc = 0.989
Average incurred loss: 0.182  
Average sample loss: 0.182  
Average acc: 0.996  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 871]:	loss = 0.205  exp loss = 0.186  adjusted loss = 0.186  adv prob = 0.250000   acc = 0.991
  waterbird_complete95 = 0, forest2water2 = 1  [n = 639]:	loss = 0.176  exp loss = 0.161  adjusted loss = 0.161  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 0  [n = 500]:	loss = 0.163  exp loss = 0.171  adjusted loss = 0.171  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1190]:	loss = 0.175  exp loss = 0.182  adjusted loss = 0.182  adv prob = 0.250000   acc = 0.996
Average incurred loss: 0.185  
Average sample loss: 0.185  
Average acc: 0.993  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 828]:	loss = 0.207  exp loss = 0.195  adjusted loss = 0.195  adv prob = 0.250000   acc = 0.987
  waterbird_complete95 = 0, forest2water2 = 1  [n = 656]:	loss = 0.170  exp loss = 0.162  adjusted loss = 0.162  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 0  [n = 510]:	loss = 0.166  exp loss = 0.168  adjusted loss = 0.168  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1206]:	loss = 0.186  exp loss = 0.189  adjusted loss = 0.189  adv prob = 0.250000   acc = 0.991
Saved results/CUB/CUB_sample_exp/train_downstream_ERM_upweight_0_epochs_80_lr_1e-05_weight_decay_0.0/final_epoch31/JTT_upweight_50_epochs_80_lr_1e-05_weight_decay_1.0/model_outputs/output_train_epoch_52.csv
logged to wandb
Average incurred loss: 0.182  
Average sample loss: 0.183  
Average acc: 0.996  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 477]:	loss = 0.200  exp loss = 0.190  adjusted loss = 0.190  adv prob = 0.250000   acc = 0.998
  waterbird_complete95 = 0, forest2water2 = 1  [n = 335]:	loss = 0.174  exp loss = 0.157  adjusted loss = 0.157  adv prob = 0.250000   acc = 0.997
  waterbird_complete95 = 1, forest2water2 = 0  [n = 244]:	loss = 0.167  exp loss = 0.174  adjusted loss = 0.174  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 689]:	loss = 0.179  exp loss = 0.186  adjusted loss = 0.186  adv prob = 0.250000   acc = 0.993

Validation:
Saved results/CUB/CUB_sample_exp/train_downstream_ERM_upweight_0_epochs_80_lr_1e-05_weight_decay_0.0/final_epoch31/JTT_upweight_50_epochs_80_lr_1e-05_weight_decay_1.0/model_outputs/output_val_epoch_52.csv
logged to wandb
Average incurred loss: 0.304  
Average sample loss: 0.303  
Average acc: 0.918  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.216  exp loss = 0.230  adjusted loss = 0.230  adv prob = 0.250000   acc = 0.972
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.322  exp loss = 0.341  adjusted loss = 0.341  adv prob = 0.250000   acc = 0.912
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 0.532  exp loss = 0.537  adjusted loss = 0.537  adv prob = 0.250000   acc = 0.744
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.323  exp loss = 0.311  adjusted loss = 0.311  adv prob = 0.250000   acc = 0.925
Spurious Score = 1.145
Saved results/CUB/CUB_sample_exp/train_downstream_ERM_upweight_0_epochs_80_lr_1e-05_weight_decay_0.0/final_epoch31/JTT_upweight_50_epochs_80_lr_1e-05_weight_decay_1.0/model_outputs/output_test_epoch_52.csv
logged to wandb
Current lr: 0.000010


Epoch [53]:
Training:
Average incurred loss: 0.184  
Average sample loss: 0.184  
Average acc: 0.994  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 812]:	loss = 0.198  exp loss = 0.195  adjusted loss = 0.195  adv prob = 0.250000   acc = 0.990
  waterbird_complete95 = 0, forest2water2 = 1  [n = 636]:	loss = 0.167  exp loss = 0.166  adjusted loss = 0.166  adv prob = 0.250000   acc = 0.997
  waterbird_complete95 = 1, forest2water2 = 0  [n = 508]:	loss = 0.175  exp loss = 0.177  adjusted loss = 0.177  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1244]:	loss = 0.188  exp loss = 0.193  adjusted loss = 0.193  adv prob = 0.250000   acc = 0.992
Average incurred loss: 0.184  
Average sample loss: 0.184  
Average acc: 0.994  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 849]:	loss = 0.205  exp loss = 0.202  adjusted loss = 0.202  adv prob = 0.250000   acc = 0.991
  waterbird_complete95 = 0, forest2water2 = 1  [n = 649]:	loss = 0.177  exp loss = 0.176  adjusted loss = 0.176  adv prob = 0.250000   acc = 0.998
  waterbird_complete95 = 1, forest2water2 = 0  [n = 496]:	loss = 0.168  exp loss = 0.163  adjusted loss = 0.163  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1206]:	loss = 0.179  exp loss = 0.175  adjusted loss = 0.175  adv prob = 0.250000   acc = 0.993
Average incurred loss: 0.185  
Average sample loss: 0.185  
Average acc: 0.997  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 842]:	loss = 0.200  exp loss = 0.190  adjusted loss = 0.190  adv prob = 0.250000   acc = 0.996
  waterbird_complete95 = 0, forest2water2 = 1  [n = 614]:	loss = 0.167  exp loss = 0.158  adjusted loss = 0.158  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 0  [n = 542]:	loss = 0.173  exp loss = 0.175  adjusted loss = 0.175  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1202]:	loss = 0.189  exp loss = 0.197  adjusted loss = 0.197  adv prob = 0.250000   acc = 0.993
Average incurred loss: 0.190  
Average sample loss: 0.190  
Average acc: 0.994  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 827]:	loss = 0.223  exp loss = 0.209  adjusted loss = 0.209  adv prob = 0.250000   acc = 0.983
  waterbird_complete95 = 0, forest2water2 = 1  [n = 707]:	loss = 0.182  exp loss = 0.177  adjusted loss = 0.177  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 0  [n = 505]:	loss = 0.177  exp loss = 0.170  adjusted loss = 0.170  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1161]:	loss = 0.177  exp loss = 0.176  adjusted loss = 0.176  adv prob = 0.250000   acc = 0.996
Saved results/CUB/CUB_sample_exp/train_downstream_ERM_upweight_0_epochs_80_lr_1e-05_weight_decay_0.0/final_epoch31/JTT_upweight_50_epochs_80_lr_1e-05_weight_decay_1.0/model_outputs/output_train_epoch_53.csv
logged to wandb
Average incurred loss: 0.189  
Average sample loss: 0.190  
Average acc: 0.994  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 468]:	loss = 0.200  exp loss = 0.194  adjusted loss = 0.194  adv prob = 0.250000   acc = 0.994
  waterbird_complete95 = 0, forest2water2 = 1  [n = 328]:	loss = 0.175  exp loss = 0.187  adjusted loss = 0.187  adv prob = 0.250000   acc = 0.997
  waterbird_complete95 = 1, forest2water2 = 0  [n = 255]:	loss = 0.178  exp loss = 0.172  adjusted loss = 0.172  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 694]:	loss = 0.192  exp loss = 0.183  adjusted loss = 0.183  adv prob = 0.250000   acc = 0.990

Validation:
Saved results/CUB/CUB_sample_exp/train_downstream_ERM_upweight_0_epochs_80_lr_1e-05_weight_decay_0.0/final_epoch31/JTT_upweight_50_epochs_80_lr_1e-05_weight_decay_1.0/model_outputs/output_val_epoch_53.csv
logged to wandb
Average incurred loss: 0.318  
Average sample loss: 0.317  
Average acc: 0.919  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.237  exp loss = 0.252  adjusted loss = 0.252  adv prob = 0.250000   acc = 0.970
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.355  exp loss = 0.376  adjusted loss = 0.376  adv prob = 0.250000   acc = 0.899
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 0.493  exp loss = 0.493  adjusted loss = 0.493  adv prob = 0.250000   acc = 0.797
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.297  exp loss = 0.286  adjusted loss = 0.286  adv prob = 0.250000   acc = 0.932
Spurious Score = 1.122
Saved results/CUB/CUB_sample_exp/train_downstream_ERM_upweight_0_epochs_80_lr_1e-05_weight_decay_0.0/final_epoch31/JTT_upweight_50_epochs_80_lr_1e-05_weight_decay_1.0/model_outputs/output_test_epoch_53.csv
logged to wandb
Current lr: 0.000010


Epoch [54]:
Training:
Average incurred loss: 0.189  
Average sample loss: 0.189  
Average acc: 0.996  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 874]:	loss = 0.207  exp loss = 0.195  adjusted loss = 0.195  adv prob = 0.250000   acc = 0.992
  waterbird_complete95 = 0, forest2water2 = 1  [n = 604]:	loss = 0.176  exp loss = 0.165  adjusted loss = 0.165  adv prob = 0.250000   acc = 0.997
  waterbird_complete95 = 1, forest2water2 = 0  [n = 500]:	loss = 0.182  exp loss = 0.177  adjusted loss = 0.177  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1222]:	loss = 0.186  exp loss = 0.190  adjusted loss = 0.190  adv prob = 0.250000   acc = 0.996
Average incurred loss: 0.187  
Average sample loss: 0.187  
Average acc: 0.997  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 783]:	loss = 0.205  exp loss = 0.192  adjusted loss = 0.192  adv prob = 0.250000   acc = 0.996
  waterbird_complete95 = 0, forest2water2 = 1  [n = 699]:	loss = 0.176  exp loss = 0.159  adjusted loss = 0.159  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 0  [n = 519]:	loss = 0.176  exp loss = 0.184  adjusted loss = 0.184  adv prob = 0.250000   acc = 0.998
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1199]:	loss = 0.186  exp loss = 0.196  adjusted loss = 0.196  adv prob = 0.250000   acc = 0.994
Average incurred loss: 0.192  
Average sample loss: 0.192  
Average acc: 0.994  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 829]:	loss = 0.214  exp loss = 0.212  adjusted loss = 0.212  adv prob = 0.250000   acc = 0.988
  waterbird_complete95 = 0, forest2water2 = 1  [n = 645]:	loss = 0.175  exp loss = 0.181  adjusted loss = 0.181  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 0  [n = 509]:	loss = 0.178  exp loss = 0.175  adjusted loss = 0.175  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1217]:	loss = 0.191  exp loss = 0.185  adjusted loss = 0.185  adv prob = 0.250000   acc = 0.992
Average incurred loss: 0.194  
Average sample loss: 0.194  
Average acc: 0.993  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 864]:	loss = 0.214  exp loss = 0.206  adjusted loss = 0.206  adv prob = 0.250000   acc = 0.988
  waterbird_complete95 = 0, forest2water2 = 1  [n = 617]:	loss = 0.178  exp loss = 0.174  adjusted loss = 0.174  adv prob = 0.250000   acc = 0.998
  waterbird_complete95 = 1, forest2water2 = 0  [n = 497]:	loss = 0.180  exp loss = 0.178  adjusted loss = 0.178  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1222]:	loss = 0.194  exp loss = 0.196  adjusted loss = 0.196  adv prob = 0.250000   acc = 0.990
Saved results/CUB/CUB_sample_exp/train_downstream_ERM_upweight_0_epochs_80_lr_1e-05_weight_decay_0.0/final_epoch31/JTT_upweight_50_epochs_80_lr_1e-05_weight_decay_1.0/model_outputs/output_train_epoch_54.csv
logged to wandb
Average incurred loss: 0.194  
Average sample loss: 0.195  
Average acc: 0.994  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 448]:	loss = 0.213  exp loss = 0.210  adjusted loss = 0.210  adv prob = 0.250000   acc = 0.991
  waterbird_complete95 = 0, forest2water2 = 1  [n = 369]:	loss = 0.185  exp loss = 0.187  adjusted loss = 0.187  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 0  [n = 281]:	loss = 0.177  exp loss = 0.175  adjusted loss = 0.175  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 647]:	loss = 0.193  exp loss = 0.194  adjusted loss = 0.194  adv prob = 0.250000   acc = 0.991

Validation:
Saved results/CUB/CUB_sample_exp/train_downstream_ERM_upweight_0_epochs_80_lr_1e-05_weight_decay_0.0/final_epoch31/JTT_upweight_50_epochs_80_lr_1e-05_weight_decay_1.0/model_outputs/output_val_epoch_54.csv
logged to wandb
Average incurred loss: 0.318  
Average sample loss: 0.317  
Average acc: 0.917  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.238  exp loss = 0.251  adjusted loss = 0.251  adv prob = 0.250000   acc = 0.970
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.350  exp loss = 0.370  adjusted loss = 0.370  adv prob = 0.250000   acc = 0.903
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 0.501  exp loss = 0.502  adjusted loss = 0.502  adv prob = 0.250000   acc = 0.774
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.306  exp loss = 0.295  adjusted loss = 0.295  adv prob = 0.250000   acc = 0.917
Spurious Score = 1.125
Saved results/CUB/CUB_sample_exp/train_downstream_ERM_upweight_0_epochs_80_lr_1e-05_weight_decay_0.0/final_epoch31/JTT_upweight_50_epochs_80_lr_1e-05_weight_decay_1.0/model_outputs/output_test_epoch_54.csv
logged to wandb
Current lr: 0.000010


Epoch [55]:
Training:
Average incurred loss: 0.195  
Average sample loss: 0.195  
Average acc: 0.993  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 841]:	loss = 0.208  exp loss = 0.207  adjusted loss = 0.207  adv prob = 0.250000   acc = 0.988
  waterbird_complete95 = 0, forest2water2 = 1  [n = 613]:	loss = 0.179  exp loss = 0.178  adjusted loss = 0.178  adv prob = 0.250000   acc = 0.997
  waterbird_complete95 = 1, forest2water2 = 0  [n = 516]:	loss = 0.190  exp loss = 0.180  adjusted loss = 0.180  adv prob = 0.250000   acc = 0.998
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1230]:	loss = 0.197  exp loss = 0.189  adjusted loss = 0.189  adv prob = 0.250000   acc = 0.991
Average incurred loss: 0.193  
Average sample loss: 0.193  
Average acc: 0.997  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 815]:	loss = 0.206  exp loss = 0.206  adjusted loss = 0.206  adv prob = 0.250000   acc = 0.995
  waterbird_complete95 = 0, forest2water2 = 1  [n = 648]:	loss = 0.180  exp loss = 0.186  adjusted loss = 0.186  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 0  [n = 539]:	loss = 0.185  exp loss = 0.176  adjusted loss = 0.176  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1198]:	loss = 0.193  exp loss = 0.179  adjusted loss = 0.179  adv prob = 0.250000   acc = 0.996
Average incurred loss: 0.197  
Average sample loss: 0.197  
Average acc: 0.993  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 841]:	loss = 0.228  exp loss = 0.211  adjusted loss = 0.211  adv prob = 0.250000   acc = 0.982
  waterbird_complete95 = 0, forest2water2 = 1  [n = 681]:	loss = 0.186  exp loss = 0.186  adjusted loss = 0.186  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 0  [n = 497]:	loss = 0.180  exp loss = 0.173  adjusted loss = 0.173  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1181]:	loss = 0.189  exp loss = 0.188  adjusted loss = 0.188  adv prob = 0.250000   acc = 0.992
Average incurred loss: 0.200  
Average sample loss: 0.200  
Average acc: 0.994  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 846]:	loss = 0.220  exp loss = 0.235  adjusted loss = 0.235  adv prob = 0.250000   acc = 0.989
  waterbird_complete95 = 0, forest2water2 = 1  [n = 639]:	loss = 0.187  exp loss = 0.188  adjusted loss = 0.188  adv prob = 0.250000   acc = 0.998
  waterbird_complete95 = 1, forest2water2 = 0  [n = 491]:	loss = 0.184  exp loss = 0.173  adjusted loss = 0.173  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1224]:	loss = 0.200  exp loss = 0.184  adjusted loss = 0.184  adv prob = 0.250000   acc = 0.992
Saved results/CUB/CUB_sample_exp/train_downstream_ERM_upweight_0_epochs_80_lr_1e-05_weight_decay_0.0/final_epoch31/JTT_upweight_50_epochs_80_lr_1e-05_weight_decay_1.0/model_outputs/output_train_epoch_55.csv
logged to wandb
Average incurred loss: 0.199  
Average sample loss: 0.198  
Average acc: 0.995  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 455]:	loss = 0.218  exp loss = 0.210  adjusted loss = 0.210  adv prob = 0.250000   acc = 0.987
  waterbird_complete95 = 0, forest2water2 = 1  [n = 353]:	loss = 0.185  exp loss = 0.182  adjusted loss = 0.182  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 0  [n = 263]:	loss = 0.188  exp loss = 0.181  adjusted loss = 0.181  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 674]:	loss = 0.197  exp loss = 0.196  adjusted loss = 0.196  adv prob = 0.250000   acc = 0.996

Validation:
Saved results/CUB/CUB_sample_exp/train_downstream_ERM_upweight_0_epochs_80_lr_1e-05_weight_decay_0.0/final_epoch31/JTT_upweight_50_epochs_80_lr_1e-05_weight_decay_1.0/model_outputs/output_val_epoch_55.csv
logged to wandb
Average incurred loss: 0.320  
Average sample loss: 0.319  
Average acc: 0.919  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.236  exp loss = 0.249  adjusted loss = 0.249  adv prob = 0.250000   acc = 0.970
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.349  exp loss = 0.367  adjusted loss = 0.367  adv prob = 0.250000   acc = 0.912
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 0.519  exp loss = 0.521  adjusted loss = 0.521  adv prob = 0.250000   acc = 0.767
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.315  exp loss = 0.305  adjusted loss = 0.305  adv prob = 0.250000   acc = 0.917
Spurious Score = 1.124
Saved results/CUB/CUB_sample_exp/train_downstream_ERM_upweight_0_epochs_80_lr_1e-05_weight_decay_0.0/final_epoch31/JTT_upweight_50_epochs_80_lr_1e-05_weight_decay_1.0/model_outputs/output_test_epoch_55.csv
logged to wandb
Current lr: 0.000010


Epoch [56]:
Training:
Average incurred loss: 0.199  
Average sample loss: 0.199  
Average acc: 0.994  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 837]:	loss = 0.218  exp loss = 0.208  adjusted loss = 0.208  adv prob = 0.250000   acc = 0.989
  waterbird_complete95 = 0, forest2water2 = 1  [n = 640]:	loss = 0.184  exp loss = 0.179  adjusted loss = 0.179  adv prob = 0.250000   acc = 0.997
  waterbird_complete95 = 1, forest2water2 = 0  [n = 517]:	loss = 0.189  exp loss = 0.187  adjusted loss = 0.187  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1206]:	loss = 0.199  exp loss = 0.197  adjusted loss = 0.197  adv prob = 0.250000   acc = 0.994
Average incurred loss: 0.200  
Average sample loss: 0.200  
Average acc: 0.994  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 873]:	loss = 0.226  exp loss = 0.223  adjusted loss = 0.223  adv prob = 0.250000   acc = 0.990
  waterbird_complete95 = 0, forest2water2 = 1  [n = 646]:	loss = 0.192  exp loss = 0.189  adjusted loss = 0.189  adv prob = 0.250000   acc = 0.997
  waterbird_complete95 = 1, forest2water2 = 0  [n = 515]:	loss = 0.183  exp loss = 0.180  adjusted loss = 0.180  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1166]:	loss = 0.193  exp loss = 0.191  adjusted loss = 0.191  adv prob = 0.250000   acc = 0.993
Average incurred loss: 0.201  
Average sample loss: 0.201  
Average acc: 0.995  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 824]:	loss = 0.225  exp loss = 0.223  adjusted loss = 0.223  adv prob = 0.250000   acc = 0.989
  waterbird_complete95 = 0, forest2water2 = 1  [n = 681]:	loss = 0.191  exp loss = 0.193  adjusted loss = 0.193  adv prob = 0.250000   acc = 0.999
  waterbird_complete95 = 1, forest2water2 = 0  [n = 483]:	loss = 0.188  exp loss = 0.182  adjusted loss = 0.182  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1212]:	loss = 0.196  exp loss = 0.186  adjusted loss = 0.186  adv prob = 0.250000   acc = 0.994
Average incurred loss: 0.205  
Average sample loss: 0.205  
Average acc: 0.993  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 839]:	loss = 0.216  exp loss = 0.226  adjusted loss = 0.226  adv prob = 0.250000   acc = 0.992
  waterbird_complete95 = 0, forest2water2 = 1  [n = 611]:	loss = 0.185  exp loss = 0.185  adjusted loss = 0.185  adv prob = 0.250000   acc = 0.997
  waterbird_complete95 = 1, forest2water2 = 0  [n = 507]:	loss = 0.200  exp loss = 0.190  adjusted loss = 0.190  adv prob = 0.250000   acc = 0.998
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1243]:	loss = 0.209  exp loss = 0.193  adjusted loss = 0.193  adv prob = 0.250000   acc = 0.990
Saved results/CUB/CUB_sample_exp/train_downstream_ERM_upweight_0_epochs_80_lr_1e-05_weight_decay_0.0/final_epoch31/JTT_upweight_50_epochs_80_lr_1e-05_weight_decay_1.0/model_outputs/output_train_epoch_56.csv
logged to wandb
Average incurred loss: 0.203  
Average sample loss: 0.203  
Average acc: 0.996  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 425]:	loss = 0.212  exp loss = 0.205  adjusted loss = 0.205  adv prob = 0.250000   acc = 0.995
  waterbird_complete95 = 0, forest2water2 = 1  [n = 356]:	loss = 0.180  exp loss = 0.179  adjusted loss = 0.179  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 0  [n = 284]:	loss = 0.198  exp loss = 0.193  adjusted loss = 0.193  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 680]:	loss = 0.211  exp loss = 0.204  adjusted loss = 0.204  adv prob = 0.250000   acc = 0.993

Validation:
Saved results/CUB/CUB_sample_exp/train_downstream_ERM_upweight_0_epochs_80_lr_1e-05_weight_decay_0.0/final_epoch31/JTT_upweight_50_epochs_80_lr_1e-05_weight_decay_1.0/model_outputs/output_val_epoch_56.csv
logged to wandb
Average incurred loss: 0.322  
Average sample loss: 0.321  
Average acc: 0.917  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.240  exp loss = 0.252  adjusted loss = 0.252  adv prob = 0.250000   acc = 0.970
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.347  exp loss = 0.366  adjusted loss = 0.366  adv prob = 0.250000   acc = 0.912
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 0.524  exp loss = 0.526  adjusted loss = 0.526  adv prob = 0.250000   acc = 0.752
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.324  exp loss = 0.315  adjusted loss = 0.315  adv prob = 0.250000   acc = 0.910
Spurious Score = 1.130
Saved results/CUB/CUB_sample_exp/train_downstream_ERM_upweight_0_epochs_80_lr_1e-05_weight_decay_0.0/final_epoch31/JTT_upweight_50_epochs_80_lr_1e-05_weight_decay_1.0/model_outputs/output_test_epoch_56.csv
logged to wandb
Current lr: 0.000010


Epoch [57]:
Training:
Average incurred loss: 0.204  
Average sample loss: 0.204  
Average acc: 0.996  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 888]:	loss = 0.224  exp loss = 0.215  adjusted loss = 0.215  adv prob = 0.250000   acc = 0.997
  waterbird_complete95 = 0, forest2water2 = 1  [n = 621]:	loss = 0.196  exp loss = 0.181  adjusted loss = 0.181  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 0  [n = 513]:	loss = 0.192  exp loss = 0.197  adjusted loss = 0.197  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1178]:	loss = 0.199  exp loss = 0.206  adjusted loss = 0.206  adv prob = 0.250000   acc = 0.992
Average incurred loss: 0.207  
Average sample loss: 0.207  
Average acc: 0.993  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 851]:	loss = 0.231  exp loss = 0.222  adjusted loss = 0.222  adv prob = 0.250000   acc = 0.985
  waterbird_complete95 = 0, forest2water2 = 1  [n = 648]:	loss = 0.194  exp loss = 0.193  adjusted loss = 0.193  adv prob = 0.250000   acc = 0.997
  waterbird_complete95 = 1, forest2water2 = 0  [n = 503]:	loss = 0.193  exp loss = 0.191  adjusted loss = 0.191  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1198]:	loss = 0.203  exp loss = 0.197  adjusted loss = 0.197  adv prob = 0.250000   acc = 0.994
Average incurred loss: 0.207  
Average sample loss: 0.207  
Average acc: 0.995  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 814]:	loss = 0.222  exp loss = 0.222  adjusted loss = 0.222  adv prob = 0.250000   acc = 0.993
  waterbird_complete95 = 0, forest2water2 = 1  [n = 662]:	loss = 0.193  exp loss = 0.191  adjusted loss = 0.191  adv prob = 0.250000   acc = 0.998
  waterbird_complete95 = 1, forest2water2 = 0  [n = 470]:	loss = 0.198  exp loss = 0.196  adjusted loss = 0.196  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1254]:	loss = 0.207  exp loss = 0.198  adjusted loss = 0.198  adv prob = 0.250000   acc = 0.994
Average incurred loss: 0.210  
Average sample loss: 0.210  
Average acc: 0.993  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 829]:	loss = 0.224  exp loss = 0.213  adjusted loss = 0.213  adv prob = 0.250000   acc = 0.992
  waterbird_complete95 = 0, forest2water2 = 1  [n = 630]:	loss = 0.192  exp loss = 0.189  adjusted loss = 0.189  adv prob = 0.250000   acc = 0.998
  waterbird_complete95 = 1, forest2water2 = 0  [n = 510]:	loss = 0.205  exp loss = 0.200  adjusted loss = 0.200  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1231]:	loss = 0.213  exp loss = 0.211  adjusted loss = 0.211  adv prob = 0.250000   acc = 0.989
Saved results/CUB/CUB_sample_exp/train_downstream_ERM_upweight_0_epochs_80_lr_1e-05_weight_decay_0.0/final_epoch31/JTT_upweight_50_epochs_80_lr_1e-05_weight_decay_1.0/model_outputs/output_train_epoch_57.csv
logged to wandb
Average incurred loss: 0.210  
Average sample loss: 0.211  
Average acc: 0.996  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 416]:	loss = 0.218  exp loss = 0.224  adjusted loss = 0.224  adv prob = 0.250000   acc = 0.998
  waterbird_complete95 = 0, forest2water2 = 1  [n = 373]:	loss = 0.197  exp loss = 0.205  adjusted loss = 0.205  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 0  [n = 310]:	loss = 0.208  exp loss = 0.196  adjusted loss = 0.196  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 646]:	loss = 0.214  exp loss = 0.198  adjusted loss = 0.198  adv prob = 0.250000   acc = 0.991

Validation:
Saved results/CUB/CUB_sample_exp/train_downstream_ERM_upweight_0_epochs_80_lr_1e-05_weight_decay_0.0/final_epoch31/JTT_upweight_50_epochs_80_lr_1e-05_weight_decay_1.0/model_outputs/output_val_epoch_57.csv
logged to wandb
Average incurred loss: 0.335  
Average sample loss: 0.334  
Average acc: 0.912  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.257  exp loss = 0.270  adjusted loss = 0.270  adv prob = 0.250000   acc = 0.966
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.373  exp loss = 0.392  adjusted loss = 0.392  adv prob = 0.250000   acc = 0.895
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 0.497  exp loss = 0.494  adjusted loss = 0.494  adv prob = 0.250000   acc = 0.782
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.312  exp loss = 0.304  adjusted loss = 0.304  adv prob = 0.250000   acc = 0.910
Spurious Score = 1.119
Saved results/CUB/CUB_sample_exp/train_downstream_ERM_upweight_0_epochs_80_lr_1e-05_weight_decay_0.0/final_epoch31/JTT_upweight_50_epochs_80_lr_1e-05_weight_decay_1.0/model_outputs/output_test_epoch_57.csv
logged to wandb
Current lr: 0.000010


Epoch [58]:
Training:
Average incurred loss: 0.212  
Average sample loss: 0.212  
Average acc: 0.994  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 830]:	loss = 0.236  exp loss = 0.231  adjusted loss = 0.231  adv prob = 0.250000   acc = 0.989
  waterbird_complete95 = 0, forest2water2 = 1  [n = 680]:	loss = 0.201  exp loss = 0.202  adjusted loss = 0.202  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 0  [n = 501]:	loss = 0.200  exp loss = 0.189  adjusted loss = 0.189  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1189]:	loss = 0.206  exp loss = 0.199  adjusted loss = 0.199  adv prob = 0.250000   acc = 0.992
Average incurred loss: 0.212  
Average sample loss: 0.212  
Average acc: 0.993  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 843]:	loss = 0.228  exp loss = 0.222  adjusted loss = 0.222  adv prob = 0.250000   acc = 0.988
  waterbird_complete95 = 0, forest2water2 = 1  [n = 611]:	loss = 0.189  exp loss = 0.189  adjusted loss = 0.189  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 0  [n = 537]:	loss = 0.208  exp loss = 0.208  adjusted loss = 0.208  adv prob = 0.250000   acc = 0.998
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1209]:	loss = 0.215  exp loss = 0.213  adjusted loss = 0.213  adv prob = 0.250000   acc = 0.990
Average incurred loss: 0.212  
Average sample loss: 0.212  
Average acc: 0.995  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 806]:	loss = 0.222  exp loss = 0.209  adjusted loss = 0.209  adv prob = 0.250000   acc = 0.991
  waterbird_complete95 = 0, forest2water2 = 1  [n = 650]:	loss = 0.198  exp loss = 0.190  adjusted loss = 0.190  adv prob = 0.250000   acc = 0.997
  waterbird_complete95 = 1, forest2water2 = 0  [n = 523]:	loss = 0.206  exp loss = 0.207  adjusted loss = 0.207  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1221]:	loss = 0.216  exp loss = 0.220  adjusted loss = 0.220  adv prob = 0.250000   acc = 0.993
Average incurred loss: 0.217  
Average sample loss: 0.217  
Average acc: 0.995  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 852]:	loss = 0.238  exp loss = 0.238  adjusted loss = 0.238  adv prob = 0.250000   acc = 0.992
  waterbird_complete95 = 0, forest2water2 = 1  [n = 657]:	loss = 0.208  exp loss = 0.214  adjusted loss = 0.214  adv prob = 0.250000   acc = 0.998
  waterbird_complete95 = 1, forest2water2 = 0  [n = 472]:	loss = 0.205  exp loss = 0.192  adjusted loss = 0.192  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1219]:	loss = 0.211  exp loss = 0.200  adjusted loss = 0.200  adv prob = 0.250000   acc = 0.993
Saved results/CUB/CUB_sample_exp/train_downstream_ERM_upweight_0_epochs_80_lr_1e-05_weight_decay_0.0/final_epoch31/JTT_upweight_50_epochs_80_lr_1e-05_weight_decay_1.0/model_outputs/output_train_epoch_58.csv
logged to wandb
Average incurred loss: 0.219  
Average sample loss: 0.219  
Average acc: 0.993  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.233  exp loss = 0.244  adjusted loss = 0.244  adv prob = 0.250000   acc = 0.987
  waterbird_complete95 = 0, forest2water2 = 1  [n = 336]:	loss = 0.206  exp loss = 0.205  adjusted loss = 0.205  adv prob = 0.250000   acc = 0.994
  waterbird_complete95 = 1, forest2water2 = 0  [n = 273]:	loss = 0.209  exp loss = 0.201  adjusted loss = 0.201  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 669]:	loss = 0.220  exp loss = 0.207  adjusted loss = 0.207  adv prob = 0.250000   acc = 0.993

Validation:
Saved results/CUB/CUB_sample_exp/train_downstream_ERM_upweight_0_epochs_80_lr_1e-05_weight_decay_0.0/final_epoch31/JTT_upweight_50_epochs_80_lr_1e-05_weight_decay_1.0/model_outputs/output_val_epoch_58.csv
logged to wandb
Average incurred loss: 0.338  
Average sample loss: 0.337  
Average acc: 0.912  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.258  exp loss = 0.272  adjusted loss = 0.272  adv prob = 0.250000   acc = 0.968
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.375  exp loss = 0.394  adjusted loss = 0.394  adv prob = 0.250000   acc = 0.895
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 0.506  exp loss = 0.502  adjusted loss = 0.502  adv prob = 0.250000   acc = 0.782
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.318  exp loss = 0.311  adjusted loss = 0.311  adv prob = 0.250000   acc = 0.910
Spurious Score = 1.120
Saved results/CUB/CUB_sample_exp/train_downstream_ERM_upweight_0_epochs_80_lr_1e-05_weight_decay_0.0/final_epoch31/JTT_upweight_50_epochs_80_lr_1e-05_weight_decay_1.0/model_outputs/output_test_epoch_58.csv
logged to wandb
Current lr: 0.000010


Epoch [59]:
Training:
Average incurred loss: 0.218  
Average sample loss: 0.218  
Average acc: 0.994  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 851]:	loss = 0.234  exp loss = 0.231  adjusted loss = 0.231  adv prob = 0.250000   acc = 0.991
  waterbird_complete95 = 0, forest2water2 = 1  [n = 612]:	loss = 0.199  exp loss = 0.192  adjusted loss = 0.192  adv prob = 0.250000   acc = 0.998
  waterbird_complete95 = 1, forest2water2 = 0  [n = 492]:	loss = 0.212  exp loss = 0.205  adjusted loss = 0.205  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1245]:	loss = 0.220  exp loss = 0.213  adjusted loss = 0.213  adv prob = 0.250000   acc = 0.993
Average incurred loss: 0.219  
Average sample loss: 0.219  
Average acc: 0.995  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 855]:	loss = 0.244  exp loss = 0.247  adjusted loss = 0.247  adv prob = 0.250000   acc = 0.992
  waterbird_complete95 = 0, forest2water2 = 1  [n = 681]:	loss = 0.216  exp loss = 0.225  adjusted loss = 0.225  adv prob = 0.250000   acc = 0.996
  waterbird_complete95 = 1, forest2water2 = 0  [n = 480]:	loss = 0.203  exp loss = 0.193  adjusted loss = 0.193  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1184]:	loss = 0.210  exp loss = 0.201  adjusted loss = 0.201  adv prob = 0.250000   acc = 0.995
Average incurred loss: 0.220  
Average sample loss: 0.220  
Average acc: 0.997  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 871]:	loss = 0.240  exp loss = 0.229  adjusted loss = 0.229  adv prob = 0.250000   acc = 0.994
  waterbird_complete95 = 0, forest2water2 = 1  [n = 633]:	loss = 0.208  exp loss = 0.199  adjusted loss = 0.199  adv prob = 0.250000   acc = 0.998
  waterbird_complete95 = 1, forest2water2 = 0  [n = 512]:	loss = 0.210  exp loss = 0.209  adjusted loss = 0.209  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1184]:	loss = 0.216  exp loss = 0.225  adjusted loss = 0.225  adv prob = 0.250000   acc = 0.996
Average incurred loss: 0.223  
Average sample loss: 0.223  
Average acc: 0.995  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 792]:	loss = 0.233  exp loss = 0.236  adjusted loss = 0.236  adv prob = 0.250000   acc = 0.992
  waterbird_complete95 = 0, forest2water2 = 1  [n = 640]:	loss = 0.199  exp loss = 0.206  adjusted loss = 0.206  adv prob = 0.250000   acc = 0.998
  waterbird_complete95 = 1, forest2water2 = 0  [n = 547]:	loss = 0.218  exp loss = 0.208  adjusted loss = 0.208  adv prob = 0.250000   acc = 0.998
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1221]:	loss = 0.232  exp loss = 0.220  adjusted loss = 0.220  adv prob = 0.250000   acc = 0.993
Saved results/CUB/CUB_sample_exp/train_downstream_ERM_upweight_0_epochs_80_lr_1e-05_weight_decay_0.0/final_epoch31/JTT_upweight_50_epochs_80_lr_1e-05_weight_decay_1.0/model_outputs/output_train_epoch_59.csv
logged to wandb
Average incurred loss: 0.226  
Average sample loss: 0.227  
Average acc: 0.994  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 429]:	loss = 0.240  exp loss = 0.233  adjusted loss = 0.233  adv prob = 0.250000   acc = 0.993
  waterbird_complete95 = 0, forest2water2 = 1  [n = 368]:	loss = 0.207  exp loss = 0.196  adjusted loss = 0.196  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 0  [n = 275]:	loss = 0.217  exp loss = 0.219  adjusted loss = 0.219  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 673]:	loss = 0.231  exp loss = 0.240  adjusted loss = 0.240  adv prob = 0.250000   acc = 0.990

Validation:
Saved results/CUB/CUB_sample_exp/train_downstream_ERM_upweight_0_epochs_80_lr_1e-05_weight_decay_0.0/final_epoch31/JTT_upweight_50_epochs_80_lr_1e-05_weight_decay_1.0/model_outputs/output_val_epoch_59.csv
logged to wandb
Average incurred loss: 0.334  
Average sample loss: 0.333  
Average acc: 0.917  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.248  exp loss = 0.261  adjusted loss = 0.261  adv prob = 0.250000   acc = 0.976
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.355  exp loss = 0.373  adjusted loss = 0.373  adv prob = 0.250000   acc = 0.908
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 0.545  exp loss = 0.540  adjusted loss = 0.540  adv prob = 0.250000   acc = 0.752
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.346  exp loss = 0.340  adjusted loss = 0.340  adv prob = 0.250000   acc = 0.910
Spurious Score = 1.137
Saved results/CUB/CUB_sample_exp/train_downstream_ERM_upweight_0_epochs_80_lr_1e-05_weight_decay_0.0/final_epoch31/JTT_upweight_50_epochs_80_lr_1e-05_weight_decay_1.0/model_outputs/output_test_epoch_59.csv
logged to wandb
Current lr: 0.000010


Epoch [60]:
Training:
Average incurred loss: 0.227  
Average sample loss: 0.227  
Average acc: 0.996  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 809]:	loss = 0.243  exp loss = 0.239  adjusted loss = 0.239  adv prob = 0.250000   acc = 0.994
  waterbird_complete95 = 0, forest2water2 = 1  [n = 664]:	loss = 0.210  exp loss = 0.195  adjusted loss = 0.195  adv prob = 0.250000   acc = 0.997
  waterbird_complete95 = 1, forest2water2 = 0  [n = 496]:	loss = 0.219  exp loss = 0.220  adjusted loss = 0.220  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1231]:	loss = 0.227  exp loss = 0.236  adjusted loss = 0.236  adv prob = 0.250000   acc = 0.995
Average incurred loss: 0.228  
Average sample loss: 0.228  
Average acc: 0.995  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 803]:	loss = 0.238  exp loss = 0.239  adjusted loss = 0.239  adv prob = 0.250000   acc = 0.996
  waterbird_complete95 = 0, forest2water2 = 1  [n = 637]:	loss = 0.206  exp loss = 0.208  adjusted loss = 0.208  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 0  [n = 534]:	loss = 0.223  exp loss = 0.218  adjusted loss = 0.218  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1226]:	loss = 0.235  exp loss = 0.226  adjusted loss = 0.226  adv prob = 0.250000   acc = 0.990
Average incurred loss: 0.231  
Average sample loss: 0.231  
Average acc: 0.992  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 868]:	loss = 0.263  exp loss = 0.255  adjusted loss = 0.255  adv prob = 0.250000   acc = 0.983
  waterbird_complete95 = 0, forest2water2 = 1  [n = 701]:	loss = 0.228  exp loss = 0.227  adjusted loss = 0.227  adv prob = 0.250000   acc = 0.999
  waterbird_complete95 = 1, forest2water2 = 0  [n = 468]:	loss = 0.208  exp loss = 0.204  adjusted loss = 0.204  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1163]:	loss = 0.217  exp loss = 0.205  adjusted loss = 0.205  adv prob = 0.250000   acc = 0.991
Average incurred loss: 0.231  
Average sample loss: 0.231  
Average acc: 0.994  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 856]:	loss = 0.243  exp loss = 0.241  adjusted loss = 0.241  adv prob = 0.250000   acc = 0.991
  waterbird_complete95 = 0, forest2water2 = 1  [n = 609]:	loss = 0.215  exp loss = 0.219  adjusted loss = 0.219  adv prob = 0.250000   acc = 0.998
  waterbird_complete95 = 1, forest2water2 = 0  [n = 507]:	loss = 0.223  exp loss = 0.214  adjusted loss = 0.214  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1228]:	loss = 0.234  exp loss = 0.226  adjusted loss = 0.226  adv prob = 0.250000   acc = 0.993
Saved results/CUB/CUB_sample_exp/train_downstream_ERM_upweight_0_epochs_80_lr_1e-05_weight_decay_0.0/final_epoch31/JTT_upweight_50_epochs_80_lr_1e-05_weight_decay_1.0/model_outputs/output_train_epoch_60.csv
logged to wandb
Average incurred loss: 0.234  
Average sample loss: 0.234  
Average acc: 0.994  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 462]:	loss = 0.247  exp loss = 0.241  adjusted loss = 0.241  adv prob = 0.250000   acc = 0.987
  waterbird_complete95 = 0, forest2water2 = 1  [n = 323]:	loss = 0.206  exp loss = 0.208  adjusted loss = 0.208  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 0  [n = 301]:	loss = 0.231  exp loss = 0.220  adjusted loss = 0.220  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 659]:	loss = 0.240  exp loss = 0.229  adjusted loss = 0.229  adv prob = 0.250000   acc = 0.992

Validation:
Saved results/CUB/CUB_sample_exp/train_downstream_ERM_upweight_0_epochs_80_lr_1e-05_weight_decay_0.0/final_epoch31/JTT_upweight_50_epochs_80_lr_1e-05_weight_decay_1.0/model_outputs/output_val_epoch_60.csv
logged to wandb
Average incurred loss: 0.345  
Average sample loss: 0.344  
Average acc: 0.910  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.260  exp loss = 0.274  adjusted loss = 0.274  adv prob = 0.250000   acc = 0.972
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.375  exp loss = 0.392  adjusted loss = 0.392  adv prob = 0.250000   acc = 0.893
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 0.536  exp loss = 0.529  adjusted loss = 0.529  adv prob = 0.250000   acc = 0.759
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.346  exp loss = 0.341  adjusted loss = 0.341  adv prob = 0.250000   acc = 0.902
Spurious Score = 1.135
Saved results/CUB/CUB_sample_exp/train_downstream_ERM_upweight_0_epochs_80_lr_1e-05_weight_decay_0.0/final_epoch31/JTT_upweight_50_epochs_80_lr_1e-05_weight_decay_1.0/model_outputs/output_test_epoch_60.csv
logged to wandb
Current lr: 0.000010


Epoch [61]:
Training:
Average incurred loss: 0.235  
Average sample loss: 0.235  
Average acc: 0.992  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 817]:	loss = 0.254  exp loss = 0.262  adjusted loss = 0.262  adv prob = 0.250000   acc = 0.984
  waterbird_complete95 = 0, forest2water2 = 1  [n = 667]:	loss = 0.218  exp loss = 0.225  adjusted loss = 0.225  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 0  [n = 532]:	loss = 0.223  exp loss = 0.212  adjusted loss = 0.212  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1184]:	loss = 0.238  exp loss = 0.226  adjusted loss = 0.226  adv prob = 0.250000   acc = 0.989
Average incurred loss: 0.237  
Average sample loss: 0.237  
Average acc: 0.993  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 838]:	loss = 0.253  exp loss = 0.253  adjusted loss = 0.253  adv prob = 0.250000   acc = 0.988
  waterbird_complete95 = 0, forest2water2 = 1  [n = 637]:	loss = 0.220  exp loss = 0.221  adjusted loss = 0.221  adv prob = 0.250000   acc = 0.998
  waterbird_complete95 = 1, forest2water2 = 0  [n = 500]:	loss = 0.230  exp loss = 0.222  adjusted loss = 0.222  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1225]:	loss = 0.237  exp loss = 0.228  adjusted loss = 0.228  adv prob = 0.250000   acc = 0.990
Average incurred loss: 0.238  
Average sample loss: 0.238  
Average acc: 0.994  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 844]:	loss = 0.250  exp loss = 0.242  adjusted loss = 0.242  adv prob = 0.250000   acc = 0.993
  waterbird_complete95 = 0, forest2water2 = 1  [n = 623]:	loss = 0.223  exp loss = 0.200  adjusted loss = 0.200  adv prob = 0.250000   acc = 0.995
  waterbird_complete95 = 1, forest2water2 = 0  [n = 494]:	loss = 0.231  exp loss = 0.242  adjusted loss = 0.242  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1239]:	loss = 0.241  exp loss = 0.248  adjusted loss = 0.248  adv prob = 0.250000   acc = 0.992
Average incurred loss: 0.238  
Average sample loss: 0.238  
Average acc: 0.997  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 837]:	loss = 0.255  exp loss = 0.246  adjusted loss = 0.246  adv prob = 0.250000   acc = 0.995
  waterbird_complete95 = 0, forest2water2 = 1  [n = 666]:	loss = 0.231  exp loss = 0.219  adjusted loss = 0.219  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 0  [n = 503]:	loss = 0.231  exp loss = 0.230  adjusted loss = 0.230  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1194]:	loss = 0.233  exp loss = 0.233  adjusted loss = 0.233  adv prob = 0.250000   acc = 0.996
Saved results/CUB/CUB_sample_exp/train_downstream_ERM_upweight_0_epochs_80_lr_1e-05_weight_decay_0.0/final_epoch31/JTT_upweight_50_epochs_80_lr_1e-05_weight_decay_1.0/model_outputs/output_train_epoch_61.csv
logged to wandb
Average incurred loss: 0.243  
Average sample loss: 0.244  
Average acc: 0.992  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 462]:	loss = 0.261  exp loss = 0.246  adjusted loss = 0.246  adv prob = 0.250000   acc = 0.983
  waterbird_complete95 = 0, forest2water2 = 1  [n = 341]:	loss = 0.225  exp loss = 0.213  adjusted loss = 0.213  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 0  [n = 277]:	loss = 0.239  exp loss = 0.245  adjusted loss = 0.245  adv prob = 0.250000   acc = 0.996
  waterbird_complete95 = 1, forest2water2 = 1  [n = 665]:	loss = 0.242  exp loss = 0.244  adjusted loss = 0.244  adv prob = 0.250000   acc = 0.992

Validation:
Saved results/CUB/CUB_sample_exp/train_downstream_ERM_upweight_0_epochs_80_lr_1e-05_weight_decay_0.0/final_epoch31/JTT_upweight_50_epochs_80_lr_1e-05_weight_decay_1.0/model_outputs/output_val_epoch_61.csv
logged to wandb
Average incurred loss: 0.352  
Average sample loss: 0.352  
Average acc: 0.910  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.270  exp loss = 0.285  adjusted loss = 0.285  adv prob = 0.250000   acc = 0.970
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.378  exp loss = 0.395  adjusted loss = 0.395  adv prob = 0.250000   acc = 0.893
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 0.544  exp loss = 0.532  adjusted loss = 0.532  adv prob = 0.250000   acc = 0.767
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.360  exp loss = 0.357  adjusted loss = 0.357  adv prob = 0.250000   acc = 0.902
Spurious Score = 1.128
Saved results/CUB/CUB_sample_exp/train_downstream_ERM_upweight_0_epochs_80_lr_1e-05_weight_decay_0.0/final_epoch31/JTT_upweight_50_epochs_80_lr_1e-05_weight_decay_1.0/model_outputs/output_test_epoch_61.csv
logged to wandb
Current lr: 0.000010


Epoch [62]:
Training:
Average incurred loss: 0.242  
Average sample loss: 0.242  
Average acc: 0.992  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 823]:	loss = 0.258  exp loss = 0.253  adjusted loss = 0.253  adv prob = 0.250000   acc = 0.982
  waterbird_complete95 = 0, forest2water2 = 1  [n = 652]:	loss = 0.228  exp loss = 0.224  adjusted loss = 0.224  adv prob = 0.250000   acc = 0.995
  waterbird_complete95 = 1, forest2water2 = 0  [n = 488]:	loss = 0.235  exp loss = 0.232  adjusted loss = 0.232  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1237]:	loss = 0.241  exp loss = 0.240  adjusted loss = 0.240  adv prob = 0.250000   acc = 0.994
Average incurred loss: 0.246  
Average sample loss: 0.246  
Average acc: 0.994  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 829]:	loss = 0.264  exp loss = 0.263  adjusted loss = 0.263  adv prob = 0.250000   acc = 0.989
  waterbird_complete95 = 0, forest2water2 = 1  [n = 639]:	loss = 0.225  exp loss = 0.221  adjusted loss = 0.221  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 0  [n = 497]:	loss = 0.238  exp loss = 0.240  adjusted loss = 0.240  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1235]:	loss = 0.248  exp loss = 0.247  adjusted loss = 0.247  adv prob = 0.250000   acc = 0.991
Average incurred loss: 0.248  
Average sample loss: 0.248  
Average acc: 0.993  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 839]:	loss = 0.270  exp loss = 0.257  adjusted loss = 0.257  adv prob = 0.250000   acc = 0.986
  waterbird_complete95 = 0, forest2water2 = 1  [n = 667]:	loss = 0.237  exp loss = 0.238  adjusted loss = 0.238  adv prob = 0.250000   acc = 0.996
  waterbird_complete95 = 1, forest2water2 = 0  [n = 518]:	loss = 0.236  exp loss = 0.232  adjusted loss = 0.232  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1176]:	loss = 0.244  exp loss = 0.241  adjusted loss = 0.241  adv prob = 0.250000   acc = 0.993
Average incurred loss: 0.251  
Average sample loss: 0.251  
Average acc: 0.994  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 864]:	loss = 0.265  exp loss = 0.262  adjusted loss = 0.262  adv prob = 0.250000   acc = 0.990
  waterbird_complete95 = 0, forest2water2 = 1  [n = 603]:	loss = 0.231  exp loss = 0.226  adjusted loss = 0.226  adv prob = 0.250000   acc = 0.998
  waterbird_complete95 = 1, forest2water2 = 0  [n = 527]:	loss = 0.244  exp loss = 0.244  adjusted loss = 0.244  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1206]:	loss = 0.253  exp loss = 0.249  adjusted loss = 0.249  adv prob = 0.250000   acc = 0.992
Saved results/CUB/CUB_sample_exp/train_downstream_ERM_upweight_0_epochs_80_lr_1e-05_weight_decay_0.0/final_epoch31/JTT_upweight_50_epochs_80_lr_1e-05_weight_decay_1.0/model_outputs/output_train_epoch_62.csv
logged to wandb
Average incurred loss: 0.247  
Average sample loss: 0.247  
Average acc: 0.995  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 443]:	loss = 0.260  exp loss = 0.254  adjusted loss = 0.254  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 0, forest2water2 = 1  [n = 373]:	loss = 0.241  exp loss = 0.240  adjusted loss = 0.240  adv prob = 0.250000   acc = 0.997
  waterbird_complete95 = 1, forest2water2 = 0  [n = 276]:	loss = 0.237  exp loss = 0.230  adjusted loss = 0.230  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 653]:	loss = 0.247  exp loss = 0.242  adjusted loss = 0.242  adv prob = 0.250000   acc = 0.988

Validation:
Saved results/CUB/CUB_sample_exp/train_downstream_ERM_upweight_0_epochs_80_lr_1e-05_weight_decay_0.0/final_epoch31/JTT_upweight_50_epochs_80_lr_1e-05_weight_decay_1.0/model_outputs/output_val_epoch_62.csv
logged to wandb
Average incurred loss: 0.371  
Average sample loss: 0.370  
Average acc: 0.907  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.296  exp loss = 0.311  adjusted loss = 0.311  adv prob = 0.250000   acc = 0.966
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.413  exp loss = 0.430  adjusted loss = 0.430  adv prob = 0.250000   acc = 0.876
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 0.512  exp loss = 0.496  adjusted loss = 0.496  adv prob = 0.250000   acc = 0.820
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.346  exp loss = 0.344  adjusted loss = 0.344  adv prob = 0.250000   acc = 0.902
Spurious Score = 1.102
Saved results/CUB/CUB_sample_exp/train_downstream_ERM_upweight_0_epochs_80_lr_1e-05_weight_decay_0.0/final_epoch31/JTT_upweight_50_epochs_80_lr_1e-05_weight_decay_1.0/model_outputs/output_test_epoch_62.csv
logged to wandb
Current lr: 0.000010


Epoch [63]:
Training:
Average incurred loss: 0.252  
Average sample loss: 0.252  
Average acc: 0.993  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 826]:	loss = 0.271  exp loss = 0.272  adjusted loss = 0.272  adv prob = 0.250000   acc = 0.988
  waterbird_complete95 = 0, forest2water2 = 1  [n = 663]:	loss = 0.239  exp loss = 0.239  adjusted loss = 0.239  adv prob = 0.250000   acc = 0.995
  waterbird_complete95 = 1, forest2water2 = 0  [n = 514]:	loss = 0.238  exp loss = 0.233  adjusted loss = 0.233  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1197]:	loss = 0.253  exp loss = 0.249  adjusted loss = 0.249  adv prob = 0.250000   acc = 0.992
Average incurred loss: 0.255  
Average sample loss: 0.255  
Average acc: 0.994  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 849]:	loss = 0.274  exp loss = 0.281  adjusted loss = 0.281  adv prob = 0.250000   acc = 0.986
  waterbird_complete95 = 0, forest2water2 = 1  [n = 634]:	loss = 0.238  exp loss = 0.244  adjusted loss = 0.244  adv prob = 0.250000   acc = 0.998
  waterbird_complete95 = 1, forest2water2 = 0  [n = 504]:	loss = 0.245  exp loss = 0.233  adjusted loss = 0.233  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1213]:	loss = 0.255  exp loss = 0.246  adjusted loss = 0.246  adv prob = 0.250000   acc = 0.996
Average incurred loss: 0.259  
Average sample loss: 0.259  
Average acc: 0.992  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 822]:	loss = 0.276  exp loss = 0.272  adjusted loss = 0.272  adv prob = 0.250000   acc = 0.985
  waterbird_complete95 = 0, forest2water2 = 1  [n = 656]:	loss = 0.243  exp loss = 0.238  adjusted loss = 0.238  adv prob = 0.250000   acc = 0.998
  waterbird_complete95 = 1, forest2water2 = 0  [n = 481]:	loss = 0.252  exp loss = 0.248  adjusted loss = 0.248  adv prob = 0.250000   acc = 0.998
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1241]:	loss = 0.260  exp loss = 0.251  adjusted loss = 0.251  adv prob = 0.250000   acc = 0.990
Average incurred loss: 0.261  
Average sample loss: 0.261  
Average acc: 0.992  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 849]:	loss = 0.276  exp loss = 0.264  adjusted loss = 0.264  adv prob = 0.250000   acc = 0.993
  waterbird_complete95 = 0, forest2water2 = 1  [n = 643]:	loss = 0.250  exp loss = 0.239  adjusted loss = 0.239  adv prob = 0.250000   acc = 0.994
  waterbird_complete95 = 1, forest2water2 = 0  [n = 524]:	loss = 0.248  exp loss = 0.256  adjusted loss = 0.256  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1184]:	loss = 0.262  exp loss = 0.269  adjusted loss = 0.269  adv prob = 0.250000   acc = 0.988
Saved results/CUB/CUB_sample_exp/train_downstream_ERM_upweight_0_epochs_80_lr_1e-05_weight_decay_0.0/final_epoch31/JTT_upweight_50_epochs_80_lr_1e-05_weight_decay_1.0/model_outputs/output_train_epoch_63.csv
logged to wandb
Average incurred loss: 0.263  
Average sample loss: 0.263  
Average acc: 0.995  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 452]:	loss = 0.279  exp loss = 0.275  adjusted loss = 0.275  adv prob = 0.250000   acc = 0.989
  waterbird_complete95 = 0, forest2water2 = 1  [n = 338]:	loss = 0.239  exp loss = 0.248  adjusted loss = 0.248  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 0  [n = 283]:	loss = 0.262  exp loss = 0.253  adjusted loss = 0.253  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 672]:	loss = 0.265  exp loss = 0.255  adjusted loss = 0.255  adv prob = 0.250000   acc = 0.996

Validation:
Saved results/CUB/CUB_sample_exp/train_downstream_ERM_upweight_0_epochs_80_lr_1e-05_weight_decay_0.0/final_epoch31/JTT_upweight_50_epochs_80_lr_1e-05_weight_decay_1.0/model_outputs/output_val_epoch_63.csv
logged to wandb
Average incurred loss: 0.375  
Average sample loss: 0.374  
Average acc: 0.905  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.298  exp loss = 0.314  adjusted loss = 0.314  adv prob = 0.250000   acc = 0.970
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.408  exp loss = 0.425  adjusted loss = 0.425  adv prob = 0.250000   acc = 0.876
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 0.535  exp loss = 0.514  adjusted loss = 0.514  adv prob = 0.250000   acc = 0.782
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.371  exp loss = 0.368  adjusted loss = 0.368  adv prob = 0.250000   acc = 0.902
Spurious Score = 1.130
Saved results/CUB/CUB_sample_exp/train_downstream_ERM_upweight_0_epochs_80_lr_1e-05_weight_decay_0.0/final_epoch31/JTT_upweight_50_epochs_80_lr_1e-05_weight_decay_1.0/model_outputs/output_test_epoch_63.csv
logged to wandb
Current lr: 0.000010


Epoch [64]:
Training:
Average incurred loss: 0.265  
Average sample loss: 0.265  
Average acc: 0.991  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 866]:	loss = 0.288  exp loss = 0.282  adjusted loss = 0.282  adv prob = 0.250000   acc = 0.980
  waterbird_complete95 = 0, forest2water2 = 1  [n = 649]:	loss = 0.255  exp loss = 0.256  adjusted loss = 0.256  adv prob = 0.250000   acc = 0.998
  waterbird_complete95 = 1, forest2water2 = 0  [n = 491]:	loss = 0.249  exp loss = 0.246  adjusted loss = 0.246  adv prob = 0.250000   acc = 0.998
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1194]:	loss = 0.260  exp loss = 0.258  adjusted loss = 0.258  adv prob = 0.250000   acc = 0.992
Average incurred loss: 0.266  
Average sample loss: 0.266  
Average acc: 0.995  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 821]:	loss = 0.275  exp loss = 0.272  adjusted loss = 0.272  adv prob = 0.250000   acc = 0.995
  waterbird_complete95 = 0, forest2water2 = 1  [n = 619]:	loss = 0.245  exp loss = 0.239  adjusted loss = 0.239  adv prob = 0.250000   acc = 0.998
  waterbird_complete95 = 1, forest2water2 = 0  [n = 532]:	loss = 0.258  exp loss = 0.260  adjusted loss = 0.260  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1228]:	loss = 0.274  exp loss = 0.277  adjusted loss = 0.277  adv prob = 0.250000   acc = 0.990
Average incurred loss: 0.272  
Average sample loss: 0.272  
Average acc: 0.992  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 826]:	loss = 0.280  exp loss = 0.285  adjusted loss = 0.285  adv prob = 0.250000   acc = 0.982
  waterbird_complete95 = 0, forest2water2 = 1  [n = 605]:	loss = 0.249  exp loss = 0.250  adjusted loss = 0.250  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 0  [n = 522]:	loss = 0.270  exp loss = 0.261  adjusted loss = 0.261  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1247]:	loss = 0.277  exp loss = 0.268  adjusted loss = 0.268  adv prob = 0.250000   acc = 0.992
Average incurred loss: 0.272  
Average sample loss: 0.272  
Average acc: 0.990  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 833]:	loss = 0.294  exp loss = 0.301  adjusted loss = 0.301  adv prob = 0.250000   acc = 0.977
  waterbird_complete95 = 0, forest2water2 = 1  [n = 665]:	loss = 0.259  exp loss = 0.259  adjusted loss = 0.259  adv prob = 0.250000   acc = 0.998
  waterbird_complete95 = 1, forest2water2 = 0  [n = 498]:	loss = 0.257  exp loss = 0.255  adjusted loss = 0.255  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1204]:	loss = 0.270  exp loss = 0.269  adjusted loss = 0.269  adv prob = 0.250000   acc = 0.989
Saved results/CUB/CUB_sample_exp/train_downstream_ERM_upweight_0_epochs_80_lr_1e-05_weight_decay_0.0/final_epoch31/JTT_upweight_50_epochs_80_lr_1e-05_weight_decay_1.0/model_outputs/output_train_epoch_64.csv
logged to wandb
Average incurred loss: 0.272  
Average sample loss: 0.274  
Average acc: 0.990  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 452]:	loss = 0.300  exp loss = 0.275  adjusted loss = 0.275  adv prob = 0.250000   acc = 0.978
  waterbird_complete95 = 0, forest2water2 = 1  [n = 396]:	loss = 0.271  exp loss = 0.254  adjusted loss = 0.254  adv prob = 0.250000   acc = 0.997
  waterbird_complete95 = 1, forest2water2 = 0  [n = 263]:	loss = 0.251  exp loss = 0.260  adjusted loss = 0.260  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 634]:	loss = 0.263  exp loss = 0.280  adjusted loss = 0.280  adv prob = 0.250000   acc = 0.991

Validation:
Saved results/CUB/CUB_sample_exp/train_downstream_ERM_upweight_0_epochs_80_lr_1e-05_weight_decay_0.0/final_epoch31/JTT_upweight_50_epochs_80_lr_1e-05_weight_decay_1.0/model_outputs/output_val_epoch_64.csv
logged to wandb
Average incurred loss: 0.381  
Average sample loss: 0.380  
Average acc: 0.904  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.303  exp loss = 0.319  adjusted loss = 0.319  adv prob = 0.250000   acc = 0.976
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.414  exp loss = 0.430  adjusted loss = 0.430  adv prob = 0.250000   acc = 0.873
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 0.543  exp loss = 0.519  adjusted loss = 0.519  adv prob = 0.250000   acc = 0.759
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.375  exp loss = 0.375  adjusted loss = 0.375  adv prob = 0.250000   acc = 0.902
Spurious Score = 1.151
Saved results/CUB/CUB_sample_exp/train_downstream_ERM_upweight_0_epochs_80_lr_1e-05_weight_decay_0.0/final_epoch31/JTT_upweight_50_epochs_80_lr_1e-05_weight_decay_1.0/model_outputs/output_test_epoch_64.csv
logged to wandb
Current lr: 0.000010


Epoch [65]:
Training:
Average incurred loss: 0.274  
Average sample loss: 0.274  
Average acc: 0.994  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 827]:	loss = 0.295  exp loss = 0.287  adjusted loss = 0.287  adv prob = 0.250000   acc = 0.983
  waterbird_complete95 = 0, forest2water2 = 1  [n = 658]:	loss = 0.259  exp loss = 0.252  adjusted loss = 0.252  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 0  [n = 521]:	loss = 0.262  exp loss = 0.262  adjusted loss = 0.262  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1194]:	loss = 0.273  exp loss = 0.275  adjusted loss = 0.275  adv prob = 0.250000   acc = 0.996
Average incurred loss: 0.280  
Average sample loss: 0.280  
Average acc: 0.992  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 825]:	loss = 0.292  exp loss = 0.275  adjusted loss = 0.275  adv prob = 0.250000   acc = 0.985
  waterbird_complete95 = 0, forest2water2 = 1  [n = 620]:	loss = 0.257  exp loss = 0.242  adjusted loss = 0.242  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 0  [n = 513]:	loss = 0.273  exp loss = 0.284  adjusted loss = 0.284  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1242]:	loss = 0.285  exp loss = 0.294  adjusted loss = 0.294  adv prob = 0.250000   acc = 0.990
Average incurred loss: 0.281  
Average sample loss: 0.281  
Average acc: 0.991  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 871]:	loss = 0.300  exp loss = 0.295  adjusted loss = 0.295  adv prob = 0.250000   acc = 0.984
  waterbird_complete95 = 0, forest2water2 = 1  [n = 630]:	loss = 0.272  exp loss = 0.269  adjusted loss = 0.269  adv prob = 0.250000   acc = 0.998
  waterbird_complete95 = 1, forest2water2 = 0  [n = 496]:	loss = 0.267  exp loss = 0.256  adjusted loss = 0.256  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1203]:	loss = 0.278  exp loss = 0.274  adjusted loss = 0.274  adv prob = 0.250000   acc = 0.988
Average incurred loss: 0.284  
Average sample loss: 0.284  
Average acc: 0.992  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 833]:	loss = 0.295  exp loss = 0.288  adjusted loss = 0.288  adv prob = 0.250000   acc = 0.990
  waterbird_complete95 = 0, forest2water2 = 1  [n = 643]:	loss = 0.272  exp loss = 0.263  adjusted loss = 0.263  adv prob = 0.250000   acc = 0.997
  waterbird_complete95 = 1, forest2water2 = 0  [n = 496]:	loss = 0.270  exp loss = 0.269  adjusted loss = 0.269  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1228]:	loss = 0.288  exp loss = 0.287  adjusted loss = 0.287  adv prob = 0.250000   acc = 0.986
Saved results/CUB/CUB_sample_exp/train_downstream_ERM_upweight_0_epochs_80_lr_1e-05_weight_decay_0.0/final_epoch31/JTT_upweight_50_epochs_80_lr_1e-05_weight_decay_1.0/model_outputs/output_train_epoch_65.csv
logged to wandb
Average incurred loss: 0.282  
Average sample loss: 0.283  
Average acc: 0.994  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 442]:	loss = 0.306  exp loss = 0.310  adjusted loss = 0.310  adv prob = 0.250000   acc = 0.986
  waterbird_complete95 = 0, forest2water2 = 1  [n = 383]:	loss = 0.274  exp loss = 0.279  adjusted loss = 0.279  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 0  [n = 280]:	loss = 0.270  exp loss = 0.256  adjusted loss = 0.256  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 640]:	loss = 0.277  exp loss = 0.265  adjusted loss = 0.265  adv prob = 0.250000   acc = 0.994

Validation:
Saved results/CUB/CUB_sample_exp/train_downstream_ERM_upweight_0_epochs_80_lr_1e-05_weight_decay_0.0/final_epoch31/JTT_upweight_50_epochs_80_lr_1e-05_weight_decay_1.0/model_outputs/output_val_epoch_65.csv
logged to wandb
Average incurred loss: 0.398  
Average sample loss: 0.397  
Average acc: 0.900  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.329  exp loss = 0.345  adjusted loss = 0.345  adv prob = 0.250000   acc = 0.970
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.438  exp loss = 0.455  adjusted loss = 0.455  adv prob = 0.250000   acc = 0.863
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 0.523  exp loss = 0.499  adjusted loss = 0.499  adv prob = 0.250000   acc = 0.782
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.372  exp loss = 0.371  adjusted loss = 0.371  adv prob = 0.250000   acc = 0.902
Spurious Score = 1.138
Saved results/CUB/CUB_sample_exp/train_downstream_ERM_upweight_0_epochs_80_lr_1e-05_weight_decay_0.0/final_epoch31/JTT_upweight_50_epochs_80_lr_1e-05_weight_decay_1.0/model_outputs/output_test_epoch_65.csv
logged to wandb
Current lr: 0.000010


Epoch [66]:
Training:
Average incurred loss: 0.285  
Average sample loss: 0.285  
Average acc: 0.993  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 871]:	loss = 0.305  exp loss = 0.308  adjusted loss = 0.308  adv prob = 0.250000   acc = 0.989
  waterbird_complete95 = 0, forest2water2 = 1  [n = 652]:	loss = 0.280  exp loss = 0.283  adjusted loss = 0.283  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 0  [n = 488]:	loss = 0.269  exp loss = 0.267  adjusted loss = 0.267  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1189]:	loss = 0.280  exp loss = 0.266  adjusted loss = 0.266  adv prob = 0.250000   acc = 0.988
Average incurred loss: 0.286  
Average sample loss: 0.286  
Average acc: 0.994  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 790]:	loss = 0.301  exp loss = 0.302  adjusted loss = 0.302  adv prob = 0.250000   acc = 0.987
  waterbird_complete95 = 0, forest2water2 = 1  [n = 661]:	loss = 0.265  exp loss = 0.262  adjusted loss = 0.262  adv prob = 0.250000   acc = 0.998
  waterbird_complete95 = 1, forest2water2 = 0  [n = 502]:	loss = 0.281  exp loss = 0.283  adjusted loss = 0.283  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1247]:	loss = 0.290  exp loss = 0.291  adjusted loss = 0.291  adv prob = 0.250000   acc = 0.994
Average incurred loss: 0.291  
Average sample loss: 0.291  
Average acc: 0.992  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 877]:	loss = 0.313  exp loss = 0.319  adjusted loss = 0.319  adv prob = 0.250000   acc = 0.981
  waterbird_complete95 = 0, forest2water2 = 1  [n = 623]:	loss = 0.279  exp loss = 0.285  adjusted loss = 0.285  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 0  [n = 504]:	loss = 0.275  exp loss = 0.263  adjusted loss = 0.263  adv prob = 0.250000   acc = 0.998
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1196]:	loss = 0.288  exp loss = 0.277  adjusted loss = 0.277  adv prob = 0.250000   acc = 0.994
Average incurred loss: 0.295  
Average sample loss: 0.295  
Average acc: 0.989  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 823]:	loss = 0.308  exp loss = 0.294  adjusted loss = 0.294  adv prob = 0.250000   acc = 0.979
  waterbird_complete95 = 0, forest2water2 = 1  [n = 631]:	loss = 0.276  exp loss = 0.272  adjusted loss = 0.272  adv prob = 0.250000   acc = 0.998
  waterbird_complete95 = 1, forest2water2 = 0  [n = 544]:	loss = 0.284  exp loss = 0.283  adjusted loss = 0.283  adv prob = 0.250000   acc = 0.998
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1202]:	loss = 0.300  exp loss = 0.299  adjusted loss = 0.299  adv prob = 0.250000   acc = 0.987
Saved results/CUB/CUB_sample_exp/train_downstream_ERM_upweight_0_epochs_80_lr_1e-05_weight_decay_0.0/final_epoch31/JTT_upweight_50_epochs_80_lr_1e-05_weight_decay_1.0/model_outputs/output_train_epoch_66.csv
logged to wandb
Average incurred loss: 0.295  
Average sample loss: 0.296  
Average acc: 0.991  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 437]:	loss = 0.309  exp loss = 0.308  adjusted loss = 0.308  adv prob = 0.250000   acc = 0.984
  waterbird_complete95 = 0, forest2water2 = 1  [n = 367]:	loss = 0.282  exp loss = 0.269  adjusted loss = 0.269  adv prob = 0.250000   acc = 0.997
  waterbird_complete95 = 1, forest2water2 = 0  [n = 268]:	loss = 0.282  exp loss = 0.286  adjusted loss = 0.286  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 673]:	loss = 0.298  exp loss = 0.304  adjusted loss = 0.304  adv prob = 0.250000   acc = 0.988

Validation:
Saved results/CUB/CUB_sample_exp/train_downstream_ERM_upweight_0_epochs_80_lr_1e-05_weight_decay_0.0/final_epoch31/JTT_upweight_50_epochs_80_lr_1e-05_weight_decay_1.0/model_outputs/output_val_epoch_66.csv
logged to wandb
Average incurred loss: 0.391  
Average sample loss: 0.390  
Average acc: 0.899  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.314  exp loss = 0.330  adjusted loss = 0.330  adv prob = 0.250000   acc = 0.976
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.417  exp loss = 0.432  adjusted loss = 0.432  adv prob = 0.250000   acc = 0.878
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 0.561  exp loss = 0.535  adjusted loss = 0.535  adv prob = 0.250000   acc = 0.714
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.400  exp loss = 0.398  adjusted loss = 0.398  adv prob = 0.250000   acc = 0.887
Spurious Score = 1.171
Saved results/CUB/CUB_sample_exp/train_downstream_ERM_upweight_0_epochs_80_lr_1e-05_weight_decay_0.0/final_epoch31/JTT_upweight_50_epochs_80_lr_1e-05_weight_decay_1.0/model_outputs/output_test_epoch_66.csv
logged to wandb
Current lr: 0.000010


Epoch [67]:
Training:
Average incurred loss: 0.299  
Average sample loss: 0.299  
Average acc: 0.988  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 818]:	loss = 0.309  exp loss = 0.301  adjusted loss = 0.301  adv prob = 0.250000   acc = 0.983
  waterbird_complete95 = 0, forest2water2 = 1  [n = 626]:	loss = 0.281  exp loss = 0.274  adjusted loss = 0.274  adv prob = 0.250000   acc = 0.995
  waterbird_complete95 = 1, forest2water2 = 0  [n = 526]:	loss = 0.290  exp loss = 0.287  adjusted loss = 0.287  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1230]:	loss = 0.305  exp loss = 0.300  adjusted loss = 0.300  adv prob = 0.250000   acc = 0.984
Average incurred loss: 0.299  
Average sample loss: 0.299  
Average acc: 0.989  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 840]:	loss = 0.315  exp loss = 0.308  adjusted loss = 0.308  adv prob = 0.250000   acc = 0.977
  waterbird_complete95 = 0, forest2water2 = 1  [n = 632]:	loss = 0.282  exp loss = 0.273  adjusted loss = 0.273  adv prob = 0.250000   acc = 0.998
  waterbird_complete95 = 1, forest2water2 = 0  [n = 482]:	loss = 0.286  exp loss = 0.292  adjusted loss = 0.292  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1246]:	loss = 0.300  exp loss = 0.306  adjusted loss = 0.306  adv prob = 0.250000   acc = 0.989
Average incurred loss: 0.299  
Average sample loss: 0.299  
Average acc: 0.994  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 814]:	loss = 0.317  exp loss = 0.312  adjusted loss = 0.312  adv prob = 0.250000   acc = 0.989
  waterbird_complete95 = 0, forest2water2 = 1  [n = 670]:	loss = 0.288  exp loss = 0.282  adjusted loss = 0.282  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 0  [n = 513]:	loss = 0.289  exp loss = 0.284  adjusted loss = 0.284  adv prob = 0.250000   acc = 0.996
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1203]:	loss = 0.297  exp loss = 0.294  adjusted loss = 0.294  adv prob = 0.250000   acc = 0.993
Average incurred loss: 0.303  
Average sample loss: 0.303  
Average acc: 0.989  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 853]:	loss = 0.325  exp loss = 0.312  adjusted loss = 0.312  adv prob = 0.250000   acc = 0.980
  waterbird_complete95 = 0, forest2water2 = 1  [n = 649]:	loss = 0.292  exp loss = 0.282  adjusted loss = 0.282  adv prob = 0.250000   acc = 0.998
  waterbird_complete95 = 1, forest2water2 = 0  [n = 515]:	loss = 0.287  exp loss = 0.292  adjusted loss = 0.292  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1183]:	loss = 0.299  exp loss = 0.299  adjusted loss = 0.299  adv prob = 0.250000   acc = 0.986
Saved results/CUB/CUB_sample_exp/train_downstream_ERM_upweight_0_epochs_80_lr_1e-05_weight_decay_0.0/final_epoch31/JTT_upweight_50_epochs_80_lr_1e-05_weight_decay_1.0/model_outputs/output_train_epoch_67.csv
logged to wandb
Average incurred loss: 0.304  
Average sample loss: 0.304  
Average acc: 0.990  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 473]:	loss = 0.324  exp loss = 0.335  adjusted loss = 0.335  adv prob = 0.250000   acc = 0.987
  waterbird_complete95 = 0, forest2water2 = 1  [n = 357]:	loss = 0.301  exp loss = 0.297  adjusted loss = 0.297  adv prob = 0.250000   acc = 0.997
  waterbird_complete95 = 1, forest2water2 = 0  [n = 270]:	loss = 0.281  exp loss = 0.278  adjusted loss = 0.278  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 645]:	loss = 0.300  exp loss = 0.292  adjusted loss = 0.292  adv prob = 0.250000   acc = 0.984

Validation:
Saved results/CUB/CUB_sample_exp/train_downstream_ERM_upweight_0_epochs_80_lr_1e-05_weight_decay_0.0/final_epoch31/JTT_upweight_50_epochs_80_lr_1e-05_weight_decay_1.0/model_outputs/output_val_epoch_67.csv
logged to wandb
Average incurred loss: 0.411  
Average sample loss: 0.411  
Average acc: 0.898  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.346  exp loss = 0.362  adjusted loss = 0.362  adv prob = 0.250000   acc = 0.972
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.447  exp loss = 0.460  adjusted loss = 0.460  adv prob = 0.250000   acc = 0.869
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 0.537  exp loss = 0.512  adjusted loss = 0.512  adv prob = 0.250000   acc = 0.744
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.390  exp loss = 0.387  adjusted loss = 0.387  adv prob = 0.250000   acc = 0.895
Spurious Score = 1.157
Saved results/CUB/CUB_sample_exp/train_downstream_ERM_upweight_0_epochs_80_lr_1e-05_weight_decay_0.0/final_epoch31/JTT_upweight_50_epochs_80_lr_1e-05_weight_decay_1.0/model_outputs/output_test_epoch_67.csv
logged to wandb
Current lr: 0.000010


Epoch [68]:
Training:
Average incurred loss: 0.306  
Average sample loss: 0.306  
Average acc: 0.990  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 823]:	loss = 0.325  exp loss = 0.316  adjusted loss = 0.316  adv prob = 0.250000   acc = 0.985
  waterbird_complete95 = 0, forest2water2 = 1  [n = 656]:	loss = 0.293  exp loss = 0.288  adjusted loss = 0.288  adv prob = 0.250000   acc = 0.995
  waterbird_complete95 = 1, forest2water2 = 0  [n = 503]:	loss = 0.291  exp loss = 0.291  adjusted loss = 0.291  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1218]:	loss = 0.307  exp loss = 0.309  adjusted loss = 0.309  adv prob = 0.250000   acc = 0.986
Average incurred loss: 0.308  
Average sample loss: 0.308  
Average acc: 0.994  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 826]:	loss = 0.320  exp loss = 0.308  adjusted loss = 0.308  adv prob = 0.250000   acc = 0.992
  waterbird_complete95 = 0, forest2water2 = 1  [n = 635]:	loss = 0.296  exp loss = 0.284  adjusted loss = 0.284  adv prob = 0.250000   acc = 0.998
  waterbird_complete95 = 1, forest2water2 = 0  [n = 544]:	loss = 0.299  exp loss = 0.302  adjusted loss = 0.302  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1195]:	loss = 0.310  exp loss = 0.316  adjusted loss = 0.316  adv prob = 0.250000   acc = 0.990
Average incurred loss: 0.311  
Average sample loss: 0.311  
Average acc: 0.987  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 844]:	loss = 0.330  exp loss = 0.316  adjusted loss = 0.316  adv prob = 0.250000   acc = 0.977
  waterbird_complete95 = 0, forest2water2 = 1  [n = 645]:	loss = 0.300  exp loss = 0.290  adjusted loss = 0.290  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 0  [n = 522]:	loss = 0.301  exp loss = 0.302  adjusted loss = 0.302  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1189]:	loss = 0.309  exp loss = 0.308  adjusted loss = 0.308  adv prob = 0.250000   acc = 0.981
Average incurred loss: 0.312  
Average sample loss: 0.312  
Average acc: 0.990  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 832]:	loss = 0.327  exp loss = 0.331  adjusted loss = 0.331  adv prob = 0.250000   acc = 0.989
  waterbird_complete95 = 0, forest2water2 = 1  [n = 646]:	loss = 0.303  exp loss = 0.291  adjusted loss = 0.291  adv prob = 0.250000   acc = 0.997
  waterbird_complete95 = 1, forest2water2 = 0  [n = 456]:	loss = 0.296  exp loss = 0.292  adjusted loss = 0.292  adv prob = 0.250000   acc = 0.998
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1266]:	loss = 0.312  exp loss = 0.317  adjusted loss = 0.317  adv prob = 0.250000   acc = 0.983
Saved results/CUB/CUB_sample_exp/train_downstream_ERM_upweight_0_epochs_80_lr_1e-05_weight_decay_0.0/final_epoch31/JTT_upweight_50_epochs_80_lr_1e-05_weight_decay_1.0/model_outputs/output_train_epoch_68.csv
logged to wandb
Average incurred loss: 0.317  
Average sample loss: 0.317  
Average acc: 0.986  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 473]:	loss = 0.343  exp loss = 0.327  adjusted loss = 0.327  adv prob = 0.250000   acc = 0.973
  waterbird_complete95 = 0, forest2water2 = 1  [n = 352]:	loss = 0.305  exp loss = 0.294  adjusted loss = 0.294  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 0  [n = 281]:	loss = 0.303  exp loss = 0.308  adjusted loss = 0.308  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 639]:	loss = 0.310  exp loss = 0.306  adjusted loss = 0.306  adv prob = 0.250000   acc = 0.983

Validation:
Saved results/CUB/CUB_sample_exp/train_downstream_ERM_upweight_0_epochs_80_lr_1e-05_weight_decay_0.0/final_epoch31/JTT_upweight_50_epochs_80_lr_1e-05_weight_decay_1.0/model_outputs/output_val_epoch_68.csv
logged to wandb
Average incurred loss: 0.410  
Average sample loss: 0.410  
Average acc: 0.895  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.342  exp loss = 0.358  adjusted loss = 0.358  adv prob = 0.250000   acc = 0.970
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.438  exp loss = 0.450  adjusted loss = 0.450  adv prob = 0.250000   acc = 0.871
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 0.557  exp loss = 0.532  adjusted loss = 0.532  adv prob = 0.250000   acc = 0.714
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.407  exp loss = 0.402  adjusted loss = 0.402  adv prob = 0.250000   acc = 0.895
Spurious Score = 1.176
Saved results/CUB/CUB_sample_exp/train_downstream_ERM_upweight_0_epochs_80_lr_1e-05_weight_decay_0.0/final_epoch31/JTT_upweight_50_epochs_80_lr_1e-05_weight_decay_1.0/model_outputs/output_test_epoch_68.csv
logged to wandb
Current lr: 0.000010


Epoch [69]:
Training:
Average incurred loss: 0.314  
Average sample loss: 0.314  
Average acc: 0.988  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 827]:	loss = 0.333  exp loss = 0.340  adjusted loss = 0.340  adv prob = 0.250000   acc = 0.979
  waterbird_complete95 = 0, forest2water2 = 1  [n = 650]:	loss = 0.302  exp loss = 0.300  adjusted loss = 0.300  adv prob = 0.250000   acc = 0.998
  waterbird_complete95 = 1, forest2water2 = 0  [n = 516]:	loss = 0.301  exp loss = 0.293  adjusted loss = 0.293  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1207]:	loss = 0.314  exp loss = 0.308  adjusted loss = 0.308  adv prob = 0.250000   acc = 0.983
Average incurred loss: 0.316  
Average sample loss: 0.316  
Average acc: 0.988  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 839]:	loss = 0.339  exp loss = 0.337  adjusted loss = 0.337  adv prob = 0.250000   acc = 0.976
  waterbird_complete95 = 0, forest2water2 = 1  [n = 650]:	loss = 0.303  exp loss = 0.296  adjusted loss = 0.296  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 0  [n = 505]:	loss = 0.303  exp loss = 0.299  adjusted loss = 0.299  adv prob = 0.250000   acc = 0.998
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1206]:	loss = 0.313  exp loss = 0.316  adjusted loss = 0.316  adv prob = 0.250000   acc = 0.987
Average incurred loss: 0.317  
Average sample loss: 0.317  
Average acc: 0.993  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 845]:	loss = 0.336  exp loss = 0.336  adjusted loss = 0.336  adv prob = 0.250000   acc = 0.988
  waterbird_complete95 = 0, forest2water2 = 1  [n = 642]:	loss = 0.308  exp loss = 0.308  adjusted loss = 0.308  adv prob = 0.250000   acc = 0.997
  waterbird_complete95 = 1, forest2water2 = 0  [n = 488]:	loss = 0.301  exp loss = 0.289  adjusted loss = 0.289  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1225]:	loss = 0.315  exp loss = 0.313  adjusted loss = 0.313  adv prob = 0.250000   acc = 0.991
Average incurred loss: 0.320  
Average sample loss: 0.320  
Average acc: 0.989  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 849]:	loss = 0.344  exp loss = 0.333  adjusted loss = 0.333  adv prob = 0.250000   acc = 0.979
  waterbird_complete95 = 0, forest2water2 = 1  [n = 660]:	loss = 0.313  exp loss = 0.303  adjusted loss = 0.303  adv prob = 0.250000   acc = 0.998
  waterbird_complete95 = 1, forest2water2 = 0  [n = 517]:	loss = 0.306  exp loss = 0.308  adjusted loss = 0.308  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1174]:	loss = 0.312  exp loss = 0.320  adjusted loss = 0.320  adv prob = 0.250000   acc = 0.987
Saved results/CUB/CUB_sample_exp/train_downstream_ERM_upweight_0_epochs_80_lr_1e-05_weight_decay_0.0/final_epoch31/JTT_upweight_50_epochs_80_lr_1e-05_weight_decay_1.0/model_outputs/output_train_epoch_69.csv
logged to wandb
Average incurred loss: 0.321  
Average sample loss: 0.322  
Average acc: 0.991  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 438]:	loss = 0.326  exp loss = 0.333  adjusted loss = 0.333  adv prob = 0.250000   acc = 0.986
  waterbird_complete95 = 0, forest2water2 = 1  [n = 332]:	loss = 0.302  exp loss = 0.310  adjusted loss = 0.310  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 0  [n = 280]:	loss = 0.317  exp loss = 0.305  adjusted loss = 0.305  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 695]:	loss = 0.328  exp loss = 0.309  adjusted loss = 0.309  adv prob = 0.250000   acc = 0.986

Validation:
Saved results/CUB/CUB_sample_exp/train_downstream_ERM_upweight_0_epochs_80_lr_1e-05_weight_decay_0.0/final_epoch31/JTT_upweight_50_epochs_80_lr_1e-05_weight_decay_1.0/model_outputs/output_val_epoch_69.csv
logged to wandb
Average incurred loss: 0.420  
Average sample loss: 0.419  
Average acc: 0.898  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.357  exp loss = 0.372  adjusted loss = 0.372  adv prob = 0.250000   acc = 0.970
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.446  exp loss = 0.458  adjusted loss = 0.458  adv prob = 0.250000   acc = 0.884
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 0.559  exp loss = 0.538  adjusted loss = 0.538  adv prob = 0.250000   acc = 0.707
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.410  exp loss = 0.405  adjusted loss = 0.405  adv prob = 0.250000   acc = 0.887
Spurious Score = 1.167
Saved results/CUB/CUB_sample_exp/train_downstream_ERM_upweight_0_epochs_80_lr_1e-05_weight_decay_0.0/final_epoch31/JTT_upweight_50_epochs_80_lr_1e-05_weight_decay_1.0/model_outputs/output_test_epoch_69.csv
logged to wandb
Current lr: 0.000010


Epoch [70]:
Training:
Average incurred loss: 0.323  
Average sample loss: 0.323  
Average acc: 0.985  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 861]:	loss = 0.341  exp loss = 0.348  adjusted loss = 0.348  adv prob = 0.250000   acc = 0.974
  waterbird_complete95 = 0, forest2water2 = 1  [n = 610]:	loss = 0.313  exp loss = 0.314  adjusted loss = 0.314  adv prob = 0.250000   acc = 0.995
  waterbird_complete95 = 1, forest2water2 = 0  [n = 489]:	loss = 0.310  exp loss = 0.305  adjusted loss = 0.305  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1240]:	loss = 0.321  exp loss = 0.310  adjusted loss = 0.310  adv prob = 0.250000   acc = 0.982
Average incurred loss: 0.325  
Average sample loss: 0.325  
Average acc: 0.990  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 818]:	loss = 0.356  exp loss = 0.353  adjusted loss = 0.353  adv prob = 0.250000   acc = 0.980
  waterbird_complete95 = 0, forest2water2 = 1  [n = 698]:	loss = 0.315  exp loss = 0.322  adjusted loss = 0.322  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 0  [n = 476]:	loss = 0.312  exp loss = 0.301  adjusted loss = 0.301  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1208]:	loss = 0.314  exp loss = 0.306  adjusted loss = 0.306  adv prob = 0.250000   acc = 0.986
Average incurred loss: 0.326  
Average sample loss: 0.326  
Average acc: 0.991  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 807]:	loss = 0.344  exp loss = 0.341  adjusted loss = 0.341  adv prob = 0.250000   acc = 0.979
  waterbird_complete95 = 0, forest2water2 = 1  [n = 655]:	loss = 0.315  exp loss = 0.312  adjusted loss = 0.312  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 0  [n = 543]:	loss = 0.316  exp loss = 0.319  adjusted loss = 0.319  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1195]:	loss = 0.325  exp loss = 0.324  adjusted loss = 0.324  adv prob = 0.250000   acc = 0.991
Average incurred loss: 0.331  
Average sample loss: 0.331  
Average acc: 0.986  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 864]:	loss = 0.352  exp loss = 0.362  adjusted loss = 0.362  adv prob = 0.250000   acc = 0.981
  waterbird_complete95 = 0, forest2water2 = 1  [n = 623]:	loss = 0.323  exp loss = 0.327  adjusted loss = 0.327  adv prob = 0.250000   acc = 0.995
  waterbird_complete95 = 1, forest2water2 = 0  [n = 517]:	loss = 0.315  exp loss = 0.301  adjusted loss = 0.301  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1196]:	loss = 0.327  exp loss = 0.308  adjusted loss = 0.308  adv prob = 0.250000   acc = 0.978
Saved results/CUB/CUB_sample_exp/train_downstream_ERM_upweight_0_epochs_80_lr_1e-05_weight_decay_0.0/final_epoch31/JTT_upweight_50_epochs_80_lr_1e-05_weight_decay_1.0/model_outputs/output_train_epoch_70.csv
logged to wandb
Average incurred loss: 0.331  
Average sample loss: 0.333  
Average acc: 0.985  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 448]:	loss = 0.347  exp loss = 0.366  adjusted loss = 0.366  adv prob = 0.250000   acc = 0.978
  waterbird_complete95 = 0, forest2water2 = 1  [n = 348]:	loss = 0.317  exp loss = 0.310  adjusted loss = 0.310  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 0  [n = 281]:	loss = 0.320  exp loss = 0.311  adjusted loss = 0.311  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 668]:	loss = 0.332  exp loss = 0.344  adjusted loss = 0.344  adv prob = 0.250000   acc = 0.975

Validation:
Saved results/CUB/CUB_sample_exp/train_downstream_ERM_upweight_0_epochs_80_lr_1e-05_weight_decay_0.0/final_epoch31/JTT_upweight_50_epochs_80_lr_1e-05_weight_decay_1.0/model_outputs/output_val_epoch_70.csv
logged to wandb
Average incurred loss: 0.423  
Average sample loss: 0.422  
Average acc: 0.894  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.360  exp loss = 0.373  adjusted loss = 0.373  adv prob = 0.250000   acc = 0.968
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.442  exp loss = 0.455  adjusted loss = 0.455  adv prob = 0.250000   acc = 0.880
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 0.573  exp loss = 0.553  adjusted loss = 0.553  adv prob = 0.250000   acc = 0.699
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.425  exp loss = 0.417  adjusted loss = 0.417  adv prob = 0.250000   acc = 0.880
Spurious Score = 1.170
Saved results/CUB/CUB_sample_exp/train_downstream_ERM_upweight_0_epochs_80_lr_1e-05_weight_decay_0.0/final_epoch31/JTT_upweight_50_epochs_80_lr_1e-05_weight_decay_1.0/model_outputs/output_test_epoch_70.csv
logged to wandb
Current lr: 0.000010


Epoch [71]:
Training:
Average incurred loss: 0.331  
Average sample loss: 0.331  
Average acc: 0.987  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 857]:	loss = 0.359  exp loss = 0.353  adjusted loss = 0.353  adv prob = 0.250000   acc = 0.978
  waterbird_complete95 = 0, forest2water2 = 1  [n = 668]:	loss = 0.326  exp loss = 0.323  adjusted loss = 0.323  adv prob = 0.250000   acc = 0.997
  waterbird_complete95 = 1, forest2water2 = 0  [n = 493]:	loss = 0.311  exp loss = 0.307  adjusted loss = 0.307  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1182]:	loss = 0.322  exp loss = 0.318  adjusted loss = 0.318  adv prob = 0.250000   acc = 0.983
Average incurred loss: 0.335  
Average sample loss: 0.335  
Average acc: 0.988  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 845]:	loss = 0.358  exp loss = 0.354  adjusted loss = 0.354  adv prob = 0.250000   acc = 0.976
  waterbird_complete95 = 0, forest2water2 = 1  [n = 635]:	loss = 0.323  exp loss = 0.318  adjusted loss = 0.318  adv prob = 0.250000   acc = 0.998
  waterbird_complete95 = 1, forest2water2 = 0  [n = 536]:	loss = 0.325  exp loss = 0.320  adjusted loss = 0.320  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1184]:	loss = 0.329  exp loss = 0.326  adjusted loss = 0.326  adv prob = 0.250000   acc = 0.985
Average incurred loss: 0.335  
Average sample loss: 0.335  
Average acc: 0.988  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 834]:	loss = 0.354  exp loss = 0.346  adjusted loss = 0.346  adv prob = 0.250000   acc = 0.981
  waterbird_complete95 = 0, forest2water2 = 1  [n = 639]:	loss = 0.328  exp loss = 0.325  adjusted loss = 0.325  adv prob = 0.250000   acc = 0.997
  waterbird_complete95 = 1, forest2water2 = 0  [n = 513]:	loss = 0.320  exp loss = 0.316  adjusted loss = 0.316  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1214]:	loss = 0.333  exp loss = 0.335  adjusted loss = 0.335  adv prob = 0.250000   acc = 0.984
Average incurred loss: 0.340  
Average sample loss: 0.340  
Average acc: 0.986  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 778]:	loss = 0.356  exp loss = 0.350  adjusted loss = 0.350  adv prob = 0.250000   acc = 0.978
  waterbird_complete95 = 0, forest2water2 = 1  [n = 629]:	loss = 0.314  exp loss = 0.311  adjusted loss = 0.311  adv prob = 0.250000   acc = 0.998
  waterbird_complete95 = 1, forest2water2 = 0  [n = 499]:	loss = 0.337  exp loss = 0.341  adjusted loss = 0.341  adv prob = 0.250000   acc = 0.998
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1294]:	loss = 0.344  exp loss = 0.348  adjusted loss = 0.348  adv prob = 0.250000   acc = 0.981
Saved results/CUB/CUB_sample_exp/train_downstream_ERM_upweight_0_epochs_80_lr_1e-05_weight_decay_0.0/final_epoch31/JTT_upweight_50_epochs_80_lr_1e-05_weight_decay_1.0/model_outputs/output_train_epoch_71.csv
logged to wandb
Average incurred loss: 0.339  
Average sample loss: 0.340  
Average acc: 0.989  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 484]:	loss = 0.379  exp loss = 0.370  adjusted loss = 0.370  adv prob = 0.250000   acc = 0.975
  waterbird_complete95 = 0, forest2water2 = 1  [n = 363]:	loss = 0.334  exp loss = 0.335  adjusted loss = 0.335  adv prob = 0.250000   acc = 0.997
  waterbird_complete95 = 1, forest2water2 = 0  [n = 265]:	loss = 0.318  exp loss = 0.322  adjusted loss = 0.322  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 633]:	loss = 0.321  exp loss = 0.323  adjusted loss = 0.323  adv prob = 0.250000   acc = 0.989

Validation:
Saved results/CUB/CUB_sample_exp/train_downstream_ERM_upweight_0_epochs_80_lr_1e-05_weight_decay_0.0/final_epoch31/JTT_upweight_50_epochs_80_lr_1e-05_weight_decay_1.0/model_outputs/output_val_epoch_71.csv
logged to wandb
Average incurred loss: 0.433  
Average sample loss: 0.433  
Average acc: 0.889  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.374  exp loss = 0.387  adjusted loss = 0.387  adv prob = 0.250000   acc = 0.964
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.453  exp loss = 0.469  adjusted loss = 0.469  adv prob = 0.250000   acc = 0.873
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 0.571  exp loss = 0.557  adjusted loss = 0.557  adv prob = 0.250000   acc = 0.692
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.428  exp loss = 0.420  adjusted loss = 0.420  adv prob = 0.250000   acc = 0.880
Spurious Score = 1.178
Saved results/CUB/CUB_sample_exp/train_downstream_ERM_upweight_0_epochs_80_lr_1e-05_weight_decay_0.0/final_epoch31/JTT_upweight_50_epochs_80_lr_1e-05_weight_decay_1.0/model_outputs/output_test_epoch_71.csv
logged to wandb
Current lr: 0.000010


Epoch [72]:
Training:
Average incurred loss: 0.341  
Average sample loss: 0.341  
Average acc: 0.986  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 835]:	loss = 0.365  exp loss = 0.363  adjusted loss = 0.363  adv prob = 0.250000   acc = 0.980
  waterbird_complete95 = 0, forest2water2 = 1  [n = 650]:	loss = 0.331  exp loss = 0.343  adjusted loss = 0.343  adv prob = 0.250000   acc = 0.995
  waterbird_complete95 = 1, forest2water2 = 0  [n = 499]:	loss = 0.326  exp loss = 0.315  adjusted loss = 0.315  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1216]:	loss = 0.337  exp loss = 0.323  adjusted loss = 0.323  adv prob = 0.250000   acc = 0.979
Average incurred loss: 0.341  
Average sample loss: 0.341  
Average acc: 0.987  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 858]:	loss = 0.370  exp loss = 0.366  adjusted loss = 0.366  adv prob = 0.250000   acc = 0.971
  waterbird_complete95 = 0, forest2water2 = 1  [n = 647]:	loss = 0.331  exp loss = 0.322  adjusted loss = 0.322  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 0  [n = 515]:	loss = 0.326  exp loss = 0.326  adjusted loss = 0.326  adv prob = 0.250000   acc = 0.998
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1180]:	loss = 0.332  exp loss = 0.332  adjusted loss = 0.332  adv prob = 0.250000   acc = 0.986
Average incurred loss: 0.343  
Average sample loss: 0.343  
Average acc: 0.988  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 829]:	loss = 0.377  exp loss = 0.364  adjusted loss = 0.364  adv prob = 0.250000   acc = 0.978
  waterbird_complete95 = 0, forest2water2 = 1  [n = 692]:	loss = 0.336  exp loss = 0.334  adjusted loss = 0.334  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 0  [n = 509]:	loss = 0.324  exp loss = 0.329  adjusted loss = 0.329  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1170]:	loss = 0.330  exp loss = 0.330  adjusted loss = 0.330  adv prob = 0.250000   acc = 0.983
Average incurred loss: 0.347  
Average sample loss: 0.347  
Average acc: 0.985  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 857]:	loss = 0.370  exp loss = 0.349  adjusted loss = 0.349  adv prob = 0.250000   acc = 0.974
  waterbird_complete95 = 0, forest2water2 = 1  [n = 587]:	loss = 0.326  exp loss = 0.318  adjusted loss = 0.318  adv prob = 0.250000   acc = 0.997
  waterbird_complete95 = 1, forest2water2 = 0  [n = 509]:	loss = 0.342  exp loss = 0.343  adjusted loss = 0.343  adv prob = 0.250000   acc = 0.998
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1247]:	loss = 0.343  exp loss = 0.346  adjusted loss = 0.346  adv prob = 0.250000   acc = 0.982
Saved results/CUB/CUB_sample_exp/train_downstream_ERM_upweight_0_epochs_80_lr_1e-05_weight_decay_0.0/final_epoch31/JTT_upweight_50_epochs_80_lr_1e-05_weight_decay_1.0/model_outputs/output_train_epoch_72.csv
logged to wandb
Average incurred loss: 0.347  
Average sample loss: 0.347  
Average acc: 0.987  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 419]:	loss = 0.367  exp loss = 0.379  adjusted loss = 0.379  adv prob = 0.250000   acc = 0.974
  waterbird_complete95 = 0, forest2water2 = 1  [n = 358]:	loss = 0.327  exp loss = 0.319  adjusted loss = 0.319  adv prob = 0.250000   acc = 0.994
  waterbird_complete95 = 1, forest2water2 = 0  [n = 274]:	loss = 0.349  exp loss = 0.349  adjusted loss = 0.349  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 694]:	loss = 0.343  exp loss = 0.337  adjusted loss = 0.337  adv prob = 0.250000   acc = 0.986

Validation:
Saved results/CUB/CUB_sample_exp/train_downstream_ERM_upweight_0_epochs_80_lr_1e-05_weight_decay_0.0/final_epoch31/JTT_upweight_50_epochs_80_lr_1e-05_weight_decay_1.0/model_outputs/output_val_epoch_72.csv
logged to wandb
Average incurred loss: 0.437  
Average sample loss: 0.437  
Average acc: 0.886  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.382  exp loss = 0.394  adjusted loss = 0.394  adv prob = 0.250000   acc = 0.951
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.457  exp loss = 0.475  adjusted loss = 0.475  adv prob = 0.250000   acc = 0.878
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 0.570  exp loss = 0.556  adjusted loss = 0.556  adv prob = 0.250000   acc = 0.699
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.429  exp loss = 0.421  adjusted loss = 0.421  adv prob = 0.250000   acc = 0.872
Spurious Score = 1.156
Saved results/CUB/CUB_sample_exp/train_downstream_ERM_upweight_0_epochs_80_lr_1e-05_weight_decay_0.0/final_epoch31/JTT_upweight_50_epochs_80_lr_1e-05_weight_decay_1.0/model_outputs/output_test_epoch_72.csv
logged to wandb
Current lr: 0.000010


Epoch [73]:
Training:
Average incurred loss: 0.348  
Average sample loss: 0.348  
Average acc: 0.988  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 839]:	loss = 0.378  exp loss = 0.380  adjusted loss = 0.380  adv prob = 0.250000   acc = 0.976
  waterbird_complete95 = 0, forest2water2 = 1  [n = 638]:	loss = 0.334  exp loss = 0.333  adjusted loss = 0.333  adv prob = 0.250000   acc = 0.998
  waterbird_complete95 = 1, forest2water2 = 0  [n = 539]:	loss = 0.335  exp loss = 0.326  adjusted loss = 0.326  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1184]:	loss = 0.341  exp loss = 0.338  adjusted loss = 0.338  adv prob = 0.250000   acc = 0.984
Average incurred loss: 0.350  
Average sample loss: 0.350  
Average acc: 0.987  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 824]:	loss = 0.379  exp loss = 0.383  adjusted loss = 0.383  adv prob = 0.250000   acc = 0.975
  waterbird_complete95 = 0, forest2water2 = 1  [n = 649]:	loss = 0.335  exp loss = 0.337  adjusted loss = 0.337  adv prob = 0.250000   acc = 0.997
  waterbird_complete95 = 1, forest2water2 = 0  [n = 509]:	loss = 0.339  exp loss = 0.329  adjusted loss = 0.329  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1218]:	loss = 0.342  exp loss = 0.331  adjusted loss = 0.331  adv prob = 0.250000   acc = 0.986
Average incurred loss: 0.352  
Average sample loss: 0.352  
Average acc: 0.984  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 855]:	loss = 0.381  exp loss = 0.374  adjusted loss = 0.374  adv prob = 0.250000   acc = 0.975
  waterbird_complete95 = 0, forest2water2 = 1  [n = 648]:	loss = 0.343  exp loss = 0.326  adjusted loss = 0.326  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 0  [n = 471]:	loss = 0.340  exp loss = 0.353  adjusted loss = 0.353  adv prob = 0.250000   acc = 0.998
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1226]:	loss = 0.341  exp loss = 0.349  adjusted loss = 0.349  adv prob = 0.250000   acc = 0.976
Average incurred loss: 0.352  
Average sample loss: 0.352  
Average acc: 0.988  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 816]:	loss = 0.380  exp loss = 0.391  adjusted loss = 0.391  adv prob = 0.250000   acc = 0.983
  waterbird_complete95 = 0, forest2water2 = 1  [n = 660]:	loss = 0.340  exp loss = 0.338  adjusted loss = 0.338  adv prob = 0.250000   acc = 0.994
  waterbird_complete95 = 1, forest2water2 = 0  [n = 516]:	loss = 0.346  exp loss = 0.336  adjusted loss = 0.336  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1208]:	loss = 0.343  exp loss = 0.339  adjusted loss = 0.339  adv prob = 0.250000   acc = 0.984
Saved results/CUB/CUB_sample_exp/train_downstream_ERM_upweight_0_epochs_80_lr_1e-05_weight_decay_0.0/final_epoch31/JTT_upweight_50_epochs_80_lr_1e-05_weight_decay_1.0/model_outputs/output_train_epoch_73.csv
logged to wandb
Average incurred loss: 0.358  
Average sample loss: 0.358  
Average acc: 0.979  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 464]:	loss = 0.387  exp loss = 0.386  adjusted loss = 0.386  adv prob = 0.250000   acc = 0.966
  waterbird_complete95 = 0, forest2water2 = 1  [n = 339]:	loss = 0.344  exp loss = 0.334  adjusted loss = 0.334  adv prob = 0.250000   acc = 0.997
  waterbird_complete95 = 1, forest2water2 = 0  [n = 271]:	loss = 0.342  exp loss = 0.349  adjusted loss = 0.349  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 671]:	loss = 0.351  exp loss = 0.346  adjusted loss = 0.346  adv prob = 0.250000   acc = 0.970

Validation:
Saved results/CUB/CUB_sample_exp/train_downstream_ERM_upweight_0_epochs_80_lr_1e-05_weight_decay_0.0/final_epoch31/JTT_upweight_50_epochs_80_lr_1e-05_weight_decay_1.0/model_outputs/output_val_epoch_73.csv
logged to wandb
Average incurred loss: 0.446  
Average sample loss: 0.446  
Average acc: 0.879  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.389  exp loss = 0.396  adjusted loss = 0.396  adv prob = 0.250000   acc = 0.951
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.459  exp loss = 0.479  adjusted loss = 0.479  adv prob = 0.250000   acc = 0.871
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 0.592  exp loss = 0.582  adjusted loss = 0.582  adv prob = 0.250000   acc = 0.669
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.451  exp loss = 0.446  adjusted loss = 0.446  adv prob = 0.250000   acc = 0.865
Spurious Score = 1.179
Saved results/CUB/CUB_sample_exp/train_downstream_ERM_upweight_0_epochs_80_lr_1e-05_weight_decay_0.0/final_epoch31/JTT_upweight_50_epochs_80_lr_1e-05_weight_decay_1.0/model_outputs/output_test_epoch_73.csv
logged to wandb
Current lr: 0.000010


Epoch [74]:
Training:
Average incurred loss: 0.358  
Average sample loss: 0.358  
Average acc: 0.982  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 858]:	loss = 0.395  exp loss = 0.405  adjusted loss = 0.405  adv prob = 0.250000   acc = 0.963
  waterbird_complete95 = 0, forest2water2 = 1  [n = 646]:	loss = 0.348  exp loss = 0.350  adjusted loss = 0.350  adv prob = 0.250000   acc = 0.994
  waterbird_complete95 = 1, forest2water2 = 0  [n = 510]:	loss = 0.342  exp loss = 0.325  adjusted loss = 0.325  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1186]:	loss = 0.345  exp loss = 0.336  adjusted loss = 0.336  adv prob = 0.250000   acc = 0.982
Average incurred loss: 0.362  
Average sample loss: 0.362  
Average acc: 0.981  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 819]:	loss = 0.394  exp loss = 0.387  adjusted loss = 0.387  adv prob = 0.250000   acc = 0.961
  waterbird_complete95 = 0, forest2water2 = 1  [n = 642]:	loss = 0.344  exp loss = 0.341  adjusted loss = 0.341  adv prob = 0.250000   acc = 0.997
  waterbird_complete95 = 1, forest2water2 = 0  [n = 512]:	loss = 0.349  exp loss = 0.346  adjusted loss = 0.346  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1227]:	loss = 0.355  exp loss = 0.349  adjusted loss = 0.349  adv prob = 0.250000   acc = 0.977
Average incurred loss: 0.361  
Average sample loss: 0.361  
Average acc: 0.986  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 801]:	loss = 0.383  exp loss = 0.370  adjusted loss = 0.370  adv prob = 0.250000   acc = 0.976
  waterbird_complete95 = 0, forest2water2 = 1  [n = 628]:	loss = 0.342  exp loss = 0.341  adjusted loss = 0.341  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 0  [n = 517]:	loss = 0.356  exp loss = 0.361  adjusted loss = 0.361  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1254]:	loss = 0.358  exp loss = 0.362  adjusted loss = 0.362  adv prob = 0.250000   acc = 0.978
Average incurred loss: 0.361  
Average sample loss: 0.361  
Average acc: 0.986  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 852]:	loss = 0.390  exp loss = 0.392  adjusted loss = 0.392  adv prob = 0.250000   acc = 0.973
  waterbird_complete95 = 0, forest2water2 = 1  [n = 632]:	loss = 0.352  exp loss = 0.357  adjusted loss = 0.357  adv prob = 0.250000   acc = 0.998
  waterbird_complete95 = 1, forest2water2 = 0  [n = 501]:	loss = 0.349  exp loss = 0.339  adjusted loss = 0.339  adv prob = 0.250000   acc = 0.998
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1215]:	loss = 0.351  exp loss = 0.345  adjusted loss = 0.345  adv prob = 0.250000   acc = 0.983
Saved results/CUB/CUB_sample_exp/train_downstream_ERM_upweight_0_epochs_80_lr_1e-05_weight_decay_0.0/final_epoch31/JTT_upweight_50_epochs_80_lr_1e-05_weight_decay_1.0/model_outputs/output_train_epoch_74.csv
logged to wandb
Average incurred loss: 0.365  
Average sample loss: 0.366  
Average acc: 0.981  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 468]:	loss = 0.409  exp loss = 0.414  adjusted loss = 0.414  adv prob = 0.250000   acc = 0.959
  waterbird_complete95 = 0, forest2water2 = 1  [n = 386]:	loss = 0.361  exp loss = 0.361  adjusted loss = 0.361  adv prob = 0.250000   acc = 0.997
  waterbird_complete95 = 1, forest2water2 = 0  [n = 266]:	loss = 0.337  exp loss = 0.330  adjusted loss = 0.330  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 625]:	loss = 0.345  exp loss = 0.335  adjusted loss = 0.335  adv prob = 0.250000   acc = 0.978

Validation:
Saved results/CUB/CUB_sample_exp/train_downstream_ERM_upweight_0_epochs_80_lr_1e-05_weight_decay_0.0/final_epoch31/JTT_upweight_50_epochs_80_lr_1e-05_weight_decay_1.0/model_outputs/output_val_epoch_74.csv
logged to wandb
Average incurred loss: 0.463  
Average sample loss: 0.463  
Average acc: 0.865  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.416  exp loss = 0.420  adjusted loss = 0.420  adv prob = 0.250000   acc = 0.936
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.488  exp loss = 0.507  adjusted loss = 0.507  adv prob = 0.250000   acc = 0.845
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 0.569  exp loss = 0.563  adjusted loss = 0.563  adv prob = 0.250000   acc = 0.692
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.432  exp loss = 0.430  adjusted loss = 0.430  adv prob = 0.250000   acc = 0.857
Spurious Score = 1.166
Saved results/CUB/CUB_sample_exp/train_downstream_ERM_upweight_0_epochs_80_lr_1e-05_weight_decay_0.0/final_epoch31/JTT_upweight_50_epochs_80_lr_1e-05_weight_decay_1.0/model_outputs/output_test_epoch_74.csv
logged to wandb
Current lr: 0.000010


Epoch [75]:
Training:
Average incurred loss: 0.366  
Average sample loss: 0.366  
Average acc: 0.986  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 804]:	loss = 0.396  exp loss = 0.390  adjusted loss = 0.390  adv prob = 0.250000   acc = 0.975
  waterbird_complete95 = 0, forest2water2 = 1  [n = 643]:	loss = 0.347  exp loss = 0.349  adjusted loss = 0.349  adv prob = 0.250000   acc = 0.995
  waterbird_complete95 = 1, forest2water2 = 0  [n = 515]:	loss = 0.359  exp loss = 0.356  adjusted loss = 0.356  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1238]:	loss = 0.359  exp loss = 0.354  adjusted loss = 0.354  adv prob = 0.250000   acc = 0.982
Average incurred loss: 0.366  
Average sample loss: 0.366  
Average acc: 0.985  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 847]:	loss = 0.403  exp loss = 0.400  adjusted loss = 0.400  adv prob = 0.250000   acc = 0.967
  waterbird_complete95 = 0, forest2water2 = 1  [n = 662]:	loss = 0.357  exp loss = 0.353  adjusted loss = 0.353  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 0  [n = 515]:	loss = 0.346  exp loss = 0.347  adjusted loss = 0.347  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1176]:	loss = 0.354  exp loss = 0.351  adjusted loss = 0.351  adv prob = 0.250000   acc = 0.982
Average incurred loss: 0.371  
Average sample loss: 0.371  
Average acc: 0.979  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 842]:	loss = 0.399  exp loss = 0.406  adjusted loss = 0.406  adv prob = 0.250000   acc = 0.961
  waterbird_complete95 = 0, forest2water2 = 1  [n = 618]:	loss = 0.357  exp loss = 0.350  adjusted loss = 0.350  adv prob = 0.250000   acc = 0.998
  waterbird_complete95 = 1, forest2water2 = 0  [n = 507]:	loss = 0.357  exp loss = 0.345  adjusted loss = 0.345  adv prob = 0.250000   acc = 0.998
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1233]:	loss = 0.364  exp loss = 0.363  adjusted loss = 0.363  adv prob = 0.250000   acc = 0.974
Average incurred loss: 0.371  
Average sample loss: 0.371  
Average acc: 0.978  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 837]:	loss = 0.408  exp loss = 0.434  adjusted loss = 0.434  adv prob = 0.250000   acc = 0.956
  waterbird_complete95 = 0, forest2water2 = 1  [n = 677]:	loss = 0.364  exp loss = 0.371  adjusted loss = 0.371  adv prob = 0.250000   acc = 0.997
  waterbird_complete95 = 1, forest2water2 = 0  [n = 482]:	loss = 0.353  exp loss = 0.337  adjusted loss = 0.337  adv prob = 0.250000   acc = 0.998
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1204]:	loss = 0.356  exp loss = 0.345  adjusted loss = 0.345  adv prob = 0.250000   acc = 0.975
Saved results/CUB/CUB_sample_exp/train_downstream_ERM_upweight_0_epochs_80_lr_1e-05_weight_decay_0.0/final_epoch31/JTT_upweight_50_epochs_80_lr_1e-05_weight_decay_1.0/model_outputs/output_train_epoch_75.csv
logged to wandb
Average incurred loss: 0.374  
Average sample loss: 0.374  
Average acc: 0.978  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 468]:	loss = 0.412  exp loss = 0.405  adjusted loss = 0.405  adv prob = 0.250000   acc = 0.951
  waterbird_complete95 = 0, forest2water2 = 1  [n = 334]:	loss = 0.351  exp loss = 0.353  adjusted loss = 0.353  adv prob = 0.250000   acc = 0.997
  waterbird_complete95 = 1, forest2water2 = 0  [n = 287]:	loss = 0.362  exp loss = 0.352  adjusted loss = 0.352  adv prob = 0.250000   acc = 0.997
  waterbird_complete95 = 1, forest2water2 = 1  [n = 656]:	loss = 0.363  exp loss = 0.358  adjusted loss = 0.358  adv prob = 0.250000   acc = 0.979

Validation:
Saved results/CUB/CUB_sample_exp/train_downstream_ERM_upweight_0_epochs_80_lr_1e-05_weight_decay_0.0/final_epoch31/JTT_upweight_50_epochs_80_lr_1e-05_weight_decay_1.0/model_outputs/output_val_epoch_75.csv
logged to wandb
Average incurred loss: 0.470  
Average sample loss: 0.470  
Average acc: 0.867  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.419  exp loss = 0.422  adjusted loss = 0.422  adv prob = 0.250000   acc = 0.936
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.493  exp loss = 0.513  adjusted loss = 0.513  adv prob = 0.250000   acc = 0.850
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 0.584  exp loss = 0.577  adjusted loss = 0.577  adv prob = 0.250000   acc = 0.692
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.453  exp loss = 0.451  adjusted loss = 0.451  adv prob = 0.250000   acc = 0.857
Spurious Score = 1.163
Saved results/CUB/CUB_sample_exp/train_downstream_ERM_upweight_0_epochs_80_lr_1e-05_weight_decay_0.0/final_epoch31/JTT_upweight_50_epochs_80_lr_1e-05_weight_decay_1.0/model_outputs/output_test_epoch_75.csv
logged to wandb
Current lr: 0.000010


Epoch [76]:
Training:
Average incurred loss: 0.376  
Average sample loss: 0.376  
Average acc: 0.977  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 847]:	loss = 0.409  exp loss = 0.416  adjusted loss = 0.416  adv prob = 0.250000   acc = 0.956
  waterbird_complete95 = 0, forest2water2 = 1  [n = 639]:	loss = 0.366  exp loss = 0.367  adjusted loss = 0.367  adv prob = 0.250000   acc = 0.995
  waterbird_complete95 = 1, forest2water2 = 0  [n = 543]:	loss = 0.360  exp loss = 0.359  adjusted loss = 0.359  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1171]:	loss = 0.365  exp loss = 0.363  adjusted loss = 0.363  adv prob = 0.250000   acc = 0.971
Average incurred loss: 0.378  
Average sample loss: 0.378  
Average acc: 0.977  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 863]:	loss = 0.413  exp loss = 0.408  adjusted loss = 0.408  adv prob = 0.250000   acc = 0.947
  waterbird_complete95 = 0, forest2water2 = 1  [n = 628]:	loss = 0.367  exp loss = 0.363  adjusted loss = 0.363  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 0  [n = 488]:	loss = 0.367  exp loss = 0.358  adjusted loss = 0.358  adv prob = 0.250000   acc = 0.994
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1221]:	loss = 0.364  exp loss = 0.358  adjusted loss = 0.358  adv prob = 0.250000   acc = 0.980
Average incurred loss: 0.383  
Average sample loss: 0.383  
Average acc: 0.977  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 824]:	loss = 0.420  exp loss = 0.409  adjusted loss = 0.409  adv prob = 0.250000   acc = 0.956
  waterbird_complete95 = 0, forest2water2 = 1  [n = 661]:	loss = 0.367  exp loss = 0.358  adjusted loss = 0.358  adv prob = 0.250000   acc = 0.994
  waterbird_complete95 = 1, forest2water2 = 0  [n = 468]:	loss = 0.366  exp loss = 0.369  adjusted loss = 0.369  adv prob = 0.250000   acc = 0.998
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1247]:	loss = 0.373  exp loss = 0.370  adjusted loss = 0.370  adv prob = 0.250000   acc = 0.974
Average incurred loss: 0.381  
Average sample loss: 0.381  
Average acc: 0.981  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 830]:	loss = 0.419  exp loss = 0.405  adjusted loss = 0.405  adv prob = 0.250000   acc = 0.964
  waterbird_complete95 = 0, forest2water2 = 1  [n = 639]:	loss = 0.362  exp loss = 0.354  adjusted loss = 0.354  adv prob = 0.250000   acc = 0.997
  waterbird_complete95 = 1, forest2water2 = 0  [n = 511]:	loss = 0.369  exp loss = 0.372  adjusted loss = 0.372  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1220]:	loss = 0.369  exp loss = 0.373  adjusted loss = 0.373  adv prob = 0.250000   acc = 0.977
Saved results/CUB/CUB_sample_exp/train_downstream_ERM_upweight_0_epochs_80_lr_1e-05_weight_decay_0.0/final_epoch31/JTT_upweight_50_epochs_80_lr_1e-05_weight_decay_1.0/model_outputs/output_train_epoch_76.csv
logged to wandb
Average incurred loss: 0.383  
Average sample loss: 0.383  
Average acc: 0.981  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 434]:	loss = 0.418  exp loss = 0.406  adjusted loss = 0.406  adv prob = 0.250000   acc = 0.954
  waterbird_complete95 = 0, forest2water2 = 1  [n = 367]:	loss = 0.372  exp loss = 0.373  adjusted loss = 0.373  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 0  [n = 296]:	loss = 0.375  exp loss = 0.379  adjusted loss = 0.379  adv prob = 0.250000   acc = 0.997
  waterbird_complete95 = 1, forest2water2 = 1  [n = 648]:	loss = 0.370  exp loss = 0.358  adjusted loss = 0.358  adv prob = 0.250000   acc = 0.980

Validation:
Saved results/CUB/CUB_sample_exp/train_downstream_ERM_upweight_0_epochs_80_lr_1e-05_weight_decay_0.0/final_epoch31/JTT_upweight_50_epochs_80_lr_1e-05_weight_decay_1.0/model_outputs/output_val_epoch_76.csv
logged to wandb
Average incurred loss: 0.474  
Average sample loss: 0.474  
Average acc: 0.867  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.419  exp loss = 0.421  adjusted loss = 0.421  adv prob = 0.250000   acc = 0.940
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.486  exp loss = 0.506  adjusted loss = 0.506  adv prob = 0.250000   acc = 0.865
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 0.609  exp loss = 0.608  adjusted loss = 0.608  adv prob = 0.250000   acc = 0.662
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.488  exp loss = 0.486  adjusted loss = 0.486  adv prob = 0.250000   acc = 0.820
Spurious Score = 1.153
Saved results/CUB/CUB_sample_exp/train_downstream_ERM_upweight_0_epochs_80_lr_1e-05_weight_decay_0.0/final_epoch31/JTT_upweight_50_epochs_80_lr_1e-05_weight_decay_1.0/model_outputs/output_test_epoch_76.csv
logged to wandb
Current lr: 0.000010


Epoch [77]:
Training:
Average incurred loss: 0.385  
Average sample loss: 0.385  
Average acc: 0.977  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 824]:	loss = 0.420  exp loss = 0.419  adjusted loss = 0.419  adv prob = 0.250000   acc = 0.960
  waterbird_complete95 = 0, forest2water2 = 1  [n = 633]:	loss = 0.369  exp loss = 0.366  adjusted loss = 0.366  adv prob = 0.250000   acc = 0.995
  waterbird_complete95 = 1, forest2water2 = 0  [n = 504]:	loss = 0.369  exp loss = 0.362  adjusted loss = 0.362  adv prob = 0.250000   acc = 0.998
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1239]:	loss = 0.376  exp loss = 0.378  adjusted loss = 0.378  adv prob = 0.250000   acc = 0.972
Average incurred loss: 0.389  
Average sample loss: 0.389  
Average acc: 0.975  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 845]:	loss = 0.434  exp loss = 0.439  adjusted loss = 0.439  adv prob = 0.250000   acc = 0.941
  waterbird_complete95 = 0, forest2water2 = 1  [n = 669]:	loss = 0.378  exp loss = 0.369  adjusted loss = 0.369  adv prob = 0.250000   acc = 0.994
  waterbird_complete95 = 1, forest2water2 = 0  [n = 482]:	loss = 0.369  exp loss = 0.365  adjusted loss = 0.365  adv prob = 0.250000   acc = 0.998
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1204]:	loss = 0.371  exp loss = 0.368  adjusted loss = 0.368  adv prob = 0.250000   acc = 0.980
Average incurred loss: 0.389  
Average sample loss: 0.389  
Average acc: 0.979  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 768]:	loss = 0.414  exp loss = 0.407  adjusted loss = 0.407  adv prob = 0.250000   acc = 0.954
  waterbird_complete95 = 0, forest2water2 = 1  [n = 637]:	loss = 0.370  exp loss = 0.376  adjusted loss = 0.376  adv prob = 0.250000   acc = 0.995
  waterbird_complete95 = 1, forest2water2 = 0  [n = 557]:	loss = 0.388  exp loss = 0.387  adjusted loss = 0.387  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1238]:	loss = 0.384  exp loss = 0.375  adjusted loss = 0.375  adv prob = 0.250000   acc = 0.977
Average incurred loss: 0.388  
Average sample loss: 0.388  
Average acc: 0.979  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 888]:	loss = 0.423  exp loss = 0.426  adjusted loss = 0.426  adv prob = 0.250000   acc = 0.961
  waterbird_complete95 = 0, forest2water2 = 1  [n = 642]:	loss = 0.387  exp loss = 0.377  adjusted loss = 0.377  adv prob = 0.250000   acc = 0.992
  waterbird_complete95 = 1, forest2water2 = 0  [n = 473]:	loss = 0.372  exp loss = 0.376  adjusted loss = 0.376  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1197]:	loss = 0.369  exp loss = 0.369  adjusted loss = 0.369  adv prob = 0.250000   acc = 0.978
Saved results/CUB/CUB_sample_exp/train_downstream_ERM_upweight_0_epochs_80_lr_1e-05_weight_decay_0.0/final_epoch31/JTT_upweight_50_epochs_80_lr_1e-05_weight_decay_1.0/model_outputs/output_train_epoch_77.csv
logged to wandb
Average incurred loss: 0.396  
Average sample loss: 0.396  
Average acc: 0.973  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 473]:	loss = 0.439  exp loss = 0.419  adjusted loss = 0.419  adv prob = 0.250000   acc = 0.928
  waterbird_complete95 = 0, forest2water2 = 1  [n = 353]:	loss = 0.383  exp loss = 0.379  adjusted loss = 0.379  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 0  [n = 290]:	loss = 0.382  exp loss = 0.388  adjusted loss = 0.388  adv prob = 0.250000   acc = 1.000
  waterbird_complete95 = 1, forest2water2 = 1  [n = 629]:	loss = 0.377  exp loss = 0.377  adjusted loss = 0.377  adv prob = 0.250000   acc = 0.979

Validation:
Saved results/CUB/CUB_sample_exp/train_downstream_ERM_upweight_0_epochs_80_lr_1e-05_weight_decay_0.0/final_epoch31/JTT_upweight_50_epochs_80_lr_1e-05_weight_decay_1.0/model_outputs/output_val_epoch_77.csv
logged to wandb
Average incurred loss: 0.495  
Average sample loss: 0.496  
Average acc: 0.859  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.448  exp loss = 0.448  adjusted loss = 0.448  adv prob = 0.250000   acc = 0.927
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.515  exp loss = 0.536  adjusted loss = 0.536  adv prob = 0.250000   acc = 0.843
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 0.600  exp loss = 0.598  adjusted loss = 0.598  adv prob = 0.250000   acc = 0.707
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.489  exp loss = 0.486  adjusted loss = 0.486  adv prob = 0.250000   acc = 0.827
Spurious Score = 1.132
Saved results/CUB/CUB_sample_exp/train_downstream_ERM_upweight_0_epochs_80_lr_1e-05_weight_decay_0.0/final_epoch31/JTT_upweight_50_epochs_80_lr_1e-05_weight_decay_1.0/model_outputs/output_test_epoch_77.csv
logged to wandb
Current lr: 0.000010


Epoch [78]:
Training:
Average incurred loss: 0.392  
Average sample loss: 0.392  
Average acc: 0.980  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 825]:	loss = 0.425  exp loss = 0.432  adjusted loss = 0.432  adv prob = 0.250000   acc = 0.955
  waterbird_complete95 = 0, forest2water2 = 1  [n = 654]:	loss = 0.385  exp loss = 0.383  adjusted loss = 0.383  adv prob = 0.250000   acc = 0.991
  waterbird_complete95 = 1, forest2water2 = 0  [n = 496]:	loss = 0.385  exp loss = 0.380  adjusted loss = 0.380  adv prob = 0.250000   acc = 0.998
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1225]:	loss = 0.377  exp loss = 0.372  adjusted loss = 0.372  adv prob = 0.250000   acc = 0.983
Average incurred loss: 0.397  
Average sample loss: 0.397  
Average acc: 0.974  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 871]:	loss = 0.441  exp loss = 0.432  adjusted loss = 0.432  adv prob = 0.250000   acc = 0.946
  waterbird_complete95 = 0, forest2water2 = 1  [n = 656]:	loss = 0.388  exp loss = 0.378  adjusted loss = 0.378  adv prob = 0.250000   acc = 0.992
  waterbird_complete95 = 1, forest2water2 = 0  [n = 489]:	loss = 0.378  exp loss = 0.384  adjusted loss = 0.384  adv prob = 0.250000   acc = 0.994
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1184]:	loss = 0.376  exp loss = 0.373  adjusted loss = 0.373  adv prob = 0.250000   acc = 0.976
Average incurred loss: 0.399  
Average sample loss: 0.399  
Average acc: 0.973  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 815]:	loss = 0.434  exp loss = 0.427  adjusted loss = 0.427  adv prob = 0.250000   acc = 0.941
  waterbird_complete95 = 0, forest2water2 = 1  [n = 622]:	loss = 0.378  exp loss = 0.368  adjusted loss = 0.368  adv prob = 0.250000   acc = 0.998
  waterbird_complete95 = 1, forest2water2 = 0  [n = 528]:	loss = 0.387  exp loss = 0.397  adjusted loss = 0.397  adv prob = 0.250000   acc = 0.998
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1235]:	loss = 0.391  exp loss = 0.397  adjusted loss = 0.397  adv prob = 0.250000   acc = 0.970
Average incurred loss: 0.402  
Average sample loss: 0.402  
Average acc: 0.972  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 843]:	loss = 0.446  exp loss = 0.442  adjusted loss = 0.442  adv prob = 0.250000   acc = 0.943
  waterbird_complete95 = 0, forest2water2 = 1  [n = 664]:	loss = 0.391  exp loss = 0.384  adjusted loss = 0.384  adv prob = 0.250000   acc = 0.992
  waterbird_complete95 = 1, forest2water2 = 0  [n = 499]:	loss = 0.382  exp loss = 0.389  adjusted loss = 0.389  adv prob = 0.250000   acc = 0.992
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1194]:	loss = 0.385  exp loss = 0.386  adjusted loss = 0.386  adv prob = 0.250000   acc = 0.974
Saved results/CUB/CUB_sample_exp/train_downstream_ERM_upweight_0_epochs_80_lr_1e-05_weight_decay_0.0/final_epoch31/JTT_upweight_50_epochs_80_lr_1e-05_weight_decay_1.0/model_outputs/output_train_epoch_78.csv
logged to wandb
Average incurred loss: 0.404  
Average sample loss: 0.404  
Average acc: 0.974  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 444]:	loss = 0.430  exp loss = 0.429  adjusted loss = 0.429  adv prob = 0.250000   acc = 0.946
  waterbird_complete95 = 0, forest2water2 = 1  [n = 338]:	loss = 0.392  exp loss = 0.394  adjusted loss = 0.394  adv prob = 0.250000   acc = 0.994
  waterbird_complete95 = 1, forest2water2 = 0  [n = 294]:	loss = 0.391  exp loss = 0.381  adjusted loss = 0.381  adv prob = 0.250000   acc = 0.997
  waterbird_complete95 = 1, forest2water2 = 1  [n = 669]:	loss = 0.397  exp loss = 0.389  adjusted loss = 0.389  adv prob = 0.250000   acc = 0.973

Validation:
Saved results/CUB/CUB_sample_exp/train_downstream_ERM_upweight_0_epochs_80_lr_1e-05_weight_decay_0.0/final_epoch31/JTT_upweight_50_epochs_80_lr_1e-05_weight_decay_1.0/model_outputs/output_val_epoch_78.csv
logged to wandb
Average incurred loss: 0.513  
Average sample loss: 0.514  
Average acc: 0.830  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.470  exp loss = 0.468  adjusted loss = 0.468  adv prob = 0.250000   acc = 0.899
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.553  exp loss = 0.571  adjusted loss = 0.571  adv prob = 0.250000   acc = 0.792
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 0.573  exp loss = 0.570  adjusted loss = 0.570  adv prob = 0.250000   acc = 0.707
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.467  exp loss = 0.463  adjusted loss = 0.463  adv prob = 0.250000   acc = 0.842
Spurious Score = 1.162
Saved results/CUB/CUB_sample_exp/train_downstream_ERM_upweight_0_epochs_80_lr_1e-05_weight_decay_0.0/final_epoch31/JTT_upweight_50_epochs_80_lr_1e-05_weight_decay_1.0/model_outputs/output_test_epoch_78.csv
logged to wandb
Current lr: 0.000010


Epoch [79]:
Training:
Average incurred loss: 0.403  
Average sample loss: 0.403  
Average acc: 0.975  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 840]:	loss = 0.439  exp loss = 0.441  adjusted loss = 0.441  adv prob = 0.250000   acc = 0.946
  waterbird_complete95 = 0, forest2water2 = 1  [n = 595]:	loss = 0.382  exp loss = 0.380  adjusted loss = 0.380  adv prob = 0.250000   acc = 0.997
  waterbird_complete95 = 1, forest2water2 = 0  [n = 541]:	loss = 0.398  exp loss = 0.392  adjusted loss = 0.392  adv prob = 0.250000   acc = 0.983
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1224]:	loss = 0.390  exp loss = 0.389  adjusted loss = 0.389  adv prob = 0.250000   acc = 0.980
Average incurred loss: 0.406  
Average sample loss: 0.406  
Average acc: 0.972  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 842]:	loss = 0.443  exp loss = 0.443  adjusted loss = 0.443  adv prob = 0.250000   acc = 0.941
  waterbird_complete95 = 0, forest2water2 = 1  [n = 626]:	loss = 0.394  exp loss = 0.388  adjusted loss = 0.388  adv prob = 0.250000   acc = 0.995
  waterbird_complete95 = 1, forest2water2 = 0  [n = 516]:	loss = 0.394  exp loss = 0.390  adjusted loss = 0.390  adv prob = 0.250000   acc = 0.992
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1216]:	loss = 0.392  exp loss = 0.386  adjusted loss = 0.386  adv prob = 0.250000   acc = 0.973
Average incurred loss: 0.411  
Average sample loss: 0.411  
Average acc: 0.967  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 837]:	loss = 0.461  exp loss = 0.447  adjusted loss = 0.447  adv prob = 0.250000   acc = 0.925
  waterbird_complete95 = 0, forest2water2 = 1  [n = 692]:	loss = 0.399  exp loss = 0.392  adjusted loss = 0.392  adv prob = 0.250000   acc = 0.994
  waterbird_complete95 = 1, forest2water2 = 0  [n = 520]:	loss = 0.394  exp loss = 0.402  adjusted loss = 0.402  adv prob = 0.250000   acc = 0.988
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1151]:	loss = 0.389  exp loss = 0.392  adjusted loss = 0.392  adv prob = 0.250000   acc = 0.973
Average incurred loss: 0.410  
Average sample loss: 0.410  
Average acc: 0.971  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 835]:	loss = 0.449  exp loss = 0.442  adjusted loss = 0.442  adv prob = 0.250000   acc = 0.946
  waterbird_complete95 = 0, forest2water2 = 1  [n = 668]:	loss = 0.404  exp loss = 0.395  adjusted loss = 0.395  adv prob = 0.250000   acc = 0.993
  waterbird_complete95 = 1, forest2water2 = 0  [n = 471]:	loss = 0.393  exp loss = 0.392  adjusted loss = 0.392  adv prob = 0.250000   acc = 0.987
  waterbird_complete95 = 1, forest2water2 = 1  [n = 1226]:	loss = 0.393  exp loss = 0.397  adjusted loss = 0.397  adv prob = 0.250000   acc = 0.971
Saved results/CUB/CUB_sample_exp/train_downstream_ERM_upweight_0_epochs_80_lr_1e-05_weight_decay_0.0/final_epoch31/JTT_upweight_50_epochs_80_lr_1e-05_weight_decay_1.0/model_outputs/output_train_epoch_79.csv
logged to wandb
Average incurred loss: 0.411  
Average sample loss: 0.411  
Average acc: 0.975  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 444]:	loss = 0.447  exp loss = 0.446  adjusted loss = 0.446  adv prob = 0.250000   acc = 0.932
  waterbird_complete95 = 0, forest2water2 = 1  [n = 353]:	loss = 0.401  exp loss = 0.402  adjusted loss = 0.402  adv prob = 0.250000   acc = 0.994
  waterbird_complete95 = 1, forest2water2 = 0  [n = 258]:	loss = 0.389  exp loss = 0.388  adjusted loss = 0.388  adv prob = 0.250000   acc = 0.996
  waterbird_complete95 = 1, forest2water2 = 1  [n = 690]:	loss = 0.401  exp loss = 0.398  adjusted loss = 0.398  adv prob = 0.250000   acc = 0.984

Validation:
Saved results/CUB/CUB_sample_exp/train_downstream_ERM_upweight_0_epochs_80_lr_1e-05_weight_decay_0.0/final_epoch31/JTT_upweight_50_epochs_80_lr_1e-05_weight_decay_1.0/model_outputs/output_val_epoch_79.csv
logged to wandb
Average incurred loss: 0.510  
Average sample loss: 0.510  
Average acc: 0.840  
  waterbird_complete95 = 0, forest2water2 = 0  [n = 467]:	loss = 0.459  exp loss = 0.457  adjusted loss = 0.457  adv prob = 0.250000   acc = 0.914
  waterbird_complete95 = 0, forest2water2 = 1  [n = 466]:	loss = 0.523  exp loss = 0.540  adjusted loss = 0.540  adv prob = 0.250000   acc = 0.843
  waterbird_complete95 = 1, forest2water2 = 0  [n = 133]:	loss = 0.625  exp loss = 0.625  adjusted loss = 0.625  adv prob = 0.250000   acc = 0.632
  waterbird_complete95 = 1, forest2water2 = 1  [n = 133]:	loss = 0.528  exp loss = 0.526  adjusted loss = 0.526  adv prob = 0.250000   acc = 0.774
Spurious Score = 1.145
Saved results/CUB/CUB_sample_exp/train_downstream_ERM_upweight_0_epochs_80_lr_1e-05_weight_decay_0.0/final_epoch31/JTT_upweight_50_epochs_80_lr_1e-05_weight_decay_1.0/model_outputs/output_test_epoch_79.csv
logged to wandb
Current lr: 0.000010

wandb: Waiting for W&B process to finish, PID 114546
wandb: Program ended successfully.
wandb: - 0.02MB of 0.02MB uploaded (0.00MB deduped)wandb: \ 0.68MB of 0.68MB uploaded (0.00MB deduped)wandb:                                                                                
wandb: Find user logs for this run at: wandb/run-20220715_135613-3u7z0meo/logs/debug.log
wandb: Find internal logs for this run at: wandb/run-20220715_135613-3u7z0meo/logs/debug-internal.log
wandb: Run summary:
wandb:                   train/avg_loss_group:0 0.44744
wandb:               train/exp_avg_loss_group:0 0.44607
wandb:                    train/avg_acc_group:0 0.93243
wandb:       train/processed_data_count_group:0 444.0
wandb:          train/update_data_count_group:0 444.0
wandb:         train/update_batch_count_group:0 28.0
wandb:                   train/avg_loss_group:1 0.40091
wandb:               train/exp_avg_loss_group:1 0.40228
wandb:                    train/avg_acc_group:1 0.99433
wandb:       train/processed_data_count_group:1 353.0
wandb:          train/update_data_count_group:1 353.0
wandb:         train/update_batch_count_group:1 28.0
wandb:                   train/avg_loss_group:2 0.38933
wandb:               train/exp_avg_loss_group:2 0.38836
wandb:                    train/avg_acc_group:2 0.99612
wandb:       train/processed_data_count_group:2 258.0
wandb:          train/update_data_count_group:2 258.0
wandb:         train/update_batch_count_group:2 28.0
wandb:                   train/avg_loss_group:3 0.40088
wandb:               train/exp_avg_loss_group:3 0.39795
wandb:                    train/avg_acc_group:3 0.98406
wandb:       train/processed_data_count_group:3 690.0
wandb:          train/update_data_count_group:3 690.0
wandb:         train/update_batch_count_group:3 28.0
wandb:                    train/avg_actual_loss 0.41146
wandb:                train/avg_per_sample_loss 0.41102
wandb:                            train/avg_acc 0.97479
wandb:                      train/model_norm_sq 220.93404
wandb:                           train/reg_loss 110.46702
wandb:                              train/epoch 79
wandb:                              train/batch 199
wandb:                                    epoch 79
wandb:                                batch_idx 90
wandb:                                    _step 559
wandb:                                 _runtime 11653
wandb:                               _timestamp 1657919426
wandb:                     val/avg_loss_group:0 0.45896
wandb:                 val/exp_avg_loss_group:0 0.45728
wandb:                      val/avg_acc_group:0 0.91435
wandb:         val/processed_data_count_group:0 467.0
wandb:            val/update_data_count_group:0 467.0
wandb:           val/update_batch_count_group:0 19.0
wandb:                     val/avg_loss_group:1 0.5231
wandb:                 val/exp_avg_loss_group:1 0.5402
wandb:                      val/avg_acc_group:1 0.84335
wandb:         val/processed_data_count_group:1 466.0
wandb:            val/update_data_count_group:1 466.0
wandb:           val/update_batch_count_group:1 19.0
wandb:                     val/avg_loss_group:2 0.62532
wandb:                 val/exp_avg_loss_group:2 0.62479
wandb:                      val/avg_acc_group:2 0.63158
wandb:         val/processed_data_count_group:2 133.0
wandb:            val/update_data_count_group:2 133.0
wandb:           val/update_batch_count_group:2 12.0
wandb:                     val/avg_loss_group:3 0.52763
wandb:                 val/exp_avg_loss_group:3 0.52566
wandb:                      val/avg_acc_group:3 0.77444
wandb:         val/processed_data_count_group:3 133.0
wandb:            val/update_data_count_group:3 133.0
wandb:           val/update_batch_count_group:3 12.0
wandb:                      val/avg_actual_loss 0.51041
wandb:                  val/avg_per_sample_loss 0.50996
wandb:                              val/avg_acc 0.83987
wandb:                        val/model_norm_sq 220.93404
wandb:                             val/reg_loss 110.46702
wandb:                    test/avg_loss_group:0 0.46357
wandb:                test/exp_avg_loss_group:0 0.45758
wandb:                     test/avg_acc_group:0 0.92106
wandb:        test/processed_data_count_group:0 2255.0
wandb:           test/update_data_count_group:0 2255.0
wandb:          test/update_batch_count_group:0 79.0
wandb:                    test/avg_loss_group:1 0.52233
wandb:                test/exp_avg_loss_group:1 0.50479
wandb:                     test/avg_acc_group:1 0.81907
wandb:        test/processed_data_count_group:1 2255.0
wandb:           test/update_data_count_group:1 2255.0
wandb:          test/update_batch_count_group:1 79.0
wandb:                    test/avg_loss_group:2 0.62224
wandb:                test/exp_avg_loss_group:2 0.61652
wandb:                     test/avg_acc_group:2 0.62617
wandb:        test/processed_data_count_group:2 642.0
wandb:           test/update_data_count_group:2 642.0
wandb:          test/update_batch_count_group:2 32.0
wandb:                    test/avg_loss_group:3 0.49385
wandb:                test/exp_avg_loss_group:3 0.49631
wandb:                     test/avg_acc_group:3 0.81931
wandb:        test/processed_data_count_group:3 642.0
wandb:           test/update_data_count_group:3 642.0
wandb:          test/update_batch_count_group:3 30.0
wandb:                     test/avg_actual_loss 0.50679
wandb:                 test/avg_per_sample_loss 0.50738
wandb:                             test/avg_acc 0.83742
wandb:                       test/model_norm_sq 220.93404
wandb:                            test/reg_loss 110.46702
wandb: Run history:
wandb:               train/avg_loss_group:0 ‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ
wandb:           train/exp_avg_loss_group:0 ‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ
wandb:                train/avg_acc_group:0 ‚ñÅ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá
wandb:   train/processed_data_count_group:0 ‚ñà‚ñà‚ñá‚ñà‚ñá‚ñà‚ñà‚ñá‚ñá‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñá‚ñá‚ñá‚ñà‚ñá‚ñà‚ñá‚ñá‚ñà‚ñá‚ñá‚ñá‚ñà‚ñà‚ñá‚ñà‚ñá‚ñà‚ñà‚ñà‚ñá‚ñÜ‚ñÅ
wandb:      train/update_data_count_group:0 ‚ñà‚ñà‚ñá‚ñà‚ñá‚ñà‚ñà‚ñá‚ñá‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñá‚ñá‚ñá‚ñà‚ñá‚ñà‚ñá‚ñá‚ñà‚ñá‚ñá‚ñá‚ñà‚ñà‚ñá‚ñà‚ñá‚ñà‚ñà‚ñà‚ñá‚ñÜ‚ñÅ
wandb:     train/update_batch_count_group:0 ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñÅ
wandb:               train/avg_loss_group:1 ‚ñà‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ
wandb:           train/exp_avg_loss_group:1 ‚ñà‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ
wandb:                train/avg_acc_group:1 ‚ñÅ‚ñÑ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:   train/processed_data_count_group:1 ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñá‚ñá‚ñá‚ñà‚ñá‚ñà‚ñá‚ñá‚ñÜ‚ñá‚ñÜ‚ñá‚ñÜ‚ñÜ‚ñá‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÅ
wandb:      train/update_data_count_group:1 ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñá‚ñá‚ñá‚ñà‚ñá‚ñà‚ñá‚ñá‚ñÜ‚ñá‚ñÜ‚ñá‚ñÜ‚ñÜ‚ñá‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÅ
wandb:     train/update_batch_count_group:1 ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñÅ
wandb:               train/avg_loss_group:2 ‚ñà‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ
wandb:           train/exp_avg_loss_group:2 ‚ñà‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ
wandb:                train/avg_acc_group:2 ‚ñÅ‚ñÉ‚ñÇ‚ñÉ‚ñÅ‚ñÖ‚ñÉ‚ñÑ‚ñÜ‚ñÜ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:   train/processed_data_count_group:2 ‚ñÜ‚ñá‚ñá‚ñÜ‚ñÜ‚ñá‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñá‚ñÜ‚ñà‚ñÜ‚ñá‚ñá‚ñá‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñá‚ñÜ‚ñà‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñÜ‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñà‚ñÅ
wandb:      train/update_data_count_group:2 ‚ñÜ‚ñá‚ñá‚ñÜ‚ñÜ‚ñá‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñá‚ñÜ‚ñà‚ñÜ‚ñá‚ñá‚ñá‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñá‚ñÜ‚ñà‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñÜ‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñà‚ñÅ
wandb:     train/update_batch_count_group:2 ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñÅ
wandb:               train/avg_loss_group:3 ‚ñà‚ñà‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ
wandb:           train/exp_avg_loss_group:3 ‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ
wandb:                train/avg_acc_group:3 ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñà‚ñà‚ñà
wandb:   train/processed_data_count_group:3 ‚ñà‚ñá‚ñà‚ñá‚ñà‚ñá‚ñà‚ñà‚ñà‚ñà‚ñá‚ñà‚ñà‚ñá‚ñà‚ñà‚ñá‚ñá‚ñà‚ñá‚ñà‚ñà‚ñá‚ñá‚ñá‚ñà‚ñá‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñà‚ñà‚ñá‚ñà‚ñà‚ñà‚ñÅ
wandb:      train/update_data_count_group:3 ‚ñà‚ñá‚ñà‚ñá‚ñà‚ñá‚ñà‚ñà‚ñà‚ñà‚ñá‚ñà‚ñà‚ñá‚ñà‚ñà‚ñá‚ñá‚ñà‚ñá‚ñà‚ñà‚ñá‚ñá‚ñá‚ñà‚ñá‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñà‚ñà‚ñá‚ñà‚ñà‚ñà‚ñÅ
wandb:     train/update_batch_count_group:3 ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñÅ
wandb:                train/avg_actual_loss ‚ñà‚ñá‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ
wandb:            train/avg_per_sample_loss ‚ñà‚ñá‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ
wandb:                        train/avg_acc ‚ñÅ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà
wandb:                  train/model_norm_sq ‚ñà‚ñà‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                       train/reg_loss ‚ñà‚ñà‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                          train/epoch ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà
wandb:                          train/batch ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                                epoch ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà
wandb:                            batch_idx ‚ñÇ‚ñÑ‚ñá‚ñÅ‚ñÇ‚ñÑ‚ñá‚ñÅ‚ñÇ‚ñÑ‚ñá‚ñÅ‚ñÇ‚ñÖ‚ñá‚ñÅ‚ñÇ‚ñÖ‚ñá‚ñÅ‚ñÇ‚ñÖ‚ñá‚ñÅ‚ñÇ‚ñÖ‚ñà‚ñÅ‚ñÇ‚ñÖ‚ñà‚ñÅ‚ñÇ‚ñÖ‚ñà‚ñÅ‚ñÇ‚ñÖ‚ñà‚ñÉ
wandb:                                _step ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà
wandb:                             _runtime ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà
wandb:                           _timestamp ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà
wandb:                 val/avg_loss_group:0 ‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ
wandb:             val/exp_avg_loss_group:0 ‚ñà‚ñà‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ
wandb:                  val/avg_acc_group:0 ‚ñÅ‚ñÇ‚ñÉ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá
wandb:     val/processed_data_count_group:0 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:        val/update_data_count_group:0 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       val/update_batch_count_group:0 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                 val/avg_loss_group:1 ‚ñà‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ
wandb:             val/exp_avg_loss_group:1 ‚ñà‚ñá‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ
wandb:                  val/avg_acc_group:1 ‚ñÅ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
wandb:     val/processed_data_count_group:1 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:        val/update_data_count_group:1 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       val/update_batch_count_group:1 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                 val/avg_loss_group:2 ‚ñÜ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÇ‚ñÇ‚ñÉ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñÜ‚ñÜ‚ñà‚ñà
wandb:             val/exp_avg_loss_group:2 ‚ñÜ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÇ‚ñÇ‚ñÉ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÑ‚ñÖ‚ñÑ‚ñÖ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñà
wandb:                  val/avg_acc_group:2 ‚ñá‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÅ
wandb:     val/processed_data_count_group:2 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:        val/update_data_count_group:2 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       val/update_batch_count_group:2 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                 val/avg_loss_group:3 ‚ñà‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñá
wandb:             val/exp_avg_loss_group:3 ‚ñà‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñá
wandb:                  val/avg_acc_group:3 ‚ñÉ‚ñÖ‚ñÜ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñá‚ñà‚ñà‚ñà‚ñÜ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÉ‚ñÅ
wandb:     val/processed_data_count_group:3 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:        val/update_data_count_group:3 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       val/update_batch_count_group:3 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                  val/avg_actual_loss ‚ñà‚ñá‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ
wandb:              val/avg_per_sample_loss ‚ñà‚ñá‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ
wandb:                          val/avg_acc ‚ñÅ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá
wandb:                    val/model_norm_sq ‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                         val/reg_loss ‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                test/avg_loss_group:0 ‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ
wandb:            test/exp_avg_loss_group:0 ‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ
wandb:                 test/avg_acc_group:0 ‚ñÅ‚ñÇ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá
wandb:    test/processed_data_count_group:0 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test/update_data_count_group:0 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:      test/update_batch_count_group:0 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                test/avg_loss_group:1 ‚ñà‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÇ‚ñÉ‚ñÇ‚ñÇ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ
wandb:            test/exp_avg_loss_group:1 ‚ñà‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÉ‚ñÇ‚ñÇ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ
wandb:                 test/avg_acc_group:1 ‚ñÅ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ
wandb:    test/processed_data_count_group:1 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test/update_data_count_group:1 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:      test/update_batch_count_group:1 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                test/avg_loss_group:2 ‚ñÜ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÖ‚ñÑ‚ñÖ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà
wandb:            test/exp_avg_loss_group:2 ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÇ‚ñÇ‚ñÉ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÑ‚ñÜ‚ñÖ‚ñÜ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà
wandb:                 test/avg_acc_group:2 ‚ñá‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:    test/processed_data_count_group:2 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test/update_data_count_group:2 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:      test/update_batch_count_group:2 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                test/avg_loss_group:3 ‚ñà‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÜ
wandb:            test/exp_avg_loss_group:3 ‚ñà‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ
wandb:                 test/avg_acc_group:3 ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñá‚ñà‚ñà‚ñà‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñà‚ñá‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÖ‚ñÉ‚ñÉ‚ñÑ‚ñÇ‚ñÇ
wandb:    test/processed_data_count_group:3 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:       test/update_data_count_group:3 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:      test/update_batch_count_group:3 ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                 test/avg_actual_loss ‚ñà‚ñá‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ
wandb:             test/avg_per_sample_loss ‚ñà‚ñá‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ
wandb:                         test/avg_acc ‚ñÅ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá
wandb:                   test/model_norm_sq ‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                        test/reg_loss ‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: 
wandb: Synced 5 W&B file(s), 1 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: 
wandb: Synced graceful-butterfly-57: https://wandb.ai/gaotang/spurious_CUB/runs/3u7z0meo

Done
Downstream Accuracies for JTT_upweight_20_epochs_80_lr_1e-05_weight_decay_1.0 with 4 groups.
Val Robust Worst Group val   acc (early stop at epoch 42): 78.2
Val Robust Worst Group test  acc (early stop at epoch 42): 82.1
Val Average Acc val   acc (early stop at epoch 42): 90.5
Val Average Acc test  acc (early stop at epoch 42): 90.7
group 0 acc val   acc (early stop at epoch 42): 97.4
group 0 acc test  acc (early stop at epoch 42): 97.4
group 1 acc val   acc (early stop at epoch 42): 86.3
group 1 acc test  acc (early stop at epoch 42): 85.9
group 2 acc val   acc (early stop at epoch 42): 78.2
group 2 acc test  acc (early stop at epoch 42): 82.1
group 3 acc val   acc (early stop at epoch 42): 93.2
group 3 acc test  acc (early stop at epoch 42): 92.7




problem with metadata_aug.csv
(<class 'NotADirectoryError'>, NotADirectoryError(20, 'Not a directory'), <traceback object at 0x2b7f541c3f08>)
Downstream Accuracies for JTT_upweight_100_epochs_80_lr_1e-05_weight_decay_1.0 with 4 groups.
Val Robust Worst Group val   acc (early stop at epoch 22): 87.2
Val Robust Worst Group test  acc (early stop at epoch 22): 87.1
Val Average Acc val   acc (early stop at epoch 22): 89.0
Val Average Acc test  acc (early stop at epoch 22): 89.0
group 0 acc val   acc (early stop at epoch 22): 91.0
group 0 acc test  acc (early stop at epoch 22): 91.0
group 1 acc val   acc (early stop at epoch 22): 88.0
group 1 acc test  acc (early stop at epoch 22): 87.1
group 2 acc val   acc (early stop at epoch 22): 87.2
group 2 acc test  acc (early stop at epoch 22): 89.9
group 3 acc val   acc (early stop at epoch 22): 87.2
group 3 acc test  acc (early stop at epoch 22): 87.9


Downstream Accuracies for JTT_upweight_50_epochs_80_lr_1e-05_weight_decay_1.0 with 4 groups.
Val Robust Worst Group val   acc (early stop at epoch 22): 87.1
Val Robust Worst Group test  acc (early stop at epoch 22): 87.3
Val Average Acc val   acc (early stop at epoch 22): 89.6
Val Average Acc test  acc (early stop at epoch 22): 89.2
group 0 acc val   acc (early stop at epoch 22): 93.1
group 0 acc test  acc (early stop at epoch 22): 91.1
group 1 acc val   acc (early stop at epoch 22): 87.1
group 1 acc test  acc (early stop at epoch 22): 87.3
group 2 acc val   acc (early stop at epoch 22): 87.2
group 2 acc test  acc (early stop at epoch 22): 90.2
group 3 acc val   acc (early stop at epoch 22): 88.0
group 3 acc test  acc (early stop at epoch 22): 88.8




problem with val_accuracies.txt
(<class 'NotADirectoryError'>, NotADirectoryError(20, 'Not a directory'), <traceback object at 0x2b7f541a3608>)
